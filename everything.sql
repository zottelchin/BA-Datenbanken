--
-- PostgreSQL database dump
--

-- Dumped from database version 13.1 (Debian 13.1-1.pgdg100+1)
-- Dumped by pg_dump version 13.1 (Debian 13.1-1.pgdg100+1)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

SET default_tablespace = '';

SET default_table_access_method = heap;

--
-- Name: acm; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.acm (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.acm OWNER TO postgres;

--
-- Name: acm_manual; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.acm_manual (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.acm_manual OWNER TO postgres;

--
-- Name: acm_manual_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.acm_manual_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.acm_manual_id_seq OWNER TO postgres;

--
-- Name: acm_manual_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.acm_manual_id_seq OWNED BY public.acm_manual.id;


--
-- Name: dblp; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.dblp (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.dblp OWNER TO postgres;

--
-- Name: dblp_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.dblp_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.dblp_id_seq OWNER TO postgres;

--
-- Name: dblp_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.dblp_id_seq OWNED BY public.dblp.id;


--
-- Name: dblp_manual; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.dblp_manual (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.dblp_manual OWNER TO postgres;

--
-- Name: dblp_manual_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.dblp_manual_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.dblp_manual_id_seq OWNER TO postgres;

--
-- Name: dblp_manual_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.dblp_manual_id_seq OWNED BY public.dblp_manual.id;


--
-- Name: final; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.final (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.final OWNER TO postgres;

--
-- Name: final_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.final_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.final_id_seq OWNER TO postgres;

--
-- Name: final_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.final_id_seq OWNED BY public.final.id;


--
-- Name: scopus; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.scopus (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.scopus OWNER TO postgres;

--
-- Name: scopus_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.scopus_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.scopus_id_seq OWNER TO postgres;

--
-- Name: scopus_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.scopus_id_seq OWNED BY public.scopus.id;


--
-- Name: scopus_manual; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.scopus_manual (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.scopus_manual OWNER TO postgres;

--
-- Name: scopus_manual_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.scopus_manual_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.scopus_manual_id_seq OWNER TO postgres;

--
-- Name: scopus_manual_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.scopus_manual_id_seq OWNED BY public.scopus_manual.id;


--
-- Name: selection_1; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.selection_1 (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.selection_1 OWNER TO postgres;

--
-- Name: selection_1_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.selection_1_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.selection_1_id_seq OWNER TO postgres;

--
-- Name: selection_1_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.selection_1_id_seq OWNED BY public.selection_1.id;


--
-- Name: snowballing; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.snowballing (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.snowballing OWNER TO postgres;

--
-- Name: snowballing_org; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.snowballing_org (
    id integer NOT NULL,
    author text,
    title text,
    doi text,
    year text,
    abstract text,
    url text
);


ALTER TABLE public.snowballing_org OWNER TO postgres;

--
-- Name: snowballing_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.snowballing_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.snowballing_id_seq OWNER TO postgres;

--
-- Name: snowballing_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.snowballing_id_seq OWNED BY public.snowballing_org.id;


--
-- Name: snowballing_id_seq1; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.snowballing_id_seq1
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.snowballing_id_seq1 OWNER TO postgres;

--
-- Name: snowballing_id_seq1; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.snowballing_id_seq1 OWNED BY public.snowballing.id;


--
-- Name: tablename_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.tablename_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.tablename_id_seq OWNER TO postgres;

--
-- Name: tablename_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.tablename_id_seq OWNED BY public.acm.id;


--
-- Name: acm id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.acm ALTER COLUMN id SET DEFAULT nextval('public.tablename_id_seq'::regclass);


--
-- Name: acm_manual id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.acm_manual ALTER COLUMN id SET DEFAULT nextval('public.acm_manual_id_seq'::regclass);


--
-- Name: dblp id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.dblp ALTER COLUMN id SET DEFAULT nextval('public.dblp_id_seq'::regclass);


--
-- Name: dblp_manual id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.dblp_manual ALTER COLUMN id SET DEFAULT nextval('public.dblp_manual_id_seq'::regclass);


--
-- Name: final id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.final ALTER COLUMN id SET DEFAULT nextval('public.final_id_seq'::regclass);


--
-- Name: scopus id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.scopus ALTER COLUMN id SET DEFAULT nextval('public.scopus_id_seq'::regclass);


--
-- Name: scopus_manual id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.scopus_manual ALTER COLUMN id SET DEFAULT nextval('public.scopus_manual_id_seq'::regclass);


--
-- Name: selection_1 id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.selection_1 ALTER COLUMN id SET DEFAULT nextval('public.selection_1_id_seq'::regclass);


--
-- Name: snowballing id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.snowballing ALTER COLUMN id SET DEFAULT nextval('public.snowballing_id_seq1'::regclass);


--
-- Name: snowballing_org id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.snowballing_org ALTER COLUMN id SET DEFAULT nextval('public.snowballing_id_seq'::regclass);


--
-- Data for Name: acm; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.acm (id, author, title, doi, year, abstract, url) FROM stdin;
1	Reinhardt, Anastasia and Zhang, Tianyi and Mathur, Mihir and Kim, Miryung	Augmenting Stack Overflow with API Usage Patterns Mined from GitHub	10.1145/3236024.3264585	2018	Programmers often consult Q&amp;A websites such as Stack Overflow (SO) to learn new APIs. However, online code snippets are not always complete or reliable in terms of API usage. To assess online code snippets, we build a Chrome extension, ExampleCheck that detects API usage violations in SO posts using API usage patterns mined from 380K GitHub projects. It quantifies how many GitHub examples follow common API usage and illustrates how to remedy the detected violation in a given SO snippet. With ExampleCheck, programmers can easily identify the pitfalls of a given SO snippet and learn how much it deviates from common API usage patterns in GitHub. The demo video is at https://youtu.be/WOnN-wQZsH0.	https://doi.org/10.1145/3236024.3264585
2	Kochhar, Pavneet Singh and Lo, David	Revisiting Assert Use in GitHub Projects	10.1145/3084226.3084259	2017	Assertions are often used to test the assumptions that developers have about a program. An assertion contains a boolean expression which developers believe to be true at a particular program point. It throws an error if the expression is not satisfied, which helps developers to detect and correct bugs. Since assertions make developer assumptions explicit, assertions are also believed to improve under-standability of code. Recently, Casalnuovo et al. analyse C and C++ programs to understand the relationship between assertion usage and defect occurrence. Their results show that asserts have a small effect on reducing the density of bugs and developers often add asserts to methods they have prior knowledge of and larger ownership. In this study, we perform a partial replication of the above study on a large dataset of Java projects from GitHub (185 projects, 20 million LOC, 4 million commits, 0.2 million files and 1 million methods). We collect metrics such as number of asserts, number of defects, number of developers and number of lines changed to a method, and examine the relationship between asserts and defect occurrence. We also analyse relationship between developer experience and ownership and the number of asserts. Furthermore, we perform a study of what are different types of asserts added and why they are added by developers. We find that asserts have a small yet significant relationship with defect occurrence and developers who have added asserts to methods often have higher ownership of and experience with the methods than developers who did not add asserts.	https://doi.org/10.1145/3084226.3084259
3	Longo, Justin and Kelley, Tanya M.	Use of GitHub as a Platform for Open Collaboration on Text Documents	10.1145/2788993.2789838	2015	Recently, researchers are paying attention to the use of the software development and code-hosting web service GitHub for other collaborative purposes, including a class of activity referred to as document, text, or prose collaboration. These alternative uses of GitHub as a platform for sharing non-code artifacts represent an important modification in the practice of open collaboration. We survey cases where GitHub has been used to facilitate collaboration on non-code outputs, identify its strengths and weaknesses when used in this mode, and propose conditions for successful collaborations on co-created text documents.	https://doi.org/10.1145/2788993.2789838
4	Feliciano, Joseph and Storey, Margaret-Anne and Zagalsky, Alexey	Student Experiences Using GitHub in Software Engineering Courses: A Case Study	10.1145/2889160.2889195	2016	GitHub has been embraced by the software development community as an important social platform for managing software projects and to support collaborative development. More recently, educators have begun to adopt it for hosting course content and student assignments. From our previous research, we found that educators leverage GitHub's collaboration and transparency features to create, reuse and remix course materials, and to encourage student contributions and monitor student activity on assignments and projects. However, our previous research did not consider the student perspective.In this paper, we present a case study where GitHub is used as a learning platform for two software engineering courses. We gathered student perspectives on how the use of GitHub in their courses might benefit them and to identify the challenges they may face. The findings from our case study indicate that software engineering students do benefit from GitHub's transparent and open workflow. However, students were concerned that since GitHub is not inherently an educational tool, it lacks key features important for education and poses learning and privacy concerns. Our findings provide recommendations for designers on how tools such as GitHub can be used to improve software engineering education, and also point to recommendations for instructors on how to use it more effectively in their courses.	https://doi.org/10.1145/2889160.2889195
5	Neto, Casimiro Conde Marco and de O. Barros, M\\'arcio	A Structured Survey on the Usage of the Issue Tracking System Provided by the GitHub Platform	10.1145/3132498.3134110	2017	Issue tracking systems help software development teams in identifying problems to be solved and new features to be added to a software system. In this paper, we replicate and extend a study carried out in 2013 on the usage of the issue tracking system provided by the GitHub platform. The replication aims at determining whether the results observed four years ago are still valid. The extension seeks to analyze how often issues are terminated by commits to the version control system and understand whether this feature allows developers to relate an issue to the source code modules that were changed to resolve it. We conclude that the results of the previous study remain valid and that issues closed by commits are uncommon (about 4% of our sample) and often linked to technical aspects of the project.	https://doi.org/10.1145/3132498.3134110
6	Zhang, Yang and Wang, Huaimin and Yin, Gang and Wang, Tao and Yu, Yue	Exploring the Use of @-Mention to Assist Software Development in GitHub	10.1145/2875913.2875914	2015	Recently, many researches propose that social media tools can promote the collaboration among developers, which are beneficial to the software development. Nevertheless, there is little empirical evidence to confirm that using @-mention has indeed a beneficial impact on the issues in GitHub. In this paper, we analyze the data from GitHub and give some insights on how @-mention is used in the issues (general-issues and pull-requests). Our statistical results indicate that, @-mention attracts more participants and tends to be used in the difficult issues. @-mention favors the solving process of issues by enlarging the visibility of issues and facilitating the developers' collaboration. In addition to this global study, our study also build a @-network based on the @-mention database we extract. Through the @-network, we can mine the relationships and characteristics of developers in GitHub's issues.	https://doi.org/10.1145/2875913.2875914
7	Hu, Zhewei and Gehringer, Edward	Use Bots to Improve GitHub Pull-Request Feedback	10.1145/3287324.3293787	2019	Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student's work. In our software engineering course, we have 50-120 students each semester. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check code style and functionality. However, these tools cannot enforce system-specific customized guidelines and do not explicitly display detailed information. In this study, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. The Expertiza Bot can help detect violations of more than 35 system-specific guidelines. The Travis CI Bot can explicitly display instant test execution results on the GitHub pull-request page. The Code Climate Bot can insert pull-request comments to remind students to fix issues detected by the static code analyzer. These bots are either open source or free for OSS projects, and can be easily integrated with GitHub repositories. Our survey results show that more than 70% of students think the advice given by the bots is useful. We tallied the amount of feedback given by the bots and the teaching staff for each GitHub pull request. Results show that bots can provide significantly more feedback (six times more on average) than teaching staff. Bots can also offer more timely feedback than teaching staff and help student contributions avoid more than 33% system-specific guideline violations.	https://doi.org/10.1145/3287324.3293787
8	Vendome, Christopher and Linares-Vasquez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and German, Daniel and Poshyvanyk, Denys	License Usage and Changes: A Large-Scale Study of Java Projects on GitHub	10.1109/ICPC.2015.32	2015	Software licenses determine, from a legal point of view, under which conditions software can be integrated, used, and above all, redistributed. Licenses evolve over time to meet the needs of development communities and to cope with emerging legal issues and new development paradigms. Such evolution of licenses is likely to be accompanied by changes in the way how software uses such licenses, resulting in some licenses being adopted while others are abandoned. This paper reports a large empirical study aimed at quantitatively and qualitatively investigating when and why developer change software licenses. Specifically, we first identify licenses' changes in 1,731,828 commits, representing the entire history of 16,221 Java projects hosted on GitHub. Then, to understand the rationale of license changes, we perform a qualitative analysis -- following a grounded theory approach -- of commit notes and issue tracker discussions concerning licensing topics and, whenever possible, try to build trace ability links between discussions and changes. Our results point out a lack of trace ability of when and why licensing changes are made. This can be a major concern, because a change in the license of a system can negatively impact those that reuse it.	https://doi.org/10.1109/ICPC.2015.32
9	Agrawall, Akash and Chaitanya, Krishna and Agrawal, Arnav Kumar and Choppella, Venkatesh	Mitigating Browser-Based DDoS Attacks Using CORP	10.1145/3021460.3021477	2017	On March 27, 2015, Github witnessed a massive DDoS attack, the largest in Github's history till date. In this incident, browsers and users were used as vectors to launch the attack. In this paper, we analyse such browser-based DDoS attacks and simulate them in a lab environment. Existing browser security policies like Same Origin Policy (SOP), Content Security Policy (CSP) do not mitigate these attacks by design. In this paper we observe that CORP (Cross Origin Request Policy), a browser security policy, can be used to mitigate these attacks. CORP enables a server to control cross-origin interactions initiated by a browser. The browser intercepts the cross-origin requests and blocks unwanted requests by the server. This takes the load off the server to mitigate the attack.	https://doi.org/10.1145/3021460.3021477
10	Lee, Michael J. and Ferwerda, Bruce and Choi, Junghong and Hahn, Jungpil and Moon, Jae Yun and Kim, Jinwoo	GitHub Developers Use Rockstars to Overcome Overflow of News	10.1145/2468356.2468381	2013	Keeping track of a constantly updating stream of news items on social networking enabled software development sites may be difficult. We analyzed the actions of 544 GitHub.com developers working across 5,657 projects to examine how the network of developers and projects influence where developers choose to contribute. Our analyses revealed the existence of a group of extremely well connected developers, or rockstars. We found that these rockstars': 1) actions have a greater influence on their followers compared to regular developers, 2) type of action affect their followers differently, 3) influence on followers may depend on a project's age, 4) increased activity on a project increases activity by followers, and 5) followers use as guides to projects to work on. We discuss the implications of these findings to the design of software development environments.	https://doi.org/10.1145/2468356.2468381
11	Hsing, Courtney and Gennarelli, Vanessa	Using GitHub in the Classroom Predicts Student Learning Outcomes and Classroom Experiences: Findings from a Survey of Students and Teachers	10.1145/3287324.3287460	2019	GitHub is a widely-used software development platform that supports version control, collaborative development, and project hosting. Currently, an estimated 18,000 educators use GitHub in programming classrooms. Depending on how GitHub is implemented in the classroom, students may rely on GitHub for activities such as, submitting assignments, collaborating on group projects, and receiving feedback. Despite GitHub's growing presence in programming classrooms, to date, few studies have explored how GitHub and the design of its implementation shape students' learning outcomes and classroom experiences. Building on previous research, we investigated how students in classrooms that used GitHub (GitHub classrooms), as opposed to classrooms that did not use GitHub (non-GitHub classrooms), differed across key variables. We surveyed 7530 students and 300 educators from GitHub and non-GitHub classrooms. Overall, we found that using GitHub in the classroom predicted better learning outcomes and classroom experiences. For example, students felt more prepared for the future, and they felt a greater sense of belonging in the classroom and in the field. Importantly, the design of implementation affected learning outcomes. For example, of the students who used GitHub in the classroom and received instructor feedback, those who received (versus did not receive) feedback via GitHub benefited more from the feedback. We discuss best practices for maximizing benefits to student learning when implementing GitHub in the classroom, study limitations, and future research directions. Our research is a step towards understanding how GitHub, a tool with a growing presence in programming classrooms, impacts students' learning experiences.	https://doi.org/10.1145/3287324.3287460
12	Arcelli Fontana, Francesca and Raibulet, Claudia	Students' Feedback in Using GitHub in a Project Development for a Software Engineering Course	10.1145/3059009.3072984	2017	GitHub is a platform used for the development of software projects. It provides a traceable project repository and a social meeting place for communities of practices. This poster presents the students' feedback on using GitHub as a development platform for software projects counting as an exam for a 3rd-year undergraduate software engineering course on software design. Students worked in teams and their feedback is positive overall.	https://doi.org/10.1145/3059009.3072984
13	Borges, Hudson and Brito, Rodrigo and Valente, Marco Tulio	Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions	10.1145/3350768.3350788	2019	Recently, GitHub introduced a new social feature, named reactions, which are "pictorial characters" similar to emoji symbols widely used nowadays in text-based communications. Particularly, GitHub users can use a pre-defined set of such symbols to react to issues and pull requests. However, little is known about the real usage and impact of GitHub reactions. In this paper, we analyze the reactions provided by developers to more than 2.5 million issues and 9.7 million issue comments, in order to answer an extensive list of nine research questions about the usage and adoption of reactions. We show that reactions are being increasingly used by open source developers. Moreover, we also found that issues with reactions usually take more time to be handled and have longer discussions.	https://doi.org/10.1145/3350768.3350788
14	Hebig, Regina and Quang, Truong Ho and Chaudron, Michel R. V. and Robles, Gregorio and Fernandez, Miguel Angel	The Quest for Open Source Projects That Use UML: Mining GitHub	10.1145/2976767.2976778	2016	Context: While industrial use of UML was studied intensely, little is known about UML use in Free/Open Source Software (FOSS) projects. Goal: We aim at systematically mining GitHub projects to answer the question when models, if used, are created and updated throughout the whole project's life-span. Method: We present a semi-automated approach to collect UML stored in images, .xmi, and .uml files and scanned ten percent of all GitHub projects (1.24 million). Our focus was on number and role of contributors that created/updated models and the time span during which this happened. Results: We identified and studied 21 316 UML diagrams within 3 295 projects. Conclusion: Creating/updating of UML happens most often during a very short phase at the project start. For 12% of the models duplicates were found, which are in average spread across 1.88 projects. Finally, we contribute a list of GitHub projects that include UML files.	https://doi.org/10.1145/2976767.2976778
15	Zhu, Jiaxin and Zhou, Minghui and Mockus, Audris	Patterns of Folder Use and Project Popularity: A Case Study of Github Repositories	10.1145/2652524.2652564	2014	Context: Every software development project uses folders to organize software artifacts. Goal: We would like to understand how folders are used and what ramifications different uses may have. Method: In this paper we study the frequency of folders used by 140k Github projects and use regression analysis to model how folder use is related to project popularity, i.e., the extent of forking. Results: We find that the standard folders, such as document, testing, and examples, are not only among the most frequently used, but their presence in a project is associated with increased chances that a project's code will be forked (i.e., used by others) and an increased number of forks. Conclusions: This preliminary study of folder use suggests opportunities to quantify (and improve) file organization practices based on folder use patterns of large collections of repositories.	https://doi.org/10.1145/2652524.2652564
16	Kikas, Riivo and Dumas, Marlon and Pfahl, Dietmar	Using Dynamic and Contextual Features to Predict Issue Lifetime in GitHub Projects	10.1145/2901739.2901751	2016	Methods for predicting issue lifetime can help software project managers to prioritize issues and allocate resources accordingly. Previous studies on issue lifetime prediction have focused on models built from static features, meaning features calculated at one snapshot of the issue's lifetime based on data associated to the issue itself. However, during its lifetime, an issue typically receives comments from various stakeholders, which may carry valuable insights into its perceived priority and difficulty and may thus be exploited to update lifetime predictions. Moreover, the lifetime of an issue depends not only on characteristics of the issue itself, but also on the state of the project as a whole. Hence, issue lifetime prediction may benefit from taking into account features capturing the issue's context (contextual features). In this work, we analyze issues from more than 4000 GitHub projects and build models to predict, at different points in an issue's lifetime, whether or not the issue will close within a given calendric period, by combining static, dynamic and contextual features. The results show that dynamic and contextual features complement the predictive power of static ones, particularly for long-term predictions.	https://doi.org/10.1145/2901739.2901751
17	Gustavsson, Henrik and Brohede, Marcus	Continuous Assessment in Software Engineering Project Course Using Publicly Available Data from GitHub	10.1145/3306446.3340820	2019	This paper describes an approach for assessment in a large software engineering project course. We propose an approach for continuously collecting information from a source code repository and collaboration tool, and using this information for assessing student contributions and also for assessing the course as a whole from the teacher's standpoint. We present how we display metrics for how the students perform in relation to some of the requirements of the course. We argue that continuous summative assessment feedback to the students on how they are performing in the project is a suitable strategy for ensuring active participation from the students for the duration of the project course.	https://doi.org/10.1145/3306446.3340820
18	Lars\\'en, Simon and Glassey, Richard	RepoBee: Developing Tool Support for Courses Using Git/GitHub	10.1145/3304221.3319784	2019	The use of version control systems within computing education is growing in popularity. However, this is challenging because such systems are not particularly well designed to support educational situations, nor are they easy to use with confidence in teaching, as specialist knowledge and experience is required. This experience paper reports the development of the open source tool RepoBee, which assists in the use of Git/GitHub in an educational context. The tool provides a straightforward interface for managing batch tasks such as repository generation and cloning for setting and gathering assignments, opening and closing of issues to communicate with students, as well as facilitating peer reviews. Parts of RepoBee are open to integration with third party tools for additional tasks, such as running unit tests or static analysis on student repositories. We also include the perspectives of both teachers and teaching assistants who have been using the tool as part of a first year course for computer scientists.	https://doi.org/10.1145/3304221.3319784
19	Glassey, Richard	Managing Assignment Feedback via Issue Tracking	10.1145/3197091.3205819	2018	This poster provides insight into the use of an issue tracker for the management of assignment feedback within an introductory course in computer science (CS). Students have made use of Github for three successive years, and the issue tracker has become one of the key mechanisms for managing formative feedback. This approach has yielded three key benefits: increased student engagement in their own feedback; provided an early experience of an authentic and industry desirable communication skill; and created a means to oversee and learn from feedback discussions for the teaching team.	https://doi.org/10.1145/3197091.3205819
20	Kavaler, David and Trockman, Asher and Vasilescu, Bogdan and Filkov, Vladimir	Tool Choice Matters: JavaScript Quality Assurance Tools and Usage Outcomes in GitHub Projects	10.1109/ICSE.2019.00060	2019	Quality assurance automation is essential in modern software development. In practice, this automation is supported by a multitude of tools that fit different needs and require developers to make decisions about which tool to choose in a given context. Data and analytics of the pros and cons can inform these decisions. Yet, in most cases, there is a dearth of empirical evidence on the effectiveness of existing practices and tool choices.We propose a general methodology to model the time-dependent effect of automation tool choice on four outcomes of interest: prevalence of issues, code churn, number of pull requests, and number of contributors, all with a multitude of controls. On a large data set of npm JavaScript projects, we extract the adoption events for popular tools in three task classes: linters, dependency managers, and coverage reporters. Using mixed methods approaches, we study the reasons for the adoptions and compare the adoption effects within each class, and sequential tool adoptions across classes. We find that some tools within each group are associated with more beneficial outcomes than others, providing an empirical perspective for the benefits of each. We also find that the order in which some tools are implemented is associated with varying outcomes.	https://doi.org/10.1109/ICSE.2019.00060
21	Chapman, Carl and Stolee, Kathryn T.	Exploring Regular Expression Usage and Context in Python	10.1145/2931037.2931073	2016	Due to the popularity and pervasive use of regular expressions, researchers have created tools to support their creation, validation, and use. However, little is known about the context in which regular expressions are used, the features that are most common, and how behaviorally similar regular expressions are to one another.  In this paper, we explore the context in which regular expressions are used through a combination of developer surveys and repository analysis. We survey 18 professional developers about their regular expression usage and pain points. Then, we analyze nearly 4,000 open source Python projects from GitHub and extract nearly 14,000 unique regular expression patterns. We map the most common features used in regular expressions to those features supported by four major regex research efforts from industry and academia: brics, Hampi, RE2, and Rex. Using similarity analysis of regular expressions across projects, we identify six common behavioral clusters that describe how regular expressions are often used in practice. This is the first rigorous examination of regex usage and it provides empirical evidence to support design decisions by regex tool builders. It also points to areas of needed future work, such as refactoring regular expressions to increase regex understandability and context-specific tool support for common regex usages. 	https://doi.org/10.1145/2931037.2931073
22	McDonnell, Tyler and Ray, Baishakhi and Kim, Miryung	An Empirical Study of API Stability and Adoption in the Android Ecosystem	10.1109/ICSM.2013.18	2013	When APIs evolve, clients make corresponding changes to their applications to utilize new or updated APIs. Despite the benefits of new or updated APIs, developers are often slow to adopt the new APIs. As a first step toward understanding the impact of API evolution on software ecosystems, we conduct an in-depth case study of the co-evolution behavior of Android API and dependent applications using the version history data found in github. Our study confirms that Android is evolving fast at a rate of 115 API updates per month on average. Client adoption, however, is not catching up with the pace of API evolution. About 28% of API references in client applications are outdated with a median lagging time of 16 months. 22% of outdated API usages eventually upgrade to use newer API versions, but the propagation time is about 14 months, much slower than the average API release interval (3 months). Fast evolving APIs are used more by clients than slow evolving APIs but the average time taken to adopt new versions is longer for fast evolving APIs. Further, API usage adaptation code is more defect prone than the one without API usage adaptation. This may indicate that developers avoid API instability.	https://doi.org/10.1109/ICSM.2013.18
23	Biswas, Sumon and Islam, Md Johirul and Huang, Yijia and Rajan, Hridesh	Boa Meets Python: A Boa Dataset of Data Science Software in Python Language	10.1109/MSR.2019.00086	2019	The popularity of Python programming language has surged in recent years due to its increasing usage in Data Science. The availability of Python repositories in Github presents an opportunity for mining software repository research, e.g., suggesting the best practices in developing Data Science applications, identifying bug-patterns, recommending code enhancements, etc. To enable this research, we have created a new dataset that includes 1,558 mature Github projects that develop Python software for Data Science tasks. By analyzing the metadata and code, we have included the projects in our dataset which use a diverse set of machine learning libraries and managed by a variety of users and organizations. The dataset is made publicly available through Boa infrastructure both as a collection of raw projects as well as in a processed form that could be used for performing large scale analysis using Boa language. We also present two initial applications to demonstrate the potential of the dataset that could be leveraged by the community.	https://doi.org/10.1109/MSR.2019.00086
24	Reiss, Steven P.	Tool Demo: Browsing Software Repositories	10.1109/ICSME.2014.102	2014	We demonstrate a tool for browsing large software repositories such as GitHub or Source Forge using all the facilities one normally associates with an integrated development environment. The tool integrates code search engines with the Code Bubbles development environment. It lets the user perform and compare multiple searches, investigate and explore the results that are returned, expand searches as necessary, and eventually export appropriate results.	https://doi.org/10.1109/ICSME.2014.102
194	Heymann, S\\'ebastien and Le Grand, B\\'en\\'edicte	Towards a Redefinition of Time in Information Networks?	10.1145/2464464.2464498	2013	How should we characterize the dynamics of the Web? Whereas network maps have contributed to a redefinition of distances and space in information networks, current studies still use a traditional time unit -the second- to understand the temporality of the Web. This unit leads to the observation of exogenous phenomena like day-night patterns. In order to capture the intrinsic dynamics of the network, we introduce an innovative -yet simple- concept of time which relies on the measure of changes in the network space. We demonstrate its practical interest on the evolution of the Github social network.	https://doi.org/10.1145/2464464.2464498
25	Rao, A. Eashaan and Chimalakonda, Sridhar	An Exploratory Study Towards Understanding Lambda Expressions in Python	10.1145/3383219.3383255	2020	Lambda expressions are anonymous functions in Python. It is one of the alternatives to write a function definition. Syntactically, it is a single expression and defined using the keyword lambda. Lambda expression is a functional programming feature, currently in use, in many mainstream programming languages such as Python, Java8, C++11. There are few studies in C++ and Java to understand the impact of lambda expressions on programmers. These studies are focusing on the developer's adaptability to use a functional style of construct and the benefit they gain from using it. However, we are not aware of any literature on the use of lambda expressions in Python. Thus, there is a need to study lambda expressions in Python projects. In this paper, we examine 15 GitHub repositories out of 760 from our dataset, that are using Python as their primary language. In this study, we are classifying the uses of lambda expressions based on varying scenarios. We identified 13 different usages of lambda expressions from these Python repositories. This catalog is an attempt to support programmers to use lambda expressions more effectively and efficiently.	https://doi.org/10.1145/3383219.3383255
26	Gousios, Georgios and Spinellis, Diomidis	Mining Software Engineering Data from GitHub	10.1109/ICSE-C.2017.164	2017	GitHub is the largest collaborative source code hosting site built on top of the Git version control system. The availability of a comprehensive API has made GitHub a target for many software engineering and online collaboration research efforts. In our work, we have discovered that a) obtaining data from GitHub is not trivial, b) the data may not be suitable for all types of research, and c) improper use can lead to biased results. In this tutorial, we analyze how data from GitHub can be used for large-scale, quantitative research, while avoiding common pitfalls. We use the GHTorrent dataset, a queryable offline mirror of the GitHub API data, to draw examples from and present pitfall avoidance strategies.	https://doi.org/10.1109/ICSE-C.2017.164
27	Roveda, Riccardo and Arcelli Fontana, Francesca and Raibulet, Claudia and Zanoni, Marco and Rampazzo, Federico	Does the Migration to GitHub Relate to Internal Software Quality?	10.5220/0006367402930300	2017	Software development is more and more influenced by the usage of FLOSS (Free, Libre and Open Source Software) projects. These software projects are developed in web collaborative environments hosted on web platforms, called code forges. Many code forges exist, with different capabilities. Github is perhaps the largest code forge available, and many projects have been migrated from different code forges to Github. Given its success, we want to understand if its adoption has effect on the projects' internal quality. To consider objective measures of internal quality, we apply four known tools performing static analysis to extract metrics and code anomalies. These data is extracted on six versions of six FLOSS projects, and compared to understand if the migration to Github had any consistent effect over any of the considered measures.	https://doi.org/10.5220/0006367402930300
28	F\\"arber, Michael	Analyzing the GitHub Repositories of Research Papers	10.1145/3383583.3398578	2020	Linking to code repositories, such as on GitHub, in scientific papers becomes increasingly common in the field of computer science. The actual quality and usage of these repositories are, however, to a large degree unknown so far. In this paper, we present for the first time a thorough analysis of all GitHub code repositories linked in scientific papers using the Microsoft Academic Graph as a data source. We analyze the repositories and their associated papers with respect to various dimensions. We observe that the number of stars and forks, respectively, over all repositories follows a power-law distribution. In the majority of cases, only one person from the authors is contributing to the repository. The GitHub manuals are mostly kept rather short with few sentences. The source code is mostly provided in Python. The papers containing the repository URLs as well as the papers' authors are typically from the AI field.	https://doi.org/10.1145/3383583.3398578
29	Nguyen, Phuong T. and Di Rocco, Juri and Di Ruscio, Davide and Ochoa, Lina and Degueule, Thomas and Di Penta, Massimiliano	FOCUS: A Recommender System for Mining API Function Calls and Usage Patterns	10.1109/ICSE.2019.00109	2019	Software developers interact with APIs on a daily basis and, therefore, often face the need to learn how to use new APIs suitable for their purposes. Previous work has shown that recommending usage patterns to developers facilitates the learning process. Current approaches to usage pattern recommendation, however, still suffer from high redundancy and poor run-time performance. In this paper, we reformulate the problem of usage pattern recommendation in terms of a collaborative-filtering recommender system. We present a new tool, FOCUS, which mines open-source project repositories to recommend API method invocations and usage patterns by analyzing how APIs are used in projects similar to the current project. We evaluate FOCUS on a large number of Java projects extracted from GitHub and Maven Central and find that it outperforms the state-of-the-art approach PAM with regards to success rate, accuracy, and execution time. Results indicate the suitability of context-aware collaborative-filtering recommender systems to provide API usage patterns.	https://doi.org/10.1109/ICSE.2019.00109
30	Stefan, Petr and Horky, Vojtech and Bulej, Lubomir and Tuma, Petr	Unit Testing Performance in Java Projects: Are We There Yet?	10.1145/3030207.3030226	2017	Although methods and tools for unit testing of performance exist for over a decade, anecdotal evidence suggests unit testing of performance is not nearly as common as unit testing of functionality. We examine this situation in a study of GitHub projects written in Java, looking for occurrences of performance evaluation code in common performance testing frameworks. We quantify the use of such frameworks, identifying the most relevant performance testing approaches, and describe how we adjust the design of our SPL performance testing framework to follow these conclusions.	https://doi.org/10.1145/3030207.3030226
42	Li, Zhixing and Yin, Gang and Yu, Yue and Wang, Tao and Wang, Huaimin	Detecting Duplicate Pull-Requests in GitHub	10.1145/3131704.3131725	2017	The widespread use of pull-requests boosts the development and evolution for many open source software projects. However, due to the parallel and uncoordinated nature of development process in GitHub, duplicate pull-requests may be submitted by different contributors to solve the same problem. Duplicate pull-requests increase the maintenance cost of GitHub, result in the waste of time spent on the redundant effort of code review, and even frustrate developers' willing to offer continuous contribution. In this paper, we investigate using text information to automatically detect duplicate pull-requests in GitHub. For a new-arriving pull-request, we compare the textual similarity between it and other existing pull-requests, and then return a candidate list of the most similar ones. We evaluate our approach on three popular projects hosted in GitHub, namely Rails, Elasticsearch and Angular.JS. The evaluation shows that about 55.3% -- 71.0% of the duplicates can be found when we use the combination of title similarity and description similarity.	https://doi.org/10.1145/3131704.3131725
31	Fang, Hongbo and Klug, Daniel and Lamba, Hemank and Herbsleb, James and Vasilescu, Bogdan	Need for Tweet: How Open Source Developers Talk About Their GitHub Work on Twitter	10.1145/3379597.3387466	2020	Social media, especially Twitter, has always been a part of the professional lives of software developers, with prior work reporting on a diversity of usage scenarios, including sharing information, staying current, and promoting one's work. However, previous studies of Twitter use by software developers typically lack information about activities of the study subjects (and their outcomes) on other platforms. To enable such future research, in this paper we propose a computational approach to cross-link users across Twitter and GitHub, revealing (at least) 70,427 users active on both. As a preliminary analysis of this dataset, we report on a case study of 786 tweets by open-source developers about GitHub work, combining automatic characterization of tweet authors in terms of their relationship to the GitHub items linked in their tweets with qualitative analysis of the tweet contents. We find that different developer roles tend to have different tweeting behaviors, with repository owners being perhaps the most distinctive group compared to other project contributors and followers. We also note a sizeable group of people who follow others on GitHub and tweet about these people's work, but do not otherwise contribute to those open-source projects. Our results and public dataset open up multiple future research directions.	https://doi.org/10.1145/3379597.3387466
32	Pe-Than, Ei Pa Pa and Dabbish, Laura and Herbsleb, James D.	Collaborative Writing on GitHub: A Case Study of a Book Project	10.1145/3272973.3274083	2018	Social coding platforms such as GitHub are increasingly becoming a digital workspace for the production of non-software digital artifacts. Since GitHub offers unique features that are different from traditional ways of collaborative writing, it is interesting to investigate how GitHub features are used for writing. In this paper, we present the preliminary findings of a mixed-methods, case study of collaboration practices in a GitHub book project. We found that the use of GitHub depended on task interdependence and audience participation. GitHub's direct push method was used to coordinate both loosely- and tightly-coupled work, with the latter requiring collaborators to follow socially-accepted conventions. The pull-based method was adopted once the project was released to the public. While face-to-face and online meetings were prominent in the early phases, GitHub's issues became instrumental for communication and project management in later phases. Our findings have implications for the design of collaborative writing tools.	https://doi.org/10.1145/3272973.3274083
33	Chang, Christopher H. and Carpenter, Ilene L. and Jones, Wesley B.	The ESIF-HPC-2 Benchmark Suite	10.1145/3380868.3398200	2020	We describe the development of the ESIF-HPC-2 benchmark suite, a collection of kernel and application benchmark codes for measuring computational and I/O performance from single nodes to full HPC systems that was used for acceptance testing in our recent HPC procurement. The configurations of the benchmarks used for our system is presented. We also describe a set of "dimensions" that can be used to classify benchmarks and assess coverage of a suite systematically. The collection is offered cost-free as a GitHub repository for general usage and further development.	https://doi.org/10.1145/3380868.3398200
34	Padhye, Rohan and Mukherjee, Debdoot and Sinha, Vibha Singhal	API as a Social Glue	10.1145/2591062.2591115	2014	The rapid growth of social platforms such as Facebook, Twitter and LinkedIn underscores the need for people to connect to existing and new contacts for recreational and professional purposes. A parallel of this phenomenon exists in the software development arena as well. Open-source code sharing platforms such as GitHub provide the ability to follow people and projects of interest. However, users are manually required to identify projects or other users whom they might be interested in following. We observe that most software projects use third-party libraries and that developers who contribute to multiple projects often use the same library APIs across projects. Thus, the library APIs seem to be a good fingerprint of their skill set. Hence, we argue that library APIs can form the social glue to connect people and projects having similar interests. We propose APINet, a system that mines API usage profiles from source code version management systems and create a social network of people, projects and libraries. We describe our initial implementation that uses data from 568 open-source projects hosted on GitHub. Our system recommends to a user new projects and people that they may be interested in, suggests communities of people who use related libraries and finds experts for a given topic who are closest in a user's social graph. 	https://doi.org/10.1145/2591062.2591115
35	Kalliamvakou, Eirini and Gousios, Georgios and Blincoe, Kelly and Singer, Leif and German, Daniel M. and Damian, Daniela	The Promises and Perils of Mining GitHub	10.1145/2597073.2597074	2014	With over 10 million git repositories, GitHub is becoming one of the most important source of software artifacts on the Internet. Researchers are starting to mine the information stored in GitHub's event logs, trying to understand how its users employ the site to collaborate on software. However, so far there have been no studies describing the quality and properties of the data available from GitHub. We document the results of an empirical study aimed at understanding the characteristics of the repositories in GitHub and how users take advantage of GitHub's main features---namely commits, pull requests, and issues. Our results indicate that, while GitHub is a rich source of data on software development, mining GitHub for research purposes should take various potential perils into consideration. We show, for example, that the majority of the projects are personal and inactive; that GitHub is also being used for free storage and as a Web hosting service; and that almost 40% of all pull requests do not appear as merged, even though they were. We provide a set of recommendations for software engineering researchers on how to approach the data in GitHub. 	https://doi.org/10.1145/2597073.2597074
36	Escobar-Velasquez, Camilo and Osorio-Ria\\~no, Michael and Linares-V\\'asquez, Mario	MutAPK: Source-Codeless Mutant Generation for Android Apps	10.1109/ASE.2019.00109	2019	The amount of Android application is having a tremendous increasing trend, exerting pressure over practitioners and researchers around application quality, frequent releases, and quick fixing of bugs. This pressure leads practitioners to make usage of automated approaches based on using source-code as input. Nevertheless, third-party services are not able to use these approaches due to privacy factors. In this paper we present MutAPK, an open source mutation testing tool that enables the usage of Android Application Packages (APKs) as input for this task. MutAPK generates mutants without the need of having access to source code, because the mutations are done in an intermediate representation of the code (i.e., SMALI) that does not require compilation. MutAPK is publicly available at GitHub: https://bit.ly/2KYvgP9 VIDEO: https://bit.ly/2WOjiyy	https://doi.org/10.1109/ASE.2019.00109
37	Rusk, David and Coady, Yvonne	Location-Based Analysis of Developers and Technologies on GitHub	10.1109/WAINA.2014.110	2014	GitHub is a popular platform for collaboration on open source projects. It also provides a rich API to query various aspects of the public activity. This combination of a popular social coding website with a rich API presents an opportunity for researchers to gather empirical data about software development practices. There are an overwhelmingly large number of competing platforms to choose from in software development. Knowing which are gaining widespread adoption is valuable both for individual developers trying to increase their employability, as well as software engineers deciding which technology to use in their next big project. In terms of a developer's employability and an employer's ability to find available developers in their economic region, it is important to identify the most common technologies by geographic location. In this paper, analyses are done on GitHub data taking into account the developers' location and their technology usage. A web-based tool has been developed to interact with and visualize this data. In its current state of development, the tool summarizes the amount of code developers have in their public repositories broken down by programming language, and summarizes data about programmers using specific programming languages. This allows website visitors to get an immediate picture of the programming language usage in their region of interest. Future research could expand this work to technologies beyond programming languages such as frameworks and libraries.	https://doi.org/10.1109/WAINA.2014.110
38	Hilton, Michael and Tunnell, Timothy and Huang, Kai and Marinov, Darko and Dig, Danny	Usage, Costs, and Benefits of Continuous Integration in Open-Source Projects	10.1145/2970276.2970358	2016	Continuous integration (CI) systems automate the compilation, building, and testing of software. Despite CI rising as a big success story in automated software engineering, it has received almost no attention from the research community. For example, how widely is CI used in practice, and what are some costs and benefits associated with CI? Without answering such questions, developers, tool builders, and researchers make decisions based on folklore instead of data. In this paper, we use three complementary methods to study the usage of CI in open-source projects. To understand which CI systems developers use, we analyzed 34,544 open-source projects from GitHub. To understand how developers use CI, we analyzed 1,529,291 builds from the most commonly used CI system. To understand why projects use or do not use CI, we surveyed 442 developers. With this data, we answered several key questions related to the usage, costs, and benefits of CI. Among our results, we show evidence that supports the claim that CI helps projects release more often, that CI is widely adopted by the most popular projects, as well as finding that the overall percentage of projects using CI continues to grow, making it important and timely to focus more research on CI. 	https://doi.org/10.1145/2970276.2970358
39	Chen, Fangwei and Li, Lei and Jiang, Jing and Zhang, Li	Predicting the Number of Forks for Open Source Software Project	10.1145/2627508.2627515	2014	GitHub is successful open source software platform which attract many developers. In GitHub, developers are allowed to fork repositories and copy repositories without asking for permission, which make contribution to projects much easier than it has ever been. It is significant to predict the number of forks for open source software projects. The prediction can help GitHub to recommend popular projects, and guide developers to find projects which are likely to succeed and worthy of their contribution.  In this paper, we use stepwise regression and design a model to predict the number of forks for open source software projects. Then we collect datasets of 1,000 repositories through GitHub’s APIs. We use datasets of 700 repositories to compute the weight of attributes and realize the model. Then we use other 300 repositories to verify the prediction accuracy of our model. Advantages of our model include: (1) Some attributes used in our model are new. This is because GitHub is different from traditional open source software platforms and has some new features. These new features are used to build our model. (2) Our model uses project information within t month after its creation, and predicts the number of forks in the month T (t &lt; T). It allows users to set the combination of time parameters and satisfy their own needs. (3) Our model predicts the exact number of forks, rather than the range of the number of forks (4) Experiments show that our model has high prediction accuracy. For example, we use project information with 3 months to prediction the number of forks in month 6 after its creation. The correlation coefficient is as high as 0.992, and the median number of absolute difference between prediction value and actual value is only 1.8. It shows that the predicted number of forks is very close to the actual number of forks. Our model also has high prediction accuracy when we set other time parameters. 	https://doi.org/10.1145/2627508.2627515
40	Giannakopoulos, Theodoros and Siantikos, Georgios	A ROS Framework for Audio-Based Activity Recognition	10.1145/2910674.2935858	2016	Research on robot perception mostly focuses on visual information analytics. Audio-based perception is mostly based on speech-related information. However, non-verbal information of the audio channel can be equally important in the perception procedure, or at least play a complementary role. This paper presents a framework for audio signal analysis that utilizes the ROS architectural principles. Details on the design and implementation issues of this workflow are described, while classification results are also presented in the context of two use-cases motivated by the task of medical monitoring. The proposed audio analysis framework is provided as an open-source library at github (https://github.com/tyiannak/AUROS).	https://doi.org/10.1145/2910674.2935858
41	Lee, Roy Ka-Wei and Lo, David	Wisdom in Sum of Parts: Multi-Platform Activity Prediction in Social Collaborative Sites	10.1145/3201064.3201067	2018	In this paper, we proposed a novel framework which uses user interests inferred from activities (a.k.a., activity interests) in multiple social collaborative platforms to predict users' platform activities. Included in the framework are two prediction approaches: (i) direct platform activity prediction, which predicts a user's activities in a platform using his or her activity interests from the same platform (e.g., predict if a user answers a given Stack Overflow question using the user's interests inferred from his or her prior answer and favorite activities in Stack Overflow), and (ii) cross-platform activity prediction, which predicts a user's activities in a platform using his or her activity interests from another platform (e.g., predict if a user answers a given Stack Overflow question using the user's interests inferred from his or her fork and watch activities in GitHub). To evaluate our proposed method, we conduct prediction experiments on two widely used social collaborative platforms in the software development community: GitHub and Stack Overflow. Our experiments show that combining both direct and cross platform activity prediction approaches yield the best accuracies for predicting user activities in GitHub (AUC=0.75) and Stack Overflow (AUC=0.89).	https://doi.org/10.1145/3201064.3201067
43	Fowkes, Jaroslav and Sutton, Charles	Parameter-Free Probabilistic API Mining across GitHub	10.1145/2950290.2950319	2016	Existing API mining algorithms can be difficult to use as they require expensive parameter tuning and the returned set of API calls can be large, highly redundant and difficult to understand. To address this, we present PAM (Probabilistic API Miner), a near parameter-free probabilistic algorithm for mining the most interesting API call patterns. We show that PAM significantly outperforms both MAPO and UPMiner, achieving 69% test-set precision, at retrieving relevant API call sequences from GitHub. Moreover, we focus on libraries for which the developers have explicitly provided code examples, yielding over 300,000 LOC of hand-written API example code from the 967 client projects in the data set. This evaluation suggests that the hand-written examples actually have limited coverage of real API usages.	https://doi.org/10.1145/2950290.2950319
44	K\\"afer, Verena and Graziotin, Daniel and Bogicevic, Ivan and Wagner, Stefan and Ramadani, Jasmin	Communication in Open-Source Projects-End of the e-Mail Era?	10.1145/3183440.3194951	2018	Communication is essential in software engineering. Especially in distributed open-source teams, communication needs to be supported by channels including mailing lists, forums, issue trackers, and chat systems. Yet, we do not have a clear understanding of which communication channels stakeholders in open-source projects use. In this study, we fill the knowledge gap by investigating a statistically representative sample of 400 GitHub projects. We discover the used communication channels by regular expressions on project data. We show that (1) half of the GitHub projects use observable communication channels; (2) GitHub Issues, e-mail addresses, and the modern chat system Gitter are the most common channels; (3) mailing lists are only in place five and have a lower market share than all modern chat systems combined.	https://doi.org/10.1145/3183440.3194951
45	Barnaby, Celeste and Sen, Koushik and Zhang, Tianyi and Glassman, Elena and Chandra, Satish	Exempla Gratis (E.G.): Code Examples for Free	10.1145/3368089.3417052	2020	Modern software engineering often involves using many existing APIs, both open source and – in industrial coding environments– proprietary. Programmers reference documentation and code search tools to remind themselves of proper common usage patterns of APIs. However, high-quality API usage examples are computationally expensive to curate and maintain, and API usage examples retrieved from company-wide code search can be tedious to review. We present a tool, EG, that mines codebases and shows the common, idiomatic us-age examples for API methods. EG was integrated into Facebook’s internal code search tool for the Hack language and evaluated on open-source GitHub projects written in Python. EG was also compared against code search results and hand-written examples from a popular programming website called ProgramCreek. Compared with these two baselines, examples generated by EG are more succinct and representative with less extraneous statements. In addition, a survey with Facebook developers shows that EG examples are preferred in 97% of cases.	https://doi.org/10.1145/3368089.3417052
46	Au\\'e, Joop and Haisma, Michiel and T\\'omasd\\'ottir, Krist\\'\\in Fj\\'ola and Bacchelli, Alberto	Social Diversity and Growth Levels of Open Source Software Projects on GitHub	10.1145/2961111.2962633	2016	Background: Projects of all sizes and impact are leveraging the services of the social coding platform GitHub to collaborate. Since users' information and actions are recorded, GitHub has been mined for over 6 years now to investigate aspects of the collaborative open source software (OSS) development paradigm. Aim: In this research, we use this data to investigate the relation between project growth as a proxy for success, and social diversity. Method: We first categorize active OSS projects into a five-star rating using a benchmarking system we based on various project growth metrics; then we study the relation between this rating and the reported social diversities for the team members of those projects. Results: Our findings highlight a statistically significant relation; however, the effect is small. Conclusions: Our findings suggest the need for further research on this topic; moreover, the proposed benchmarking method may be used in future work to determine OSS project success on collaboration platforms such as GitHub.	https://doi.org/10.1145/2961111.2962633
47	Manes, Saraj Singh and Baysal, Olga	How Often and What StackOverflow Posts Do Developers Reference in Their GitHub Projects?	10.1109/MSR.2019.00047	2019	Stack Overflow (SO) is a popular Q&amp;A forum for software developers, providing a large amount of copyable code snippets. While GitHub is an independent code collaboration platform, developers often reuse SO code in their GitHub projects. In this paper, we investigate how often GitHub developers re-use code snippets from the SO forum, as well as what concepts they are more likely to reference in their code. To accomplish our goal, we mine SOTorrent dataset that provides connectivity between code snippets on the SO posts with software projects hosted on GitHub. We then study the characteristics of GitHub projects that reference SO posts and discover popular SO discussions that happen in GitHub projects. Our results demonstrate that on average developers make 45 references to SO posts in their projects, with the highest number of references being made within the JavaScript code. We also found that 79% of the SO posts with code snippets that are referenced in GitHub code do change over time (at least ones) raising code maintainability and reliability concerns.	https://doi.org/10.1109/MSR.2019.00047
48	Porkol\\'ab, Zolt\\'an and Brunner, Tibor and Krupp, D\\'aniel and Csord\\'as, M\\'arton	Codecompass: An Open Software Comprehension Framework for Industrial Usage	10.1145/3196321.3197546	2018	CodeCompass is an open source LLVM/Clang-based tool developed by Ericsson Ltd. and E\\"otv\\"os Lor\\'and University, Budapest to help the understanding of large legacy software systems. Based on the LLVM/Clang compiler infrastructure, CodeCompass gives exact information on complex C/C++ language elements like overloading, inheritance, the usage of variables and types, possible uses of function pointers and virtual functions - features that various existing tools support only partially. Steensgaard's and Andersen's pointer analysis algorithms are used to compute and visualize the use of pointers/references. The wide range of interactive visualizations extends further than the usual class and function call diagrams; architectural, component and interface diagrams are a few of the implemented graphs. To make comprehension more extensive, CodeCompass also utilizes build information to explore the system architecture as well as version control information.CodeCompass is regularly used by hundreds of designers and developers. Having a web-based, pluginable, extensible architecture, the CodeCompass framework can be an open platform to further code comprehension, static analysis and software metrics efforts. The source code and a tutorial is publicly available on GitHub, and a live demo is also available online.	https://doi.org/10.1145/3196321.3197546
49	Ahmar, Yosser El and Pallec, Xavier Le and G\\'erard, S\\'ebastien	The Visual Variables in UML: How Are They Used by Women?	10.1145/3241403.3241422	2018	This paper presents results of an empirical research study of the Unified Modeling Language (UML) actual state of practice. It reports on a quantitative analysis of &gt; 3500 UML diagrams related to open source projects in GitHub. The aim of the study is to shed light on the use of the visual variables (i.e., color, size, brightness, texture/grain, shape and orientation) in UML, with a particular focus on the practices of women in such usages. The theoretical perspective of the study is to explore the usefulness of the visual variables in UML. These latter are highly significant in reducing the cognitive load of human beings, when effectively employed. We conclude by discussions of the obtained results and commenting on the role of women in the projects involving visual variations in their diagrams.	https://doi.org/10.1145/3241403.3241422
50	Zhang, Tianyi and Upadhyaya, Ganesha and Reinhardt, Anastasia and Rajan, Hridesh and Kim, Miryung	Are Code Examples on an Online Q&amp;A Forum Reliable? A Study of API Misuse on Stack Overflow	10.1145/3180155.3180260	2018	Programmers often consult an online Q&amp;A forum such as Stack Overflow to learn new APIs. This paper presents an empirical study on the prevalence and severity of API misuse on Stack Overflow. To reduce manual assessment effort, we design ExampleCheck, an API usage mining framework that extracts patterns from over 380K Java repositories on GitHub and subsequently reports potential API usage violations in Stack Overflow posts. We analyze 217,818 Stack Overflow posts using ExampleCheck and find that 31% may have potential API usage violations that could produce unexpected behavior such as program crashes and resource leaks. Such API misuse is caused by three main reasons---missing control constructs, missing or incorrect order of API calls, and incorrect guard conditions. Even the posts that are accepted as correct answers or upvoted by other programmers are not necessarily more reliable than other posts in terms of API misuse. This study result calls for a new approach to augment Stack Overflow with alternative API usage details that are not typically shown in curated examples.	https://doi.org/10.1145/3180155.3180260
51	Glassey, Richard	Adopting Git/Github within Teaching: A Survey of Tool Support	10.1145/3300115.3309518	2019	The adoption and use of Git and Github within computer science education is growing in popularity. The motivation for this shift is strong: it combines a robust system for managing student coursework, sophisticated collaboration and communication tools for students and teaching staff, and an authentic experience of an important software engineering skill. Whilst previous literature has reported upon experience and benefits, there still exists a technical barrier to overcome in adopting Git and Github within an educational context. In response, both the community of teachers using Git/Github and the Github organisation itself have developed tool support to help solve the challenge of adoption, however these efforts are somewhat isolated and relatively unstudied. This work aims to provide an overview of these tools, identify the commonalities and differences, and develop a framework for comparison to assist teachers when looking for solutions for their own courses.	https://doi.org/10.1145/3300115.3309518
52	DeCausemaker, Remy and Jacobs, Stephen	Steal This Courseware: FOSS, Github, Python, and OpenShift (Abstract Only)	10.1145/2676723.2678305	2015	This workshop introduces participants to the pedagogy and practice of using Free/Open Source Software development practices into their curriculum, and then guides them through deployment of a turnkey courseware framework to be used for their own courses. The framework supports automatic blog checking, automatically generated student profile pages, Gravatar integration for profile pictures, Travis-CI continuous Integration tests, and repository changes reported via Github webhooks to IRC. Participants will learn how to use Github in the Classroom, the basics of Flask, a python web framework, and how to deploy their courseware to Red Hat's OpenShift Cloud, a free Platform-as-a-Service to host courseware and/or other web sites.	https://doi.org/10.1145/2676723.2678305
53	Cetinkaya-Rundel, Mine	Computing Infrastructure and Curriculum Design for Introductory Data Science	10.1145/3287324.3287556	2019	The goal of this workshop is to equip educators with concrete information on content and infrastructure for designing and painlessly running a modern data science course. This is a three-part workshop. Part 1 will outline a curriculum for an introductory data science course and discuss pedagogical decisions that go into the choice of topics and concepts as well as the choice of programming language (R) and syntax (primarily tidyverse), and the emphasis on literate programming for reproducibility (with R Markdown). Part 2 will discuss infrastructure choices around teaching data science with R: RStudio as an integrated development environment, cloud-based access with RStudio Cloud and Server, version control with Git, and collaboration with GitHub. Part 3 will focus on classroom management on GitHub (with ghclass). Workshop attendees will work through several exercises from the course and get first-hand experience with using the tool-chains and techniques described above. While the workshop content will focus on usage of R, many of the pedagogical takeaways will be language agnostic. All workshop content, including teacher facing documentation and student facing course materials, will also be available to participants via datasciencebox.org. Please bring a laptop with you.	https://doi.org/10.1145/3287324.3287556
54	Zagalsky, Alexey and Feliciano, Joseph and Storey, Margaret-Anne and Zhao, Yiyun and Wang, Weiliang	The Emergence of GitHub as a Collaborative Platform for Education	10.1145/2675133.2675284	2015	The software development community has embraced GitHub as an essential platform for managing their software projects. GitHub has created efficiencies and helped improve the way software professionals work. It not only provides a traceable project repository, but it acts as a social meeting place for interested parties, supporting communities of practice. Recently, educators have seen the potential in GitHub's collaborative features for managing and improving---perhaps even transforming---the learning experience. In this study, we examine how GitHub is emerging as a collaborative platform for education. We aim to understand how environments such as GitHub---environments that provide social and collaborative features in conjunction with distributed version control---may improve (or possibly hinder) the educational experience for students and teachers. We conduct a qualitative study focusing on how GitHub is being used in education, and the motivations, benefits and challenges it brings.	https://doi.org/10.1145/2675133.2675284
55	Fan, Jiahao and Li, Yi and Wang, Shaohua and Nguyen, Tien N.	A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries	10.1145/3379597.3387501	2020	We collected a large C/C++ code vulnerability dataset from open-source Github projects, namely Big-Vul. We crawled the public Common Vulnerabilities and Exposures (CVE) database and CVE-related source code repositories. Specifically, we collected the descriptive information of the vulnerabilities from the CVE database, e.g., CVE IDs, CVE severity scores, and CVE summaries. With the CVE information and its related published Github code repository links, we downloaded all of the code repositories and extracted vulnerability related code changes. In total, Big-Vul contains 3,754 code vulnerabilities spanning 91 different vulnerability types. All these code vulnerabilities are extracted from 348 Github projects. All information is stored in the CSV format. We linked the code changes with the CVE descriptive information. Thus, our Big-Vul can be used for various research topics, e.g., detecting and fixing vulnerabilities, analyzing the vulnerability related code changes. Big-Vul is publicly available on Github.	https://doi.org/10.1145/3379597.3387501
73	Sochat, Vanessa	AskCI Server: Collaborative Knowledge Base	10.1145/3311790.3399616	2020	AskCI Server is a collaborative, open source documentation server that uses GitHub for automation and version control of shared knowledge. A programmatic application programming interface, friendly user interface, and organization of concepts into questions makes it versatile as a support or collaborative knowledge base.	https://doi.org/10.1145/3311790.3399616
56	Kochhar, Pavneet Singh and Swierc, Stanislaw and Carnahan, Trevor and Sajnani, Hitesh and Nagappan, Meiyappan	Understanding the Role of Reporting in Work Item Tracking Systems for Software Development: An Industrial Case Study	10.1145/3183440.3195071	2018	Work item tracking systems such as Visual Studio Team Services, JIRA, and GitHub issue tracker are widely used by software engineers. They help in managing different kinds of deliverables (e.g.\\^A\\uafeatures, user stories, bugs), plan sprints, distribute tasks across the team and prioritize the work. While these tools provide reporting capabilities there has been little research into the role these reports play in the overall software development process.In this study, we conduct an empirical investigation on the usage of Analytics Service - a reporting service provided by Visual Studio Team Services (VSTS) to build dashboards and reports out of their work item tracking data. In particular, we want to understand why and how users interact with Analytics Service and what are the outcomes and business decisions taken by stakeholders from reports built using Analytics Service. We perform semi-structured interviews and survey with users of Analytics Service to understand usage and challenges. Our report on qualitative and quantitative analysis can help organizations and engineers building similar tools or services.	https://doi.org/10.1145/3183440.3195071
57	Izbicki, Mike	Open Sourcing the Classroom (Abstract Only)	10.1145/2839509.2851052	2016	This project describes an experimental course on open source software construction. The course has two twists on the standard project-based software construction course. The first twist is simple: all projects are developed and released on GitHub. The second twist is more radical: the course uses an "open source textbook." The textbook is hosted in a git repository that students are required to contribute to throughout the term. Contributions range from minor typo fixes to adding entire chapters. Currently, 88% of the textbook is written by students, including many of the assignments. We use student surveys, participation in social networking sites like GitHub, and web traffic logs to determine that these assignments had a positive effect on students' future contributions to the open source community.	https://doi.org/10.1145/2839509.2851052
58	Wu, Yu and Kropczynski, Jessica and Shih, Patrick C. and Carroll, John M.	Exploring the Ecosystem of Software Developers on GitHub and Other Platforms	10.1145/2556420.2556483	2014	GitHub provides various social features for developers to collaborate with others. Those features are important for developers to coordinate their work (Dabbish et al., 2012; Marlow et al., 2013). We hypothesized that the social system of GitHub users was bound by system interactions such that contributing to similar code repositories would lead to users following one another on GitHub or vice versa. Using a quadratic assignment procedure (QAP) correlation, however, only a weak correlation among followship and production activities (code, issue, and wiki contributions) was found. Survey with GitHub users revealed an ecosystem on the Internet for software developers, which includes many platforms, such as Forrst, Twitter, and Hacker News, among others. Developers make social introductions and other interactions on these platforms and engage with one anther on GitHub. Due to these preliminary findings, we describe GitHub as a part of a larger ecosystem of developer interactions.	https://doi.org/10.1145/2556420.2556483
59	Borle, Neil C. and Feghhi, Meysam and Stroulia, Eleni and Greiner, Russell and Hindle, Abram	Analyzing the Effects of Test Driven Development in GitHub	10.1145/3180155.3182535	2018	Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. Previous work by Fucci et al. [2, 3] engaged in laboratory studies of developers actively engaged in test-driven development practices. Fucci et al. found little difference between test-first behaviour of TDD and test-later behaviour. To that end, we opted to conduct a study about TDD behaviours in the "wild" rather than in the laboratory. Thus we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and that contained at least one test file. We compared how the TDD sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. We found that Java TDD projects were relatively rare. In addition, there were very few significant differences in any of the metrics we used to compare TDD-like and non-TDD projects; therefore, our results do not reveal any observable benefits from using TDD.	https://doi.org/10.1145/3180155.3182535
60	Borges, Hudson and Hora, Andre and Valente, Marco Tulio	Predicting the Popularity of GitHub Repositories	10.1145/2972958.2972966	2016	GitHub is the largest source code repository in the world. It provides a git-based source code management platform and also many features inspired by social networks. For example, GitHub users can show appreciation to projects by adding stars to them. Therefore, the number of stars of a repository is a direct measure of its popularity. In this paper, we use multiple linear regressions to predict the number of stars of GitHub repositories. These predictions are useful both to repository owners and clients, who usually want to know how their projects are performing in a competitive open source development market. In a large-scale analysis, we show that the proposed models start to provide accurate predictions after being trained with the number of stars received in the last six months. Furthermore, specific models---generated using data from repositories that share the same growth trends---are recommended for repositories with slow growth and/or for repositories with less stars. Finally, we evaluate the ability to predict not the number of stars of a repository but its rank among the GitHub repositories. We found a very strong correlation between predicted and real rankings (Spearman's rho greater than 0.95).	https://doi.org/10.1145/2972958.2972966
61	Abid, Shamsa	Recommending Related Functions from API Usage-Based Function Clone Structures	10.1145/3338906.3342486	2019	Developers need to be able to find reusable code for desired software features in a way that supports opportunistic programming for increased developer productivity. Our objective is to develop a recommendation system that provides a developer with function recommendations having functionality relevant to her development task. We employ a combination of information retrieval, static code analysis and data mining techniques to build the proposed recommendation system called FACER (Feature-driven API usage-based Code Examples Recommender). We performed an experimental evaluation on 122 projects from GitHub from selected categories to determine the accuracy of the retrieved code for related features. FACER recommended functions with a precision of 54% and 75% when evaluated using automated and manual methods respectively.	https://doi.org/10.1145/3338906.3342486
62	Marlow, Jennifer and Dabbish, Laura	Activity Traces and Signals in Software Developer Recruitment and Hiring	10.1145/2441776.2441794	2013	Social networking tools now allow professionals to post and share their work in online spaces. These professionals build reputation within a community of practice, often with the goal of finding a job. But how are the visible traces of their actions and interactions in online workspaces used in the hiring process? We conducted interviews with members of the GitHub "social coding" community to understand how profiles on the site are used to assess people during recruitment and hiring for software development positions. Both employers and job seekers pointed to specific cues provided on profiles that led them to make inferences (or form impressions) about a candidate's technical skills, motivations, and values. These cues were seen as more reliable indicators of technical abilities and motivation than information provided on a resume, because of the transparency of work actions on GitHub and relative difficulty of manipulating behavior traces. The use of online workspaces like GitHub has implications for the type of information sought by employers as well as the activity traces job hunters might seek to leave.	https://doi.org/10.1145/2441776.2441794
63	Kr\\'ol, Micha\\l and Re\\~n\\'e, Sergi and Ascigil, Onur and Psaras, Ioannis	ChainSoft: Collaborative Software Development Using Smart Contracts	10.1145/3211933.3211934	2018	In recent years, more and more companies require dedicated software to increase the efficiency of their business. However, with rapidly changing technologies it is often inefficient to maintain a dedicated team of developers. On the other hand, outsourcing software development requires considerable effort and trust between involved parties to ensure the quality of the code and adequate payment.We present ChainSoft - a platform for outsourcing software development and automatic payments between parties that distrust each other, by means of blockchain technology. ChainSoft allows any developer to create software and submit software, includes automatic code verification and enforce users' proper behavior. We implement our system using Ethereum Smart Contracts and Github/Travis CI and present first evaluation proving its security and low usage cost.	https://doi.org/10.1145/3211933.3211934
64	Rahman, Mohammad Masudur and Roy, Chanchal K.	An Insight into the Pull Requests of GitHub	10.1145/2597073.2597121	2014	Given the increasing number of unsuccessful pull requests in GitHub projects, insights into the success and failure of these requests are essential for the developers. In this paper, we provide a comparative study between successful and unsuccessful pull requests made to 78 GitHub base projects by 20,142 developers from 103,192 forked projects. In the study, we analyze pull request discussion texts, project specific information (e.g., domain, maturity), and developer specific information (e.g., experience) in order to report useful insights, and use them to contrast between successful and unsuccessful pull requests. We believe our study will help developers overcome the issues with pull requests in GitHub, and project administrators with informed decision making. 	https://doi.org/10.1145/2597073.2597121
65	Luo, Zizhan and Mao, Xiaoguang and Li, Ang	An Exploratory Research of GitHub Based on Graph Model	10.1109/FCST.2015.45	2015	GitHub has accumulated a great number of developers and open source projects. In this research, we utilize property graph model to explore complex relationships and entities of GitHub. We attempt to answer three questions associated with GitHub using the dataset from MSR2014 data challenge. Firstly, we propose a graph based method to find out the cross technology background developers on GitHub. Secondly we define interesting metrics based on discrete entropy to analyze the project imbalance induced by commit action within a software family. The results show that the imbalance of development size induced by root projects is greater than that of development speed. Finally, we sort out the relatively important root projects with two link analysis methods and the experiment result demonstrates that our method is effective.	https://doi.org/10.1109/FCST.2015.45
66	Mostafa, Shaikh and Wang, Xiaoyin	An Empirical Study on the Usage of Mocking Frameworks in Software Testing	10.1109/QSIC.2014.19	2014	In software testing, especially unit testing, it is very common that software testers need to test a class or a component without integration with some of its dependencies. Typical reasons for excluding dependencies in testing include the unavailability of some dependency due to concurrent software development and callbacks in frameworks, high cost of invoking some dependencies (e.g., slow network or database operations, commercial third-party web services), and the potential interference of bugs in the dependencies. In practice, mock objects have been used in software testing to simulate such missing dependencies, and a number of popular mocking frameworks (e.g., Mockito, EasyMock) have been developed for software testers to generate mock objects more conveniently. However, despite the wide usage of mocking frameworks in software practice, there have been very few academic studies to observe and understand the usage status of mocking frameworks, and the major issues software testers are facing when using such mocking frameworks. In this paper, we report on an empirical study on the usage of four most popular mock frameworks (Mockito, EasyMock, JMock, and JMockit) in 5,000 open source software projects from GitHub. The results of our study show that the above mentioned mocking frameworks are used in a large portion (about 23%) of software projects that have test code. We also find that software testers typically create mocks for only part of the software dependencies, and there are more mocking of source code classes than library classes.	https://doi.org/10.1109/QSIC.2014.19
67	Montandon, Jo\\~ao Eduardo and Silva, Luciana Lourdes and Valente, Marco Tulio	Identifying Experts in Software Libraries and Frameworks among GitHub Users	10.1109/MSR.2019.00054	2019	Software development increasingly depends on libraries and frameworks to increase productivity and reduce time-to-market. Despite this fact, we still lack techniques to assess developers expertise in widely popular libraries and frameworks. In this paper, we evaluate the performance of unsupervised (based on clustering) and supervised machine learning classifiers (Random Forest and SVM) to identify experts in three popular JavaScript libraries: facebook/react, mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 features about developers activity on GitHub projects, including commits on source code files that depend on these libraries. We also build a ground truth including the expertise of 575 developers on the studied libraries, as self-reported by them in a survey. Based on our findings, we document the challenges of using machine learning classifiers to predict expertise in software libraries, using features extracted from GitHub. Then, we propose a method to identify library experts based on clustering feature data from GitHub; by triangulating the results of this method with information available on Linkedin profiles, we show that it is able to recommend dozens of GitHub users with evidences of being experts in the studied JavaScript libraries. We also provide a public dataset with the expertise of 575 developers on the studied libraries.	https://doi.org/10.1109/MSR.2019.00054
68	Tan, Shin Hwei and Li, Ziqiang	Collaborative Bug Finding for Android Apps	10.1145/3377811.3380349	2020	Many automated test generation techniques have been proposed for finding crashes in Android apps. Despite recent advancement in these approaches, a study shows that Android app developers prefer reading test cases written in natural language. Meanwhile, there exist redundancies in bug reports (written in natural language) across different apps that have not been previously reused. We propose collaborative bug finding, a novel approach that uses bugs in other similar apps to discover bugs in the app under test. We design three settings with varying degrees of interactions between programmers: (1) bugs from programmers who develop a different app, (2) bugs from manually searching for bug reports in GitHub repositories, (3) bugs from a bug recommendation system, Bugine. Our studies of the first two settings in a software testing course show that collaborative bug finding helps students who are novice Android app testers to discover 17 new bugs. As students admit that searching for relevant bug reports could be time-consuming, we introduce Bugine, an approach that automatically recommends relevant GitHub issues for a given app. Bugine uses (1) natural language processing to find GitHub issues that mention common UI components shared between the app under test and other apps in our database, and (2) a ranking algorithm to select GitHub issues that are of the best quality. Our results show that Bugine is able to find 34 new bugs. In total, collaborative bug finding helps us find 51 new bugs, in which eight have been confirmed and 11 have been fixed by the developers. These results confirm our intuition that our proposed technique is useful in discovering new bugs for Android apps.	https://doi.org/10.1145/3377811.3380349
69	Di Rocco, Juri and Di Ruscio, Davide and Di Sipio, Claudio and Nguyen, Phuong and Rubei, Riccardo	TopFilter: An Approach to Recommend Relevant GitHub Topics	10.1145/3382494.3410690	2020	Background: In the context of software development, GitHub has been at the forefront of platforms to store, analyze and maintain a large number of software repositories. Topics have been introduced by GitHub as an effective method to annotate stored repositories. However, labeling GitHub repositories should be carefully conducted to avoid adverse effects on project popularity and reachability. Aims: We present TopFilter, a novel approach to assist open source software developers in selecting suitable topics for GitHub repositories being created. Method: We built a project-topic matrix and applied a syntactic-based similarity function to recommend missing topics by representing repositories and related topics in a graph. The ten-fold cross-validation methodology has been used to assess the performance of TopFilter by considering different metrics, i.e., success rate, precision, recall, and catalog coverage. Result: The results show that TopFilter recommends good topics depending on different factors, i.e., collaborative filtering settings, considered datasets, and pre-processing activities. Moreover, TopFilter can be combined with a state-of-the-art topic recommender system (i.e., MNB network) to improve the overall prediction performance. Conclusion: Our results confirm that collaborative filtering techniques can successfully be used to provide relevant topics for GitHub repositories. Moreover, TopFilter can gain a significant boost in prediction performances by employing the outcomes obtained by the MNB network as its initial set of topics.	https://doi.org/10.1145/3382494.3410690
70	Baltes, Sebastian and Kiefer, Richard and Diehl, Stephan	Attribution Required: Stack Overflow Code Snippets in GitHub Projects	10.1109/ICSE-C.2017.99	2017	Stack Overflow (SO) is the largest Q&amp;A website for developers, providing a huge amount of copyable code snippets. Using these snippets raises various maintenance and legal issues. The SO license requires attribution, i.e., referencing the original question or answer, and requires derived work to adopt a compatible license. While there is a heated debate on SO's license model for code snippets and the required attribution, little is known about the extent to which snippets are copied from SO without proper attribution. In this paper, we present the research design and summarized results of an empirical study analyzing attributed and unattributed usages of SO code snippets in GitHub projects. On average, 3.22% of all analyzed repositories and 7.33% of the popular ones contained a reference to SO. Further, we found that developers rather refer to the whole thread on SO than to a specific answer. For Java, at least two thirds of the copied snippets were not attributed.	https://doi.org/10.1109/ICSE-C.2017.99
71	Devanbu, Premkumar and Kudigrama, Pallavi and Rubio-Gonz\\'alez, Cindy and Vasilescu, Bogdan	Timezone and Time-of-Day Variance in GitHub Teams: An Empirical Method and Study	10.1145/3121257.3121261	2017	Open source projects based in ecosystems like GitHub seamlessly allow distributed software development. Contributors to some GitHub projects may originate from many different timezones; in others they may all reside in just one timezone. How might this timezone dispersion (or concentration) affect the diurnal distribution of work activity in these projects? In commercial projects, there has been a desire to use top-down management and work allocation to exploit timezone dispersion of project teams, to engender a more round-the-clock work cycle. We focus on GitHub, and explore the relationship between timezone dispersion and work activity dispersion. We find that while time-of-day work activity dispersion is indeed associated strongly with timezone dispersion, it is equally (if not more strongly) affected by project team size. 	https://doi.org/10.1145/3121257.3121261
72	Seifer, Philipp and H\\"artel, Johannes and Leinberger, Martin and L\\"ammel, Ralf and Staab, Steffen	Empirical Study on the Usage of Graph Query Languages in Open Source Java Projects	10.1145/3357766.3359541	2019	Graph data models are interesting in various domains, in part because of the intuitiveness and flexibility they offer compared to relational models. Specialized query languages, such as Cypher for property graphs or SPARQL for RDF, facilitate their use. In this paper, we present an empirical study on the usage of graph-based query languages in open-source Java projects on GitHub. We investigate the usage of SPARQL, Cypher, Gremlin and GraphQL in terms of popularity and their development over time. We select repositories based on dependencies related to these technologies and employ various popularity and source-code based filters and ranking features for a targeted selection of projects. For the concrete languages SPARQL and Cypher, we analyze the activity of repositories over time. For SPARQL, we investigate common application domains, query use and existence of ontological data modeling in applications that query for concrete instance data. Our results show, that the usage of graph query languages in open-source projects increased over the last years, with SPARQL and Cypher being by far the most popular. SPARQL projects are more active in terms of query related artifact changes and unique developers involved, but Cypher is catching up. Relatively few applications use SPARQL to query for concrete instance data: A majority of those applications employ multiple different ontologies, including project and domain specific ones. Common application domains are management systems and data visualization tools.	https://doi.org/10.1145/3357766.3359541
74	Aljemabi, Mohammed Abdelrahman and Wang, Zhongjie	Empirical Study on the Similarity and Difference between VCS-DSN and BTS-DSN	10.1145/3034950.3034980	2017	Most of the developers are collaborating freely as the team works through the Internet, for developing open source software projects without access restriction, playing different tasks including communications and coordination, making various social collaboration in the open source software projects (e.g., Bug/issue report, discussion, code revisions, etc.). All these activities can be recorded into software repositories like GitHub, and used to generate an implicit developer social network (DSN). In this paper, we conduct our empirical study using 50 open source software projects collected from GitHub and construct VCS-DSN and BTS-DSN to investigate the same collaboration between developers in the real world, and to find similarities and differences between them, in addition to the degree of similarity and diversity.	https://doi.org/10.1145/3034950.3034980
75	Chen, Boyuan and Jiang, Zhen Ming (Jack)	Studying the Use of Java Logging Utilities in the Wild	10.1145/3377811.3380408	2020	Software logging is widely used in practice. Logs have been used for a variety of purposes like debugging, monitoring, security compliance, and business analytics. Instead of directly invoking the standard output functions, developers usually prefer to use logging utilities (LUs) (e.g., SLF4J), which provide additional functionalities like thread-safety and verbosity level support, to instrument their source code. Many of the previous research works on software logging are focused on the log printing code. There are very few works studying the use of LUs, although new LUs are constantly being introduced by companies and researchers. In this paper, we conducted a large-scale empirical study on the use of Java LUs in the wild. We analyzed the use of 3, 856 LUs from 11,194 projects in GitHub and found that many projects have complex usage patterns for LUs. For example, 75.8% of the large-sized projects have implemented their own LUs in their projects. More than 50% of these projects use at least three LUs. We conducted further qualitative studies to better understand and characterize the complex use of LUs. Our findings show that different LUs are used for a variety of reasons (e.g., internationalization of the log messages). Some projects develop their own LUs to satisfy project-specific logging needs (e.g., defining the logging format). Multiple uses of LUs in one project are pretty common for large and very largesized projects mainly for context like enabling and configuring the logging behavior for the imported packages. Interviewing with 13 industrial developers showed that our findings are also generally true for industrial projects and are considered as very helpful for them to better configure and manage the logging behavior for their projects. The findings and the implications presented in this paper will be useful for developers and researchers who are interested in developing and maintaining LUs.	https://doi.org/10.1145/3377811.3380408
76	Yamashita, Kazuhiro and McIntosh, Shane and Kamei, Yasutaka and Hassan, Ahmed E. and Ubayashi, Naoyasu	Revisiting the Applicability of the Pareto Principle to Core Development Teams in Open Source Software Projects	10.1145/2804360.2804366	2015	It is often observed that the majority of the development work of an Open Source Software (OSS) project is contributed by a core team, i.e., a small subset of the pool of active devel- opers. In fact, recent work has found that core development teams follow the Pareto principle — roughly 80% of the code contributions are produced by 20% of the active developers. However, those findings are based on samples of between one and nine studied systems. In this paper, we revisit prior studies about core developers using 2,496 projects hosted on GitHub. We find that even when we vary the heuristic for detecting core developers, and when we control for system size, team size, and project age: (1) the Pareto principle does not seem to apply for 40%-87% of GitHub projects; and (2) more than 88% of GitHub projects have fewer than 16 core developers. Moreover, we find that when we control for the quantity of contributions, bug fixing accounts for a similar proportion of the contributions of both core (18%-20%) and non-core developers (21%-22%). Our findings suggest that the Pareto principle is not compatible with the core teams of many GitHub projects. In fact, several of the studied GitHub projects are susceptible to the “bus factor,” where the impact of a core developer leaving would be quite harmful. 	https://doi.org/10.1145/2804360.2804366
77	Afzali, Hammad and Torres-Arias, Santiago and Curtmola, Reza and Cappos, Justin	Le-Git-Imate: Towards Verifiable Web-Based Git Repositories	10.1145/3196494.3196523	2018	Web-based Git hosting services such as GitHub and GitLab are popular choices to manage and interact with Git repositories. However, they lack an important security feature - the ability to sign Git commits. Users instruct the server to perform repository operations on their behalf and have to trust that the server will execute their requests faithfully. Such trust may be unwarranted though because a malicious or a compromised server may execute the requested actions in an incorrect manner, leading to a different state of the repository than what the user intended.In this paper, we show a range of high-impact attacks that can be executed stealthily when developers use the web UI of a Git hosting service to perform common actions such as editing files or merging branches. We then propose le-git-imate, a defense against these attacks which provides security guarantees comparable and compatible with Git's standard commit signing mechanism. We implement le-git-imate as a Chrome browser extension. le-git-imate does not require changes on the server side and can thus be used immediately. It also preserves current workflows used in Github/GitLab and does not require the user to leave the browser, and it allows anyone to verify that the server's actions faithfully follow the user's requested actions. Moreover, experimental evaluation using the browser extension shows that le-git-imate has comparable performance with Git's standard commit signature mechanism. With our solution in place, users can take advantage of GitHub/GitLab's web-based features without sacrificing security, thus paving the way towards verifiable web-based Git repositories.	https://doi.org/10.1145/3196494.3196523
78	Bentley, Carmen A. and Gehringer, Edward F.	Promoting Collaborative Skills with Github Project Boards	10.1145/3328778.3372646	2020	Teamwork skills are much in demand in the workplace, even more so with the growth of Agile methods. This calls for giving Computer Science students more practice in the kinds of team scenarios they will encounter on the job. Key for success are hands-on experience with planning methods, prioritization techniques, time management and organization. This poster shows how the cooperative tracking tool Github Project Boards helps teams strategize development, track progress, distribute work evenly, and facilitate collaboration. It also shows how instructors can use Github Project Boards to visualize and evaluate a team's development process.	https://doi.org/10.1145/3328778.3372646
90	Wessel, Mairieli and Steinmacher, Igor and Wiese, Igor and Gerosa, Marco A.	Should I Stale or Should I Close? An Analysis of a Bot That Closes Abandoned Issues and Pull Requests	10.1109/BotSE.2019.00018	2019	On GitHub, projects use bots to automate predefined and repetitive tasks related to issues and pull requests. Our research investigates the adoption of the stale bot, which helps maintainers triaging abandoned issues and pull requests. We analyzed the bots' configuration settings and their modifications over time. These settings define the time for tagging issues and pull request as stale and closing them. We collected data from 765 OSS projects hosted on GitHub. Our results indicate that most of the studied projects made no more than three modifications in the configurations file, issues tagged as bug reports are exempt from being considered stale, while the same occurs with pull requests that need some input to be processed.	https://doi.org/10.1109/BotSE.2019.00018
79	Coelho, Jailton and Valente, Marco Tulio and Silva, Luciana L. and Shihab, Emad	Identifying Unmaintained Projects in Github	10.1145/3239235.3240501	2018	Background: Open source software has an increasing importance in modern software development. However, there is also a growing concern on the sustainability of such projects, which are usually managed by a small number of developers, frequently working as volunteers. Aims: In this paper, we propose an approach to identify GitHub projects that are not actively maintained. Our goal is to alert users about the risks of using these projects and possibly motivate other developers to assume the maintenance of the projects. Method: We train machine learning models to identify unmaintained or sparsely maintained projects, based on a set of features about project activity (commits, forks, issues, etc). We empirically validate the model with the best performance with the principal developers of 129 GitHub projects. Results: The proposed machine learning approach has a precision of 80%, based on the feedback of real open source developers; and a recall of 96%. We also show that our approach can be used to assess the risks of projects becoming unmaintained. Conclusions: The model proposed in this paper can be used by open source users and developers to identify GitHub projects that are not actively maintained anymore.	https://doi.org/10.1145/3239235.3240501
80	Tsay, Jason and Dabbish, Laura and Herbsleb, James	Influence of Social and Technical Factors for Evaluating Contribution in GitHub	10.1145/2568225.2568315	2014	Open source software is commonly portrayed as a meritocracy, where decisions are based solely on their technical merit. However, literature on open source suggests a complex social structure underlying the meritocracy. Social work environments such as GitHub make the relationships between users and between users and work artifacts transparent. This transparency enables developers to better use information such as technical value and social connections when making work decisions. We present a study on open source software contribution in GitHub that focuses on the task of evaluating pull requests, which are one of the primary methods for contributing code in GitHub. We analyzed the association of various technical and social measures with the likelihood of contribution acceptance. We found that project managers made use of information signaling both good technical contribution practices for a pull request and the strength of the social connection between the submitter and project manager when evaluating pull requests. Pull requests with many comments were much less likely to be accepted, moderated by the submitter's prior interaction in the project. Well-established projects were more conservative in accepting pull requests. These findings provide evidence that developers use both technical and social information when evaluating potential contributions to open source software projects. 	https://doi.org/10.1145/2568225.2568315
81	Gharehyazie, Mohammad and Ray, Baishakhi and Filkov, Vladimir	Some from Here, Some from There: Cross-Project Code Reuse in GitHub	10.1109/MSR.2017.15	2017	Code reuse has well-known benefits on code quality, coding efficiency, and maintenance. Open Source Software (OSS) programmers gladly share their own code and they happily reuse others'. Social programming platforms like GitHub have normalized code foraging via their common platforms, enabling code search and reuse across different projects. Removing project borders may facilitate more efficient code foraging, and consequently faster programming. But looking for code across projects takes longer and, once found, may be more challenging to tailor to one's needs. Learning how much code reuse goes on across projects, and identifying emerging patterns in past cross-project search behavior may help future foraging efforts.To understand cross-project code reuse, here we present an in-depth study of cloning in GitHub. Using Deckard, a clone finding tool, we identified copies of code fragments across projects, and investigate their prevalence and characteristics using statistical and network science approaches, and with multiple case studies. By triangulating findings from different methods, we find that cross-project cloning is prevalent in GitHub, ranging from cloning few lines of code to whole project repositories. Some of the projects serve as popular sources of clones, and others seem to contain more clones than their fair share. Moreover, we find that ecosystem cloning follows an onion model: most clones come from the same project, then from projects in the same application domain, and finally from projects in different domains. Our results show directions for new tools that can facilitate code foraging and sharing within GitHub.	https://doi.org/10.1109/MSR.2017.15
82	Horawalavithana, Sameera and Bhattacharjee, Abhishek and Liu, Renhao and Choudhury, Nazim and O. Hall, Lawrence and Iamnitchi, Adriana	Mentions of Security Vulnerabilities on Reddit, Twitter and GitHub	10.1145/3350546.3352519	2019	Activity on social media is seen as a relevant sensor for different aspects of the society. In a heavily digitized society, security vulnerabilities pose a significant threat that is publicly discussed on social media. This study presents a comparison of user-generated content related to security vulnerabilities on three digital platforms: two social media conversation channels (Reddit and Twitter) and a collaborative software development platform (GitHub). Our data analysis shows that while more security vulnerabilities are discussed on Twitter, relevant conversations go viral earlier on Reddit. We show that the two social media platforms can be used to accurately predict activity on GitHub. 	https://doi.org/10.1145/3350546.3352519
83	Thung, Ferdian and Bissyande, Tegawende F. and Lo, David and Jiang, Lingxiao	Network Structure of Social Coding in GitHub	10.1109/CSMR.2013.41	2013	Social coding enables a different experience of software development as the activities and interests of one developer are easily advertised to other developers. Developers can thus track the activities relevant to various projects in one umbrella site. Such a major change in collaborative software development makes an investigation of networkings on social coding sites valuable. Furthermore, project hosting platforms promoting this development paradigm have been thriving, among which GitHub has arguably gained the most momentum. In this paper, we contribute to the body of knowledge on social coding by investigating the network structure of social coding in GitHub. We collect 100,000 projects and 30,000 developers from GitHub, construct developer-developer and project-project relationship graphs, and compute various characteristics of the graphs. We then identify influential developers and projects on this sub network of GitHub by using PageRank. Understanding how developers and projects are actually related to each other on a social coding site is the first step towards building tool supports to aid social programmers in performing their tasks more efficiently.	https://doi.org/10.1109/CSMR.2013.41
108	Lowe-Power, Jason and Nitta, Christopher	The Davis In-Order (DINO) CPU: A Teaching-Focused RISC-V CPU Design	10.1145/3338698.3338892	2019	The DINO CPU is an open source teaching-focused RISC-V CPU design available on GitHub (https://github.com/jlpteaching/dinocpu). We have used the DINO CPU in the computer architecture course at UC Davis for two quarters with two separate instructors. In this paper, we present details of the DINO CPU, the tools included with the DINO CPU, and our experiences using the DINO CPU.	https://doi.org/10.1145/3338698.3338892
84	Wang, Zhendong and Wang, Yi and Redmiles, David	Competence-Confidence Gap: A Threat to Female Developers' Contribution on Github	10.1145/3183428.3183437	2018	On GitHub, contributing to a new project is crucial for a developer to gain personal growth and maximize impact in the community. It is known that female developers are often hesitant to explore the opportunities to contribute to new projects even when they possess the competence to make valuable contributions. Drawing from the literature of the competence-confidence gap, we develop a fresh explanation for this phenomenon. We validate the theoretical explanation through an empirical study using GitHub's historical data. In this study, we identify all female developers ranking in top 5,000 GitHub users. Using the Granger Causality Test, we find that, for the majority of identified female developers, initiating a pull request to a new repository is "Granger" caused by the quick increase of followers in the preceding couple of weeks. For most male developers, our observations show that their new pull requests have no relationship with the dynamics of follower numbers. The results indicate that the competence-confidence gap is a threat to female developers' contribution on GitHub. The research suggests that helping female developers to overcome the competence-confidence gap is critical for encouraging female's contribution open source development, as well as growing their reputations and impacts in the community.	https://doi.org/10.1145/3183428.3183437
85	Gu, Xiaodong and Zhang, Hongyu and Zhang, Dongmei and Kim, Sunghun	Deep API Learning	10.1145/2950290.2950334	2016	Developers often wonder how to implement a certain functionality (e.g., how to parse XML files) using APIs. Obtaining an API usage sequence based on an API-related natural language query is very helpful in this regard. Given a query, existing approaches utilize information retrieval models to search for matching API sequences. These approaches treat queries and APIs as bags-of-words and lack a deep understanding of the semantics of the query. We propose DeepAPI, a deep learning based approach to generate API usage sequences for a given natural language query. Instead of a bag-of-words assumption, it learns the sequence of words in a query and the sequence of associated APIs. DeepAPI adapts a neural language model named RNN Encoder-Decoder. It encodes a word sequence (user query) into a fixed-length context vector, and generates an API sequence based on the context vector. We also augment the RNN Encoder-Decoder by considering the importance of individual APIs. We empirically evaluate our approach with more than 7 million annotated code snippets collected from GitHub. The results show that our approach generates largely accurate API sequences and outperforms the related approaches. 	https://doi.org/10.1145/2950290.2950334
86	Steinberg, Boris and Baglij, Anton and Petrenko, Victor and Burkhovetskiy, Victor and Steinberg, Oleg and Metelica, Elena	An Analyzer for Program Parallelization and Optimization	10.1145/3274856.3274875	2018	The article describes new facilities for program optimization and parallelization, work-in-progress modifications of previously implemented program transformations and compiler libraries, and future development of Optimizing parallelizing system (OPS) including opening its source code on GitHub. These new facilities, such as dialog-based optimization and parallelization, user-friendly program dependency visualization (which is needed for high-quality analyzers), parallel code generation for accelerators (GPUs, DSPs, FPGAs, or high performance clusters), are made possible by the fact, that OPS uses high-level intermediate representation as opposed to low-level intermediate representation used in popular compilers.	https://doi.org/10.1145/3274856.3274875
87	Beller, Moritz and Gousios, Georgios and Zaidman, Andy	TravisTorrent: Synthesizing Travis CI and GitHub for Full-Stack Research on Continuous Integration	10.1109/MSR.2017.24	2017	Continuous Integration (CI) has become a best practice of modern software development. Thanks in part to its tight integration with GitHub, Travis CI has emerged as arguably the most widely used CI platform for Open-Source Software (OSS) development. However, despite its prominent role in Software Engineering in practice, the benefits, costs, and implications of doing CI are all but clear from an academic standpoint. Little research has been done, and even less was of quantitative nature. In order to lay the groundwork for data-driven research on CI, we built TravisTorrent, travistorrent.testroots.org, a freely available data set based on Travis CI and GitHub that provides easy access to hundreds of thousands of analyzed builds from more than 1,000 projects. Unique to TravisTorrent is that each of its 2,640,825 Travis builds is synthesized with meta data from Travis CI's API, the results of analyzing its textual build log, a link to the GitHub commit which triggered the build, and dynamically aggregated project data from the time of commit extracted through GHTorrent.	https://doi.org/10.1109/MSR.2017.24
88	Basios, Michail and Li, Lingbo and Wu, Fan and Kanthan, Leslie and Barr, Earl T.	Darwinian Data Structure Selection	10.1145/3236024.3236043	2018	Data structure selection and tuning is laborious but can vastly improve an application’s performance and memory footprint. Some data structures share a common interface and enjoy multiple implementations. We call them Darwinian Data Structures (DDS), since we can subject their implementations to survival of the fittest. We introduce ARTEMIS a multi-objective, cloud-based search-based optimisation framework that automatically finds optimal, tuned DDS modulo a test suite, then changes an application to use that DDS. ARTEMIS achieves substantial performance improvements for every project in 5 Java projects from DaCapo benchmark, 8 popular projects and 30 uniformly sampled projects from GitHub. For execution time, CPU usage, and memory consumption, ARTEMIS finds at least one solution that improves all measures for 86% (37/43) of the projects. The median improvement across the best solutions is 4.8%, 10.1%, 5.1% for runtime, memory and CPU usage. These aggregate results understate ARTEMIS’s potential impact. Some of the benchmarks it improves are libraries or utility functions. Two examples are gson, a ubiquitous Java serialization framework, and xalan, Apache’s XML transformation tool. ARTEMIS improves gson by 16.5%, 1% and 2.2% for memory, runtime, and CPU; ARTEMIS improves xalan’s memory consumption by 23.5%. Every client of these projects will benefit from these performance improvements.	https://doi.org/10.1145/3236024.3236043
89	Dhasade, Akash Balasaheb and Venigalla, Akhila Sri Manasa and Chimalakonda, Sridhar	Towards Prioritizing GitHub Issues	10.1145/3385032.3385052	2020	The vast growth in usage of GitHub by developers to host their projects has led to extensive forking and open source contributions. These contributions occur in the form of issues that report bugs or pull requests to either fix bugs or add new features to the project. On the other hand, massive increase in the number of issues reported by developers and users is a major challenge for integrators, as the number of concurrent issues to be handled is much higher than the number of core contributors. While there exists prior work on prioritizing pull requests, in this paper we make an attempt towards prioritizing issues using machine learning techniques. We present the Issue Prioritizer, a tool to prioritize issues based on three criteria: issue lifetime, issue hotness and category of the issue. We see this work as an initial step towards supporting developers to handle large volumes of issues in projects.	https://doi.org/10.1145/3385032.3385052
91	Shao, Huajie and Sun, Dachun and Wu, Jiahao and Zhang, Zecheng and Zhang, Aston and Yao, Shuochao and Liu, Shengzhong and Wang, Tianshi and Zhang, Chao and Abdelzaher, Tarek	Paper2repo: GitHub Repository Recommendation for Academic Papers	10.1145/3366423.3380145	2020	GitHub has become a popular social application platform, where a large number of users post their open source projects. In particular, an increasing number of researchers release repositories of source code related to their research papers in order to attract more people to follow their work. Motivated by this trend, we describe a novel item-item cross-platform recommender system, paper2repo, that recommends relevant repositories on GitHub that match a given paper in an academic search system such as Microsoft Academic. The key challenge is to identify the similarity between an input paper and its related repositories across the two platforms, without the benefit of human labeling. Towards that end, paper2repo integrates text encoding and constrained graph convolutional networks (GCN) to automatically learn and map the embeddings of papers and repositories into the same space, where proximity offers the basis for recommendation. To make our method more practical in real life systems, labels used for model training are computed automatically from features of user actions on GitHub. In machine learning, such automatic labeling is often called distant supervision. To the authors’ knowledge, this is the first distant-supervised cross-platform (paper to repository) matching system. We evaluate the performance of paper2repo on real-world data sets collected from GitHub and Microsoft Academic. Results demonstrate that it outperforms other state of the art recommendation methods.	https://doi.org/10.1145/3366423.3380145
92	Wang, Jiawei and Li, Li and Liu, Kui and Cai, Haipeng	Exploring How Deprecated Python Library APIs Are (Not) Handled	10.1145/3368089.3409735	2020	In this paper, we present the first exploratory study of deprecated Python library APIs to understand the status quo of API deprecation in the realm of Python libraries. Specifically, we aim to comprehend how deprecated library APIs are declared and documented in practice by their maintainers, and how library users react to them. By thoroughly looking into six reputed Python libraries and 1,200 GitHub projects, we experimentally observe that API deprecation is poorly handled by library contributors, which subsequently introduce difficulties for Python developers to resolve the usage of deprecated library APIs. This empirical evidence suggests that our community should take immediate actions to appropriately handle the deprecation of Python library APIs.	https://doi.org/10.1145/3368089.3409735
93	Cosentino, Valerio and Luis, Javier and Cabot, Jordi	Findings from GitHub: Methods, Datasets and Limitations	10.1145/2901739.2901776	2016	GitHub, one of the most popular social coding platforms, is the platform of reference when mining Open Source repositories to learn from past experiences. In the last years, a number of research papers have been published reporting findings based on data mined from GitHub. As the community continues to deepen in its understanding of software engineering thanks to the analysis performed on this platform, we believe it is worthwhile to reflect how research papers have addressed the task of mining GitHub repositories over the last years. In this regard, we present a meta-analysis of 93 research papers which addresses three main dimensions of those papers: i) the empirical methods employed, ii) the datasets they used and iii) the limitations reported. Results of our meta-analysis show some concerns regarding the dataset collection process and size, the low level of replicability, poor sampling techniques, lack of longitudinal studies and scarce variety of methodologies.	https://doi.org/10.1145/2901739.2901776
94	Vasilescu, Bogdan and Schuylenburg, Stef van and Wulms, Jules and Serebrenik, Alexander and Brand, Mark G. J. van den	Continuous Integration in a Social-Coding World: Empirical Evidence from GitHub	10.1109/ICSME.2014.62	2014	Continuous integration is a software engineering practice of frequently merging all developer working copies with a shared main branch, e.g., several times a day. With the advent of GitHub, a platform well known for its "social coding" features that aid collaboration and sharing, and currently the largest code host in the open source world, collaborative software development has never been more prominent. In GitHub development one can distinguish between two types of developer contributions to a project: direct ones, coming from a typically small group of developers with write access to the main project repository, and indirect ones, coming from developers who fork the main repository, update their copies locally, and submit pull requests for review and merger. In this paper we explore how GitHub developers use continuous integration as well as whether the contribution type (direct versus indirect) and different project characteristics (e.g., main programming language, or project age) are associated with the success of the automatic builds.	https://doi.org/10.1109/ICSME.2014.62
95	Vandenbogaerde, Bram	A Graph-Based Framework for Analysing the Design of Smart Contracts	10.1145/3338906.3342495	2019	Used as a platform for executing smart contracts, Blockchain technology has yielded new programming languages. We propose a graph-based framework for computing software design metrics for the Solidity programming language, and use this framework in a preliminary study on 505 smart contracts mined from GitHub. The results show that most of the smart contracts are rather straightforward from an objected-oriented point of view and that new design metrics specific to smart contracts should be developed.	https://doi.org/10.1145/3338906.3342495
96	Zampetti, Fiorella and Scalabrino, Simone and Oliveto, Rocco and Canfora, Gerardo and Di Penta, Massimiliano	How Open Source Projects Use Static Code Analysis Tools in Continuous Integration Pipelines	10.1109/MSR.2017.2	2017	Static analysis tools are often used by software developers to entail early detection of potential faults, vulnerabilities, code smells, or to assess the source code adherence to coding standards and guidelines. Also, their adoption within Continuous Integration (CI) pipelines has been advocated by researchers and practitioners. This paper studies the usage of static analysis tools in 20 Java open source projects hosted on GitHub and using Travis CI as continuous integration infrastructure. Specifically, we investigate (i) which tools are being used and how they are configured for the CI, (ii) what types of issues make the build fail or raise warnings, and (iii) whether, how, and after how long are broken builds and warnings resolved. Results indicate that in the analyzed projects build breakages due to static analysis tools are mainly related to adherence to coding standards, and there is also some attention to missing licenses. Build failures related to tools identifying potential bugs or vulnerabilities occur less frequently, and in some cases such tools are activated in a "softer" mode, without making the build fail. Also, the study reveals that build breakages due to static analysis tools are quickly fixed by actually solving the problem, rather than by disabling the warning, and are often properly documented.	https://doi.org/10.1109/MSR.2017.2
97	Cohen, Eldan and Consens, Mariano P.	Large-Scale Analysis of the Co-Commit Patterns of the Active Developers in Github's Top Repositories	10.1145/3196398.3196436	2018	GitHub, the largest code hosting site (with 25 million public active repositories and contributions from 6 million active users), provides an unprecedented opportunity to observe the collaboration patterns of software developers. Understanding the patterns behind the social coding phenomena is an active research area where the insights gained can guide the design of better collaboration tools, and can also help to identify and select developer talent. In this paper, we present a large-scale analysis of the co-commit patterns in GitHub. We analyze 10 million commits made by 200 thousand developers to 16 thousand repositories, using 17 of the most popular programming languages over a period of 3 years. Although a large volume of data is included in our study, we pay close attention to the participation criteria for repositories and developers. We select repositories by reputation (based on star ranking), and we introduce the notion of active developer in GitHub (observing that a limited subset of developers is responsible for the vast majority of the commits). Using co-authorship networks, we analyze the co-commit patterns of the active developer network for each programming language. We observe that the active developer networks are less connected and more centralized than the general GitHub developer networks, and that the patterns vary significantly among languages. We compare our results to other collaborative environments (Wikipedia and scientific research networks), and we also describe the evolution of the co-commit patterns over time.	https://doi.org/10.1145/3196398.3196436
98	Wang, Peipei and Brown, Chris and Jennings, Jamie A. and Stolee, Kathryn T.	An Empirical Study on Regular Expression Bugs	10.1145/3379597.3387464	2020	Understanding the nature of regular expression (regex) issues is important to tackle practical issues developers face in regular expression usage. Knowledge about the nature and frequency of various types of regular expression issues, such as those related to performance, API misuse, and code smells, can guide testing, inform documentation writers, and motivate refactoring efforts. However, beyond ReDoS (Regular expression Denial of Service), little is known about to what extent regular expression issues affect software development and how these issues are addressed in practice.This paper presents a comprehensive empirical study of 350 merged regex-related pull requests from Apache, Mozilla, Facebook, and Google GitHub repositories. Through classifying the root causes and manifestations of those bugs, we show that incorrect regular expression behavior is the dominant root cause of regular expression bugs (165/356, 46.3%). The remaining root causes are incorrect API usage (9.3%) and other code issues that require regular expression changes in the fix (29.5%). By studying the code changes of regex-related pull requests, we observe that fixing regular expression bugs is nontrivial as it takes more time and more lines of code to fix them compared to the general pull requests. The results of this study contribute to a broader understanding of the practical problems faced by developers when using regular expressions.	https://doi.org/10.1145/3379597.3387464
99	Walsh, Thomas A. and Kapfhammer, Gregory M. and McMinn, Phil	ReDeCheck: An Automatic Layout Failure Checking Tool for Responsively Designed Web Pages	10.1145/3092703.3098221	2017	Since people frequently access websites with a wide variety of devices (e.g., mobile phones, laptops, and desktops), developers need frameworks and tools for creating layouts that are useful at many viewport widths. While responsive web design (RWD) principles and frameworks facilitate the development of such sites, there is a lack of tools supporting the detection of failures in their layout. Since the quality assurance process for responsively designed websites is often manual, time-consuming, and error-prone, this paper presents ReDeCheck, an automated layout checking tool that alerts developers to both potential unintended regressions in responsive layout and common types of layout failure. In addition to summarizing ReDeCheck’s benefits, this paper explores two different usage scenarios for this tool that is publicly available on GitHub. 	https://doi.org/10.1145/3092703.3098221
100	Zhang, Tianyi and Yang, Di and Lopes, Crista and Kim, Miryung	Analyzing and Supporting Adaptation of Online Code Examples	10.1109/ICSE.2019.00046	2019	Developers often resort to online Q&amp;A forums such as Stack Overflow (SO) for filling their programming needs. Although code examples on those forums are good starting points, they are often incomplete and inadequate for developers' local program contexts; adaptation of those examples is necessary to integrate them to production code. As a consequence, the process of adapting online code examples is done over and over again, by multiple developers independently. Our work extensively studies these adaptations and variations, serving as the basis for a tool that helps integrate these online code examples in a target context in an interactive manner.We perform a large-scale empirical study about the nature and extent of adaptations and variations of SO snippets. We construct a comprehensive dataset linking SO posts to GitHub counterparts based on clone detection, time stamp analysis, and explicit URL references. We then qualitatively inspect 400 SO examples and their GitHub counterparts and develop a taxonomy of 24 adaptation types. Using this taxonomy, we build an automated adaptation analysis technique on top of GumTree to classify the entire dataset into these types. We build a Chrome extension called ExampleStack that automatically lifts an adaptation-aware template from each SO example and its GitHub counterparts to identify hot spots where most changes happen. A user study with sixteen programmers shows that seeing the commonalities and variations in similar GitHub counterparts increases their confidence about the given SO example, and helps them grasp a more comprehensive view about how to reuse the example differently and avoid common pitfalls.	https://doi.org/10.1109/ICSE.2019.00046
101	Imtiaz, Nasif and Middleton, Justin and Chakraborty, Joymallya and Robson, Neill and Bai, Gina and Murphy-Hill, Emerson	Investigating the Effects of Gender Bias on GitHub	10.1109/ICSE.2019.00079	2019	Diversity, including gender diversity, is valued by many software development organizations, yet the field remains dominated by men. One reason for this lack of diversity is gender bias. In this paper, we study the effects of that bias by using an existing framework derived from the gender studies literature. We adapt the four main effects proposed in the framework by posing hypotheses about how they might manifest on GitHub, then evaluate those hypotheses quantitatively. While our results show that effects of gender bias are largely invisible on the GitHub platform itself, there are still signals of women concentrating their work in fewer places and being more restrained in communication than men.	https://doi.org/10.1109/ICSE.2019.00079
102	Yu, Yue and Li, Zhixing and Yin, Gang and Wang, Tao and Wang, Huaimin	A Dataset of Duplicate Pull-Requests in Github	10.1145/3196398.3196455	2018	In GitHub, the pull-based development model enables community contributors to collaborate in a more efficient way. However, the distributed and parallel characteristics of this model pose a potential risk for developers to submit duplicate pull-requests (PRs), which increase the extra cost of project maintenance. To facilitate the further studies to better understand and solve the issues introduced by duplicate PRs, we construct a large dataset of historical duplicate PRs extracted from 26 popular open source projects in GitHub by using a semi-automatic approach. Furthermore, we present some preliminary applications to illustrate how further researches can be conducted based on this dataset.	https://doi.org/10.1145/3196398.3196455
103	Rahman, Mohammad Masudur and Roy, Chanchal K.	On the Use of Context in Recommending Exception Handling Code Examples	10.1109/SCAM.2014.15	2014	Studies show that software developers often either misuse exception handling features or use them inefficiently, and such a practice may lead an undergoing software project to a fragile, insecure and non-robust application system. In this paper, we propose a context-aware code recommendation approach that recommends exception handling code examples from a number of popular open source code repositories hosted at GitHub. It collects the code examples exploiting GitHub code search API, and then analyzes, filters and ranks them against the code under development in the IDE by leveraging not only the structural (i.e., graph-based) and lexical features but also the heuristic quality measures of exception handlers in the examples. Experiments with 4,400 code examples and 65 exception handling scenarios as well as comparisons with four existing approaches show that the proposed approach is highly promising.	https://doi.org/10.1109/SCAM.2014.15
104	Wu, Yiwen and Zhang, Yang and Wang, Tao and Wang, Huaimin	Exploring the Relationship Between Developer Activities and Profile Images on GitHub	10.1145/3361242.3361244	2019	In the GitHub platform, social media profile images are one of many visual components of developers. Besides, developer activities such as reporting issues or following other developers are regarded as important development and self-expression behaviors. However, to the best of our knowledge, no study has yet been conducted to study the relationship between GitHub developer activities and profile images. In this paper, we aim to investigate the relationship between developer activities and profile images to gain some insights into the developers' internal properties. During our experiments, we manually classify profile images into seven categories. Next, we investigate the relationship between developer's demographic information and developer activity. Further, using logistic regression analysis, when controlled for various variables, we statistically identify and quantify the relationships between developer activities and profile image categories. We find that several profile image categories significantly correlate with developer's demographic information and activities. We also provide a rich resource of research ideas for further study. Our examination and analysis provide insights into the developers' internal properties when using different profile images. Moreover, this study is the first step in understanding the relationship between developer activities and profile images on GitHub.	https://doi.org/10.1145/3361242.3361244
105	Chen, Di and Stolee, Kathryn T. and Menzies, Tim	Replication Can Improve Prior Results: A GitHub Study of Pull Request Acceptance	10.1109/ICPC.2019.00037	2019	Crowdsourcing and data mining can be used to effectively reduce the effort associated with the partial replication and enhancement of qualitative studies.For example, in a primary study, other researchers explored factors influencing the fate of GitHub pull requests using an extensive qualitative analysis of 20 pull requests. Guided by their findings, we mapped some of their qualitative insights onto quantitative questions. To determine how well their findings generalize, we collected much more data (170 additional pull requests from 142 GitHub projects). Using crowdsourcing, that data was augmented with subjective qualitative human opinions about how pull requests extended the original issue. The crowd's answers were then combined with quantitative features and, using data mining, used to build a predictor for whether code would be merged. That predictor was far more accurate than the one built from the primary study's qualitative factors (F1=90 vs 68%), illustrating the value of a mixed-methods approach and replication to improve prior results.To test the generality of this approach, the next step in future work is to conduct other studies that extend qualitative studies with crowdsourcing and data mining.	https://doi.org/10.1109/ICPC.2019.00037
106	Cuculovic, Milos and Fondement, Frederic and Devanne, Maxime and Weber, Jonathan and Hassenforder, Michel	Change Detection on JATS Academic Articles: An XML Diff Comparison Study	10.1145/3395027.3419581	2020	XML is currently a well established and widely used document format. It is used as a core data container in collaborative writing suites and other modern information architectures. The extraction and analysis of differences between two XML document versions is an attractive topic, and has already been tackled by several research groups. The goal of this study is to compare 12 existing state-of-the-art and commercial XML diff algorithms by applying them to JATS documents in order to extract and evaluate changes between two versions of the same academic article. Understanding changes between two article versions is important not only regarding data, but also semantics. Change information consumers in our case are editorial teams, and thus they are more generally interested in change semantics than in the exact data changes. The existing algorithms are evaluated on the following aspects: their edit detection suitability for both text and tree changes, execution speed, memory usage and delta file size. The evaluation process is supported by a Python tool available on Github.	https://doi.org/10.1145/3395027.3419581
107	Mattis, Toni and Rein, Patrick and Hirschfeld, Robert	Three Trillion Lines: Infrastructure for Mining GitHub in the Classroom	10.1145/3397537.3397551	2020	The increasing interest in collaborative software development on platforms like GitHub has led to the availability of large amounts of data about development activities. The GHTorrent project has recorded a significant proportion of GitHub’s public event stream and hosts the currently largest public dataset of meta-data about open-source development. We describe our infrastructure that makes this data locally available to researchers and students, examples for research activities carried out on this infrastructure, and what we learned from building the system. We identify a need for domain-specific tools, especially databases, that can deal with large-scale code repositories and associated meta-data and outline open challenges to use them more effectively for research and machine learning settings.	https://doi.org/10.1145/3397537.3397551
109	Rak-amnouykit, Ingkarat and McCrevan, Daniel and Milanova, Ana and Hirzel, Martin and Dolby, Julian	Python 3 Types in the Wild: A Tale of Two Type Systems	10.1145/3426422.3426981	2020	Python 3 is a highly dynamic language, but it has introduced a syntax for expressing types with PEP484. This paper explores how developers use these type annotations, the type system semantics provided by type checking and inference tools, and the performance of these tools. We evaluate the types and tools on a corpus of public GitHub repositories. We review MyPy and PyType, two canonical static type checking and inference tools, and their distinct approaches to type analysis. We then address three research questions: (i) How often and in what ways do developers use Python 3 types? (ii) Which type errors do developers make? (iii) How do type errors from different tools compare?  Surprisingly, when developers use static types, the code rarely type-checks with either of the tools. MyPy and PyType exhibit false positives, due to their static nature, but also flag many useful errors in our corpus. Lastly, MyPy and PyType embody two distinct type systems, flagging different errors in many cases. Understanding the usage of Python types can help guide tool-builders and researchers. Understanding the performance of popular tools can help increase the adoption of static types and tools by practitioners, ultimately leading to more correct and more robust Python code.	https://doi.org/10.1145/3426422.3426981
110	Yang, Di and Martins, Pedro and Saini, Vaibhav and Lopes, Cristina	Stack Overflow in Github: Any Snippets There?	10.1109/MSR.2017.13	2017	When programmers look for how to achieve certain programming tasks, Stack Overflow is a popular destination in search engine results. Over the years, Stack Overflow has accumulated an impressive knowledge base of snippets of code that are amply documented. We are interested in studying how programmers use these snippets of code in their projects. Can we find Stack Overflow snippets in real projects? When snippets are used, is this copy literal or does it suffer adaptations? And are these adaptations specializations required by the idiosyncrasies of the target artifact, or are they motivated by specific requirements of the programmer? The large-scale study presented on this paper analyzes 909k non-fork Python projects hosted on Github, which contain 290M function definitions, and 1.9M Python snippets captured in Stack Overflow. Results are presented as quantitative analysis of block-level code cloning intra and inter Stack Overflow and GitHub, and as an analysis of programming behaviors through the qualitative analysis of our findings.	https://doi.org/10.1109/MSR.2017.13
111	Brady, James F.	Computing System Congestion Management Using Exponential Smoothing Forecasting	10.1145/3388142.3388146	2020	An overloaded computer must finish what it starts and not start what will fail or hang. A congestion management algorithm, the author developed, effectively manages traffic overload with its unique formulation of Exponential Smoothing forecasting. This set of equations resolve forecasting startup issues that have limited the model's adoption as a discrete time series predictor. These expressions also satisfy implementation requirements to perform calculations using integer math and be able to reset the forecast seamlessly. A computer program, written in C language, which exercises the methodology, is downloadable from GitHub.	https://doi.org/10.1145/3388142.3388146
112	Liu, Renhao and Mubang, Frederick and Hall, Lawrence O. and Horawalavithana, Sameera and Iamnitchi, Adriana and Skvoretz, John	Predicting Longitudinal User Activity at Fine Time Granularity in Online Collaborative Platforms	10.1109/SMC.2019.8914586	2019	This paper introduces a decomposition approach to address the problem of predicting different user activities at hour granularity over a long period of time. Our approach involves two steps. First, we used a temporal neural network ensemble to predict the number of each type of activity that occurred in a day. Second, we used a set of neural networks to assign the events to a user-repository pair in a particular hour. We focused this work on a subset of the public GitHub dataset that records the activities of over 2 million users on over 400,000 software repositories. Our experiments show we were able to predict hourly user-repo activity with reasonably low error. Our simulations are accurate for 1–3 weeks (168–504 hours) after inception, with accuracy gradually falling off. It was shown that activity on Twitter and Reddit increases the accuracy of activity prediction on GitHub for most events.	https://doi.org/10.1109/SMC.2019.8914586
113	Oosterwaal, Sebastiaan and Deursen, Arie van and Coelho, Roberta and Sawant, Anand Ashok and Bacchelli, Alberto	Visualizing Code and Coverage Changes for Code Review	10.1145/2950290.2983929	2016	One of the tasks of reviewers is to verify that code modifications are well tested. However, current tools offer little support in understanding precisely how changes to the code relate to changes to the tests. In particular, it is hard to see whether (modified) test code covers the changed code. To mitigate this problem, we developed Operias, a tool that provides a combined visualization of fine-grained source code differences and coverage impact. Operias works both as a stand-alone tool on specific project versions and as a service hooked to GitHub. In the latter case, it provides automated reports for each new pull request, which reviewers can use to assess the code contribution. Operias works for any Java project that works with maven and its standard Cobertura coverage plugin. We present how Operias could be used to identify test-related problems in real-world pull requests. Operias is open source and available on GitHub with a demo video: https://github.com/SERG-Delft/operias 	https://doi.org/10.1145/2950290.2983929
114	Raman, Naveen and Cao, Minxuan and Tsvetkov, Yulia and K\\"astner, Christian and Vasilescu, Bogdan	Stress and Burnout in Open Source: Toward Finding, Understanding, and Mitigating Unhealthy Interactions	10.1145/3377816.3381732	2020	Developers from open-source communities have reported high stress levels from frequent demands for features and bug fixes and from the sometimes aggressive tone of these demands. Toxic conversations may demotivate and burn out developers, creating challenges for sustaining open source. We outline a path toward finding, understanding, and possibly mitigating such unhealthy interactions. We take a first step toward finding them, by developing and demonstrating a measurement instrument (an SVM classifier tailored for software engineering) to detect toxic discussions in GitHub issues. We used our classifier to analyze trends over time and in different GitHub communities, finding that toxicity varies by community and that toxicity decreased between 2012 and 2018.	https://doi.org/10.1145/3377816.3381732
126	Shakya, Raunak and Rahman, Akond	A Preliminary Taxonomy of Techniques Used in Software Fuzzing	10.1145/3384217.3384219	2020	Software fuzzing is a testing technique, which generates erroneous and random input to a software so that the software of interest can be monitored for exceptions such as crashes [1]. Both in the open source software (OSS) and proprietary domain, fuzzing has been widely used to explore software vulnerabilities. For example, information technology (IT) organizations such as Google1 and Microsoft2 use software fuzzing as part of the software development process. As of Jan 2019, GitHub hosts 2,915 OSS repositories related to fuzzing3.	https://doi.org/10.1145/3384217.3384219
115	Chen, Zhenpeng and Cao, Yanbin and Lu, Xuan and Mei, Qiaozhu and Liu, Xuanzhe	SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering	10.1145/3338906.3338977	2019	Sentiment analysis has various application scenarios in software engineering (SE), such as detecting developers' emotions in commit messages and identifying their opinions on Q&amp;A forums. However, commonly used out-of-the-box sentiment analysis tools cannot obtain reliable results on SE tasks and the misunderstanding of technical jargon is demonstrated to be the main reason. Then, researchers have to utilize labeled SE-related texts to customize sentiment analysis for SE tasks via a variety of algorithms. However, the scarce labeled data can cover only very limited expressions and thus cannot guarantee the analysis quality. To address such a problem, we turn to the easily available emoji usage data for help. More specifically, we employ emotional emojis as noisy labels of sentiments and propose a representation learning approach that uses both Tweets and GitHub posts containing emojis to learn sentiment-aware representations for SE-related texts. These emoji-labeled posts can not only supply the technical jargon, but also incorporate more general sentiment patterns shared across domains. They as well as labeled data are used to learn the final sentiment classifier. Compared to the existing sentiment analysis methods used in SE, the proposed approach can achieve significant improvement on representative benchmark datasets. By further contrast experiments, we find that the Tweets make a key contribution to the power of our approach. This finding informs future research not to unilaterally pursue the domain-specific resource, but try to transform knowledge from the open domain through ubiquitous signals such as emojis.	https://doi.org/10.1145/3338906.3338977
116	Rastogi, Ayushi	Do Biases Related to Geographical Location Influence Work-Related Decisions in GitHub?	10.1145/2889160.2891035	2016	Visible demographic characteristics are seen as elements of bias in offline work environments. In this study, we investigate the influence of the geographical location on the evaluation of pull requests in GitHub -- the most popular online collaborative code development environment. We use a mixed-methods approach and present analyses of 70,000+ pull requests and 2,500+ survey responses. Quantitative analysis of GitHub projects' data suggests that the geographical location significantly explains the pull request acceptance decisions. These observations are in agreement with the perceptions of submitters based on their experiences with bias. Integrators feel that it is easy to work with contributors from the same geographical location and that they encourage contributors from the same geographical location. However, integrators do not feel that contributors from some countries are better at writing pull requests compared to others.	https://doi.org/10.1145/2889160.2891035
117	Huang, Kaifeng and Chen, Bihuan and Shi, Bowen and Wang, Ying and Xu, Congying and Peng, Xin	Interactive, Effort-Aware Library Version Harmonization	10.1145/3368089.3409689	2020	As a mixed result of intensive dependency on third-party libraries, flexible mechanisms to declare dependencies and increased number of modules in a project, different modules of a project directly depend on multiple versions of the same third-party library. Such library version inconsistencies could increase dependency maintenance cost, or even lead to dependency conflicts when modules are inter-dependent. Although automated build tools (e.g., Maven's enforcer plugin) provide partial support to detect library version inconsistencies, they do not provide any support to harmonize inconsistent library versions.  We first conduct a survey with 131 Java developers from GitHub to retrieve first-hand information about the root causes, detection methods, reasons for fixing or not fixing, fixing strategies, fixing efforts, and tool expectations on library version inconsistencies. Then, based on the insights from our survey, we propose LibHarmo, an interactive, effort-aware library version harmonization technique, to detect library version inconsistencies, interactively suggest a harmonized version with the least harmonization efforts based on library API usage analysis, and refactor build configuration files.  LibHarmo is currently developed for Java Maven projects. Our experimental study on 443 highly-starred Java Maven projects from GitHub shows that i) LibHarmo detected 621 library version inconsistencies in 152 (34.3%) projects with a false positive rate of 16.8%, while Maven's enforcer plugin only detected 219 of them; and ii) LibHarmo saved 87.5% of the harmonization efforts. Further, 31 library version inconsistencies have been confirmed, and 17 of them have been already harmonized by developers.	https://doi.org/10.1145/3368089.3409689
118	Fazzolino, Rafael and Rodrigues, Gena\\'\\ina Nunes	Feature-Trace: Generating Operational Profile and Supporting Testing Prioritization from BDD Features	10.1145/3350768.3350781	2019	Operational Profiles provide quantitative information about how the software will be used, which supports highlighting those software components more sensitive to reliability based on their profile usage. However, the generation of Operational Profiles usually requires a considerable team effort to liaise requirements specification until their reification into expected software artifacts. In this sense, it becomes paramount in the software life cycle the ability to seamlessly or efficiently perform traceability from requirement to code, embracing the testing process as a means to ensure that the requirements are satisfiably covered and addressed. In this work, we propose the Feature-Trace approach which merges the advantages of the Operational Profile and the benefits of the requirements-to-code traceability present in the BDD (Behavior-Driven Development) approach. The primary goal of our work is to use the BDD approach as an information source for the semi-automated generation of the Operational Profile. The proposed approach was evaluated on the Diaspora software, on a GitHub open source software. The case study revealed that the Feature-Trace approach is capable of extracting the operational profile seamlessly from the specified Diaspora's BDD features as well as obtaining and presenting vital information to guide the process of test cases prioritization.	https://doi.org/10.1145/3350768.3350781
119	Lee, Roy Ka-Wei and Hoang, Thong and Oentaryo, Richard J. and Lo, David	Keen2Act: Activity Recommendation in Online Social Collaborative Platforms	10.1145/3340631.3394884	2020	Social collaborative platforms such as GitHub and Stack Overflow have been increasingly used to improve work productivity via collaborative efforts. To improve user experiences in these platforms, it is desirable to have a recommender system that can suggest not only items (e.g., a GitHub repository) to a user, but also activities to be performed on the suggested items (e.g., forking a repository). To this end, we propose a new approach dubbed Keen2Act, which decomposes the recommendation problem into two stages: the Keen and Act steps. The Keen step identifies, for a given user, a (sub)set of items in which he/she is likely to be interested. The Act step then recommends to the user which activities to perform on the identified set of items. This decomposition provides a practical approach to tackling complex activity recommendation tasks while producing higher recommendation quality. We evaluate our proposed approach using two real-world datasets and obtain promising results whereby Keen2Act outperforms several baseline models.	https://doi.org/10.1145/3340631.3394884
120	Janes, Andrea and Mairegger, Michael and Russo, Barbara	Code_call_lens: Raising the Developer Awareness of Critical Code	10.1145/3238147.3240488	2018	As a developer, it is often complex to foresee the impact of changes in source code on usage, e.g., it is time-consuming to find out all components that will be impacted by a change or estimate the impact on the usability of a failing piece of code. It is therefore hard to decide how much effort in quality assurance is justifiable to obtain the desired business goals. In this paper, to reduce the difficulty for developers to understand the importance of source code, we propose an automated way to provide this information to developers as they are working on a given piece of code. As a proof-of-concept, we developed a plug-in for Microsoft Visual Studio Code that informs about the importance of source code methods based on the frequency of usage by the end-users of the developed software. The plug-in aims to increase the awareness developers have about the importance of source code in an unobtrusive way, helping them to prioritize their effort to quality assurance, technical excellence, and usability. code_call_lens can be downloaded from GitHub at https://github.com/xxMUROxx/vscode.code_call_lens.	https://doi.org/10.1145/3238147.3240488
121	Cruz, Guilherme A. Maldonado da and Huzita, Elisa Hatsue Moriya and Feltrim, Val\\'eria D.	Estimating Trust in Virtual Teams	10.5220/0005830604640471	2016	The advance in technology has enabled the emergence of virtual teams. In these teams, people are in different places and possibly over different time zones, making use of computer mediated communication. At the same time distribution brings benefits, there are some challenges as the difficulty to develop trust, which is essential for efficiency in these teams. In this scenario, trust information could be used to allocate members in a new team and/or, to monitor them during the project execution. In this paper we present an automatic framework for detecting trust between members of global software development teams using sentiment analysis from comments and profile data available in versioning systems. Besides the framework description, we also present its implementation for the GitHub versioning system.	https://doi.org/10.5220/0005830604640471
122	Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas	Learning from, Understanding, and Supporting DevOps Artifacts for Docker	10.1145/3377811.3380406	2020	With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code. The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation. We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis. To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts. We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing. To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated. Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection. To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set. These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency. We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set. We also found that industrial Dockerfiles fared no better than those sourced from GitHub.The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.	https://doi.org/10.1145/3377811.3380406
123	Bhattacharjee, Avijit and Nath, Sristy Sumana and Zhou, Shurui and Chakroborti, Debasish and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin	An Exploratory Study to Find Motives Behind Cross-Platform Forks from Software Heritage Dataset	10.1145/3379597.3387512	2020	The fork-based development mechanism provides the flexibility and the unified processes for software teams to collaborate easily in a distributed setting without too much coordination overhead. Currently, multiple social coding platforms support fork-based development, such as GitHub, GitLab, and Bitbucket. Although these different platforms virtually share the same features, they have different emphasis. As GitHub is the most popular platform and the corresponding data is publicly available, most of the current studies are focusing on GitHub hosted projects. However, we observed anecdote evidences that people are confused about choosing among these platforms, and some projects are migrating from one platform to another, and the reasons behind these activities remain unknown. With the advances of Software Heritage Graph Dataset (SWHGD), we have the opportunity to investigate the forking activities across platforms. In this paper, we conduct an exploratory study on 10 popular open-source projects to identify cross-platform forks and investigate the motivation behind. Preliminary result shows that cross-platform forks do exist. For the 10 subject systems used in this study, we found 81,357 forks in total among which 179 forks are on GitLab. Based on our qualitative analysis, we found that most of the cross-platform forks that we identified are mirrors of the repositories on another platform, but we still find cases that were created due to preference of using certain functionalities (e.g. Continuous Integration (CI)) supported by different platforms. This study lays the foundation of future research directions, such as understanding the differences between platforms and supporting cross-platform collaboration.	https://doi.org/10.1145/3379597.3387512
124	Niephaus, Fabio and Henrichs, Dale and Taeumel, Marcel and Pape, Tobias and Felgentreff, Tim and Hirschfeld, Robert	SmalltalkCI: A Continuous Integration Framework for Smalltalk Projects	10.1145/2991041.2991044	2016	Continuous integration (CI) is a programming practice that reduces the risk of project failure by integrating code changes multiple times a day. This has always been important to the Smalltalk community, so custom integration infrastructures are operated that allow CI testing for Smalltalk projects shared in Monticello repositories or traditional changesets.In the last few years, the open hosting platform GitHub has become more and more popular for Smalltalk projects. Unfortunately, there was no convenient way to enable CI testing for those projects.We present smalltalkCI, a continuous integration framework for Smalltalk. It aims to provide a uniform way to load and test Smalltalk projects written in different Smalltalk dialects. smalltalkCI runs on Linux, macOS, and on Windows and can be used locally as well as on a remote server. In addition, it is compatible with Travis CI and AppVeyor, which allows developers to easily set up free CI testing for their GitHub projects without having to run a custom integration infrastructure.	https://doi.org/10.1145/2991041.2991044
125	Avram, Andrei-Marius and Morogan, Luciana and Toma, Stefan-Adrian	OpenNIG - Open Neural Image Generator	10.1109/COMM48946.2020.9142009	2020	Generative models are statistical models that learn a true underlying data distribution from samples using unsupervised learning, aiming to generate new data points with some variation. In this paper, we introduce OpenNIG (Open Neural Image Generator), an open-source neural networks toolkit for image generation. It offers the possibility to easily train, validate and test state of the art models. The framework also contains a module that enables the user to directly download and process some of the most common databases used in deep learning. OpenNIG is freely available via GitHub.	https://doi.org/10.1109/COMM48946.2020.9142009
127	Horton, Eric and Parnin, Chris	DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets	10.1109/ICSE.2019.00047	2019	Platforms like Stack Overflow and GitHub's gist system promote the sharing of ideas and programming techniques via the distribution of code snippets designed to illustrate particular tasks. Python, a popular and fast-growing programming language, sees heavy use on both sites, with nearly one million questions asked on Stack Overflow and 400 thousand public gists on GitHub. Unfortunately, around 75% of the Python example code shared through these sites cannot be directly executed. When run in a clean environment, over 50% of public Python gists fail due to an import error for a missing library.We present DockerizeMe, a technique for inferring the dependencies needed to execute a Python code snippet without import error. DockerizeMe starts with offline knowledge acquisition of the resources and dependencies for popular Python packages from the Python Package Index (PyPI). It then builds Docker specifications using a graph-based inference procedure. Our inference procedure resolves import errors in 892 out of nearly 3,000 gists from the Gistable dataset for which Gistable's baseline approach could not find and install all dependencies.	https://doi.org/10.1109/ICSE.2019.00047
128	Alqaimi, Anwar and Thongtanunam, Patanamon and Treude, Christoph	Automatically Generating Documentation for Lambda Expressions in Java	10.1109/MSR.2019.00057	2019	When lambda expressions were introduced to the Java programming language as part of the release of Java 8 in 2014, they were the language's first step into functional programming. Since lambda expressions are still relatively new, not all developers use or understand them. In this paper, we first present the results of an empirical study to determine how frequently developers of GitHub repositories make use of lambda expressions and how they are documented. We find that 11% of Java GitHub repositories use lambda expressions, and that only 6% of the lambda expressions are accompanied by source code comments. We then present a tool called LambdaDoc which can automatically detect lambda expressions in a Java repository and generate natural language documentation for them. Our evaluation of LambdaDoc with 23 professional developers shows that they perceive the generated documentation to be complete, concise, and expressive, while the majority of the documentation produced by our participants without tool support was inadequate. Our contribution builds an important step towards automatically generating documentation for functional programming constructs in an object-oriented language.	https://doi.org/10.1109/MSR.2019.00057
129	Vasilescu, Bogdan and Posnett, Daryl and Ray, Baishakhi and van den Brand, Mark G.J. and Serebrenik, Alexander and Devanbu, Premkumar and Filkov, Vladimir	Gender and Tenure Diversity in GitHub Teams	10.1145/2702123.2702549	2015	Software development is usually a collaborative venture. Open Source Software (OSS) projects are no exception; indeed, by design, the OSS approach can accommodate teams that are more open, geographically distributed, and dynamic than commercial teams. This, we find, leads to OSS teams that are quite diverse. Team diversity, predominantly in offline groups, is known to correlate with team output, mostly with positive effects. How about in OSS? Using GitHub, the largest publicly available collection of OSS projects, we studied how gender and tenure diversity relate to team productivity and turnover. Using regression modeling of GitHub data and the results of a survey, we show that both gender and tenure diversity are positive and significant predictors of productivity, together explaining a sizable fraction of the data variability. These results can inform decision making on all levels, leading to better outcomes in recruiting and performance.	https://doi.org/10.1145/2702123.2702549
130	Heller, Brandon and Marschner, Eli and Rosenfeld, Evan and Heer, Jeffrey	Visualizing Collaboration and Influence in the Open-Source Software Community	10.1145/1985441.1985476	2011	We apply visualization techniques to user profiles and repository metadata from the GitHub source code hosting service. Our motivation is to identify patterns within this development community that might otherwise remain obscured. Such patterns include the effect of geographic distance on developer relationships, social connectivity and influence among cities, and variation in projectspecific contribution styles (e.g., centralized vs. distributed). Our analysis examines directed graphs in which nodes represent users' geographic locations and edges represent (a) follower relationships, (b) successive commits, or (c) contributions to the same project. We inspect this data using a set of visualization techniques: geo-scatter maps, small multiple displays, and matrix diagrams. Using these representations, and tools based on them, we develop hypotheses about the larger GitHub community that would be difficult to discern using traditional lists, tables, or descriptive statistics. These methods are not intended to provide conclusive answers; instead, they provide a way for researchers to explore the question space and communicate initial insights.	https://doi.org/10.1145/1985441.1985476
131	Gousios, Georgios and Storey, Margaret-Anne and Bacchelli, Alberto	Work Practices and Challenges in Pull-Based Development: The Contributor's Perspective	10.1145/2884781.2884826	2016	The pull-based development model is an emerging way of contributing to distributed software projects that is gaining enormous popularity within the open source software (OSS) world. Previous work has examined this model by focusing on projects and their owners---we complement it by examining the work practices of project contributors and the challenges they face.We conducted a survey with 645 top contributors to active OSS projects using the pull-based model on GitHub, the prevalent social coding site. We also analyzed traces extracted from corresponding GitHub repositories. Our research shows that: contributors have a strong interest in maintaining awareness of project status to get inspiration and avoid duplicating work, but they do not actively propagate information; communication within pull requests is reportedly limited to low-level concerns and contributors often use communication channels external to pull requests; challenges are mostly social in nature, with most reporting poor responsiveness from integrators; and the increased transparency of this setting is a confirmed motivation to contribute. Based on these findings, we present recommendations for practitioners to streamline the contribution process and discuss potential future research directions.	https://doi.org/10.1145/2884781.2884826
132	Cesarini, Mirko and Mercorio, Fabio and Mezzanzanica, Mario and Moscato, Vincenzo and Picariello, Antonio	A Tool for Exploring Networks of Computer Scientists as a Graph	10.1145/3297280.3297501	2019	In this paper we present GraphDBLP, a tool to query the DBLP bibliography as a graph. The DBLP source data were enriched with semantic similarity relationships computed using word-embeddings. A user can interact with the system either writing queries on the graph-db visual console or using a shell-interface provided with 4 parametric and pre-defined queries.GraphDBLP would represent a first graph-database instance of the computer scientist network, that can be improved through new relationships and properties on nodes at any time, and this is the main purpose of the tool, we have made freely available on Github.	https://doi.org/10.1145/3297280.3297501
133	North, Kevin J. and Sarma, Anita and Cohen, Myra B.	Understanding Git History: A Multi-Sense View	10.1145/2993283.2993285	2016	Version control systems archive data about the development history of a project, which can be used to analyze and understand different facets of a software project. The project history can be used to evaluate the development process of a team, as an aid in bug fixing, or to help new members get on track with development. However, state of the art techniques for analyzing version control data provide only partial views into this information, and lack an easy way to present all the dimensions of the data. In this paper we present GitVS, a hybrid view that incorporates visualization and sonification to represent the multiple dimensions of version control data - development time line, conflicts, etc. In a formative user study comparing the GitHub Network Graph, GitVS, and a version of GitVS without sound, we show GitVS improves over the GitHub Network Graph and that while sound makes it easier to correctly understand version history for some tasks, it is more difficult for others. 	https://doi.org/10.1145/2993283.2993285
134	Brown, Chris and Parnin, Chris	Understanding the Impact of GitHub Suggested Changes on Recommendations between Developers	10.1145/3368089.3409722	2020	Recommendations between colleagues are effective for encouraging developers to adopt better practices. Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks. However, in-person recommendations between developers in the workplace are declining. One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions. GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests. To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception. Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests. This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.	https://doi.org/10.1145/3368089.3409722
135	Cui, Xiaodong and Zhen Wei and Zhang, Lin and Liu, Hui and Lei Sun and Zhang, Shao-Wu and Huang, Yufei and Meng, Jia	Sketching the Distribution of Transcriptomic Features on RNA Transcripts with Travis Coordinates	10.1109/BIBM.2015.7359904	2015	Biological features, such as, genes, transcription factor binding sites, SNPs, etc., are usually denoted with genome-based coordinates as the genomic features. While genome-based representation is usually very effective, it can be tedious to examine the distribution of RNA-related genomic features on RNA transcripts with existing tools due to the conversion and comparison between genome-based coordinates to RNA-based coordinates. We developed here an open source R package Travis for sketching the transcriptomic view of genomic features so as to facilitate the analysis of RNA-related but genome-based coordinates. Internally, Travis package extracts the coordinates relative to the landmarks of transcripts, with which the distribution of RNA-related genomic features can then be conveniently analyzed. We demonstrated the usage of Travis package in analyzing post-transcriptional RNA modifications (5-MethylCytosine and N6-MethylAdenosine) derived from high-throughput sequencing approaches (MeRIP-Seq and RNA BS-Seq). The Travis R package is now publicly available from GitHub: https://github.com/lzcyzm/Travis.	https://doi.org/10.1109/BIBM.2015.7359904
136	Rahman, Mohammad Masudur and Roy, Chanchal K. and Redl, Jesse and Collins, Jason A.	CORRECT: Code Reviewer Recommendation at GitHub for Vendasta Technologies	10.1145/2970276.2970283	2016	Peer code review locates common coding standard violations and simple logical errors in the early phases of software development, and thus, reduces overall cost. Unfortunately, at GitHub, identifying an appropriate code reviewer for a pull request is challenging given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation tool-CORRECT-that considers not only the relevant cross-project work experience (e.g., external library experience) of a developer but also her experience in certain specialized technologies (e.g., Google App Engine) associated with a pull request for determining her expertise as a potential code reviewer. We design our tool using client-server architecture, and then package the solution as a Google Chrome plug-in. Once the developer initiates a new pull request at GitHub, our tool automatically analyzes the request, mines two relevant histories, and then returns a ranked list of appropriate code reviewers for the request within the browser's context. Demo: https://www.youtube.com/watch?v=rXU1wTD6QQ0 	https://doi.org/10.1145/2970276.2970283
137	Favato, Danilo and Ishitani, Daniel and Oliveira, Johnatan and Figueiredo, Eduardo	Linus's Law: More Eyes Fewer Flaws in Open Source Projects	10.1145/3364641.3364650	2019	Linus's Law states that "given enough eyeballs, all bugs are shallow". In other words, given a large enough number of developers, almost every programming flaw is characterized and fixed quickly. Although there is much debate about this subject, we still lack empirical evidence to support this law. Given that this theme has, and still is, motivating business decisions in software development, we investigate the implications of Linus's Law in two empirical studies on open source projects mined from GitHub. In the first pilot study, we mined seven popular Java projects from GitHub and investigated the correlation between committers and programming flaws in source code files. Results of this pilot study suggest a positive correlation between the number of developers and programming flaws. We cross-validate these results in a second study with almost one hundred Python projects from GitHub. In this second study, we analyzed the correlation between the number of forks - i.e., a proxy for number of developers - and programming flaws identified in projects. In both studies, programming flaws were detected by using static code analysis tools. As a result of the second study, we could not observe a correlation between the number of developers and the number of programming flaws in Python projects. From both studies we conclude that we were unable to find evidence to support the Linus's Law.	https://doi.org/10.1145/3364641.3364650
138	Nakazawa, Shun and Tanaka, Tetsuo	Prototype of Kanban Tool and Preliminary Evaluation of Visualizing Method for Task Assignment	10.1109/CCATS.2015.21	2015	Kanban is a method used in agile software development. It is a most important tool as it acts as a central communication hub among the members of an agile development team. In this research, the authors develop a prototype of a Kanban tool. The tool displays each developer's tasks across multiple horizontal rows. Therefore, users can assess the task assignment and workloads of team members in one glance. The board also links up with GitHub and has a feature of real time synchronization among clients for distributed development. An experiment showed that the proposed approach was effective.	https://doi.org/10.1109/CCATS.2015.21
139	Saifullah, C M Khaled and Asaduzzaman, Muhammad and Roy, Chanchal K.	Learning from Examples to Find Fully Qualified Names of API Elements in Code Snippets	10.1109/ASE.2019.00032	2019	Developers often reuse code snippets from online forums, such as Stack Overflow, to learn API usages of software frameworks or libraries. These code snippets often contain ambiguous undeclared external references. Such external references make it difficult to learn and use those APIs correctly. In particular, reusing code snippets containing such ambiguous undeclared external references requires significant manual efforts and expertise to resolve them. Manually resolving fully qualified names (FQN) of API elements is a non-trivial task. In this paper, we propose a novel context-sensitive technique, called COSTER, to resolve FQNs of API elements in such code snippets. The proposed technique collects locally specific source code elements as well as globally related tokens as the context of FQNs, calculates likelihood scores, and builds an occurrence likelihood dictionary (OLD). Given an API element as a query, COSTER captures the context of the query API element, matches that with the FQNs of API elements stored in the OLD, and rank those matched FQNs leveraging three different scores: likelihood, context similarity, and name similarity scores. Evaluation with more than 600K code examples collected from GitHub and two different Stack Overflow datasets shows that our proposed technique improves precision by 4-6% and recall by 3-22% compared to state-of-the-art techniques. The proposed technique significantly reduces the training time compared to the StatType, a state-of-the-art technique, without sacrificing accuracy. Extensive analyses on results demonstrate the robustness of the proposed technique.	https://doi.org/10.1109/ASE.2019.00032
140	Khatchadourian, Raffi and Masuhara, Hidehiko	Automated Refactoring of Legacy Java Software to Default Methods	10.1109/ICSE.2017.16	2017	Java 8 default methods, which allow interfaces to contain (instance) method implementations, are useful for the skeletal implementation software design pattern. However, it is not easy to transform existing software to exploit default methods as it requires analyzing complex type hierarchies, resolving multiple implementation inheritance issues, reconciling differences between class and interface methods, and analyzing tie-breakers (dispatch precedence) with overriding class methods to preserve type-correctness and confirm semantics preservation. In this paper, we present an efficient, fully-automated, type constraint-based refactoring approach that assists developers in taking advantage of enhanced interfaces for their legacy Java software. The approach features an extensive rule set that covers various corner-cases where default methods cannot be used. To demonstrate applicability, we implemented our approach as an Eclipse plug-in and applied it to 19 real-world Java projects, as well as submitted pull requests to popular GitHub repositories. The indication is that it is useful in migrating skeletal implementation methods to interfaces as default methods, sheds light onto the pattern's usage, and provides insight to language designers on how this new construct applies to existing software.	https://doi.org/10.1109/ICSE.2017.16
141	Matragkas, Nicholas and Williams, James R. and Kolovos, Dimitris S. and Paige, Richard F.	Analysing the 'biodiversity' of Open Source Ecosystems: The GitHub Case	10.1145/2597073.2597119	2014	In nature the diversity of species and genes in ecological communities affects the functioning of these communities. Biologists have found out that more diverse communities appear to be more productive than less diverse communities. Moreover such communities appear to be more stable in the face of perturbations. In this paper, we draw the analogy between ecological communities and Open Source Software (OSS) ecosystems, and we investigate the diversity and structure of OSS communities. To address this question we use the MSR 2014 challenge dataset, which includes data from the top-10 software projects for the top programming languages on GitHub. Our findings show that OSS communities on GitHub consist of 3 types of users (core developers, active users, passive users). Moreover, we show that the percentage of core developers and active users does not change as the project grows and that the majority of members of large projects are passive users. 	https://doi.org/10.1145/2597073.2597119
142	Casalnuovo, Casey and Suchak, Yagnik and Ray, Baishakhi and Rubio-Gonz\\'alez, Cindy	GitcProc: A Tool for Processing and Classifying GitHub Commits	10.1145/3092703.3098230	2017	Sites such as GitHub have created a vast collection of software artifacts that researchers interested in understanding and improving software systems can use. Current tools for processing such GitHub data tend to target project metadata and avoid source code processing, or process source code in a manner that requires significant effort for each language supported. This paper presents GitcProc, a lightweight tool based on regular expressions and source code blocks, which downloads projects and extracts their project history, including fine-grained source code information and development time bug fixes. GitcProc can track changes to both single-line and block source code structures and associate these changes to the surrounding function context with minimal set up required from users. We demonstrate GitcProc's ability to capture changes in multiple languages by evaluating it on C, C++, Java, and Python projects, and show it finds bug fixes and the context of source code changes effectively with few false positives. 	https://doi.org/10.1145/3092703.3098230
143	Pafka, Szil\\'ard	Machine Learning Software in Practice: Quo Vadis?	10.1145/3097983.3106683	2017	Due to the hype in our industry in the last couple of years, there is a growing mismatch between software tools machine learning practitioners wish for, what they would truly need for their work, what's available (either commercially or open source) and what tool developers and researchers focus on. In this talk we will give a couple of examples of this mismatch. Several surveys and anecdotal evidence show that most practitioners work most of the time (at least in the modeling phase) with datasets that t in the RAM of a single server, therefore distributed computing tools are very of- ten overkill. Our benchmarks (available on github [1]) of the most widely used open source tools for binary classification (various implementations of algorithms such as linear methods, random forests, gradient boosted trees and neural networks) on such data show over 10x speed and over 10x RAM usage difference between various tools, with "big data" tools being the most inefficient. Significant performance gains have been obtained by those tools that incorporate various low-level (close to CPU and memory architecture) optimizations. Nevertheless, we will show that even the best tools show degrading performance on the multi-socket servers featuring a high number of cores, systems that have become widely accessible more recently. Finally, while most of this talk is about performance, we will also argue that machine learning tools that feature high-level easy-to-use APIs provide increasing productivity for practitioners and therefore are preferable.	https://doi.org/10.1145/3097983.3106683
144	Vasilescu, Bogdan and Yu, Yue and Wang, Huaimin and Devanbu, Premkumar and Filkov, Vladimir	Quality and Productivity Outcomes Relating to Continuous Integration in GitHub	10.1145/2786805.2786850	2015	Software processes comprise many steps; coding is followed by building, integration testing, system testing, deployment, operations, among others. Software process integration and automation have been areas of key concern in software engineering, ever since the pioneering work of Osterweil; market pressures for Agility, and open, decentralized, software development have provided additional pressures for progress in this area. But do these innovations actually help projects? Given the numerous confounding factors that can influence project performance, it can be a challenge to discern the effects of process integration and automation. Software project ecosystems such as GitHub provide a new opportunity in this regard: one can readily find large numbers of projects in various stages of process integration and automation, and gather data on various influencing factors as well as productivity and quality outcomes. In this paper we use large, historical data on process metrics and outcomes in GitHub projects to discern the effects of one specific innovation in process automation: continuous integration. Our main finding is that continuous integration improves the productivity of project teams, who can integrate more outside contributions, without an observable diminishment in code quality. 	https://doi.org/10.1145/2786805.2786850
145	Gong, Qingyuan and Zhang, Jiayun and Chen, Yang and Li, Qi and Xiao, Yu and Wang, Xin and Hui, Pan	Detecting Malicious Accounts in Online Developer Communities Using Deep Learning	10.1145/3357384.3357971	2019	Online developer communities like GitHub provide services such as distributed version control and task management, which allow a massive number of developers to collaborate online. However, the openness of the communities makes themselves vulnerable to different types of malicious attacks, since the attackers can easily join and interact with legitimate users. In this work, we formulate the malicious account detection problem in online developer communities, and propose GitSec, a deep learning-based solution to detect malicious accounts. GitSec distinguishes malicious accounts from legitimate ones based on the account profiles as well as dynamic activity characteristics. On one hand, GitSec makes use of users' descriptive features from the profiles. On the other hand, GitSec processes users' dynamic behavioral data by constructing two user activity sequences and applying a parallel neural network design to deal with each of them, respectively. An attention mechanism is used to integrate the information generated by the parallel neural networks. The final judgement is made by a decision maker implemented by a supervised machine learning-based classifier. Based on the real-world data of GitHub users, our extensive evaluations show that GitSec is an accurate detection system, with an F1-score of 0.922 and an AUC value of 0.940.	https://doi.org/10.1145/3357384.3357971
146	Nguyen, Son and Phan, Hung and Le, Trinh and Nguyen, Tien N.	Suggesting Natural Method Names to Check Name Consistencies	10.1145/3377811.3380926	2020	Misleading names of the methods in a project or the APIs in a software library confuse developers about program functionality and API usages, leading to API misuses and defects. In this paper, we introduce MNire, a machine learning approach to check the consistency between the name of a given method and its implementation. MNire first generates a candidate name and compares the current name against it. If the two names are sufficiently similar, we consider the method as consistent. To generate the method name, we draw our ideas and intuition from an empirical study on the nature of method names in a large dataset. Our key finding is that high proportions of the tokens of method names can be found in the three contexts of a given method including its body, the interface (the method's parameter types and return type), and the enclosing class' name. Even when such tokens are not there, MNire uses the contexts to predict the tokens due to the high likelihoods of their co-occurrences. Our unique idea is to treat the name generation as an abstract summarization on the tokens collected from the names of the program entities in the three above contexts.We conducted several experiments to evaluate MNire in method name consistency checking and in method name recommending on large datasets with +14M methods. In detecting inconsistency method names, MNire improves the state-of-the-art approach by 10.4% and 11% relatively in recall and precision, respectively. In method name recommendation, MNire improves relatively over the state-of-the-art technique, code2vec, in both recall (18.2% higher) and precision (11.1% higher). To assess MNire's usefulness, we used it to detect inconsistent methods and suggest new names in several active, GitHub projects. We made 50 pull requests (PRs) and received 42 responses. Among them, five PRs were merged into the main branch, and 13 were approved for later merging. In total, in 31/42 cases, the developer teams agree that our suggested names are more meaningful than the current names, showing MNire's usefulness.	https://doi.org/10.1145/3377811.3380926
147	Venkataramani, Rahul and Gupta, Atul and Asadullah, Allahbaksh and Muddu, Basavaraju and Bhat, Vasudev	Discovery of Technical Expertise from Open Source Code Repositories	10.1145/2487788.2487832	2013	Online Question and Answer websites for developers have emerged as the main forums for interaction during the software development process. The veracity of an answer in such websites is typically verified by the number of 'upvotes' that the answer garners from peer programmers using the same forum. Although this mechanism has proved to be extremely successful in rating the usefulness of the answers, it does not lend itself very elegantly to model the expertise of a user in a particular domain. In this paper, we propose a model to rank the expertise of the developers in a target domain by mining their activity in different opensource projects. To demonstrate the validity of the model, we built a recommendation system for StackOverflow which uses the data mined from GitHub.	https://doi.org/10.1145/2487788.2487832
148	Koch, Sebastian and Schneider, Teseo and Williams, Francis and Panozzo, Daniele	Geometric Computing with Python	10.1145/3305366.3328067	2019	This course is a group endeavor by Sebastian Koeh, Teseo Sehneider, Francis Williams, and Daniele Panozzo. Please contact us if you have questions or comments. For troubleshooting, please post an issue on github. We are grateful to the authors of all open souree C++ libraries we are using. In particular, libigl, tetwild, polyfem, pybind11, and Jupyter.The course will mainly use• igl (Section 2)• polyfem (Section 3)• ABC Dataset CAD Processing (Section 4)• TetWild• 3D ViewerWe provide documentation for the first 3 libraries in these course notes and we refer to https://geometryprocessing.github.io/geometric-computing-python/ for a complete and live version.	https://doi.org/10.1145/3305366.3328067
149	Ericsson, Morgan and Wingkvist, Anna	TDMentions: A Dataset of Technical Debt Mentions in Online Posts	10.1109/TechDebt.2019.00031	2019	The term technical debt is easy to understand as a metaphor, but can quickly grow complex in practice. We contribute with a dataset, TDMentions, that enables researchers to study how developers and end users use the term technical debt in online posts and discussions. The dataset consists of posts from news aggregators and Q&amp;A-sites, blog posts, and issues and commits on GitHub.	https://doi.org/10.1109/TechDebt.2019.00031
150	Heckman, Sarah and King, Jason	Developing Software Engineering Skills Using Real Tools for Automated Grading	10.1145/3159450.3159595	2018	Situated learning theory supports engaging students with materials and resources that reflect professional standards and best practices. Starting with our introductory courses, we incorporate situated learning to support student engagement in software engineering practices and processes through the use of industrial strength open-source tools in several classes throughout the undergraduate computer science curriculum at NC State University. Additionally, these tools support several logistical and educational needs in computer science classrooms, including assignment submission systems and automated grading. In this tools paper, we present our Canary Framework for supporting software engineering practices through the use of Eclipse for development; GitHub for submission and collaboration; and Jenkins for continuous integration and automated grading. These tools are used in five of ten core courses by more than 3000 students over ten semesters. While the use of these tools in education is not unique, we want to share our model of using professional tools in a classroom setting and our experiences on how this framework can support multiple courses throughout the curriculum and at scale.	https://doi.org/10.1145/3159450.3159595
151	Baltes, Sebastian and Treude, Christoph and Diehl, Stephan	SOTorrent: Studying the Origin, Evolution, and Usage of Stack Overflow Code Snippets	10.1109/MSR.2019.00038	2019	Stack Overflow (SO) is the most popular question-and-answer website for software developers, providing a large amount of copyable code snippets. Like other software artifacts, code on SO evolves over time, for example when bugs are fixed or APIs are updated to the most recent version. To be able to analyze how code and the surrounding text on SO evolves, we built SOTorrent, an open dataset based on the official SO data dump. SOTorrent provides access to the version history of SO content at the level of whole posts and individual text and code blocks. It connects code snippets from SO posts to other platforms by aggregating URLs from surrounding text blocks and comments, and by collecting references from GitHub files to SO posts. Our vision is that researchers will use SOTorrent to investigate and understand the evolution and maintenance of code on SO and its relation to other platforms such as GitHub.	https://doi.org/10.1109/MSR.2019.00038
152	Gonzalez, Danielle and Zimmermann, Thomas and Nagappan, Nachiappan	The State of the ML-Universe: 10 Years of Artificial Intelligence &amp; Machine Learning Software Development on GitHub	10.1145/3379597.3387473	2020	In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI &amp; ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI &amp; ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI &amp; ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends.In this paper, we conducted a large-scale empirical study of AI &amp; ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI &amp; ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI &amp; ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI &amp; ML community has unique characteristics that should be accounted for in future research.	https://doi.org/10.1145/3379597.3387473
153	Henze, Niels and Mayer, Sven and Le, Huy Viet and Schwind, Valentin	Improving Software-Reduced Touchscreen Latency	10.1145/3098279.3122150	2017	The latency of current mobile devices' touchscreens is around 100ms and has widely been explored. Latency down to 2ms is noticeable, and latency as low as 25ms reduces users' performance. Previous work reduced touch latency by extrapolating a finger's movement using an ensemble of shallow neural networks and showed that predicting 33ms into the future increases users' performance. Unfortunately, this prediction has a high error. Predicting beyond 33ms did not increase participants' performance, and the error affected the subjective assessment. We use more recent machine learning techniques to reduce the prediction error. We train LSTM networks and multilayer perceptrons using a large data set and regularization. We show that linear extrapolation causes an 116.7% higher error and the previously proposed ensembles of shallow networks cause a 26.7% higher error compared to the LSTM networks. The trained models, the data used for testing, and the source code is available on GitHub.	https://doi.org/10.1145/3098279.3122150
154	Subramanian, Siddharth and Inozemtseva, Laura and Holmes, Reid	Live API Documentation	10.1145/2568225.2568313	2014	Application Programming Interfaces (APIs) provide powerful abstraction mechanisms that enable complex functionality to be used by client programs. However, this abstraction does not come for free: understanding how to use an API can be difficult. While API documentation can help, it is often insufficient on its own. Online sites like Stack Overflow and Github Gists have grown to fill the gap between traditional API documentation and more example-based resources. Unfortunately, these two important classes of documentation are independent.  In this paper we describe an iterative, deductive method of linking source code examples to API documentation. We also present an implementation of this method, called Baker, that is highly precise (0.97) and supports both Java and JavaScript. Baker can be used to enhance traditional API documentation with up-to-date source code examples; it can also be used to incorporate links to the API documentation into the code snippets that use the API. 	https://doi.org/10.1145/2568225.2568313
161	Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Edward J. and Allamanis, Miltiadis and Goues, Claire Le and Neubig, Graham and Vasilescu, Bogdan	DIRE: A Neural Approach to Decompiled Identifier Naming	10.1109/ASE.2019.00064	2019	The decompiler is one of the most common tools for examining binaries without corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Decompilers can reconstruct much of the information that is lost during the compilation process (e.g., structure and type information). Unfortunately, they do not reconstruct semantically meaningful variable names, which are known to increase code understandability. We propose the Decompiled Identifier Renaming Engine (DIRE), a novel probabilistic technique for variable name recovery that uses both lexical and structural information recovered by the decompiler. We also present a technique for generating corpora suitable for training and evaluating models of decompiled code renaming, which we use to create a corpus of 164,632 unique x86-64 binaries generated from C projects mined from GitHub.1 Our results show that on this corpus DIRE can predict variable names identical to the names in the original source code up to 74.3% of the time.	https://doi.org/10.1109/ASE.2019.00064
155	Leitner, Philipp and Bezemer, Cor-Paul	An Exploratory Study of the State of Practice of Performance Testing in Java-Based Open Source Projects	10.1145/3030207.3030213	2017	The usage of open source (OS) software is wide-spread across many industries. While the functional quality of OS projects is considered to be similar to closed-source software, much is unknown about the quality in terms of performance. One challenge for OS developers is that, unlike for functional testing, there is a lack of accepted best practices for performance testing. To reveal the state of practice of performance testing in OS projects, we conduct an exploratory study on 111 Java-based OS projects from GitHub. We study the performance tests of these projects from five perspectives: (1) developers, (2) size, (3) test organization, (4) types of performance tests and (5) used tooling. We show that writing performance tests is not a popular task in OS projects: performance tests form only a small portion of the test suite, are rarely updated, and are usually maintained by a small group of core project developers. Further, even though many projects are aware that they need performance tests, developers appear to struggle implementing them. We argue that future performance testing frameworks should provider better support for low-friction testing, for instance via non-parameterized methods or performance test generation, as well as focus on a tight integration with standard continuous integration tooling.	https://doi.org/10.1145/3030207.3030213
156	Greene, Gillian J. and Fischer, Bernd	CVExplorer: Identifying Candidate Developers by Mining and Exploring Their Open Source Contributions	10.1145/2970276.2970285	2016	Open source code contributions contain a large amount of technical skill information about developers, which can help to identify suitable candidates for a particular development job and therefore impact the success of a development team. We develop CVExplorer as a tool to extract, visualize, and explore relevant technical skills data from GitHub, such as languages and libraries used. It allows non-technical users to filter and identify developers according to technical skills demonstrated across all of their open source contributions, in order to support more accurate candidate identification. We demonstrate the usefulness of CVExplorer by using it to recommend candidates for open positions in two companies. 	https://doi.org/10.1145/2970276.2970285
157	Matyukhina, Alina and Stakhanova, Natalia and Dalla Preda, Mila and Perley, Celine	Adversarial Authorship Attribution in Open-Source Projects	10.1145/3292006.3300032	2019	Open-source software is open to anyone by design, whether it is a community of developers, hackers or malicious users. Authors of open-source software typically hide their identity through nicknames and avatars. However, they have no protection against authorship attribution techniques that are able to create software author profiles just by analyzing software characteristics. In this paper we present an author imitation attack that allows to deceive current authorship attribution systems and mimic a coding style of a target developer. Withing this context we explore the potential of the existing attribution techniques to be deceived. Our results show that we are able to imitate the coding style of the developers based on the data collected from the popular source code repository, GitHub. To subvert author imitation attack, we propose a novel author obfuscation approach that allows us to hide the coding style of the author. Unlike existing obfuscation tools, this new obfuscation technique uses transformations that preserve code readability. We assess the effectiveness of our attacks on several datasets produced by actual developers from GitHub, and participants of the GoogleCodeJam competition. Throughout our experiments we show that the author hiding can be achieved by making sensible transformations which significantly reduce the likelihood of identifying the author's style to 0% by current authorship attribution systems.	https://doi.org/10.1145/3292006.3300032
158	Beniamini, Gal and Gingichashvili, Sarah and Orbach, Alon Klein and Feitelson, Dror G.	Meaningful Identifier Names: The Case of Single-Letter Variables	10.1109/ICPC.2017.18	2017	It is widely accepted that variable names in computer programs should be meaningful, and that this aids program comprehension. "Meaningful" is commonly interpreted as favoring long descriptive names. However, there is at least some use of short and even single-letter names: using i in loops is very common, and we show (by extracting variable names from 1000 popular github projects in 5 languages) that some other letters are also widely used. In addition, controlled experiments with different versions of the same functions (specifically, different variable names) failed to show significant differences in ability to modify the code. Finally, an online survey showed that certain letters are strongly associated with certain types and meanings. This implies that a single letter can in fact convey meaning. The conclusion from all this is that single letter variables can indeed be used beneficially in certain cases, leading to more concise code.	https://doi.org/10.1109/ICPC.2017.18
159	Werder, Karl and Brinkkemper, Sjaak	MEME: Toward a Method for Emotions Extraction from Github	10.1145/3194932.3194941	2018	Software engineering researchers are increasingly interested in the role of emotion during software development. While general tools are available to extract emotions from textual data, these perform poorly in the domain of software engineering. Hence, this paper develops MEME - a Method for EMotion Extraction. Using GHtorrent and GitHub as data sources, the paper presents an implementation of the method. The evaluation results suggest a better performance of MEME in contrast to Syuzhet R package emotion analysis.	https://doi.org/10.1145/3194932.3194941
160	Dong, Hao and Supratak, Akara and Mai, Luo and Liu, Fangde and Oehmichen, Axel and Yu, Simiao and Guo, Yike	TensorLayer: A Versatile Library for Efficient Deep Learning Development	10.1145/3123266.3129391	2017	Recently we have observed emerging uses of deep learning techniques in multimedia systems. Developing a practical deep learning system is arduous and complex. It involves labor-intensive tasks for constructing sophisticated neural networks, coordinating multiple network models, and managing a large amount of training-related data. To facilitate such a development process, we propose TensorLayer which is a Python-based versatile deep learning library. TensorLayer provides high-level modules that abstract sophisticated operations towards neuron layers, network models, training data and dependent training jobs. In spite of offering simplicity, it has transparent module interfaces that allows developers to flexibly embed low-level controls within a backend engine, with the aim of supporting fine-grain tuning towards training. Real-world cluster experiment results show that TensorLayeris able to achieve competitive performance and scalability in critical deep learning tasks. TensorLayer was released in September 2016 on GitHub. Since after, it soon become one of the most popular open-sourced deep learning library used by researchers and practitioners.	https://doi.org/10.1145/3123266.3129391
162	Zhang, Lingxiao and Zou, Yanzhen and Xie, Bing and Zhu, Zixiao	Recommending Relevant Projects via User Behaviour: An Exploratory Study on Github	10.1145/2666539.2666570	2014	Social coding sites (e.g., Github) provide various features like Forking and Sending Pull-requests to support crowd-based software engineering. When using these features, a large amount of user behavior data is recorded. User behavior data can reflect developers preferences and interests in software development activities. Online service providers in many fields have been using user behavior data to discover user preferences and interests to achieve various purposes. In the field of software engineering however, there has been few studies in mining large amount of user behavior data. Our goal is to design an approach based on user behavior data, to recommend relevant open source projects to developers, which can be helpful in activities like searching for the right open source solutions to quickly build prototypes. In this paper, we explore the possibilities of such a method by conducting a set of experiments on selected data sets from Github. We find it a promising direction in mining projects' relevance from user behavior data. Our study also obtain some important issues that is worth considering in this method. 	https://doi.org/10.1145/2666539.2666570
163	Tomassetti, Federico and Torchiano, Marco	An Empirical Assessment of Polyglot-Ism in GitHub	10.1145/2601248.2601269	2014	In this paper we study how the language cocktails are composed. How many languages are used in each software projects, which language types are used and which languages are typically used together. Our study was done on a sample of over 15,000 projects from the largest software forge, GitHub. The results show that many languages are used in each project: 96% projects employ at least 2 languages, over 50% employ at least two programming languages. Finally, there are strong relations between different languages: hence sets of languages tend to be adopted together.	https://doi.org/10.1145/2601248.2601269
164	Bao, Lingfeng and Lo, David and Xia, Xin and Wang, Xinyu and Tian, Cong	How Android App Developers Manage Power Consumption? An Empirical Study by Mining Power Management Commits	10.1145/2901739.2901748	2016	As Android platform becomes more and more popular, a large amount of Android applications have been developed. When developers design and implement Android applications, power consumption management is an important factor to consider since it affects the usability of the applications. Thus, it is important to help developers adopt proper strategies to manage power consumption. Interestingly, today, there is a large number of Android application repositories made publicly available in sites such as GitHub. These repositories can be mined to help crystalize common power management activities that developers do. These in turn can be used to help other developers to perform similar tasks to improve their own Android applications.In this paper, we present an empirical study of power management commits in Android applications. Our study extends that of Moura et al. who perform an empirical study on energy aware commits; however they do not focus on Android applications and only a few of the commits that they study come from Android applications. Android applications are often different from other applications (e.g., those running on a server) due to the issue of limited battery life and the use of specialized APIs. As subjects of our empirical study, we obtain a list of open source Android applications from F-Droid and crawl their commits from Github. We get 468 power management commits after we filter the commits using a set of keywords and by performing manual analysis. These 468 power management commits are from 154 different Android applications and belong to 15 different application categories. Furthermore, we use open card sort to categorize these power management commits and we obtain 6 groups which correspond to different power management activities. Our study also reveals that for different kinds of Android application (e.g., Games, Connectivity, Navigation, Internet, Phone &amp; SMS, Time, etc.), the dominant power management activities differ. For example, the percentage of power management commits belonging to Power Adaptation activity is larger for Navigation applications than those belonging to other categories.	https://doi.org/10.1145/2901739.2901748
165	Kikas, Riivo and Dumas, Marlon and Pfahl, Dietmar	Issue Dynamics in Github Projects	10.1007/978-3-319-26844-6_22	2015	Issue repositories are used to keep of track of bugs, development tasks and feature requests in software development projects. In the case of open source projects, everyone can submit a new issue in the tracker. This practice can lead to situations where more issues are created than what can be effectively handled by the project members, raising the question of how issues are treated as the capacity of the project members is exceeded. In this paper, we study the temporal dynamics of issues in a popular open source development platform, namely Github, based on a sample of 4000 projects. We specifically analyze how the rate of issue creation, the amount of pending issues, and their average lifetime evolve over the course of time. The results show that more issues are opened shortly after the creation of a project repository and that the amount of pending issues increases inexorably due to forgotten unclosed issues. Yet, the average issue lifetime for issues that do get closed is relatively stable over time. These observations suggest that Github projects have implicit mechanisms for handling issues perceived to be important to the project, while neglecting those that exceed the project's capacity.	https://doi.org/10.1007/978-3-319-26844-6_22
166	Borg, Markus and Svensson, Oscar and Berg, Kristian and Hansson, Daniel	SZZ Unleashed: An Open Implementation of the SZZ Algorithm - Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project	10.1145/3340482.3342742	2019	Machine learning applications in software engineering often rely on detailed information about bugs. While issue trackers often contain information about when bugs were fixed, details about when they were introduced to the system are often absent. As a remedy, researchers often rely on the SZZ algorithm as a heuristic approach to identify bug-introducing software changes. Unfortunately, as reported in a recent systematic literature review, few researchers have made their SZZ implementations publicly available. Consequently, there is a risk that research effort is wasted as new projects based on SZZ output need to initially reimplement the approach. Furthermore, there is a risk that newly developed (closed source) SZZ implementations have not been properly tested, thus conducting research based on their output might introduce threats to validity. We present SZZ Unleashed, an open implementation of the SZZ algorithm for git repositories. This paper describes our implementation along with a usage example for the Jenkins project, and conclude with an illustrative study on just-in-time bug prediction. We hope to continue evolving SZZ Unleashed on GitHub, and warmly invite the community to contribute.	https://doi.org/10.1145/3340482.3342742
167	Aneja, Deepali and McDuff, Daniel and Shah, Shital	A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities	10.1145/3340555.3353744	2019	Embodied avatars as virtual agents have many applications and provide benefits over disembodied agents, allowing nonverbal social and interactional cues to be leveraged, in a similar manner to how humans interact with each other. We present an open embodied avatar built upon the Unreal Engine that can be controlled via a simple python programming interface. The avatar has lip syncing (phoneme control), head gesture and facial expression (using either facial action units or cardinal emotion categories) capabilities. We release code and models to illustrate how the avatar can be controlled like a puppet or used to create a simple conversational agent using public application programming interfaces (APIs). GITHUB link: https://github.com/danmcduff/AvatarSim 	https://doi.org/10.1145/3340555.3353744
168	Schumacher, Max Eric Henry and Le, Kim Tuyen and Andrzejak, Artur	Improving Code Recommendations by Combining Neural and Classical Machine Learning Approaches	10.1145/3387940.3391489	2020	Code recommendation systems for software engineering are designed to accelerate the development of large software projects. A classical example is code completion or next token prediction offered by modern integrated development environments. A particular challenging case for such systems are dynamic languages like Python due to limited type information at editing time. Recently, researchers proposed machine learning approaches to address this challenge. In particular, the Probabilistic Higher Order Grammar technique (Bielik et al., ICML 2016) uses a grammar-based approach with a classical machine learning schema to exploit local context. A method by Li et al., (IJCAI 2018) uses deep learning methods, in detail a Recurrent Neural Network coupled with a Pointer Network. We compare these two approaches quantitatively on a large corpus of Python files from GitHub. We also propose a combination of both approaches, where a neural network decides which schema to use for each prediction. The proposed method achieves a slightly better accuracy than either of the systems alone. This demonstrates the potential of ensemble-like methods for code completion and recommendation tasks in dynamically typed languages.	https://doi.org/10.1145/3387940.3391489
169	Wilson, Greg and Perez, Fernando and Norvig, Peter	Teaching Computing with the IPython Notebook (Abstract Only)	10.1145/2538862.2539011	2014	The IPython Notebook is an interactive browser-based environment where you can combine code execution, text, mathematics, plots, and rich media into a single document. Originally designed for use as an electronic lab notebook for computational science, it is increasingly being used in teaching as well, and a rich ecosystem of open source plugins and extensions for teaching is growing around it. The first half of this hands-on workshop will introduce the Notebook and present examples of lessons and instructional materials built around it. In the second half, attendees will explore future directions for the Notebook as a teaching platform. For more information, please view our GitHub repository online at https://github.com/gvwilson/sigcse2014-ipython-workshop.	https://doi.org/10.1145/2538862.2539011
170	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	What the Fork: A Study of Inefficient and Efficient Forking Practices in Social Coding	10.1145/3338906.3338918	2019	Forking and pull requests have been widely used in open-source communities as a uniform development and contribution mechanism, giving developers the flexibility to modify their own fork without affecting others before attempting to contribute back. However, not all projects use forks efficiently; many experience lost and duplicate contributions and fragmented communities. In this paper, we explore how open-source projects on GitHub differ with regard to forking inefficiencies. First, we observed that different communities experience these inefficiencies to widely different degrees and interviewed practitioners to understand why. Then, using multiple regression modeling, we analyzed which context factors correlate with fewer inefficiencies.We found that better modularity and centralized management are associated with more contributions and a higher fraction of accepted pull requests, suggesting specific best practices that project maintainers can adopt to reduce forking-related inefficiencies in their communities.	https://doi.org/10.1145/3338906.3338918
171	Bavishi, Rohan and Yoshida, Hiroaki and Prasad, Mukul R.	Phoenix: Automated Data-Driven Synthesis of Repairs for Static Analysis Violations	10.1145/3338906.3338952	2019	Traditional automatic program repair (APR) tools rely on a test-suite as a repair specification. But test suites even when available are not of specification quality, limiting the performance and hence viability of test-suite based repair. On the other hand, static analysis-based bug finding tools are seeing increasing adoption in industry but still face challenges since the reported violations are viewed as not easily actionable. We propose a novel solution that solves both these challenges through a technique for automatically generating high-quality patches for static analysis violations by learning from examples. Our approach uses the static analyzer as an oracle and does not require a test suite. We realize our solution in a system, Phoenix, that implements a fully-automated pipeline that mines and cleans patches for static analysis violations from the wild, learns generalized executable repair strategies as programs in a novel Domain Specific Language (DSL), and then instantiates concrete repairs from them on new unseen violations. Using Phoenix we mine a corpus of 5,389 unique violations and patches from 517 Github projects. In a cross-validation study on this corpus Phoenix successfully produced 4,596 bug-fixes, with a recall of 85% and a precision of 54%. When applied to the latest revisions of a further5 Github projects, Phoenix produced 94 correct patches to previously unknown bugs, 19 of which have already been accepted and merged by the development teams. To the best of our knowledge this constitutes, by far the largest application of any automatic patch generation technology to large-scale real-world systems	https://doi.org/10.1145/3338906.3338952
172	Near, Joseph P. and Jackson, Daniel	Finding Security Bugs in Web Applications Using a Catalog of Access Control Patterns	10.1145/2884781.2884836	2016	We propose a specification-free technique for finding missing security checks in web applications using a catalog of access control patterns in which each pattern models a common access control use case. Our implementation, Space, checks that every data exposure allowed by an application's code matches an allowed exposure from a security pattern in our catalog. The only user-provided input is a mapping from application types to the types of the catalog; the rest of the process is entirely automatic. In an evaluation on the 50 most watched Ruby on Rails applications on Github, Space reported 33 possible bugs---23 previously unknown security bugs, and 10 false positives.	https://doi.org/10.1145/2884781.2884836
173	Katsuragawa, Daiki and Ihara, Akinori and Kula, Raula Gaikovina and Matsumoto, Kenichi	Maintaining Third-Party Libraries through Domain-Specific Category Recommendations	10.1145/3194124.3194129	2018	Proper maintenance of third-party libraries contributes toward sustaining a healthy project, mitigating the risk it becoming outdated and obsolete. In this paper, we propose domain-specific categories (i.e., grouping of libraries that perform similar functionality) in library recommendations that aids in library maintenance. Our empirical study covers 2,511 GitHub projects and 150 domain-specific categories of Java libraries. Our results show that a system uses up to six different categories in their dependencies. Furthermore, recommending domain-specific categories is practical (i.e., with an accuracy between 66% to 81% for multiple categories) and its suggestion of libraries within that domain is comparable to existing techniques.	https://doi.org/10.1145/3194124.3194129
174	Pooput, Panthip and Muenchaisri, Pornsiri	Finding Impact Factors for Rejection of Pull Requests on GitHub	10.1145/3301326.3301380	2018	A pull request is an important method for code contributions in GitHub that will be submitted when the developers would like to merge their code changes from their local machine to the main repository on which all source code in the project are stored. Before merging the code changes into the main repository, the developers have to request for a permission. If their source code is allowed to merge, the pull request status is accepted. On the other hand, if their source code is not allowed to merge, the pull request status is rejected. The pull request status may be rejected due to several factors, such as code complexity, code quality, the number of changed files, etc. Fixing the rejected pull requests will take some extra effort and time which may affect the project cost and timeline. This paper aims at finding the impact factors that are associated with the rejection of pull requests on GitHub and also discovering the relationships among impact factors by using the association rules in data mining.	https://doi.org/10.1145/3301326.3301380
175	Hora, Andre and Valente, Marco Tulio	Apiwave: Keeping Track of API Popularity and Migration	10.1109/ICSM.2015.7332478	2015	Every day new frameworks and libraries are created and existing ones evolve. To benefit from such newer or improved APIs, client developers should update their applications. In practice, this process presents some challenges: APIs are commonly backward-incompatible (causing client applications to fail when updating) and multiple APIs are available (making it difficult to decide which one to use). To address these challenges, we propose apiwave, a tool that keeps track of API popularity and migration of major frameworks/libraries. The current version includes data about the evolution of top 650 GitHub Java projects, from which 320K APIs were extracted. We also report an experience using apiwave on real-world scenarios.	https://doi.org/10.1109/ICSM.2015.7332478
176	Malaquias, Romero and Ribeiro, M\\'arcio and Bonif\\'acio, Rodrigo and Monteiro, Eduardo and Medeiros, Fl\\'avio and Garcia, Alessandro and Gheyi, Rohit	The Discipline of Preprocessor-Based Annotations Does #ifdef TAG n't #endif Matter	10.1109/ICPC.2017.41	2017	The C preprocessor is a simple, effective, and language-independent tool. Developers use the preprocessor in practice to deal with portability and variability issues. Despite the widespread usage, the C preprocessor suffers from severe criticism, such as negative effects on code understandability and maintainability. In particular, these problems may get worse when using undisciplined annotations, i.e., when a preprocessor directive encompasses only parts of C syntactical units. Nevertheless, despite the criticism and guidelines found in systems like Linux to avoid undisciplined annotations, the results of a previous controlled experiment indicated that the discipline of annotations has no influence on program comprehension and maintenance. To better understand whether developers care about the discipline of preprocessor-based annotations and whether they can really influence on maintenance tasks, in this paper we conduct a mixed-method research involving two studies. In the first one, we identify undisciplined annotations in 110 open-source C/C++ systems of different domains, sizes, and popularity GitHub metrics. We then refactor the identified undisciplined annotations to make them disciplined. Right away, we submit pull requests with our code changes. Our results show that almost two thirds of our pull requests have been accepted and are now merged. In the second study, we conduct a controlled experiment. We have several differences with respect to the aforementioned one, such as blocking of cofounding effects and more replicas. We have evidences that maintaining undisciplined annotations is more time consuming and error prone, representing a different result when compared to the previous experiment. Overall, we conclude that undisciplined annotations should not be neglected.	https://doi.org/10.1109/ICPC.2017.41
177	Baltes, Sebastian and Knack, Jascha and Anastasiou, Daniel and Tymann, Ralf and Diehl, Stephan	(No) Influence of Continuous Integration on the Commit Activity in GitHub Projects	10.1145/3278142.3278143	2018	A core goal of Continuous Integration (CI) is to make small incremental changes to software projects, which are integrated frequently into a mainline repository or branch. This paper presents an empirical study that investigates if developers adjust their commit activity towards the above-mentioned goal after projects start using CI. We analyzed the commit and merge activity in 93 GitHub projects that introduced the hosted CI system Travis CI, but have previously been developed for at least one year before introducing CI. In our analysis, we only found one non-negligible effect, an increased merge ratio, meaning that there were more merging commits in relation to all commits after the projects started using Travis CI. This effect has also been reported in related work. However, we observed the same effect in a random sample of 60 GitHub projects not using CI. Thus, it is unlikely that the effect is caused by the introduction of CI alone. We conclude that: (1) in our sample of projects, the introduction of CI did not lead to major changes in developers' commit activity, and (2) it is important to compare the commit activity to a baseline before attributing an effect to a treatment that may not be the cause for the observed effect.	https://doi.org/10.1145/3278142.3278143
178	Treude, Christoph and Wagner, Markus	Predicting Good Configurations for GitHub and Stack Overflow Topic Models	10.1109/MSR.2019.00022	2019	Software repositories contain large amounts of textual data, ranging from source code comments and issue descriptions to questions, answers, and comments on Stack Overflow. To make sense of this textual data, topic modelling is frequently used as a text-mining tool for the discovery of hidden semantic structures in text bodies. Latent Dirichlet allocation (LDA) is a commonly used topic model that aims to explain the structure of a corpus by grouping texts. LDA requires multiple parameters to work well, and there are only rough and sometimes conflicting guidelines available on how these parameters should be set. In this paper, we contribute (i) a broad study of parameters to arrive at good local optima for GitHub and Stack Overflow text corpora, (ii) an a-posteriori characterisation of text corpora related to eight programming languages, and (iii) an analysis of corpus feature importance via per-corpus LDA configuration. We find that (1) popular rules of thumb for topic modelling parameter configuration are not applicable to the corpora used in our experiments, (2) corpora sampled from GitHub and Stack Overflow have different characteristics and require different configurations to achieve good model fit, and (3) we can predict good configurations for unseen corpora reliably. These findings support researchers and practitioners in efficiently determining suitable configurations for topic modelling when analysing textual data contained in software repositories.	https://doi.org/10.1109/MSR.2019.00022
179	Darwish, Ali and Nakhmani, Arie	Internal Covariate Shift Reduction in Encoder-Decoder Convolutional Neural Networks	10.1145/3077286.3077320	2017	Internal covariant shift in deep neural networks affects the learning and convergence speed in ConvNets. Batch normalization was recently proposed to reduce the distribution of each layer's input to accelerate the training process. It also reduces overfitting and eliminates the need for using dropout in the fully connected layers, or RELU activation. Batch normalization, in its essence, seeks stable distribution of activation values throughout training, and normalizes the inputs of nonlinear data. In order to determine the usefulness of batch normalization in neural networks that don't use fully connected layers we evaluated the performance of an encoder-decoder ConvNet with and without using batch normalization. We found that batch normalization increased the learning performance by 18% but also increased the training time in each epoch (iteration) by 26%. The code for this work and the datasets are provided in a github repository.	https://doi.org/10.1145/3077286.3077320
180	Sathanur, Arun V. and Choudhury, Sutanay and Joslyn, Cliff and Purohit, Sumit	When Labels Fall Short: Property Graph Simulation via Blending of Network Structure and Vertex Attributes	10.1145/3132847.3133065	2017	Property graphs can be used to represent heterogeneous networks with labeled (attributed) vertices and edges. Given a property graph, simulating another graph with same or greater size with the same statistical properties with respect to the labels and connectivity is critical for privacy preservation and benchmarking purposes. In this work we tackle the problem of capturing the statistical dependence of the edge connectivity on the vertex labels and using the same distribution to regenerate property graphs of the same or expanded size in a scalable manner. However, accurate simulation becomes a challenge when the attributes do not completely explain the network structure. We propose the Property Graph Model (PGM) approach that uses a label augmentation strategy to mitigate the problem and preserve the vertex label and the edge connectivity distributions as well as their correlation, while also replicating the degree distribution. Our proposed algorithm is scalable with a linear complexity in the number of edges in the target graph. We illustrate the efficacy of the PGM approach in regenerating and expanding the datasets by leveraging two distinct illustrations. Our open-source implementation is available on GitHub.	https://doi.org/10.1145/3132847.3133065
181	Loni, Babak and Said, Alan	WrapRec: An Easy Extension of Recommender System Libraries	10.1145/2645710.2645717	2014	WrapRec is an easy-to-use Recommender Systems toolkit, which allows users to easily implement or wrap recommendation algorithms from other frameworks. The main goals of WrapRec are to provide a flexible I/O, evaluation mechanism and code reusability. WrapRec provides a rich data model which makes it easy to implement algorithms for different recommender system problems, such as context-aware and cross-domain recommendation. The toolkit is written in C# and the source code is publicly available on Github under the GPL license.	https://doi.org/10.1145/2645710.2645717
182	Mei, Qiaozhu	Decoding the New World Language: Analyzing the Popularity, Roles, and Utility of Emojis	10.1145/3308560.3316541	2019	Emojis have quickly become a universal language that is used by worldwide users, for everyday tasks, across language barriers, and in different apps and platforms. The prevalence of emojis has quickly attracted great attentions from various research communities such as natural language processing, Web mining, ubiquitous computing, and human-computer interaction, as well as other disciplines including social science, arts, psychology, and linguistics.This talk summarizes the recent efforts made by my research group and our collaborators on analyzing large-scale emoji data. The usage of emojis by worldwide users presents interesting commonality as well as divergence. In our analysis of emoji usage by millions of smartphone users in 212 countries, we show that the different preferences and usage of emojis provide rich signals for understanding the cultural differences of Internet users, which correlate with the Hofstede’s cultural dimensions [4].Emojis play different roles when used alongside text. Through jointly learning the embeddings and topological structures of words and emojis, we reveal that emojis present both complementary and supplementary relations to words. Based on the structural properties of emojis in the semantic spaces, we are able to untangle several factors behind the popularity of emojis [1].This talk also highlights the utility of emojis. In general, emojis have been used by Internet users as text supplements to describe objects and situations, express sentiments, or express humor and sarcasm; they are also used as communication tools to attract attention, adjust tones, or establish personal relationships. The benefit of using emojis goes beyond these intentions. In particular, we show that including emojis in the description of an issue report on GitHub results in the issue being responded to by more users and resolved sooner.Large-scale emoji data can also be utilized by AI systems to improve the quality of Web mining services. In particular, a smart machine learning system can infer the latent topics, sentiments, and even demographic information of users based on how they use emojis online. Our analysis reveals a considerable difference between female and male users of emojis, which is big enough for a machine learning algorithm to accurately predict the gender of a user. In Web services that are customized for gender groups, gender inference models built upon emojis can complement those based on text or behavioral traces with fewer privacy concerns [2].Emojis can be also used as an instrument to bridge Web mining tasks across language barriers, especially to transfer sentiment knowledge from a language with rich training labels (e.g., English) to languages that have been difficult for advanced natural language processing tasks [3]. Through this bridge, developers of AI systems and Web services are able to reduce the inequality in the quality of services received by the international users that has been caused by the imbalance of available human annotations in different languages.In general, emojis have evolved from visual ideograms to a brand-new world language in the era of AI and a new Web. The popularity, roles, and utility of emojis have all gone beyond people’s original intentions, which have created a huge opportunity for future research that calls for joint efforts from multiple disciplines.	https://doi.org/10.1145/3308560.3316541
183	Martie, Lee and LaToza, Thomas D. and van der Hoek, Andr\\'e	CodeExchange: Supporting Reformulation of Internet-Scale Code Queries in Context	10.1109/ASE.2015.51	2015	Programming today regularly involves searching for source code online, whether through a general search engine such as Google or a specialized code search engine such as SearchCode, Ohloh, or GitHub. Searching typically is an iterative process, with developers adjusting the keywords they use based on the results of the previous query. However, searching in this manner is not ideal, because just using keywords places limits on what developers can express as well as the overall interaction that is required. Based on the observation that the results from one query create a context in which a next is formulated, we present CodeExchange, a new code search engine that we developed to explicitly leverage this context to support fluid, expressive reformulation of queries. We motivate the need for CodeExchange, highlight its key design decisions and overall architecture, and evaluate its use in both a field deployment and a laboratory study.	https://doi.org/10.1109/ASE.2015.51
184	Li, Yi and Zhu, Chenguang and Rubin, Julia and Chechik, Marsha	CSlicerCloud: A Web-Based Semantic History Slicing Framework	10.1145/3183440.3183491	2018	Traditional commit-based sequential organization of software version histories is insufficient for many development tasks which require high-level, semantic understanding of program functionality, such as porting features or cutting new releases. Semantic history slicing is a technique which uses well-organized unit tests as identifiers for corresponding software functionalities and extracts a set of commits that correspond to a specific high-level functionality. In this paper, we present CSlicerCloud, a Web-based semantic history slicing service tailored for Java projects hosted on GitHub. It is accessible through Web browsers and powered in the backend by a collection of history slicing techniques underneath. We evaluated CSlicerCloud on a dataset containing developer-annotated change histories collected from 10 open source software projects. A video demonstration which showcases the main features of CSlicerCloud can be found at https://youtu.be/7kcswA0bQzo.	https://doi.org/10.1145/3183440.3183491
185	Spinellis, Diomidis and Kotti, Zoe and Kravvaritis, Konstantinos and Theodorou, Georgios and Louridas, Panos	A Dataset of Enterprise-Driven Open Source Software	10.1145/3379597.3387495	2020	We present a dataset of open source software developed mainly by enterprises rather than volunteers. This can be used to address known generalizability concerns, and, also, to perform research on open source business software development. Based on the premise that an enterprise's employees are likely to contribute to a project developed by their organization using the email account provided by it, we mine domain names associated with enterprises from open data sources as well as through white- and blacklisting, and use them through three heuristics to identify 17 264 enterprise GitHub projects. We provide these as a dataset detailing their provenance and properties. A manual evaluation of a dataset sample shows an identification accuracy of 89%. Through an exploratory data analysis we found that projects are staffed by a plurality of enterprise insiders, who appear to be pulling more than their weight, and that in a small percentage of relatively large projects development happens exclusively through enterprise insiders.	https://doi.org/10.1145/3379597.3387495
186	Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan	Understanding User-Bot Interactions for Small-Scale Automation in Open-Source Development	10.1145/3334480.3382998	2020	Small-scale automation tools, or "bots," have been widely deployed in open-source software development to support manual project maintenance tasks. Though interactions between these bots and human developers can have significant effects on user experience, previous research has instead mostly focused on project outcomes. We reviewed existing small-scale bots in wide use on GitHub. After an in-depth qualitative and quantitative evaluation, we compiled several important design principles for human-bot interaction in this context. Following the requirements, we further propose a workflow to support bot developers.	https://doi.org/10.1145/3334480.3382998
187	Freire, Juliana	Spatio-Temporal Analytics, Urban Analytics	10.1145/3168836.3168839	2017	Part 1Lecture 1:Urban Data: Challenges and OpportunitiesData Quality IssuesExploring Urban Data: Usability and InteractivityLecture 2:Finding Interesting FeaturesUsing Data to Discover and Explain DataTransparency and ReproducibilityHands-on 1:Data cleaningHands-on 2:Exploring shadows and trees in NYCCourse Material (lab and data) at https://github.com/julianafreire/ACMSummerSchool2017Course Notes at https://www.dropbox.com/s/4xsq0nubnbfmwaq/big-urban-data-lecture.pdf?dl=0The students will have to install OpenRefine and Jupyter+a few libraries.The instructions are in the lab descriptions in github.	https://doi.org/10.1145/3168836.3168839
188	Wang, Cong and Jiang, Yu and Zhao, Xibin and Song, Xiaoyu and Gu, Ming and Sun, Jiaguang	Weak-Assert: A Weakness-Oriented Assertion Recommendation Toolkit for Program Analysis	10.1145/3183440.3183471	2018	Assertions are helpful in program analysis, such as software testing and verification. The most challenging part of automatically recommending assertions is to design the assertion patterns and to insert assertions in proper locations. In this paper, we develop Weak-Assert1, a weakness-oriented assertion recommendation toolkit for program analysis of C code. A weakness-oriented assertion is an assertion which can help to find potential program weaknesses. Weak-Assert uses well-designed patterns to match the abstract syntax trees of source code automatically. It collects significant messages from trees and inserts assertions into proper locations of programs. These assertions can be checked by using program analysis techniques. The experiments are set up on Juliet test suite and several actual projects in Github. Experimental results show that Weak-Assert helps to find 125 program weaknesses in 26 actual projects. These weaknesses are confirmed manually to be triggered by some test cases.The address of the abstract demo video is: https://youtu.be/_RWC4GJvRWc	https://doi.org/10.1145/3183440.3183471
189	Imtiaz, Nasif and Middleton, Justin and Girouard, Peter and Murphy-Hill, Emerson	Sentiment and Politeness Analysis Tools on Developer Discussions Are Unreliable, but so Are People	10.1145/3194932.3194938	2018	Many software engineering researchers use sentiment and politeness analysis tools to study the emotional environment within collaborative software development. However, papers that use these tools rarely establish their reliability. In this paper, we evaluate popular existing tools for sentiment and politeness detection over a dataset of 589 manually rated GitHub comments that represent developer discussions. We also develop a coding scheme on how to quantify politeness for conversational texts found on collaborative platforms. We find that not only do the tools have a low agreement with human ratings on sentiment and politeness, human raters also have a low agreement among themselves.	https://doi.org/10.1145/3194932.3194938
190	Halilaj, Lavdim and Petersen, Niklas and Grangel-Gonz\\'alez, Irl\\'an and Lange, Christoph and Auer, S\\"oren and Coskun, G\\"okhan and Lohmann, Steffen	VoCol: An Integrated Environment to Support Version-Controlled Vocabulary Development	10.1007/978-3-319-49004-5_20	2016	Vocabularies are increasingly being developed on platforms for hosting version-controlled repositories, such as GitHub. However, these platforms lack important features that have proven useful in vocabulary development. We present VoCol, an integrated environment that supports the development of vocabularies using Version Control Systems. VoCol is based on a fundamental model of vocabulary development, consisting of the three core activities modeling, population, and testing. We implemented VoCol using a loose coupling of validation, querying, analytics, visualization, and documentation generation components on top of a standard Git repository. All components, including the version-controlled repository, can be configured and replaced with little effort to cater for various use cases. We demonstrate the applicability of VoCol with a real-world example and report on a user study that confirms its usability and usefulness.	https://doi.org/10.1007/978-3-319-49004-5_20
191	Amit, Idan and Feitelson, Dror G.	Which Refactoring Reduces Bug Rate?	10.1145/3345629.3345631	2019	We present a methodology to identify refactoring operations that reduce the bug rate in the code. The methodology is based on comparing the bug fixing rate in certain time windows before and after the refactoring. We analyzed 61,331 refactor commits from 1,531 large active GitHub projects. When comparing three-month windows, the bug rate is substantially reduced in 17% of the files of analyzed refactors, compared to 12% of the files in random commits. Within this group, implementing 'todo's provides the most benefits. Certain operations like reuse, upgrade, and using enum and namespaces are also especially beneficial.	https://doi.org/10.1145/3345629.3345631
192	Aarnoutse, Floor and Renes, Cassandra and Snijders, Remco and Jansen, Slinger	The Reality of an Associate Model: Comparing Partner Activity in the Eclipse Ecosystem	10.1145/2642803.2642811	2014	Two determinants of software ecosystem health are productivity of and value creation by the actors in the ecosystem. While keystone players use partnership models to orchestrate actors, the relationship between the type of partnership and activity has not been studied. To address this gap, we have researched the partnership model of the Eclipse Ecosystem and the activity of different types of partners. We have used Eclipse Dash and GitHub to gather data about the activity of Eclipse partners. The results show that a higher level of membership is related to more activity. However, it is also observed that non-member companies are more active than associate members, which suggests that Eclipse can and should improve their partnership model by motivating associate members and incorporating active non-member companies. In addition, other software ecosystems could use these results and implications to improve their own partnership models.	https://doi.org/10.1145/2642803.2642811
193	Baltes, Sebastian and Dumani, Lorik and Treude, Christoph and Diehl, Stephan	SOTorrent: Reconstructing and Analyzing the Evolution of Stack Overflow Posts	10.1145/3196398.3196430	2018	Stack Overflow (SO) is the most popular question-and-answer website for software developers, providing a large amount of code snippets and free-form text on a wide variety of topics. Like other software artifacts, questions and answers on SO evolve over time, for example when bugs in code snippets are fixed, code is updated to work with a more recent library version, or text surrounding a code snippet is edited for clarity. To be able to analyze how content on SO evolves, we built SOTorrent, an open dataset based on the official SO data dump. SOTorrent provides access to the version history of SO content at the level of whole posts and individual text or code blocks. It connects SO posts to other platforms by aggregating URLs from text blocks and by collecting references from GitHub files to SO posts. In this paper, we describe how we built SOTorrent, and in particular how we evaluated 134 different string similarity metrics regarding their applicability for reconstructing the version history of text and code blocks. Based on a first analysis using the dataset, we present insights into the evolution of SO posts, e.g., that post edits are usually small, happen soon after the initial creation of the post, and that code is rarely changed without also updating the surrounding text. Further, our analysis revealed a close relationship between post edits and comments. Our vision is that researchers will use SOTorrent to investigate and understand the evolution of SO posts and their relation to other platforms such as GitHub.	https://doi.org/10.1145/3196398.3196430
195	Zheng, Zhiwen and Wang, Liang and Xu, Jingwei and Wu, Tianheng and Wu, Simeng and Tao, Xianping	Measuring and Predicting the Relevance Ratings between FLOSS Projects Using Topic Features	10.1145/3275219.3275222	2018	Understanding the relevance between the Free/Libra Open Source Software projects is important for developers to perform code and design reuse, discover and develop new features, keep their projects up-to-date, and etc. However, it is challenging to perform relevance ratings between the FLOSS projects mainly because: 1) beyond simple code similarity, there are complex aspects considered when measuring the relevance; and 2) the prohibitive large amount of FLOSS projects available. To address the problem, in this paper, we propose a method to measure and further predict the relevance ratings between FLOSS projects. Our method uses topic features extracted by the LDA topic model to describe the characteristics of a project. By using the topic features, multiple aspects of FLOSS projects such as the application domain, technology used, and programming language are extracted and further used to measure and predict their relevance ratings. Based on the topic features, our method uses matrix factorization to leverage the partially known relevance ratings between the projects to learn the mapping between different topic features to the relevance ratings. Finally, our method combines the topic modeling and matrix factorization technologies to predict the relevance ratings between software projects without human intervention, which is scalable to a large amount of projects. We evaluate the performance of the proposed method by applying our topic extraction and relevance modeling methods using 300 projects from GitHub. The result of topic extraction experiment shows that, for topic modeling, our LDA-based approach achieves the highest hit rate of 98.3% and the highest average accuracy of 29.8%. And the relevance modeling experiment shows that our relevance modeling approach achieves the minimum average predict error of 0.093, suggesting the effectiveness of applying the proposed method on real-world data sets.	https://doi.org/10.1145/3275219.3275222
196	Trieu, Tuan and Cheng, Jianlin	3D Genome Structure Modeling by Lorentzian Objective Function	10.1145/3107411.3107455	2017	Reconstructing 3D structure of a genome from chromosomal conformation capturing data such as Hi-C data has emerged as an important problem in bioinformatics and computational biology in the recent years. In this talk, I will present our latest method that uses Lorentzian function to describe distance restraints between chromosomal regions, which will be used to guide the reconstruction of 3D structures of individual chromosomes and an entire genome. The method is more robust against noisy distance restraints derived from Hi-C data than traditional objective functions such as squared error function and Gaussian probabilistic function. The method can handle both intra- and inter-chromosomal contacts effectively to build 3D structures of a big genome such as the human genome consisting of a number of chromosomes, which are not possible with most existing methods. We have released the Java source code that implements the method (called LorDG) at GitHub (https://github.com/BDM-Lab/LorDG), which is being used by the community to model 3D genome structures. We are currently further improving the method to build very high-resolution (e.g. 1KB base pair) 3D genome and chromosome models.	https://doi.org/10.1145/3107411.3107455
197	Goeminne, Mathieu and Mens, Tom	Towards a Survival Analysis of Database Framework Usage in Java Projects	10.1109/ICSM.2015.7332512	2015	Many software projects rely on a relational database in order to realize part of their functionality. Various database frameworks and object-relational mappings have been developed and used to facilitate data manipulation. Little is known about whether and how such frameworks co-occur, how they complement or compete with each other, and how this changes over time. We empirically studied these aspects for 5 Java database frameworks, based on a corpus of 3,707 GitHub Java projects. In particular, we analysed whether certain database frameworks co-occur frequently, and whether some database frameworks get replaced over time by others. Using the statistical technique of survival analysis, we explored the survival of the database frameworks in the considered projects. This provides useful evidence to software developers about which frameworks can be used successfully in combination and which combinations should be avoided.	https://doi.org/10.1109/ICSM.2015.7332512
198	Ahmad, Mashal and Cinn\\'eide, Mel \\'O	Impact of Stack Overflow Code Snippets on Software Cohesion: A Preliminary Study	10.1109/MSR.2019.00050	2019	Developers frequently copy code snippets from publicly-available resources such as Stack Overflow (SO). While this may lead to a 'quick fix' for a development problem, little is known about how these copied code snippets affect the code quality of the recipient application, or how the quality of the recipient classes subsequently evolves over the time of the project. This has an impact on whether such code copying should be encouraged, and how classes that receive such code snippets should be monitored during evolution. To investigate this issue, we used instances from the SOTorrent database where Java snippets had been copied from Stack Overflow into GitHub projects. In each case, we measured the quality of the recipient class just prior to the addition of the snippet, immediately after the addition of the snippet, and at a later stage in the project. Our goal was to determine if the addition of the snippet caused quality to improve or deteriorate, and what the long-term implications were for the quality of the recipient class. Code quality was measured using the cohesion metrics Low-level Similarity-based Class Cohesion (LSCC) and Class Cohesion (CC). Over a random sample of 378 classes that received code snippets copied from Stack Overflow to GitHub, we found that in almost 70% of the cases where the copied snippet affected cohesion, the effect was to reduce the cohesion of the recipient class. Furthermore, this deterioration in cohesion tends to persist in the subsequent evolution of recipient class. In over 70% of cases the recipient class never fully regained the cohesion it lost in receiving the snippet. These results suggest that when copying code snippets from external repositories, more attention should be paid to integrating the code with the recipient class.	https://doi.org/10.1109/MSR.2019.00050
199	Malan, David J. and Sharp, Chad and van Assema, Jelle and Yu, Brian and Zidane, Kareem	CS50's GitHub-Based Tools for Teaching and Learning	10.1145/3328778.3367027	2020	For CS50 at Harvard, we have developed a suite of free, open-source tools to help students with writing, testing, and submitting programming assignments; and to help teachers grade those assignments and check them for plagiarism. help50, a program that parses error messages and provides beginner-friendly advice to interpreting them, helps students understand and resolve often-cryptic compiler errors. check50 runs a set of automated tests on students' code, providing feedback and hints about where students have made errors. style50 lints students' code, highlighting places where it doesn't meet the course's style guide. submit50 allows students to submit assignments to a GitHub repository, without students needing to have knowledge of git or version control themselves. And compare50, an open-source and customizable alternative to Moss, allows teachers to analyze submissions for similarity, looking for pairs or clusters of submissions that might be the result of improper collaboration. The grading and submission tools require only a GitHub account to use, and can serve as free, extensible alternatives to tools like Codio, Gradescope, and Vocareum. In this workshop, we'll introduce each of the tools, and discuss how to use them for your own classroom. To date, each tool has been deployed to hundreds of students on campus and thousands online. Along the way, we'll discuss how to use the tools effectively, compare and contrast them with other options, identify how the tools have changed students' behavior for the better and for worse, and highlight pedagogical and technological changes we've made to redress the latter. Laptop (with Wi-Fi) required. Linux, macOS, or Windows. Latest version of Chrome.	https://doi.org/10.1145/3328778.3367027
200	Nadi, Sarah and Kr\\"uger, Stefan and Mezini, Mira and Bodden, Eric	Jumping through Hoops: Why Do Java Developers Struggle with Cryptography APIs?	10.1145/2884781.2884790	2016	To protect sensitive data processed by current applications, developers, whether security experts or not, have to rely on cryptography. While cryptography algorithms have become increasingly advanced, many data breaches occur because developers do not correctly use the corresponding APIs. To guide future research into practical solutions to this problem, we perform an empirical investigation into the obstacles developers face while using the Java cryptography APIs, the tasks they use the APIs for, and the kind of (tool) support they desire. We triangulate data from four separate studies that include the analysis of 100 StackOverflow posts, 100 GitHub repositories, and survey input from 48 developers. We find that while developers find it difficult to use certain cryptographic algorithms correctly, they feel surprisingly confident in selecting the right cryptography concepts (e.g., encryption vs. signatures). We also find that the APIs are generally perceived to be too low-level and that developers prefer more task-based solutions.	https://doi.org/10.1145/2884781.2884790
201	Duan, Ruian and Bijlani, Ashish and Xu, Meng and Kim, Taesoo and Lee, Wenke	Identifying Open-Source License Violation and 1-Day Security Risk at Large Scale	10.1145/3133956.3134048	2017	With millions of apps available to users, the mobile app market is rapidly becoming very crowded. Given the intense competition, the time to market is a critical factor for the success and profitability of an app. In order to shorten the development cycle, developers often focus their efforts on the unique features and workflows of their apps and rely on third-party Open Source Software (OSS) for the common features. Unfortunately, despite their benefits, careless use of OSS can introduce significant legal and security risks, which if ignored can not only jeopardize security and privacy of end users, but can also cause app developers high financial loss. However, tracking OSS components, their versions, and interdependencies can be very tedious and error-prone, particularly if an OSS is imported with little to no knowledge of its provenance.We therefore propose OSSPolice, a scalable and fully-automated tool for mobile app developers to quickly analyze their apps and identify free software license violations as well as usage of known vulnerable versions of OSS. OSSPolice introduces a novel hierarchical indexing scheme to achieve both high scalability and accuracy, and is capable of efficiently comparing similarities of app binaries against a database of hundreds of thousands of OSS sources (billions of lines of code). We populated OSSPolice with 60K C/C++ and 77K Java OSS sources and analyzed 1.6M free Google Play Store apps. Our results show that 1) over 40K apps potentially violate GPL/AGPL licensing terms, and 2) over 100K of apps use known vulnerable versions of OSS. Further analysis shows that developers violate GPL/AGPL licensing terms due to lack of alternatives, and use vulnerable versions of OSS despite efforts from companies like Google to improve app security. OSSPolice is available on GitHub.	https://doi.org/10.1145/3133956.3134048
202	Nagappan, Meiyappan and Robbes, Romain and Kamei, Yasutaka and Tanter, \\'Eric and McIntosh, Shane and Mockus, Audris and Hassan, Ahmed E.	An Empirical Study of Goto in C Code from GitHub Repositories	10.1145/2786805.2786834	2015	It is nearly 50 years since Dijkstra argued that goto obscures the flow of control in program execution and urged programmers to abandon the goto statement. While past research has shown that goto is still in use, little is known about whether goto is used in the unrestricted manner that Dijkstra feared, and if it is ‘harmful’ enough to be a part of a post-release bug. We, therefore, conduct a two part empirical study - (1) qualitatively analyze a statistically rep- resentative sample of 384 files from a population of almost 250K C programming language files collected from over 11K GitHub repositories and find that developers use goto in C files for error handling (80.21±5%) and cleaning up resources at the end of a procedure (40.36 ± 5%); and (2) quantitatively analyze the commit history from the release branches of six OSS projects and find that no goto statement was re- moved/modified in the post-release phase of four of the six projects. We conclude that developers limit themselves to using goto appropriately in most cases, and not in an unrestricted manner like Dijkstra feared, thus suggesting that goto does not appear to be harmful in practice. 	https://doi.org/10.1145/2786805.2786834
203	Tufano, Michele and Watson, Cody and Bavota, Gabriele and Di Penta, Massimiliano and White, Martin and Poshyvanyk, Denys	An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via Neural Machine Translation	10.1145/3238147.3240732	2018	Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. We mine millions of bug-fixes from the change histories of GitHub repositories to extract meaningful examples of such bug-fixes. Then, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. Our model is able to fix hundreds of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9% of the cases.	https://doi.org/10.1145/3238147.3240732
204	Scoccia, Gian Luca and Autili, Marco	Web Frameworks for Desktop Apps: An Exploratory Study	10.1145/3382494.3422171	2020	Background: Novel frameworks for the development of desktop applications with web technologies have become popular. These desktop web app frameworks allow developers to reuse existing code and knowledge of web applications for the creation of cross-platform apps integrated with native APIs. Aims: To date, desktop web app frameworks have not been studied empirically. In this paper, we aim to fill this gap by characterizing the usage of web frameworks and providing evidence on how beneficial are their pros and how impactful are their cons. Method: We conducted an empirical study, collecting and analyzing 453 desktop web apps publicly available on GitHub. We performed qualitative and quantitative analyses to uncover the traits and issues of desktop web apps. Results: We found that desktop web app frameworks enable the development of cross-platform applications even for teams of limited dimensions, taking advantage of the abundant number of available web libraries. However, at the same time, bugs deriving from platform compatibility issues are common. Conclusions: Our study provides concrete evidence on some disadvantages associated with desktop web app frameworks. Future work is required to assess their impact on the required development and maintenance effort, and to investigate other aspects not considered in this first research.	https://doi.org/10.1145/3382494.3422171
205	Joonbakhsh, Alireza and Sami, Ashkan	Mining and Extraction of Personal Software Process Measures through IDE Interaction Logs	10.1145/3196398.3196462	2018	The Personal Software Process (PSP) is an effective software process improvement method that heavily relies on manual collection of software development data. This paper describes a semi-automated method that reduces the burden of PSP data collection by extracting the required time and size of PSP measurements from IDE interaction logs. The tool mines enriched event data streams so can be easily generalized to other developing environment also. In addition, the proposed method is adaptable to phase definition changes and creates activity visualizations and summarizations that are helpful for software project management. Tools and processed data used for this paper are available on GitHub at: https://github.com/unknowngithubuser1/data.	https://doi.org/10.1145/3196398.3196462
206	Raibulet, Claudia and Fontana, Francesca Arcelli and Pigazzini, Ilaria	Teaching Software Engineering Tools to Undergraduate Students	10.1145/3369255.3369300	2019	Today, software development is characterized by keywords such as collaborative, teamwork, distributed, agile, dynamic, qualitative and tool-supported among many others. In this paper, we present our experience in teaching three software development tools often used in industry in a software engineering course for undergraduate students: GitHub, SonarQube, and Microsoft Project. The main reasons behind the use of these tools during the development of a software project were: (1) students become familiar with examples of tools adopted in industry and academia, (2) students are enabled to collaborate in teams for the achievement of a common goal, and (3) students become aware of the management tasks needed by a project developed in teams. We exploited these tools in the software engineering course in the last three academic years. The students feedback on using these tools gathered through a questionnaire was positive. Students were enthusiastic in learning about new tools and their support for software development and management. In this paper we summarize the students feedback during three academic years and the lessons we have learned from their feedback.	https://doi.org/10.1145/3369255.3369300
207	S\\^\\irbu, Alina and Babaoglu, Ozalp	Power Consumption Modeling and Prediction in a Hybrid CPU-GPU-MIC Supercomputer	10.1007/978-3-319-43659-3_9	2016	Power consumption is a major obstacle for High Performance Computing HPC systems in their quest towards the holy grail of ExaFLOP performance. Significant advances in power efficiency have to be made before this goal can be attained and accurate modeling is an essential step towards power efficiency by optimizing system operating parameters to match dynamic energy needs. In this paper we present a study of power consumption by jobs in Eurora, a hybrid CPU-GPU-MIC system installed at the largest Italian data center. Using data from a dedicated monitoring framework, we build a data-driven model of power consumption for each user in the system and use it to predict the power requirements of future jobs. We are able to achieve good prediction results for over 80\\"\\i undefined% of the users in the system. For the remaining users, we identify possible reasons why prediction performance is not as good. Possible applications for our predictive modeling results include scheduling optimization, power-aware billing and system-scale power modeling. All the scripts used for the study have been made available on GitHub.	https://doi.org/10.1007/978-3-319-43659-3_9
208	Venkataramani, Rahul and Asadullah, Allahbaksh and Bhat, Vasudev and Muddu, Basavaraju	Latent Co-Development Analysis Based Semantic Search for Large Code Repositories	10.1109/ICSM.2013.50	2013	Distributed and collaborative software development has increased the popularity of source code repositories like GitHub. With the number of projects in such code repositories exceeding millions, it is important to identify the domains to which the projects belong. A domain is a concept or a hierarchy of concepts used to categorize a project. We have proposed a model to cluster projects in a code repository by mining the latent co-development network. These identified clusters are mapped to domains with the help of a taxonomy which we constructed using the metadata from an online Question and Answer (Q&amp;A) website. To demonstrate the validity of the model, we built a prototype for semantic search on source code repositories. In this paper, we outline the proposed model and present the early results.	https://doi.org/10.1109/ICSM.2013.50
209	Neupane, Krishna Prasad	An Approach for Investigating Emotion Dynamics in Software Development	10.1109/ASE.2019.00158	2019	Emotion awareness is critical to interpersonal communication, including that in software development. The SE community has studied emotion in software development using isolated emotion states but it has not considered the dynamic nature of emotion. To investigate the emotion dynamics, SE community needs an effective approach. In this paper, we propose such an approach which can automatically collect project teams' communication records, identify the emotions and their intensities in them, model the emotion dynamics into time series, and provide efficient data management. We demonstrate that this approach can provide end-to-end support for various emotion awareness research and practices through automated data collection, modeling, storage, analysis, and presentation using the IPython's project data on GitHub.	https://doi.org/10.1109/ASE.2019.00158
210	Beller, Moritz and Hejderup, Joseph	Blockchain-Based Software Engineering	10.1109/ICSE-NIER.2019.00022	2019	Blockchain technology has found a great number of applications, from banking to the Internet of Things (IoT). However, it has not yet been envisioned whether and which problems in Software Engineering (SE) Blockchain technology could solve. In this paper, we coin this field "Blockchain-based Software Engineering" and exemplify how Blockchain technology could solve two core SE problems: Continuous Integration (CI) Services such as Travis CI and Package Managers such as apt-get. We believe that Blockchain technology could help (1) democratize and professionalize Software Engineering infrastructure that currently relies on free work done by few volunteers, (2) improve the quality of artifacts and services, and (3) increase trust in ubiquitously used systems like GitHub or Travis CI.	https://doi.org/10.1109/ICSE-NIER.2019.00022
211	Novielli, Nicole and Calefato, Fabio and Lanubile, Filippo	The Challenges of Sentiment Detection in the Social Programmer Ecosystem	10.1145/2804381.2804387	2015	A recent research trend has emerged to study the role of affect in in the social programmer ecosystem, by applying sentiment analysis to the content available in sites such as GitHub and Stack Overflow. In this paper, we aim at assessing the suitability of a state-of-the-art sentiment analysis tool, already applied in social computing, for detecting affective expressions in Stack Overflow. We also aim at verifying the construct validity of choosing sentiment polarity and strength as an appropriate way to operationalize affective states in empirical studies on Stack Overflow. Finally, we underline the need to overcome the limitations induced by domain-dependent use of lexicon that may produce unreliable results. 	https://doi.org/10.1145/2804381.2804387
224	Wang, Kaiyuan and Sullivan, Allison and Khurshid, Sarfraz	ARepair: A Repair Framework for Alloy	10.1109/ICSE-Companion.2019.00049	2019	Researchers have proposed many automated program repair techniques for imperative languages, e.g. Java. However, little work has been done to repair programs written in declarative languages, e.g. Alloy. We proposed ARepair, the first automated program repair technique for faulty Alloy models. ARepair takes as input a faulty Alloy model and a set of tests that capture the desired model properties, and produces a fixed model that passes all tests. ARepair uses tests written for the recently introduced AUnit framework, which provides a notion of unit testing for Alloy models. In this paper, we describes our Java implementation of ARepair, which is a command-line tool, released as an open-source project on GitHub. Our experimental results show that ARepair is able to fix 28 out of 38 real-world faulty models we collected. The demo video for ARepair can be found at https://youtu.be/436drvWvbEU.	https://doi.org/10.1109/ICSE-Companion.2019.00049
212	Coppola, Riccardo and Morisio, Maurizio and Torchiano, Marco	Scripted GUI Testing of Android Apps: A Study on Diffusion, Evolution and Fragility	10.1145/3127005.3127008	2017	Background. Evidence suggests that mobile applications are not thoroughly tested as their desktop counterparts. In particular GUI testing is generally limited. Like web-based applications, mobile apps suffer from GUI test fragility, i.e. GUI test classes failing due to minor modifications in the GUI, without the application functionalities being altered.Aims. The objective of our study is to examine the diffusion of GUI testing on Android, and the amount of changes required to keep test classes up to date, and in particular the changes due to GUI test fragility. We define metrics to characterize the modifications and evolution of test classes and test methods, and proxies to estimate fragility-induced changes.Method. To perform our experiments, we selected six widely used open-source tools for scripted GUI testing of mobile applications previously described in the literature. We have mined the repositories on GitHub that used those tools, and computed our set of metrics.Results. We found that none of the considered GUI testing frameworks achieved a major diffusion among the open-source Android projects available on GitHub. For projects with GUI tests, we found that test suites have to be modified often, specifically 5%--10% of developers' modified LOCs belong to tests, and that a relevant portion (60% on average) of such modifications are induced by fragility.Conclusions. Fragility of GUI test classes constitute a relevant concern, possibly being an obstacle for developers to adopt automated scripted GUI tests. This first evaluation and measure of fragility of Android scripted GUI testing can constitute a benchmark for developers, and the basis for the definition of a taxonomy of fragility causes, and actionable guidelines to mitigate the issue.	https://doi.org/10.1145/3127005.3127008
213	Martinez, Matias and Etien, Anne and Ducasse, St\\'ephane and Fuhrman, Christopher	RTj: A Java Framework for Detecting and Refactoring Rotten Green Test Cases	10.1145/3377812.3382151	2020	Rotten green tests are passing tests which have at least one assertion that is not executed. They give developers a false sense of trust in the code. In this paper, we present RTj, a framework that analyzes test cases from Java projects with the goal of detecting and refactoring rotten test cases. RTj automatically discovered 418 rotten tests from 26 open-source Java projects hosted on GitHub. Using RTj, developers have an automated recommendation of the tests that need to be modified for improving the quality of the applications under test. A video is available at: https://youtu.be/Uqxf-Wzp3Mg	https://doi.org/10.1145/3377812.3382151
214	Madeyski, Lech and Kawalerowicz, Marcin	Continuous Defect Prediction: The Idea and a Related Dataset	10.1109/MSR.2017.46	2017	We would like to present the idea of our Continuous Defect Prediction (CDP) research and a related dataset that we created and share. Our dataset is currently a set of more than 11 million data rows, representing files involved in Continuous Integration (CI) builds, that synthesize the results of CI builds with data we mine from software repositories. Our dataset embraces 1265 software projects, 30,022 distinct commit authors and several software process metrics that in earlier research appeared to be useful in software defect prediction. In this particular dataset we use TravisTorrent as the source of CI data. TravisTorrent synthesizes commit level information from the Travis CI server and GitHub open-source projects repositories. We extend this data to a file change level and calculate the software process metrics that may be used, for example, as features to predict risky software changes that could break the build if committed to a repository with CI enabled.	https://doi.org/10.1109/MSR.2017.46
215	Lou, Yiling and Chen, Junjie and Zhang, Lingming and Hao, Dan and Zhang, Lu	History-Driven Build Failure Fixing: How Far Are We?	10.1145/3293882.3330578	2019	Build systems are essential for modern software development and maintenance since they are widely used to transform source code artifacts into executable software. Previous work shows that build systems break frequently during software evolution. Therefore, automated build-fixing techniques are in huge demand. In this paper we target a mainstream build system, Gradle, which has become the most widely used build system for Java projects in the open-source community (e.g., GitHub). HireBuild, state-of-the-art build-fixing tool for Gradle, has been recently proposed to fix Gradle build failures via mining the history of prior fixes. Although HireBuild has been shown to be effective for fixing real-world Gradle build failures, it was evaluated on only a limited set of build failures, and largely depends on the quality/availability of historical fix information. To investigate the efficacy and limitations of the history-driven build fix, we first construct a new and large build failure dataset from Top-1000 GitHub projects. Then, we evaluate HireBuild on the extended dataset both quantitatively and qualitatively. Inspired by the findings of the study, we propose a simplistic new technique that generates potential patches via searching from the present project under test and external resources rather than the historical fix information. According to our experimental results, the simplistic approach based on present information successfully fixes 2X more reproducible build failures than the state-of-art HireBuild based on historical fix information. Furthermore, our results also reveal various findings/guidelines for future advanced build failure fixing.	https://doi.org/10.1145/3293882.3330578
216	Chong, Nathan and Cook, Byron and Kallas, Konstantinos and Khazem, Kareem and Monteiro, Felipe R. and Schwartz-Narbonne, Daniel and Tasiran, Serdar and Tautschnig, Michael and Tuttle, Mark R.	Code-Level Model Checking in the Software Development Workflow	10.1145/3377813.3381347	2020	This experience report describes a style of applying symbolic model checking developed over the course of four years at Amazon Web Services (AWS). Lessons learned are drawn from proving properties of numerous C-based systems, e.g., custom hypervisors, encryption code, boot loaders, and an IoT operating system. Using our methodology, we find that we can prove the correctness of industrial low-level C-based systems with reasonable effort and predictability. Furthermore, AWS developers are increasingly writing their own formal specifications. All proofs discussed in this paper are publicly available on GitHub.	https://doi.org/10.1145/3377813.3381347
217	Peksa, Janis	Autonomous Data-Driven Integration Algorithm	10.1145/3416921.3416939	2020	In this paper, an autonomous data-driven integration algorithm is the main focus of the Autonomous Open Data Prediction Framework [1]. This paper proposes the autonomous Web Service integration into ERP systems. The paper highlights the Autonomous Open Data Prediction Framework algorithm using flowchart and UML diagrams, also pseudocode of the Kalman filter method, as well as, selection of the appropriate programming language. Described the Autonomous Open Data Prediction Framework API that all programming code is published to the GitHub repository. It is highlighting the lack of forecasting methods offered in ERP systems that have not been able to ensure all the necessary business process opportunities to increase business value.	https://doi.org/10.1145/3416921.3416939
218	Stanciulescu, Stefan and Schulze, Sandro and Wasowski, Andrzej	Forked and Integrated Variants in an Open-Source Firmware Project	10.1109/ICSM.2015.7332461	2015	Code cloning has been reported both on small (code fragments) and large (entire projects) scale. Cloning-in-the-large, or forking, is gaining ground as a reuse mechanism thanks to availability of better tools for maintaining forked project variants, hereunder distributed version control systems and interactive source management platforms such as Github. We study advantages and disadvantages of forking using the case of Marlin, an open source firmware for 3D printers. We find that many problems and advantages of cloning do translate to forking. Interestingly, the Marlin community uses both forking and integrated variability management (conditional compilation) to create variants and features. Thus, studying it increases our understanding of the choice between integrated and clone-based variant management. It also allows us to observe mechanisms governing source code maturation, in particular when, why and how feature implementations are migrated from forks to the main integrated platform. We believe that this understanding will ultimately help development of tools mixing clone-based and integrated variant management, combining the advantages of both.	https://doi.org/10.1109/ICSM.2015.7332461
219	Molavi, Abtin and Downing, Mara and Schneider, Tommy and Bang, Lucas	MCBAT: A Practical Tool for Model Counting Constraints on Bounded Integer Arrays	10.1145/3368089.3417937	2020	Model counting procedures for data structures are crucial for advancing the field of automated quantitative program analysis. We present a tool for Model Counting for Bounded Array Theory (MCBAT). MCBAT works on quantified integer array constraints in which all arrays have a finite length. We employ reductions from the theory of arrays to uninterpreted functions and linear integer arithmetic (LIA). Once reduced to LIA, we leverage Barvinok's polynomial time integer lattice point enumeration algorithm. Finally, we present a case study demonstrating applicability to automated quantitative program analysis. MCBAT is available for immediate use as a Docker image and the source code is freely available in our Github repository.	https://doi.org/10.1145/3368089.3417937
220	Pinheiro, Andr\\'e M. and Rabello, Caio S. and Furtado, Leonardo B. and Pinto, Gustavo and de Souza, Cleidson R. B.	Expecting the Unexpected: Distilling Bot Development, Challenges, and Motivations	10.1109/CHASE.2019.00021	2019	Software bots are becoming an increasingly popular tool in the software development landscape, which is particularly due to their potential of use in several different contexts. More importantly, software developers interested in transitioning to bot development may have to face challenges intrinsic related to bot software development. However, so far, it is still unclear what is the profile of bot developers, what motivate them, or what challenges do they face when dealing with bot development. To shed an initial light on this direction, we conducted a survey with 43 Github users who have been involved (showing their interest or actively contributing to) in bot software projects.	https://doi.org/10.1109/CHASE.2019.00021
221	Zhu, Jiaxin and Zhou, Minghui and Mockus, Audris	Effectiveness of Code Contribution: From Patch-Based to Pull-Request-Based Tools	10.1145/2950290.2950364	2016	Code contributions in Free/Libre and Open Source Software projects are controlled to maintain high-quality of software. Alternatives to patch-based code contribution tools such as mailing lists and issue trackers have been developed with the pull request systems being the most visible and widely available on GitHub. Is the code contribution process more effective with pull request systems? To answer that, we quantify the effectiveness via the rates contributions are accepted and ignored, via the time until the first response and final resolution and via the numbers of contributions. To control for the latent variables, our study includes a project that migrated from an issue tracker to the GitHub pull request system and a comparison between projects using mailing lists and pull request systems. Our results show pull request systems to be associated with reduced review times and larger numbers of contributions. However, not all the comparisons indicate substantially better accept or ignore rates in pull request systems. These variations may be most simply explained by the differences in contribution practices the projects employ and may be less affected by the type of tool. Our results clarify the importance of understanding the role of tools in effective management of the broad network of potential contributors and may lead to strategies and practices making the code contribution more satisfying and efficient from both contributors' and maintainers' perspectives. 	https://doi.org/10.1145/2950290.2950364
222	Rahman, Akond Ashfaque Ur and Helms, Eric and Williams, Laurie and Parnin, Chris	Synthesizing Continuous Deployment Practices Used in Software Development	10.1109/Agile.2015.12	2015	Continuous deployment speeds up the process of existing agile methods, such as Scrum, and Extreme Programming (XP) through the automatic deployment of software changes to end-users upon passing of automated tests. Continuous deployment has become an emerging software engineering process amongst numerous software companies, such as Facebook, Github, Netflix, and Rally Software. A systematic analysis of software practices used in continuous deployment can facilitate a better understanding of continuous deployment as a software engineering process. Such analysis can also help software practitioners in having a shared vocabulary of practices and in choosing the software practices that they can use to implement continuous deployment. The goal of this paper is to aid software practitioners in implementing continuous deployment through a systematic analysis of software practices that are used by software companies. We studied the continuous deployment practices of 19 software companies by performing a qualitative analysis of Internet artifacts and by conducting follow-up inquiries. In total, we found 11 software practices that are used by 19 software companies. We also found that in terms of use, eight of the 11 software practices are common across 14 software companies. We observe that continuous deployment necessitates the consistent use of sound software engineering practices such as automated testing, automated deployment, and code review.	https://doi.org/10.1109/Agile.2015.12
223	Werder, Karl	The Evolution of Emotional Displays in Open Source Software Development Teams: An Individual Growth Curve Analysis	10.1145/3194932.3194934	2018	Software developers communicate and interact with each other in order to solve complex problems. Such communication often includes emotional displays that have been shown to influence team processes and performance. Yet, little is known about the evolution of team emotional displays. Hence, we investigate a sample of 1121 Open Source Software (OSS) projects from GitHub, using longitudinal data analysis. The results from growth curve analysis shows that the team emotional display decrease over time. This negative linear trend decelerates mid-term as suggested by a positive quadratic trend of time. Such deceleration diminishes toward the end as a negative cubic trend suggests.	https://doi.org/10.1145/3194932.3194934
225	Lazzari, Hugo Schroter and Tavares da Costa Filho, Roberto Iraja and Roesler, Valter	QoE Analyser: A Framework to QoE Knowledge Base Generation	10.1145/3126858.3131598	2017	This paper presents a framework for the creation of a knowledge database on QoE. The QoE Analyzer framework enables the simulation of degradations in video playout and also the application of a survey to evaluate the impact of degradations on the user Quality of Experience. In order to show the versatility of the framework, an instantiation of the framework and its application to a group of 62 users was carried out. The framework was implemented using the JavaScript language and, through it, it was possible to show the impacts of degradation patterns on the user experience. The framework was released under GNU GPLv3 license and is available in github (https://github.com/hugoschroterl/qoe-analyser).	https://doi.org/10.1145/3126858.3131598
226	Islam, Md Johirul and Nguyen, Giang and Pan, Rangeet and Rajan, Hridesh	A Comprehensive Study on Deep Learning Bug Characteristics	10.1145/3338906.3338955	2019	Deep learning has gained substantial popularity in recent years. Developers mainly rely on libraries and tools to add deep learning capabilities to their software. What kinds of bugs are frequently found in such software? What are the root causes of such bugs? What impacts do such bugs have? Which stages of deep learning pipeline are more bug prone? Are there any antipatterns? Understanding such characteristics of bugs in deep learning software has the potential to foster the development of better deep learning platforms, debugging mechanisms, development practices, and encourage the development of analysis and verification frameworks. Therefore, we study 2716 high-quality posts from Stack Overflow and 500 bug fix commits from Github about five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand the types of bugs, root causes of bugs, impacts of bugs, bug-prone stage of deep learning pipeline as well as whether there are some common antipatterns found in this buggy software. The key findings of our study include: data bug and logic bug are the most severe bug types in deep learning software appearing more than 48% of the times, major root causes of these bugs are Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing up more than 43% of the times.We have also found that the bugs in the usage of deep learning libraries have some common antipatterns.	https://doi.org/10.1145/3338906.3338955
227	Kao, Po-Yu and Zhang, Angela and Goebel, Michael and Chen, Jefferson W. and Manjunath, B. S.	Predicting Fluid Intelligence of Children Using T1-Weighted MR Images and a StackNet	10.1007/978-3-030-31901-4_2		In this work, we utilize T1-weighted MR images and StackNet to predict fluid intelligence in adolescents. Our framework includes feature extraction, feature normalization, feature denoising, feature selection, training a StackNet, and predicting fluid intelligence. The extracted feature is the distribution of different brain tissues in different brain parcellation regions. The proposed StackNet consists of three layers and 11 models. Each layer uses the predictions from all previous layers including the input layer. The proposed StackNet is tested on a public benchmark Adolescent Brain Cognitive Development Neurocognitive Prediction Challenge 2019 and achieves a mean squared error of 82.42 on the combined training and validation set with 10-fold cross-validation. The proposed StackNet achieves a mean squared error of 94.25 on the testing data. The source code is available on GitHub ().	https://doi.org/10.1007/978-3-030-31901-4_2
228	Ding, Jin and Sun, Hailong and Wang, Xu and Liu, Xudong	Entity-Level Sentiment Analysis of Issue Comments	10.1145/3194932.3194935	2018	Emotions and sentiment of software developers can largely influence the software productivity and quality. However, existing work on emotion mining and sentiment analysis is still in the early stage in software engineering in terms of accuracy, the size of datasets used and the specificity of the analysis. In this work, we are concerned with conducting entity-level sentiment analysis. We first build a manually labeled dataset containing 3,000 issue comments selected from 231,732 issue comments collected from 10 open source projects in GitHub. Then we design and develop SentiSW, an entity-level sentiment analysis tool consisting of sentiment classification and entity recognition, which can classify issue comments into <sentiment, entity=""> tuples. We evaluate the sentiment classification using ten-fold cross validation, and it achieves 68.71% mean precision, 63.98% mean recall and 77.19% accuracy, which is significantly higher than existing tools. We evaluate the entity recognition by manually annotation and it achieves a 75.15% accuracy.	https://doi.org/10.1145/3194932.3194935
229	Sachdev, Saksham and Li, Hongyu and Luan, Sifei and Kim, Seohyun and Sen, Koushik and Chandra, Satish	Retrieval on Source Code: A Neural Code Search	10.1145/3211346.3211353	2018	Searching over large code corpora can be a powerful productivity tool for both beginner and experienced developers because it helps them quickly find examples of code related to their intent. Code search becomes even more attractive if developers could express their intent in natural language, similar to the interaction that Stack Overflow supports. In this paper, we investigate the use of natural language processing and information retrieval techniques to carry out natural language search directly over source code, i.e. without having a curated Q&amp;A forum such as Stack Overflow at hand. Our experiments using a benchmark suite derived from Stack Overflow and GitHub repositories show promising results. We find that while a basic word–embedding based search procedure works acceptably, better results can be obtained by adding a layer of supervision, as well as by a customized ranking strategy.	https://doi.org/10.1145/3211346.3211353
230	Guerrero-Higueras, \\'Angel Manuel and S\\'anchez-Gonz\\'alez, Lidia and Conde, Miguel \\'Angel and Lera, Francisco J. Rodr\\'\\iguez and Castej\\'on-Limas, Manuel and Petkov, Nicolai	Facilitating the Learning Process in Parallel Computing by Using Instant Messaging	10.1145/3362789.3362877	2019	Parallel Programming skills may require long time to acquire. "Think in parallel" is a skill which requires time, effort, and experience. In this work, we propose to facilitate the learning process in parallel programming by using instant messaging by students. Our aim is to find out if students' interaction through instant messaging is beneficial for the learning process. We asked several students of an HPC course of the Master's degree in Computer Science to develop a specific parallel application, each of them using a different application program interface: OpenMP, MPI, CUDA, or OpenCL. Even though the used APIs are different, there are common points in the design process. We proposed to these students to interact with each other by using Gitter, an instant messaging tool for GitHub users. Our analysis of the communications and results demonstrate that the direct interaction of students through the Gitter tool has a positive impact on the learning process.	https://doi.org/10.1145/3362789.3362877
231	Argyriou, Andreas and Gonz\\'alez-Fierro, Miguel and Zhang, Le	Microsoft Recommenders: Best Practices for Production-Ready Recommendation Systems	10.1145/3366424.3382692	2020	Recommendation algorithms have been widely applied in various contemporary business areas, however the process of implementing them in production systems is complex and has to address significant challenges. We present Microsoft Recommenders, an open-source Github repository for helping researchers, developers and non-experts in general to prototype, experiment with and bring to production both classic and state-of-the-art recommendation algorithms. A focus of this repository is on best practices in development of recommendation systems. We have also incorporated learnings from our experience with recommendation systems in production, in order to enhance ease of use; speed of implementation and deployment; scalability and performance.	https://doi.org/10.1145/3366424.3382692
232	Wagner, Paul J.	The SQL File Evaluation (SQLFE) Tool: A Flexible and Extendible System for Evaluation of SQL Queries	10.1145/3328778.3372599	2020	The SQL File Evaluation (SQLFE) tool is a GUI-based, flexible, and extendible software system for evaluating the correctness of files of student SQL queries as compared to specified SQL query answers. SQLFE can be configured per question to weight any of over 30 different tests in judging correctness of a submitted answer for a particular question. These tests include successful DBMS interpretation of the query, same result set (as specified answer), the use count of particular keywords, simple formatting style, and partial credit based on simple structural format. SQLFE currently works for databases constructed under Oracle and MySQL database management systems (DBMSs), and can be extended to more DBMSs. SQLFE is available from GitHub.	https://doi.org/10.1145/3328778.3372599
233	Viitanen, Marko and Koivula, Ari and Lemmetti, Ari and Yl\\"a-Outinen, Arttu and Vanne, Jarno and H\\"am\\"al\\"ainen, Timo D.	Kvazaar: Open-Source HEVC/H.265 Encoder	10.1145/2964284.2973796	2016	Kvazaar is an academic software video encoder for the emerging High Efficiency Video Coding (HEVC/H.265) standard. It provides students, academic professionals, and industry experts a free, cross-platform HEVC encoder for x86, x64, PowerPC, and ARM processors on Windows, Linux, and Mac. Kvazaar is being developed from scratch in C and optimized in Assembly under the LGPLv2.1 license. The development is being coordinated by Ultra Video Group at Tampere University of Technology (TUT) and the implementation work is carried out by an active community on GitHub. Developer friendly source code of Kvazaar makes joining easy for new developers. Currently, Kvazaar includes all essential coding tools of HEVC and its modular source code facilitates parallelization on multi and manycore processors as well as algorithm acceleration on hardware. Kvazaar is able to attain real-time HEVC coding speed up to 4K video on an Intel 14-core Xeon processor. Kvazaar is also supported by FFmpeg and Libav. These de-facto standard multimedia frameworks boost Kvazaar popularity and enable its joint usage with other well-known multimedia processing tools. Nowadays, Kvazaar is an integral part of teaching at TUT and it has got a key role in three Eureka Celtic-Plus projects in the fields of 4K TV broadcasting, virtual advertising, Video on Demand, and video surveillance.	https://doi.org/10.1145/2964284.2973796
234	Kery, Mary Beth and Le Goues, Claire and Myers, Brad A.	Examining Programmer Practices for Locally Handling Exceptions	10.1145/2901739.2903497	2016	Many have argued that the current try/catch mechanism for handling exceptions in Java is flawed. A major complaint is that programmers often write minimal and low quality handlers. We used the Boa tool to examine a large number of Java projects on GitHub to provide empirical evidence about how programmers currently deal with exceptions. We found that programmers handle exceptions locally in catch blocks much of the time, rather than propagating by throwing an Exception. Programmers make heavy use of actions like Log, Print, Return, or Throw in catch blocks, and also frequently copy code between handlers. We found bad practices like empty catch blocks or catching Exception are indeed widespread. We discuss evidence that programmers may misjudge risk when catching Exception, and face a tension between handlers that directly address local program statement failure and handlers that consider the program-wide implications of an exception. Some of these issues might be addressed by future tools which autocomplete more complete handlers.	https://doi.org/10.1145/2901739.2903497
235	Vobl, Thorsten and Gotscharek, Annette and Reffle, Uli and Ringlstetter, Christoph and Schulz, Klaus U.	PoCoTo - an Open Source System for Efficient Interactive Postcorrection of OCRed Historical Texts	10.1145/2595188.2595197	2014	When applied to historical texts, OCR engines often produce a non-negligible number of OCR errors. For research in the Humanities, text mining and retrieval, the option is important to improve the quality of OCRed historical texts using interactive postcorrection. We describe a system for interactive postcorrection of OCRed historical documents developed in the EU project IMPACT. Various advanced features of the system help to efficiently correct texts. Language technology used in the background takes orthographic variation in historical language into account. Using this knowledge, the tool visualizes possible OCR errors and series of similar possible OCR errors in a given input document. Error series can be corrected in one shot. Practical user tests in three major European libraries have shown that the system considerably reduces the time needed by human correctors to eliminate a certain number of OCR errors. The system has been published as an open source tool under GitHub.	https://doi.org/10.1145/2595188.2595197
236	Lu, Yao and Mao, Xinjun and Wang, Tao and Yin, Gang and Li, Zude and Wang, Huaimin	Continuous Inspection in the Classroom: Improving Students' Programming Quality with Social Coding Methods	10.1145/3183440.3195054	2018	Rich research has shown that both the teaching and learning of high-quality programming are challenging and deficient in most colleges' education systems. Recently the continuous inspection paradigm has been widely used by developers on social coding sites (e.g., GitHub) as an important method to ensure the internal quality of massive code contributions. In this study we designed a specific continuous inspection process for students' collaborative projects and conducted a controlled experiment with 48 students from the same course during two school years to evaluate how the process affects their programming quality. Our results show that continuous inspection can significantly reduce the density of code quality issues introduced in the code.	https://doi.org/10.1145/3183440.3195054
237	Ringlstetter, Andreas and Scherzinger, Stefanie and Bissyand\\'e, Tegawend\\'e F.	Data Model Evolution Using Object-NoSQL Mappers: Folklore or State-of-the-Art?	10.1145/2896825.2896827	2016	In big data software engineering, the schema flexibility of NoSQL document stores is a major selling point: When the document store itself does not actively manage a schema, the data model is maintained within the application. Just like object-relational mappers for relational databases, object-NoSQL mappers are part of professional software development with NoSQL document stores. Some mappers go beyond merely loading and storing Java objects: Using dedicated evolution annotations, developers may conveniently add, remove, or rename attributes from stored objects, and also conduct more complex transformations. In this paper, we analyze the dissemination of this technology in Java open source projects. While we find evidence on GitHub that evolution annotations are indeed being used, developers do not employ them so much for evolving the data model, but to solve different tasks instead. Our observations trigger interesting questions for further research.	https://doi.org/10.1145/2896825.2896827
238	Wang, Kaiyuan and Sullivan, Allison and Marinov, Darko and Khurshid, Sarfraz	ASketch: A Sketching Framework for Alloy	10.1145/3236024.3264594	2018	Alloy is a declarative modeling language that supports first-order logic with transitive closure. Alloy has been used in a variety of domains to model software systems and find design deficiencies. However, it is often challenging to make an Alloy model correct or to debug a faulty Alloy model. ASketch is a sketching/synthesis technique that can help users write correct Alloy models. ASketch allows users to provide a partial Alloy model with holes, a generator that specifies candidate fragments to be considered for each hole, and a set of tests that capture the desired model properties. Then, the tool completes the holes such that all tests for the completed model pass. ASketch uses tests written for the recently introduced AUnit framework, which provides a foundation of testing (unit tests, test execution, and model coverage) for Alloy models in the spirit of traditional unit testing. This paper describes our Java implementation of ASketch, which is a command-line tool, released as an open-source project on GitHub. Our experimental results show that ASketch can handle partial Alloy models with multiple holes and a large search space. The demo video for ASketch can be found at https://youtu.be/T5NIVsV329E.	https://doi.org/10.1145/3236024.3264594
239	M\\'endez-Acu\\~na, David and Galindo, Jos\\'e A. and Combemale, Benoit and Blouin, Arnaud and Baudry, Benoit and Guernic, Gurvan	Reverse-Engineering Reusable Language Modules from Legacy Domain-Specific Languages	10.1007/978-3-319-35122-3_24	2016	The use of domain-specific languages DSLs has become a successful technique in the development of complex systems. Nevertheless, the construction of this type of languages is time-consuming and requires highly-specialized knowledge and skills. An emerging practice to facilitate this task is to enable reuse through the definition of language modules which can be later put together to build up new DSLs. Still, the identification and definition of language modules are complex and error-prone activities, thus hindering the reuse exploitation when developing DSLs. In this paper, we propose a computer-aided approach to i identify potential reuse in a set of legacy DSLs; and ii capitalize such potential reuse by extracting a set of reusable language modules with well defined interfaces that facilitate their assembly. We validate our approach by using realistic DSLs coming out from industrial case studies and obtained from public GitHub repositories.	https://doi.org/10.1007/978-3-319-35122-3_24
240	Caulo, Maria and Lin, Bin and Bavota, Gabriele and Scanniello, Giuseppe and Lanza, Michele	Knowledge Transfer in Modern Code Review	10.1145/3387904.3389270	2020	Knowledge transfer is one of the main goals of modern code review, as shown by several studies that surveyed and interviewed developers. While knowledge transfer is a clear expectation of the code review process, there are no analytical studies using data mined from software repositories to assess the effectiveness of code review in "training" developers and improve their skills over time. We present a mining-based study investigating how and whether the code review process helps developers to improve their contributions to open source projects over time. We analyze 32,062 peer-reviewed pull requests (PRs) made across 4,981 GitHub repositories by 728 developers who created their GitHub account in 2015. We assume that PRs performed in the past by a developer D that have been subject to a code review process have "transferred knowledge" to D. Then, we verify if over time (i.e., when more and more reviewed PRs are made by D), the quality of the contributions made by D to open source projects increases (as assessed by proxies we defined, such as the acceptance of PRs, or the polarity of the sentiment in the review comments left for the submitted PRs). With the above measures, we were unable to capture the positive impact played by the code review process on the quality of developers' contributions. This might be due to several factors, including the choices we made in our experimental design.Additional investigations are needed to confirm or contradict such a negative result.	https://doi.org/10.1145/3387904.3389270
241	Zhu, Jiaxin and Wei, Jun	An Empirical Study of Multiple Names and Email Addresses in OSS Version Control Repositories	10.1109/MSR.2019.00068	2019	Data produced by version control systems are widely used in software research and development. Version control data users always use the name or email address field to identify the committer or author of a modification. However, developers may use multiple names and email addresses, which brings difficulties for identification of distinct developers. In this paper, we sample 450 Git repositories from GitHub to study the multiple names and email addresses of developers. We conduct a conservative estimation of its prevalence and impact on related measurements. We merge the multiple names and email addresses of a developer through a method of high precision. With the merged identities, we obtain a number of interesting findings, e.g., about 6% of the developers used multiple names or email addresses in more than 60% of the repositories, and they contributed about half of all the commits. Our impact analysis shows that the multiple names and email addresses issue cannot be ignored for the basic related measurements, e.g., the number of developers in a repository. Our results could help researchers and practitioners have a more clear understanding of multiple names and email addresses in practice to improve the accuracy of related measurements.	https://doi.org/10.1109/MSR.2019.00068
242	Greene, Gillian J.	A Generic Framework for Concept-Based Exploration of Semi-Structured Software Engineering Data	10.1109/ASE.2015.34	2015	Software engineering meta-data (SE data), such as revision control data, Github project data or test reports, is typically semi-structured; it comprises a mixture of formatted and free-text fields and is often self-describing. Semi-structured SE data cannot be queried in a SQL-like manner because of its lack of structure. Consequently, there are a variety of customized tools built to analyze specific datasets but these do not generalize. We propose to develop a generic framework for exploration and querying of semi-structured SE data. Our approach investigates the use of a formal concept lattice as a universal data structure and a tag cloud as an intuitive interface to support data exploration.	https://doi.org/10.1109/ASE.2015.34
243	Li, Kaiyuan and Woo, Maverick and Jia, Limin	On the Generation of Disassembly Ground Truth and the Evaluation of Disassemblers	10.1145/3411502.3418429	2020	When a software transformation or software security task needs to analyze a given program binary, the first step is often disassembly. Since many modern disassemblers have become highly accurate on many binaries, we believe reliable disassembler benchmarking requires standardizing the set of binaries used and the disassembly ground truth about these binaries. This paper presents (i) a first version of our work-in-progress disassembly benchmark suite, which comprises $879$ binaries from diverse projects compiled with multiple compilers and optimization settings, and (ii) a novel disassembly ground truth generator leveraging the notion of "listing files'', which has broad support by clang, gcc, icc, and msvc. In additional, it presents our evaluation of four prominent open-source disassemblers using this benchmark suite and a custom evaluation system. Our entire system and all generated data are maintained openly on GitHub to encourage community adoption.	https://doi.org/10.1145/3411502.3418429
244	Coelho, Jailton and Valente, Marco Tulio and Silva, Luciana L. and Hora, Andr\\'e	Why We Engage in FLOSS: Answers from Core Developers	10.1145/3195836.3195848	2018	The maintenance and evolution of Free/Libre Open Source Software (FLOSS) projects demand the constant attraction of core developers. In this paper, we report the results of a survey with 52 developers, who recently became core contributors of popular GitHub projects. We reveal their motivations to assume a key role in FLOSS projects (e.g., improving the projects because they are also using it), the project characteristics that most helped in their engagement process (e.g., a friendly community), and the barriers faced by the surveyed core developers (e.g., lack of time of the project leaders). We also compare our results with related studies about others kinds of open source contributors (casual, one-time, and newcomers).	https://doi.org/10.1145/3195836.3195848
245	Hansen, Nikolaus	A Global Surrogate Assisted CMA-ES	10.1145/3321707.3321842	2019	We explore the arguably simplest way to build an effective surrogate fitness model in continuous search spaces. The model complexity is linear or diagonal-quadratic or full quadratic, depending on the number of available data. The model parameters are computed from the Moore-Penrose pseudoinverse. The model is used as a surrogate fitness for CMA-ES if the rank correlation between true fitness and surrogate value of recently sampled data points is high. Otherwise, further samples from the current population are successively added as data to the model. We empirically compare the IPOP scheme of the new model assisted lq-CMA-ES with a variety of previously proposed methods and with a simple portfolio algorithm using SLSQP and CMA-ES. We conclude that a global quadratic model and a simple portfolio algorithm are viable options to enhance CMA-ES. The model building code is available as part of the pycma Python module on Github and PyPI.	https://doi.org/10.1145/3321707.3321842
246	Awan, Muaaz Gul and Saeed, Fahad	An Out-of-Core GPU Based Dimensionality Reduction Algorithm for Big Mass Spectrometry Data and Its Application in Bottom-up Proteomics	10.1145/3107411.3107466	2017	Modern high resolution Mass Spectrometry instruments can generate millions of spectra in a single systems biology experiment. Each spectrum consists of thousands of peaks but only a small number of peaks actively contribute to deduction of peptides. Therefore, pre-processing of MS data to detect noisy and non-useful peaks are an active area of research. Most of the sequential noise reducing algorithms are impractical to use as a pre-processing step due to high time-complexity. In this paper, we present a GPU based dimensionality-reduction algorithm, called G-MSR, for MS2 spectra. Our proposed algorithm uses novel data structures which optimize the memory and computational operations inside GPU. These novel data structures include Binary Spectra and Quantized Indexed Spectra (QIS). The former helps in communicating essential information between CPU and GPU using minimum amount of data while latter enables us to store and process complex 3-D data structure into a 1-D array structure while maintaining the integrity of MS data. Our proposed algorithm also takes into account the limited memory of GPUs and switches between in-core and out-of-core modes based upon the size of input data. G-MSR achieves a peak speed-up of 386x over its sequential counterpart and is shown to process over a million spectra in just 32 seconds. The code for this algorithm is available as a GPL open-source at GitHub at the following link: https://github.com/pcdslab/G-MSR.	https://doi.org/10.1145/3107411.3107466
247	Sinha, Vinayak and Lazar, Alina and Sharif, Bonita	Analyzing Developer Sentiment in Commit Logs	10.1145/2901739.2903501	2016	The paper presents an analysis of developer commit logs for GitHub projects. In particular, developer sentiment in commits is analyzed across 28,466 projects within a seven year time frame. We use the Boa infrastructure's online query system to generate commit logs as well as files that were changed during the commit. We analyze the commits in three categories: large, medium, and small based on the number of commits using a sentiment analysis tool. In addition, we also group the data based on the day of week the commit was made and map the sentiment to the file change history to determine if there was any correlation. Although a majority of the sentiment was neutral, the negative sentiment was about 10% more than the positive sentiment overall. Tuesdays seem to have the most negative sentiment overall. In addition, we do find a strong correlation between the number of files changed and the sentiment expressed by the commits the files were part of. Future work and implications of these results are discussed.	https://doi.org/10.1145/2901739.2903501
248	R\\"ummer, Philipp	JayHorn: A Java Model Checker	10.1145/3340672.3341113	2019	This talk will give an overview of the JayHorn verification tool, a model checker for sequential Java programs annotated with assertions expressing safety conditions. JayHorn is fully automatic and based to a large degree on standard infrastructure for compilation and verification: it uses the Soot library as front-end to read Java bytecode and translate it to the Jimple three-address format, and the state-of-the-art Horn solvers SPACER and Eldarica as back-ends that infer loop invariants, object and class invariants, and method contracts. Since JayHorn uses an invariant-based representation of heap data-structures, it is particularly useful for analysing programs with unbounded data-structures and unbounded run-time, while at the same time avoiding the use of logical theories, like the theory of arrays, often considered hard for Horn solvers. The development of JayHorn is ongoing, and the talk will also cover some of the future features of JayHorn, in particular the handling of strings.The talk presents joint work with Daniel Dietsch, Temesghen Kahsai, Rody Kersten, Huascar Sanchez, Martin Sch\\"af, and Valentin W\\"ustholz.JayHorn is open source and distributed under MIT license, and its source code is available on Github (https://github.com/jayhorn/jayhorn). The development of JayHorn is funded in parts by AFRL contract No. FA8750-15-C-0010, NSF Award No. 1422705, by the Swedish Research Council (VR) under grants 2014-5484 and 2018-4727, and by the Swedish Foundation for Strategic Research (SSF) under the project WebSec (Ref. RIT17-0011).	https://doi.org/10.1145/3340672.3341113
249	Lamba, Hemank and Trockman, Asher and Armanios, Daniel and K\\"astner, Christian and Miller, Heather and Vasilescu, Bogdan	Heard It through the Gitvine: An Empirical Study of Tool Diffusion across the Npm Ecosystem	10.1145/3368089.3409705	2020	Automation tools like continuous integration services, code coverage reporters, style checkers, dependency managers, etc. are all known to provide significant improvements in developer productivity and software quality. Some of these tools are widespread, others are not. How do these automation "best practices" spread? And how might we facilitate the diffusion process for those that have seen slower adoption? In this paper, we rely on a recent innovation in transparency on code hosting platforms like GitHub---the use of repository badges---to track how automation tools spread in open-source ecosystems through different social and technical mechanisms over time. Using a large longitudinal data set, multivariate network science techniques, and survival analysis, we study which socio-technical factors can best explain the observed diffusion process of a number of popular automation tools. Our results show that factors such as social exposure, competition, and observability affect the adoption of tools significantly, and they provide a roadmap for software engineers and researchers seeking to propagate best practices and tools.	https://doi.org/10.1145/3368089.3409705
250	Zadrozny, Wlodek W. and Gallagher, Sean and Shalaby, Walid and Avadhani, Adarsh	Simulating IBM Watson in the Classroom	10.1145/2676723.2677287	2015	IBM Watson exemplifies multiple innovations in natural language processing and question answering. In addition, Watson uses most of the known techniques in these two domains as well as many methods from related domains. Hence, there is pedagogical value in a rigorous understanding of its function. The paper provides the description of a text analytics course focused on building a simulator of IBM Watson, conducted in Spring 2014 at UNC Charlotte. We believe this is the first time a simulation containing all the major Watson components was created in a university classroom. The system achieved a respectable (close to) 20% accuracy on Jeopardy! questions, and there remain many known and new avenues of improving performance that can be explored in the future. The code and documentation are available on GitHub. The paper is a joint effort of the teacher and some of the students who were leading teams implementing component technologies, and therefore deeply involved in making the class successful.	https://doi.org/10.1145/2676723.2677287
251	Bogart, Christopher and Kastner, Christian and Herbsleb, James	When It Breaks, It Breaks: How Ecosystem Developers Reason about the Stability of Dependencies	10.1109/ASEW.2015.21	2015	Dependencies among software projects and libraries are an indicator of the often implicit collaboration among many developers in software ecosystems. Negotiating change can be tricky: changes to one module may cause ripple effects to many other modules that depend on it, yet insisting on only backward-compatible changes may incur significant opportunity cost and stifle change. We argue that awareness mechanisms based on various notions of stability can enable developers to make decisions that are independent yet wise and provide stewardship rather than disruption to the ecosystem. In ongoing interviews with developers in two software ecosystems (CRAN and Node.js), we are finding that developers in fact struggle with change, that they often use adhoc mechanisms to negotiate change, and that existing awareness mechanisms like Github notification feeds are rarely used due to information overload. We study the state of the art and current information needs and outline a vision toward a change-based awareness system.	https://doi.org/10.1109/ASEW.2015.21
252	Rule, Adam and Tabard, Aur\\'elien and Hollan, James D.	Exploration and Explanation in Computational Notebooks	10.1145/3173574.3173606	2018	Computational notebooks combine code, visualizations, and text in a single document. Researchers, data analysts, and even journalists are rapidly adopting this new medium. We present three studies of how they are using notebooks to document and share exploratory data analyses. In the first, we analyzed over 1 million computational notebooks on GitHub, finding that one in four had no explanatory text but consisted entirely of visualizations or code. In a second study, we examined over 200 academic computational notebooks, finding that although the vast majority described methods, only a minority discussed reasoning or results. In a third study, we interviewed 15 academic data analysts, finding that most considered computational notebooks personal, exploratory, and messy. Importantly, they typically used other media to share analyses. These studies demonstrate a tension between exploration and explanation in constructing and sharing computational notebooks. We conclude with opportunities to encourage explanation in computational media without hindering exploration.	https://doi.org/10.1145/3173574.3173606
253	Asaduzzaman, Muhammad and Ahasanuzzaman, Muhammad and Roy, Chanchal K. and Schneider, Kevin A.	How Developers Use Exception Handling in Java?	10.1145/2901739.2903500	2016	Exception handling is a technique that addresses exceptional conditions in applications, allowing the normal flow of execution to continue in the event of an exception and/or to report on such events. Although exception handling techniques, features and bad coding practices have been discussed both in developer communities and in the literature, there is a marked lack of empirical evidence on how developers use exception handling in practice. In this paper we use the Boa language and infrastructure to analyze 274k open source Java projects in GitHub to discover how developers use exception handling. We not only consider various exception handling features but also explore bad coding practices and their relation to the experience of developers. Our results provide some interesting insights. For example, we found that bad exception handling coding practices are common in open source Java projects and regardless of experience all developers use bad exception handling coding practices.	https://doi.org/10.1145/2901739.2903500
254	Hazhirpasand, Mohammadreza and Ghafari, Mohammad and Nierstrasz, Oscar	Java Cryptography Uses in the Wild	10.1145/3382494.3422166	2020	[Background] Previous research has shown that developers commonly misuse cryptography APIs. [Aim] We have conducted an exploratory study to find out how crypto APIs are used in open-source Java projects, what types of misuses exist, and why developers make such mistakes. [Method] We used a static analysis tool to analyze hundreds of open-source Java projects that rely on Java Cryptography Architecture, and manually inspected half of the analysis results to assess the tool results. We also contacted the maintainers of these projects by creating an issue on the GitHub repository of each project, and discussed the misuses with developers. [Results] We learned that 85% of Cryptography APIs are misused, however, not every misuse has severe consequences. Developer feedback showed that security caveats in the documentation of crypto APIs are rare, developers may overlook misuses that originate in third-party code, and the context where a Crypto API is used should be taken into account. [Conclusion] We conclude that using Crypto APIs is still problematic for developers but blindly blaming them for such misuses may lead to erroneous conclusions.	https://doi.org/10.1145/3382494.3422166
255	Raghuraman, Adithya and Ho-Quang, Truong and Chaudron, Michel R. V. and Serebrenik, Alexander and Vasilescu, Bogdan	Does UML Modeling Associate with Lower Defect Proneness? A Preliminary Empirical Investigation	10.1109/MSR.2019.00024	2019	The benefits of modeling the design to improve the quality and maintainability of software systems have long been advocated and recognized. Yet, the empirical evidence on this remains scarce. In this paper, we fill this gap by reporting on an empirical study of the relationship between UML modeling and software defect proneness in a large sample of open-source GitHub projects. Using statistical modeling, and controlling for confounding variables, we show that projects containing traces of UML models in their repositories experience, on average, a statistically minorly different number of software defects (as mined from their issue trackers) than projects without traces of UML models.	https://doi.org/10.1109/MSR.2019.00024
256	Wang, Peipei and Stolee, Kathryn T.	How Well Are Regular Expressions Tested in the Wild?	10.1145/3236024.3236072	2018	Developers report testing their regular expressions less than the rest of their code. In this work, we explore how thoroughly tested regular expressions are by examining open source projects.  Using standard metrics of coverage, such as line and branch coverage, gives an incomplete picture of the test coverage of regular expressions. We adopt graph-based coverage metrics for the DFA representation of regular expressions, providing fine-grained test coverage metrics. Using over 15,000 tested regular expressions in 1,225 Java projects on GitHub, we measure node, edge, and edge-pair coverage. Our results show that only 17% of the regular expressions in the repositories are tested at all. For those that are tested, the median number of test inputs is two. For nearly 42% of the tested regular expressions, only one test input is used. Average node and edge coverage levels on the DFAs for tested regular expressions are 59% and 29%, respectively. Due to the lack of testing of regular expressions, we explore whether a string generation tool for regular expressions, Rex, achieves high coverage levels. With some exceptions, we found that tools such as Rex can be used to write test inputs with similar coverage to the developer tests.	https://doi.org/10.1145/3236024.3236072
257	Aamulehto, Rami and Kuhna, Mikko and Tarvainen, Jussi and Oittinen, Pirkko	Stage Framework: An HTML5 and CSS3 Framework for Digital Publishing	10.1145/2502081.2502228	2013	In this paper we present Stage Framework, an HTML5 and CSS3 framework for digital book, magazine and newspaper publishing. The framework offers publishers the means and tools for publishing editorial content in the HTML5 format using a single web application. The approach is cross-platform and is based on open web standards. Stage Framework serves as an alternative for platform-specific native publications using pure HTML5 to deliver book, magazine and newspaper content while retaining the familiar gesture interaction of native applications. Available gesture actions include for example the page swipe and kinetic scrolling. The magazine browsing view relies entirely on CSS3 3D Transforms and Transitions, thus utilizing hardware acceleration in most devices and platforms. The web application also features a magazine stand which, can be used to offer issues of multiple publications. Developed as a part of master's thesis research, the framework has been published under the GPL and MIT licenses and is available to everyone via the framework website (http://stageframework.com) and the GitHub repository (http://github.com/ralatalo/stage).	https://doi.org/10.1145/2502081.2502228
258	Tillquist, Richard C.	Low-Dimensional Representation of Biological Sequence Data	10.1145/3307339.3343174	2019	Systems of interest in bioinformatics and computational biology tend to be large, complex, interdependent, and stochastic. As our ability to collect sequence data at finer resolutions improves, we can better understand and predict system behavior under different conditions. Machine learning algorithms are a powerful set of tools designed to help with this understanding. However, many of the most effective of these algorithms are not immediately amenable to application on symbolic data. It is often necessary to map biological symbols to real vectors before performing analysis or prediction using sequence data. This tutorial will cover several techniques for embedding sequence data. Common methods utilizing k-mer count and binary vector representations will be addressed along with state of the art methods based on neural networks, like BioVec, and graph embeddings, like Node2Vec and multilateration. This tutorial is in collaboration with M. Lladser. Slides, datasets, and code from the tutorial will be made freely available for future use on GitHub.	https://doi.org/10.1145/3307339.3343174
259	Torres, Johnny and Vaca, Carmen and Abad, Cristina L.	What Ignites a Reply? Characterizing Conversations in Microblogs	10.1145/3148055.3148071	2017	Nowadays, microblog platforms provide a medium to share content and interact with other users. With the large-scale data generated on these platforms, the origin and reasons of users engagement in conversations has attracted the attention of the research community. In this paper, we analyze the factors that might spark conversations in Twitter, for the English and Spanish languages. Using a corpus of 2.7 million tweets, we reconstruct existing conversations, then extract several contextual and content features. Based on the features extracted, we train and evaluate several predictive models to identify tweets that will spark a conversation. Our findings show that conversations are more likely to be initiated by users with high activity level and popularity. For less popular users, the type of content generated is a more important factor. Experimental results shows that the best predictive model is able obtain an average score $F1=0.80$. We made available the dataset scripts and code used in this paper to the research community via Github.	https://doi.org/10.1145/3148055.3148071
260	Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas	A Dataset of Dockerfiles	10.1145/3379597.3387498	2020	Dockerfiles are one of the most prevalent kinds of DevOps artifacts used in industry. Despite their prevalence, there is a lack of sophisticated semantics-aware static analysis of Dockerfiles. In this paper, we introduce a dataset of approximately 178,000 unique Dockerfiles collected from GitHub. To enhance the usability of this data, we describe five representations we have devised for working with, mining from, and analyzing these Dockerfiles. Each Dockerfile representation builds upon the previous ones, and the final representation, created by three levels of nested parsing and abstraction, makes tasks such as mining and static checking tractable. The Dockerfiles, in each of the five representations, along with metadata and the tools used to shepard the data from one representation to the next are all available at: https://doi.org/10.5281/zenodo.3628771.	https://doi.org/10.1145/3379597.3387498
261	Zhang, Chen and Chen, Bihuan and Chen, Linlin and Peng, Xin and Zhao, Wenyun	A Large-Scale Empirical Study of Compiler Errors in Continuous Integration	10.1145/3338906.3338917	2019	Continuous Integration (CI) is a widely-used software development practice to reduce risks. CI builds often break, and a large amount of efforts are put into troubleshooting broken builds. Despite that compiler errors have been recognized as one of the most frequent types of build failures, little is known about the common types, fix efforts and fix patterns of compiler errors that occur in CI builds of open-source projects. To fill such a gap, we present a large-scale empirical study on 6,854,271 CI builds from 3,799 open-source Java projects hosted on GitHub. Using the build data, we measured the frequency of broken builds caused by compiler errors, investigated the ten most common compiler error types, and reported their fix time. We manually analyzed 325 broken builds to summarize fix patterns of the ten most common compiler error types. Our findings help to characterize and understand compiler errors during CI and provide practical implications to developers, tool builders and researchers.	https://doi.org/10.1145/3338906.3338917
262	Loyola, Pablo and Ko, In-Young	Population Dynamics in Open Source Communities: An Ecological Approach Applied to Github	10.1145/2567948.2578843	2014	Open Source Software (OSS) has gained high amount of popularity during the last few years. It is becoming used by public and private institutions, even companies release portions of their code to obtain feedback from the community of voluntary developers. As OSS is based on the voluntary contributions of developers, the number of participants represents one of the key elements that impact the quality of the software. In order to understand how the the population of contributors evolve over time, we propose a methodology that adapts Lotka-Volterra-based biological models used for describing host-parasite interactions. Experiments based on data from the Github collaborative platform showed that the proposed approach performs effectively in terms of providing an estimation of the population of developers for each project over time.	https://doi.org/10.1145/2567948.2578843
263	Cor\\`o, Federico and Verdecchia, Roberto and Cruciani, Emilio and Miranda†, Breno and Bertolino, Antonia	JTeC: A Large Collection of Java Test Classes for Test Code Analysis and Processing	10.1145/3379597.3387484	2020	The recent push towards test automation and test-driven development continues to scale up the dimensions of test code that needs to be maintained, analysed, and processed side-by-side with production code. As a consequence, on the one side regression testing techniques, e.g., for test suite prioritization or test case selection, capable to handle such large-scale test suites become indispensable; on the other side, as test code exposes own characteristics, specific techniques for its analysis and refactoring are actively sought. We present JTeC, a large-scale dataset of test cases that researchers can use for benchmarking the above techniques or any other type of tool expressly targeting test code. JTeC collects more than 2.5M test classes belonging to 31K+ GitHub projects and summing up to more than 430 Million SLOCs of ready-to-use real-world test code.	https://doi.org/10.1145/3379597.3387484
264	Pimentel, Jo\\~ao Felipe and Murta, Leonardo and Braganholo, Vanessa and Freire, Juliana	A Large-Scale Study about Quality and Reproducibility of Jupyter Notebooks	10.1109/MSR.2019.00077	2019	Jupyter Notebooks have been widely adopted by many different communities, both in science and industry. They support the creation of literate programming documents that combine code, text, and execution results with visualizations and all sorts of rich media. The self-documenting aspects and the ability to reproduce results have been touted as significant benefits of notebooks. At the same time, there has been growing criticism that the way notebooks are being used leads to unexpected behavior, encourage poor coding practices, and that their results can be hard to reproduce. To understand good and bad practices used in the development of real notebooks, we studied 1.4 million notebooks from GitHub. We present a detailed analysis of their characteristics that impact reproducibility. We also propose a set of best practices that can improve the rate of reproducibility and discuss open challenges that require further research and development.	https://doi.org/10.1109/MSR.2019.00077
265	Constantinou, Eleni and Mens, Tom	Social and Technical Evolution of Software Ecosystems: A Case Study of Rails	10.1145/2993412.3003384	2016	Software ecosystems evolve through an active community of developers who contribute to projects within the ecosystem. However, development teams change over time, suggesting a potential impact on the evolution of the technical parts of the ecosystem. The impact of such modifications has been studied by previous works, but only temporary changes have been investigated, while the long-term effect of permanent changes has yet to be explored. In this paper, we investigate the evolution of the ecosystem of Ruby on Rails in GitHub in terms of such temporary and permanent changes of the development team. We use three viewpoints of the Rails ecosystem evolution to discuss our preliminary findings: (1) the base project; (2) the forks; and (3) the entire ecosystem containing both base project and forks.	https://doi.org/10.1145/2993412.3003384
266	Silva, Danilo and Tsantalis, Nikolaos and Valente, Marco Tulio	Why We Refactor? Confessions of GitHub Contributors	10.1145/2950290.2950305	2016	Refactoring is a widespread practice that helps developers to improve the maintainability and readability of their code. However, there is a limited number of studies empirically investigating the actual motivations behind specific refactoring operations applied by developers. To fill this gap, we monitored Java projects hosted on GitHub to detect recently applied refactorings, and asked the developers to explain the reasons behind their decision to refactor the code. By applying thematic analysis on the collected responses, we compiled a catalogue of 44 distinct motivations for 12 well-known refactoring types. We found that refactoring activity is mainly driven by changes in the requirements and much less by code smells. Extract Method is the most versatile refactoring operation serving 11 different purposes. Finally, we found evidence that the IDE used by the developers affects the adoption of automated refactoring tools. 	https://doi.org/10.1145/2950290.2950305
277	Trouv\\'e, Antoine and Murakami, Kazuaki J.	Interactive Visualization of Quantitative Data with G2D3	10.1145/2801040.2801066	2015	This article introduces G2D3, an implementation of the grammar of graphics in JavaScript, along with two practical use cases that illustrate its practicability. It makes it possible to generate interactive visualization of quantitative data in HTML/SVG. Compared to traditional static data visualization systems such as those featured in Excel and R, G2D3 makes it possible to greatly enhance the amount of conveyed information by means of animation and interaction. Compared to other JavaScript plotting libraries such as Rapha\\"el and D3, G2D3 leverages the expressiveness and the flexibility of the grammar of graphics to concisely generate complex visualization with many plotting dimensions, including time. It makes it possible to create a wide range of graphics with a few lines of code. G2D3 is open source and hosted in GitHub: join us!	https://doi.org/10.1145/2801040.2801066
267	Sobania, Dominik and Rothlauf, Franz	Teaching GP to Program like a Human Software Developer: Using Perplexity Pressure to Guide Program Synthesis Approaches	10.1145/3321707.3321738	2019	Program synthesis is one of the relevant applications of GP with a strong impact on new fields such as genetic improvement. In order for synthesized code to be used in real-world software, the structure of the programs created by GP must be maintainable. We can teach GP how real-world software is built by learning the relevant properties of mined human-coded software - which can be easily accessed through repository hosting services such as GitHub. So combining program synthesis and repository mining is a logical step. In this paper, we analyze if GP can write programs with properties similar to code produced by human software developers. First, we compare the structure of functions generated by different GP initialization methods to a mined corpus containing real-world software. The results show that the studied GP initialization methods produce a totally different combination of programming language elements in comparison to real-world software. Second, we propose perplexity pressure and analyze how its use changes the properties of code produced by GP. The results are very promising and show that we can guide the search to the desired program structure. Thus, we recommend using perplexity pressure as it can be easily integrated in various search-based algorithms.	https://doi.org/10.1145/3321707.3321738
268	Martin, Taylor and Brasiel, Sarah and Jeong, Soojeong and Close, Kevin and Lawanto, Kevin and Janisciewcz, Phil	Macro Data for Micro Learning: Developing the FUN! Tool for Automated Assessment of Learning	10.1145/2876034.2893422	2016	Digital learning environments are becoming more common for students to engage in during and outside of school. With the immense amount of data now available from these environments, researchers need tools to process, manage, and analyze the data. Current methods used by many education researchers are inefficient; however, without data science experience tools used in other professions are not accessible. In this paper, we share about a tool we created called the Functional Understanding Navigator! (FUN! Tool). We have used this tool for different research projects which has allowed us the opportunity to (1) organize our workflow process from start to finish, (2) record log data of all of our analyses, and (3) provide a platform to share our analyses with others through GitHub. This paper extends and improves existing work in educational data mining and learning analytics.	https://doi.org/10.1145/2876034.2893422
269	Eslami, Taban and Saeed, Fahad	Auto-ASD-Network: A Technique Based on Deep Learning and Support Vector Machines for Diagnosing Autism Spectrum Disorder Using FMRI Data	10.1145/3307339.3343482	2019	Quantitative analysis of brain disorders such as Autism Spectrum Disorder (ASD) is an ongoing field of research. Machine learning and deep learning techniques have been playing an important role in automating the diagnosis of brain disorders by extracting discriminative features from the brain data. In this study, we propose a model called Auto-ASD-Network in order to classify subjects with Autism disorder from healthy subjects using only fMRI data. Our model consists of a multilayer perceptron (MLP) with two hidden layers. We use an algorithm called SMOTE for performing data augmentation in order to generate artificial data and avoid overfitting, which helps increase the classification accuracy. We further investigate the discriminative power of features extracted using MLP by feeding them to an SVM classifier. In order to optimize the hyperparameters of SVM, we use a technique called Auto Tune Models (ATM) which searches over the hyperparameter space to find the best values of SVM hyperparameters. Our model achieves more than 70% classification accuracy for 4 fMRI datasets with the highest accuracy of 80%. It improves the performance of SVM by 26%, the stand-alone MLP by 16% and the state of the art method in ASD classification by 14%. The implemented code will be available as GPL license on GitHub portal of our lab (https://github.com/PCDS).	https://doi.org/10.1145/3307339.3343482
270	Pietri, Antoine and Spinellis, Diomidis and Zacchiroli, Stefano	The Software Heritage Graph Dataset: Public Software Development under One Roof	10.1109/MSR.2019.00030	2019	Software Heritage is the largest existing public archive of software source code and accompanying development history: it currently spans more than five billion unique source code files and one billion unique commits, coming from more than 80 million software projects.This paper introduces the Software Heritage graph dataset: a fully-deduplicated Merkle DAG representation of the Software Heritage archive. The dataset links together file content identifiers, source code directories, Version Control System (VCS) commits tracking evolution over time, up to the full states of VCS repositories as observed by Software Heritage during periodic crawls. The dataset's contents come from major development forges (including GitHub and GitLab), FOSS distributions (e.g., Debian), and language-specific package managers (e.g., PyPI). Crawling information is also included, providing timestamps about when and where all archived source code artifacts have been observed in the wild.The Software Heritage graph dataset is available in multiple formats, including downloadable CSV dumps and Apache Parquet files for local use, as well as a public instance on Amazon Athena interactive query service for ready-to-use powerful analytical processing.Source code file contents are cross-referenced at the graph leaves, and can be retrieved through individual requests using the Software Heritage archive API.	https://doi.org/10.1109/MSR.2019.00030
271	Nandigam, Viswanath and Lin, Kai and Shantharam, Manu and Sakai, Scott and Sivagnanam, Subhashini	Research Workflows - Towards Reproducible Science via Detailed Provenance Tracking in Open Science Chain	10.1145/3311790.3399619	2020	Scientific research has always struggled with problems related to reproducibility caused in part by low data sharing rates and lack of provenance. Credibility of the research hypothesis comes into question when results cannot be replicated. While the growing amount of data and widespread use of computational code in research has been pushing scientific breakthroughs, their references in scientific publications is insufficient from a reproducibility perspective. The NSF funded Open Science Chain (OSC) is a cyberinfrastructure platform built using blockchain technologies that enables researchers to efficiently validate the authenticity of published data, track their provenance and view lineage. It does this by leveraging blockchain technology to securely store metadata and verification information about research data and track changes to that data in an auditable manner. In this poster we introduce the concept of ”research workflows”, a tool that allows researchers to create a detailed workflow of their scientific experiment, linking specific data and computational code used in their published results in order to enable independent verification of the analysis. OSC research workflows will allow for detailed provenance tracking both within the OSC platform as well as external repositories like Github, thereby enabling transparency and fostering trust in the scientific process. 	https://doi.org/10.1145/3311790.3399619
272	Misra, Vishal and Reddy, Jakku Sai Krupa and Chimalakonda, Sridhar	Is There a Correlation between Code Comments and Issues? An Exploratory Study	10.1145/3341105.3374009	2020	Comments in a software code base are one of the key artifacts that help developers in understanding the code with respect to development and maintenance. Comments provide us with the information that is used as a software metric to assess the code quality and which further can be applied to demonstrate its impact on the issues in the code. In this paper, we set out to understand the correlation between code comments and issues in Github. We conduct an empirical study on 625 repositories hosted on GitHub with Python as their primary language. We manually classify comments from a randomly selected sample of python repositories and then train and evaluate classifiers to automatically label comments as Relevant or Auxiliary. We extract the metadata of issues in each repository present in our dataset and perform various experiments to understand the correlation between code comments and issues. From our dataset of python repositories, we then plot a graph between the average time taken to resolve an issue and percentage of relevant comments in a repository to find if there is any relation or a pattern by which the latter affects the former. Our statistical approach of finding out the correlation between code comments and issues gives us the correlation factor by which code comments are related to issues. We conclude from our study that comments are indeed important and play an important role in solving issues of the project. We also found that increasing the percentage of relevant comments along with the source code can help in the reduction of the average number of days before an issue is resolved.	https://doi.org/10.1145/3341105.3374009
273	Pietri, Antoine and Rousseau, Guillaume and Zacchiroli, Stefano	Forking Without Clicking: On How to Identify Software Repository Forks	10.1145/3379597.3387450	2020	The notion of software "fork" has been shifting over time from the (negative) phenomenon of community disagreements that result in the creation of separate development lines and ultimately software products, to the (positive) practice of using distributed version control system (VCS) repositories to collaboratively improve a single product without stepping on each others toes. In both cases the VCS repositories participating in a fork share parts of a common development history.Studies of software forks generally rely on hosting platform metadata, such as GitHub, as the source of truth for what constitutes a fork. These "forge forks" however can only identify as forks repositories that have been created on the platform, e.g., by clicking a "fork" button on the platform user interface. The increased diversity in code hosting platforms (e.g., GitLab) and the habits of significant development communities (e.g., the Linux kernel, which is not primarily hosted on any single platform) call into question the reliability of trusting code hosting platforms to identify forks. Doing so might introduce selection and methodological biases in empirical studies.In this article we explore various definitions of "software forks", trying to capture forking workflows that exist in the real world. We quantify the differences in how many repositories would be identified as forks on GitHub according to the various definitions, confirming that a significant number could be overlooked by only considering forge forks. We study the structure and size of fork networks, observing how they are affected by the proposed definitions and discuss the potential impact on empirical research.	https://doi.org/10.1145/3379597.3387450
274	Singer, Leif and Figueira Filho, Fernando and Storey, Margaret-Anne	Software Engineering at the Speed of Light: How Developers Stay Current Using Twitter	10.1145/2568225.2568305	2014	The microblogging service Twitter has over 500 million users posting over 500 million tweets daily. Research has established that software developers use Twitter in their work, but this has not yet been examined in detail. Twitter is an important medium in some software engineering circles—understanding its use could lead to improved support, and learning more about the reasons for non-adoption could inform the design of improved tools. In a qualitative study, we surveyed 271 and interviewed 27 developers active on GitHub. We find that Twitter helps them keep up with the fast-paced development landscape. They use it to stay aware of industry changes, for learning, and for building relationships. We discover the challenges they experience and extract their coping strategies. Some developers do not want to or cannot embrace Twitter for their work—we show their reasons and alternative channels. We validate our findings in a follow-up survey with more than 1,200 respondents. 	https://doi.org/10.1145/2568225.2568305
275	Mustyatsa, Vadim	BDD by Example: Russian Bylina Written in Gherkin Language	10.1145/2855667.2855678	2015	In this paper is presented the User Stories technique within the Behaviour-Driven Development process by example of the famous Russian bylina (epic poem) "Three trips of Ilya Muromets" written in Gherkin language. In the first part are given explanations about the choice of the bylina as a good example for presentation of this technique and about the choice of GitHub as a good environment for this presentation. In the second part is placed the text of the presentation divided by the stages of the Story development and fitted with the links to the corresponding commits and file versions in the educational repository. A distinct advantage of this presentation is that it reflects a Story in its evolution, as a process. It reflects a more complex and changeable behaviour than in static trivial examples, which are usually used. Also, there are presented the main features of using the User Stories technique in Russian language, which have not been previously covered nowhere. Besides that, the using of the educational repository can significantly increase the possibilities for further spreading and development of the example.	https://doi.org/10.1145/2855667.2855678
276	Widder, David Gray and Hilton, Michael and K\\"astner, Christian and Vasilescu, Bogdan	A Conceptual Replication of Continuous Integration Pain Points in the Context of Travis CI	10.1145/3338906.3338922	2019	Continuous integration (CI) is an established software quality assurance practice, and the focus of much prior research with a diverse range of methods and populations. In this paper, we first conduct a literature review of 37 papers on CI pain points. We then conduct a conceptual replication study on results from these papers using a triangulation design consisting of a survey with 132 responses, 12 interviews, and two logistic regressions predicting Travis CI abandonment and switching on a dataset of 6,239 GitHub projects. We report and discuss which past results we were able to replicate, those for which we found conflicting evidence, those for which we did not find evidence, and the implications of these findings.	https://doi.org/10.1145/3338906.3338922
278	Zhu, Zhaomeng and Zhang, Gongxuan and Zhang, Yongping and Guo, Jian and Xiong, Naixue	Briareus: Accelerating Python Applications with Cloud	10.1109/IPDPSW.2013.161	2013	Briareus provides convenient tools to make use of computing resources provided by cloud to accelerate Python applications. In this paper, three techniques are presented. First, some of the functions in a Python program can be migrated to cloud and be evaluated using the hardware and software provided by that cloud platform, while the other parts still running locally. Second, Briareus can automatically parallelize specified loops in a program to accelerate it. And third, specified functions can be called asynchronously after being patched, so that two or more functions can be evaluated simultaneously. By combining these three methods, a Python application can make part of itself to run in a remote cloud platform in parallel. To use Briareus, developers do not need to modify the existing source much, but only need to insert some descriptive comments and invoke a patching function at the beginning. Experiments show that Briareus can significantly speed up the running of programs written by Python, especially for those for scientific and engineering computing. The early beta version of Briareus has been developed for testing and all sources are accessible to public via GitHub and installable via PyPI.	https://doi.org/10.1109/IPDPSW.2013.161
279	Trockman, Asher and van Tonder, Rijnard and Vasilescu, Bogdan	Striking Gold in Software Repositories? An Econometric Study of Cryptocurrencies on GitHub	10.1109/MSR.2019.00036	2019	Cryptocurrencies have a significant open source development presence on GitHub. This presents a unique opportunity to observe their related developer effort and software growth. Individual cryptocurrency prices are partly driven by attractiveness, and we hypothesize that high-quality, actively-developed software is one of its influences. Thus, we report on a study of a panel data set containing nearly a year of daily observations of development activity, popularity, and market capitalization for over two hundred open source cryptocurrencies. We find that open source project popularity is associated with higher market capitalization, though development activity and quality assurance practices are insignificant variables in our models. Using Granger causality tests, we find no compelling evidence for a dynamic relation between market capitalization and metrics such as daily stars, forks, watchers, commits, contributors, and lines of code changed.	https://doi.org/10.1109/MSR.2019.00036
280	Santolucito, Mark	Version Space Learning for Verification on Temporal Differentials	10.1145/3092703.3098238	2017	Configuration files provide users with the ability to quickly alter the behavior of their software system. Ensuring that a configuration file does not induce errors in the software is a complex verification issue. The types of errors can be easy to measure, such as an initialization failure of system boot, or more insidious such as performance degrading over time under heavy network loads. In order to warn a user of potential configuration errors ahead of time, we propose using version space learning specifications for configuration languages. We frame an existing tool, ConfigC, in terms of version space learning. We extend that algorithm to leverage the temporal structuring available in training sets scraped from versioning control systems. We plan to evaluate our system on a case study using TravisCI configuration files collected from Github. 	https://doi.org/10.1145/3092703.3098238
281	Celi\\'nska, Dorota	Coding Together in a Social Network: Collaboration among GitHub Users	10.1145/3217804.3217895	2018	In this article we investigate developers involved in the creation of Open Source software to identify which characteristics favor innovation in the Open Source community. The results of the analysis show that higher reputation in the community improves the probability of gaining collaborators to a certain degree, but developers are also driven by reciprocity. This is consistent with the concept of gift economy. A significant network effect exists and emerges from standardization, showing that developers using the most popular programming languages in the service are likely to have more collaborators. Providing additional information (valid URL to developer's homepage) improves the chances of finding coworkers. The results can be generalized for the population of mature users of GitHub.	https://doi.org/10.1145/3217804.3217895
282	Hassan, Foyzul and Wang, Xiaoyin	Mining Readme Files to Support Automatic Building of Java Projects in Software Repositories: Poster	10.1109/ICSE-C.2017.114	2017	Automatic building of software projects provides a desirable foundation to support a large variety of software engineering research tasks based on open software repositories. In this paper, we propose the first technique to automatically extract software build commands from software readme files and Wiki pages, and combine the extracted commands for software building. Specifically, we leverage the Named Entity Recognition (NER) technique for build-command extraction, and prioritize the extracted build commands to identify which one should be used in software build. Our experiment on top Java projects from GitHub reveals that, the proposed technique can correctly identify more than 90% of build commands, and can successfully build 84% of the projects that can be built successfully through manual inspection of software support documents.	https://doi.org/10.1109/ICSE-C.2017.114
283	Ford, Denae and Behroozi, Mahnaz and Serebrenik, Alexander and Parnin, Chris	Beyond the Code Itself: How Programmers <i>Really</i> Look at Pull Requests	10.1109/ICSE-SEIS.2019.17	2019	Developers in open source projects must make decisions on contributions from other community members, such as whether or not to accept a pull request. However, secondary factors---beyond the code itself---can influence those decisions. For example, signals from GitHub profiles, such as a number of followers, activity, names, or gender can also be considered when developers make decisions. In this paper, we examine how developers use these signals (or not) when making decisions about code contributions. To evaluate this question, we evaluate how signals related to perceived gender identity and code quality influenced decisions on accepting pull requests. Unlike previous work, we analyze this decision process with data collected from an eye-tracker. We analyzed differences in what signals developers said are important for themselves versus what signals they actually used to make decisions about others. We found that after the code snippet (x = 57%), the second place programmers spent their time ixating is on supplemental technical signals (x = 32%), such as previous contributions and popular repositories. Diverging from what participants reported themselves, we also found that programmers ixated on social signals more than recalled.	https://doi.org/10.1109/ICSE-SEIS.2019.17
284	Linares-Vasquez, Mario and Vendome, Christopher and Luo, Qi and Poshyvanyk, Denys	How Developers Detect and Fix Performance Bottlenecks in Android Apps	10.1109/ICSM.2015.7332486	2015	Performance of rapidly evolving mobile apps is one of the top concerns for users and developers nowadays. Despite the efforts of researchers and mobile API designers to provide developers with guidelines and best practices for improving the performance of mobile apps, performance bottlenecks are still a significant and frequent complaint that impacts the ratings and apps' chances for success. However, little research has been done into understanding actual developers' practices for detecting and fixing performance bottlenecks in mobile apps. In this paper, we present the results of an empirical study aimed at studying and understanding these practices by surveying 485 open source Android app and library developers, and manually analyzing performance bugs and fixes in their app repositories hosted on GitHub. The paper categorizes actual practices and tools used by real developers while dealing with performance issues. In general, our findings indicate that developers heavily rely on user reviews and manual execution of the apps for detecting performance bugs. While developers also use available tools to detect performance bottlenecks, these tools are mostly for profiling and do not help in detecting and fixing performance issues automatically.	https://doi.org/10.1109/ICSM.2015.7332486
285	Chua, Bee Bee and Zhang, Ying	Predicting Open Source Programming Language Repository File Survivability from Forking Data	10.1145/3306446.3340827	2019	Very few studies have looked at repositories' programming language survivability in response to forking conditions. A high number of repository programming languages does not alone ensure good forking performance. To address this issue and assist project owners in adopting the right programming language, it is necessary to predict programming language survivability from forking in repositories. This paper therefore addresses two related questions: are there statistically meaningful patterns within repository data and, if so, can these patterns be used to predict programming language survival? To answer these questions we analysed 47,000 forking instances in 1000 GitHub projects. We used Euclidean distance applied in the K-Nearest Neighbour algorithm to predict the distance between repository file longevity and forking conditions. We found three pattern types ('once-only', intermittent or steady) and propose reasons for short-lived programming languages.	https://doi.org/10.1145/3306446.3340827
286	Noten, Jeroen and Mengerink, Josh G. M. and Serebrenik, Alexander	A Data Set of OCL Expressions on GitHub	10.1109/MSR.2017.52	2017	In model driven engineering (MDE), meta-models are the central artifacts. As a complement, the Object Constraint Language (OCL) is a language used to express constraints and operations on meta-models. The Eclipse Modeling Framework (EMF) provides an implementation of OCL, enabling OCL annotated meta-models.Existing empirical studies of the OCL have been conducted on small collections of data. To facilitate empirical research into the OCL on a larger scale, we present the first publicly-available data set of OCL expressions. The data set contains 9188 OCL expressions originating from 504 EMF meta-models in 245 systematically selected GitHub repositories. Both the original meta-models and the generated abstract syntax trees are included, allowing for a variety of empirical studies of the OCL. To illustrate the applicability of this data set in practice, we performed three case studies.	https://doi.org/10.1109/MSR.2017.52
287	Wittern, Erik and Suter, Philippe and Rajagopalan, Shriram	A Look at the Dynamics of the JavaScript Package Ecosystem	10.1145/2901739.2901743	2016	The node package manager (npm) serves as the frontend to a large repository of JavaScript-based software packages, which foster the development of currently huge amounts of server-side Node. js and client-side JavaScript applications. In a span of 6 years since its inception, npm has grown to become one of the largest software ecosystems, hosting more than 230, 000 packages, with hundreds of millions of package installations every week. In this paper, we examine the npm ecosystem from two complementary perspectives: 1) we look at package descriptions, the dependencies among them, and download metrics, and 2) we look at the use of npm packages in publicly available applications hosted on GitHub. In both perspectives, we consider historical data, providing us with a unique view on the evolution of the ecosystem. We present analyses that provide insights into the ecosystem's growth and activity, into conflicting measures of package popularity, and into the adoption of package versions over time. These insights help understand the evolution of npm, design better package recommendation engines, and can help developers understand how their packages are being used.	https://doi.org/10.1145/2901739.2901743
288	Granderath, Malte and Sch\\"onw\\"alder, J\\"urgen	A Resource Efficient Implementation of the RESTCONF Protocol for OpenWrt Systems	10.1109/NOMS47738.2020.9110458	2020	In recent years, the open source operating system OpenWrt has become a popular option for replacing proprietary firmware on networking devices such as home routers or access points. In order to configure an OpenWrt system, like setting up firewall rules, the user has to either sign in to the web interface or use SSH to manually change configuration files on the device. While the current approach is sufficient for small home networks, it only allows for limited automation of management tasks and configuration management becomes time-consuming, for example, on larger campus networks where access control lists on OpenWrt access points need updates regularly.This paper describes our efforts to implement the RESTCONF configuration management protocol standardized by the IETF on OpenWrt systems that have limited CPU and memory resources. We detail our design choices that make our implementation resource efficient for the use cases we target and we compare our implementation against other similar solutions. Our implementation is available on GitHub under an open source license<sup>1</sup>.	https://doi.org/10.1109/NOMS47738.2020.9110458
289	Urli, Simon and Yu, Zhongxing and Seinturier, Lionel and Monperrus, Martin	How to Design a Program Repair Bot? Insights from the Repairnator Project	10.1145/3183519.3183540	2018	Program repair research has made tremendous progress over the last few years, and software development bots are now being invented to help developers gain productivity. In this paper, we investigate the concept of a "program repair bot" and present Repairnator. The Repairnator bot is an autonomous agent that constantly monitors test failures, reproduces bugs, and runs program repair tools against each reproduced bug. If a patch is found, Repairnator bot reports it to the developers. At the time of writing, Repairnator uses three different program repair systems and has been operating since February 2017. In total, it has studied 11 523 test failures over 1 609 open-source software projects hosted on GitHub, and has generated patches for 15 different bugs. Over months, we hit a number of hard technical challenges and had to make various design and engineering decisions. This gives us a unique experience in this area. In this paper, we reflect upon Repairnator in order to share this knowledge with the automatic program repair community.	https://doi.org/10.1145/3183519.3183540
290	Salgado, Ronie and Bergel, Alexandre	Pharo Git Thermite: A Visual Tool for Deciding to Weld a Pull Request	10.1145/3139903.3139916	2017	Collaborative software development platforms such as GitHub simplify the process of contributing into open source projects by the use of a pull request. The decision of accepting or rejecting a pull request has to be made by an integrator. Because reviewing a pull request can be time consuming, social factors are known to have an important effect on the acceptation of a pull request. This effect can be especially important for large and complicated pull request.In this paper we present Git Thermite, a tool to assess the internal structure of a pull request and simplifying the job of the integrator. Git Thermite details the structural changes made on the source code. In Git Thermite we use a pull request business card visual metaphor for describing a pull request. In this business card, we present the pull request metadata and describe the modified files, and the structural changes in the modified source code.	https://doi.org/10.1145/3139903.3139916
291	Song, Bowen and Trachtenberg, Ari	Scalable String Reconciliation by Recursive Content-Dependent Shingling	10.1109/ALLERTON.2019.8919901	2019	We consider the problem of reconciling similar, but remote, strings with minimum communication complexity. This “string reconciliation” problem is a fundamental building block for a variety of networking applications, including those that maintain large-scale distributed networks and perform remote file synchronization. We present the novel Recursive Content-Dependent Shingling (RCDS) protocol that is computationally practical for large strings and scales linearly with the edit distance between the remote strings. We provide comparisons to the performance of rsync, one of the most popular file synchronization tools in active use. Our experiments show that, with minimal engineering, RCDS outperforms the heavily optimized rsync in reconciling release revisions for about 51% of the 5000 top starred git repositories on GitHub. The improvement is particularly evident for repositories that see frequent, but small, updates.	https://doi.org/10.1109/ALLERTON.2019.8919901
292	Meinicke, Jens and Hoyos, Juan and Vasilescu, Bogdan and K\\"astner, Christian	Capture the Feature Flag: Detecting Feature Flags in Open-Source	10.1145/3379597.3387463	2020	Feature flags (a.k.a feature toggles) are a mechanism to keep new features hidden behind a boolean option during development. Flags are used for many purposes, such as A/B testing and turning off a feature more easily in case of failures. While software engineering research on feature flags is burgeoning, examples of software projects using flags rarely come from outside commercial and private projects, stifling academic progress. To address this gap, in this paper we present a novel semi-automated mining software repositories approach to detect feature flags in open-source projects, based on analyzing the projects' commit messages and other project characteristics. With our approach, we search over all open-source GitHub projects, finding multiple thousand plausible and active candidate feature flagging projects. We manually validate projects and assemble a dataset of 100 confirmed feature flagging projects. To demonstrate the benefits of our detection technique, we report on an initial analysis of feature flags in the validated sample of 100 projects, investigating practices that correlate with shorter flag lifespans (typically desirable to reduce technical debt), such as using the issue tracker and having a flag owner.	https://doi.org/10.1145/3379597.3387463
293	Tavares, Alberto Trindade and Borba, Paulo and Cavalcanti, Guilherme and Soares, S\\'ergio	Semistructured Merge in JavaScript Systems	10.1109/ASE.2019.00098	2019	Industry widely uses unstructured merge tools that rely on textual analysis to detect and resolve conflicts between code contributions. Semistructured merge tools go further by partially exploring the syntactic structure of code artifacts, and, as a consequence, obtaining significant merge accuracy gains for Java-like languages. To understand whether semistructured merge and the observed gains generalize to other kinds of languages, we implement two semistructured merge tools for JavaScript, and compare them to an unstructured tool. We find that current semistructured merge algorithms and frameworks are not directly applicable for scripting languages like JavaScript. By adapting the algorithms, and studying 10,345 merge scenarios from 50 JavaScript projects on GitHub, we find evidence that our JavaScript tools report fewer spurious conflicts than unstructured merge, without compromising the correctness of the merging process. The gains, however, are much smaller than the ones observed for Java-like languages, suggesting that semistructured merge advantages might be limited for languages that allow both commutative and non-commutative declarations at the same syntactic level.	https://doi.org/10.1109/ASE.2019.00098
294	Yang, Le and Zhang, Zhongda and Chen, Enci	Customization and Localization of DSpace-CRIS in China	10.1145/3383583.3398548	2020	Traditional institutional repository (IR) has been broadly used and improved in practice for decades. Current Research Information System (CRIS) is one of the extended systems that broadens the traditional IR systems' functionality by expanding the data and visualization modules. Beyond the basic functions of an IR, CRIS extends to distribute multimedia scholarly publications, manage research data, provide evaluation on research performance, visualize research network, enable research profiling, support project-based activities, integrate citation metrics, etc. This paper introduces the first DSpace-CRIS system that was implemented in mainland China at Wenzhou-Kean University (WKU) and explains the localized efforts of technologies and customized development of modules. The development team has also released the installation of developed modules as open sources on GitHub. The paper outlines the future development plan for the institution.	https://doi.org/10.1145/3383583.3398548
295	Shi, August and Gyori, Alex and Mahmood, Suleman and Zhao, Peiyuan and Marinov, Darko	Evaluating Test-Suite Reduction in Real Software Evolution	10.1145/3213846.3213875	2018	Test-suite reduction (TSR) speeds up regression testing by removing redundant tests from the test suite, thus running fewer tests in the future builds. To decide whether to use TSR or not, a developer needs some way to predict how well the reduced test suite will detect real faults in the future compared to the original test suite. Prior research evaluated the cost of TSR using only program versions with seeded faults, but such evaluations do not explicitly predict the effectiveness of the reduced test suite in future builds.  We perform the first extensive study of TSR using real test failures in (failed) builds that occurred for real code changes. We analyze 1478 failed builds from 32 GitHub projects that run their tests on Travis. Each failed build can have multiple faults, so we propose a family of mappings from test failures to faults. We use these mappings to compute Failed-Build Detection Loss (FBDL), the percentage of failed builds where the reduced test suite misses to detect all the faults detected by the original test suite. We find that FBDL can be up to 52.2%, which is higher than suggested by traditional TSR metrics. Moreover, traditional TSR metrics are not good predictors of FBDL, making it difficult for developers to decide whether to use reduced test suites.	https://doi.org/10.1145/3213846.3213875
296	Thung, Ferdian and Kochhar, Pavneet Singh and Lo, David	DupFinder: Integrated Tool Support for Duplicate Bug Report Detection	10.1145/2642937.2648627	2014	To track bugs that appear in a software, developers often make use of a bug tracking system. Users can report bugs that they encounter in such a system. Bug reporting is inherently an uncoordinated distributed process though and thus when a user submits a new bug report, there might be cases when another bug report describing exactly the same problem is already present in the system. Such bug reports are duplicate of each other and these duplicate bug reports need to be identified. A number of past studies have proposed a number of automated approaches to detect duplicate bug reports. However, these approaches are not integrated to existing bug tracking systems. In this paper, we propose a tool named DupFinder, which implements the state-of-the-art unsupervised duplicate bug report approach by Runeson et al., as a Bugzilla extension. DupFinder does not require any training data and thus can easily be deployed to any project. DupFinder extracts texts from summary and description fields of a new bug report and recent bug reports present in a bug tracking system, uses vector space model to measure similarity of bug reports, and provides developers with a list of potential duplicate bug reports based on the similarity of these reports with the new bug report. We have released DupFinder as an open source tool in GitHub, which is available at: https://github.com/smagsmu/dupfinder.	https://doi.org/10.1145/2642937.2648627
297	Peng, Zhenhui and Yoo, Jeehoon and Xia, Meng and Kim, Sunghun and Ma, Xiaojuan	Exploring How Software Developers Work with Mention Bot in GitHub	10.1145/3202667.3202694	2018	Recently, major software development platforms have started to provide automatic reviewer recommendation (ARR) services for pull requests, to improve the collaborative coding review process. However, the user experience of ARR is under-investigated. In this paper, we use a two-stage mixed-methods approach to study how software developers perceive and work with the Facebook mention bot, one of the most popular ARR bots in GitHub. Specifically, in Stage I, we conduct archival analysis on projects employing mention bot and a user survey to investigate the bot's performance. A year later, in Stage II, we revisit these projects and conduct additional surveys and interviews with three user groups: project owners, contributors and reviewers. Results show that developers appreciate mention bot saving their effort, but are bothered by its unstable setting and unbalanced workload allocation. We conclude with design considerations for improving ARR services.	https://doi.org/10.1145/3202667.3202694
298	Humbatova, Nargiz and Jahangirova, Gunel and Bavota, Gabriele and Riccio, Vincenzo and Stocco, Andrea and Tonella, Paolo	Taxonomy of Real Faults in Deep Learning Systems	10.1145/3377811.3380395	2020	The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance. In this paper we introduce a large taxonomy of faults in deep learning (DL) systems. We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our taxonomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants.	https://doi.org/10.1145/3377811.3380395
299	Squire, Megan	Forge++: The Changing Landscape of FLOSS Development	10.1109/HICSS.2014.405	2014	Software forges are centralized online systems that provide useful tools to help distributed development teams work together, especially in free, libre, and open source software (FLOSS). Forge-provided tools may include web space, version control systems, mailing lists and communication forums, bug tracking systems, file downloads, wikis, and the like. Empirical software engineering researchers can mine the artifacts from these tools to better understand how FLOSS is made. As the landscape of distributed software development has grown and changed, the tools needed to make FLOSS have changed as well. There are three newer tools at the center of FLOSS development today: distributed version control based forges (like Github), programmer question-and-answer communities (like Stack Overflow), and paste bin tools (like Gist or Pastebin.com). These tools are extending and changing the toolset used for FLOSS development, and redefining what a software forge looks like. The main contributions of this paper are to describe each of these tools, to identify the data and artifacts available for mining from these tools, and to outline some of the ways researchers can use these artifacts to continue to understand how FLOSS is made.	https://doi.org/10.1109/HICSS.2014.405
300	Overney, Cassandra and Meinicke, Jens and K\\"astner, Christian and Vasilescu, Bogdan	How to Not Get Rich: An Empirical Study of Donations in Open Source	10.1145/3377811.3380410	2020	Open source is ubiquitous and many projects act as critical infrastructure, yet funding and sustaining the whole ecosystem is challenging. While there are many different funding models for open source and concerted efforts through foundations, donation platforms like PayPal, Patreon, and OpenCollective are popular and low-bar platforms to raise funds for open-source development. With a mixed-method study, we investigate the emerging and largely unexplored phenomenon of donations in open source. Specifically, we quantify how commonly open-source projects ask for donations, statistically model characteristics of projects that ask for and receive donations, analyze for what the requested funds are needed and used, and assess whether the received donations achieve the intended outcomes. We find 25,885 projects asking for donations on GitHub, often to support engineering activities; however, we also find no clear evidence that donations influence the activity level of a project. In fact, we find that donations are used in a multitude of ways, raising new research questions about effective funding.	https://doi.org/10.1145/3377811.3380410
323	Sanchez, Beatriz A. and Barmpis, Konstantinos and Neubauer, Patrick and Paige, Richard F. and Kolovos, Dimitrios S.	Restmule: Enabling Resilient Clients for Remote APIs	10.1145/3196398.3196405	2018	Mining data from remote repositories, such as GitHub and StackExchange, involves the execution of requests that can easily reach the limitations imposed by the respective APIs to shield their services from overload and abuse. Therefore, data mining clients are left alone to deal with such protective service policies which usually involves an extensive amount of manual implementation effort. In this work we present RestMule, a framework for handling various service policies, such as limited number of requests within a period of time and multi-page responses, by generating resilient clients that are able to handle request rate limits, network failures, response caching, and paging in a graceful and transparent manner. As a result, RestMule clients generated from OpenAPI specifications (i.e. standardized REST API descriptors), are suitable for intensive data-fetching scenarios. We evaluate our framework by reproducing an existing repository mining use case and comparing the results produced by employing a popular hand-written client and a RestMule client.	https://doi.org/10.1145/3196398.3196405
301	Kanakia, Anshul and Shen, Zhihong and Eide, Darrin and Wang, Kuansan	A Scalable Hybrid Research Paper Recommender System for Microsoft Academic	10.1145/3308558.3313700	2019	We present the design and methodology for the large scale hybrid paper recommender system used by Microsoft Academic. The system provides recommendations for approximately 160 million English research papers and patents. Our approach handles incomplete citation information while also alleviating the cold-start problem that often affects other recommender systems. We use the Microsoft Academic Graph (MAG), titles, and available abstracts of research papers to build a recommendation list for all documents, thereby combining co-citation and content based approaches. Tuning system parameters also allows for blending and prioritization of each approach which, in turn, allows us to balance paper novelty versus authority in recommendation results. We evaluate the generated recommendations via a user study of 40 participants, with over 2400 recommendation pairs graded and discuss the quality of the results using P@10 and nDCG scores. We see that there is a strong correlation between participant scores and the similarity rankings produced by our system but that additional focus needs to be put towards improving recommender precision, particularly for content based recommendations. The results of the user survey and associated analysis scripts are made available via GitHub and the recommendations produced by our system are available as part of the MAG on Azure to facilitate further research and light up novel research paper recommendation applications.	https://doi.org/10.1145/3308558.3313700
302	Ehmueller, Jan and Riese, Alexander and Tjabben, Hendrik and Niephaus, Fabio and Hirschfeld, Robert	Polyglot Code Finder	10.1145/3397537.3397559	2020	With the increasing complexity of software, it becomes even more important to build on the work of others. At the same time, websites, such as Stack Overflow or GitHub, are used by millions of developers to host their code, which could potentially be reused.  The process of finding the right code, however, is often time-consuming. In addition, the right solution may be written in a programming language that does not fit the developer's requirements. Current approaches to automate code search allow users to search for code based on keywords and transformation rules, but they are limited to one programming language.  Our approach enables developers to find code for reuse written in different languages, which is especially useful when building polyglot applications. In addition to conventional search filters, users can filter code by providing example input and expected output. Based on our approach, we have implemented a tool prototype in GraalSqueak. We evaluate both approach and prototype with an experience report.	https://doi.org/10.1145/3397537.3397559
303	Murillo, Andr\\'es Felipe and C\\'ombita, Luis Francisco and Gonzalez, Andrea Calder\\'on and Rueda, Sandra and Cardenas, Alvaro A. and Quijano, Nicanor	A Virtual Environment for Industrial Control Systems: A Nonlinear Use-Case in Attack Detection, Identification, and Response	10.1145/3295453.3295457	2018	The integration of modern information technologies with industrial control systems has created an enormous interest in the security of industrial control, however, given the cost, variety, and industry practices, it is hard for researchers to test and deploy security solutions in real-world systems. Industrial control testbeds can be used as tools to test security solutions before they are deployed, and in this paper we extend our previous work to develop open-source virtual industrial control testbeds where computing and networking components are emulated and virtualized, and the physical system is simulated through differential equations. In particular, we implement a nonlinear control system emulating a three-water tank with the associated sensors, PLCs, and actuators that communicate through an emulated network. In addition, we design unknown input observers (UIO) to not only detect that an attack is occurring, but also to identify the source of the malicious false data injections and mitigate its impact. Our system is available through Github to the academic community.	https://doi.org/10.1145/3295453.3295457
304	Wu, Yiwen and Zhang, Yang and Wang, Tao and Wang, Huaimin	An Empirical Study of Build Failures in the Docker Context	10.1145/3379597.3387483	2020	Docker containers have become the de-facto industry standard. Docker builds often break, and a large amount of efforts are put into troubleshooting broken builds. Prior studies have evaluated the rate at which builds in large organizations fail. However, little is known about the frequency and fix effort of failures that occur in Docker builds of open-source projects. This paper provides a first attempt to present a preliminary study on 857,086 Docker builds from 3,828 open-source projects hosted on GitHub. Using the Docker build data, we measure the frequency of broken builds and report their fix time. Furthermore, we explore the evolution of Docker build failures across time. Our findings help to characterize and understand Docker build failures and motivate the need for collecting more empirical evidence.	https://doi.org/10.1145/3379597.3387483
305	Hu, Xing and Li, Ge and Xia, Xin and Lo, David and Jin, Zhi	Deep Code Comment Generation	10.1145/3196321.3196334	2018	During software maintenance, code comments help developers comprehend programs and reduce additional time spent on reading and navigating source code. Unfortunately, these comments are often mismatched, missing or outdated in the software projects. Developers have to infer the functionality from the source code. This paper proposes a new approach named DeepCom to automatically generate code comments for Java methods. The generated comments aim to help developers understand the functionality of Java methods. DeepCom applies Natural Language Processing (NLP) techniques to learn from a large code corpus and generates comments from learned features. We use a deep neural network that analyzes structural information of Java methods for better comments generation. We conduct experiments on a large-scale Java corpus built from 9,714 open source projects from GitHub. We evaluate the experimental results on a machine translation metric. Experimental results demonstrate that our method DeepCom outperforms the state-of-the-art by a substantial margin.	https://doi.org/10.1145/3196321.3196334
306	Lin, Bin and Ponzanelli, Luca and Mocci, Andrea and Bavota, Gabriele and Lanza, Michele	On the Uniqueness of Code Redundancies	10.1109/ICPC.2017.36	2017	Code redundancy widely occurs in software projects. Researchers have investigated the existence, causes, and impacts of code redundancy, showing that it can be put to good use, for example in the context of code completion. When analyzing source code redundancy, previous studies considered software projects as sequences of tokens, neglecting the role of the syntactic structures enforced by programming languages. However, differences in the redundancy of such structures may jeopardize the performance of applications leveraging code redundancy.We present a study of the redundancy of several types of code constructs in a large-scale dataset of active Java projects mined from GitHub, unveiling that redundancy is not uniform and mainly resides in specific code constructs. We further investigate the implications of the locality of redundancy by analyzing the performance of language models when applied to code completion. Our study discloses the perils of exploiting code redundancy without taking into account its strong locality in specific code constructs.	https://doi.org/10.1109/ICPC.2017.36
307	D\\'esarmeaux, Casimir and Pecatikov, Andrea and McIntosh, Shane	The Dispersion of Build Maintenance Activity across Maven Lifecycle Phases	10.1145/2901739.2903498	2016	Build systems describe how source code is translated into deliverables. Developers use build management tools like Maven to specify their build systems. Past work has shown that while Maven provides invaluable features (e.g., incremental building), it introduces an overhead on software development. Indeed, Maven build systems require maintenance. However, Maven build systems follow the build lifecycle, which is comprised of validate, compile, test, packaging, install, and deploy phases. Little is known about how build maintenance activity is dispersed among these lifecycle phases. To bridge this gap, in this paper, we analyze the dispersion of build maintenance activity across build lifecycle phases. Through analysis of 1,181 GitHub repositories that use Maven, we find that: (1) the compile phase accounts for 24% more of the build maintenance activity than the other phases; and (2) while the compile phase generates a consistent amount of maintenance activity over time, the other phases tend to generate peaks and valleys of maintenance activity. Software teams that use Maven should plan for these shifts in the characteristics of build maintenance activity.	https://doi.org/10.1145/2901739.2903498
308	Wang, Jingbo and Aryani, Amir and Wyborn, Lesley and Evans, Ben	Providing Research Graph Data in JSON-LD Using Schema.Org	10.1145/3041021.3053052	2017	In this position paper, we describe a pilot project that provides Research Graph records to external web services using JSON-LD. The Research Graph database contains a large-scale graph that links research datasets (i.e., data used to support research) to funding records (i.e. grants), publications and researcher records such as ORCID profiles. This database was derived from the work of the Research Data Alliance Working Group on Data Description Registry Interoperability (DDRI), and curated using the Research Data Switchboard open source software. By being available in Linked Data format, the Research Graph database is more accessible to third-party web services over the Internet, which thus opens the opportunity to connect to the rest of the world in the semantic format.The primary purpose of this pilot project is to evaluate the feasibility of converting registry objects in Research Graph to JSON-LD by accessing widely used vocabularies published at Schema.org. In this paper, we provide examples of publications, datasets and grants from international research institutions such as CERN INSPIREHEP, National Computational Infrastructure (NCI) in Australia, and Australian Research Council (ARC). Furthermore, we show how these Research Graph records are made semantically available as Linked Data through using Schema.org. The mapping between Research Graph schema and Schema.org is available on GitHub repository. We also discuss the potential need for an extension to Schema.org vocabulary for scholarly communication.	https://doi.org/10.1145/3041021.3053052
309	Rahkema, Kristiina and Pfahl, Dietmar	Empirical Study on Code Smells in IOS Applications	10.1145/3387905.3388597	2020	Code smells are recurring patterns in code that have been identified as bad practices. They have been analysed extensively in Java desktop applications. For mobile applications most of the research has been done for Android with very little research done for iOS. Although Android has the largest market share, iOS is a very popular platform. Our goal is to understand the distribution of code smells in iOS applications. For this analysis we used a collaborative list of open source iOS applications from GitHub. We combined code smells defined by Fowler and object oriented code smells studied on Android. We developed a tool that can detect these code smells in Swift applications. We discovered that iOS applications are most often affected by Lazy Class, Long Method and Message Chain code smells. Most often occurring code smells are Internal Duplication, Lazy Class and Long Method.	https://doi.org/10.1145/3387905.3388597
310	He, Yeye and Ganjam, Kris and Lee, Kukjin and Wang, Yue and Narasayya, Vivek and Chaudhuri, Surajit and Chu, Xu and Zheng, Yudian	Transform-Data-by-Example (TDE): Extensible Data Transformation in Excel	10.1145/3183713.3193539	2018	Business analysts and data scientists today increasingly need to clean, standardize and transform diverse data sets, such as name, address, date time, phone number, etc., before they can perform analysis. These ad-hoc transformation problems are typically solved by one-off scripts, which is both difficult and time-consuming.Our observation is that these domain-specific transformation problems have long been solved by developers with code libraries, which are often shared in places like GitHub. We thus develop an extensible data transformation system called Transform-Data-by-Example (TDE) that can leverage rich transformation logic in source code, DLLs, web services and mapping tables, so that end-users only need to provide a few (typically 3) input/output examples, and TDE can synthesize desired programs using relevant transformation logic from these sources. The beta version of TDE was released in Office Store for Excel.	https://doi.org/10.1145/3183713.3193539
311	Islam, Md Johirul and Pan, Rangeet and Nguyen, Giang and Rajan, Hridesh	Repairing Deep Neural Networks: Fix Patterns and Challenges	10.1145/3377811.3380378	2020	Significant interest in applying Deep Neural Network (DNN) has fueled the need to support engineering of software that uses DNNs. Repairing software that uses DNNs is one such unmistakable SE need where automated tools could be beneficial; however, we do not fully understand challenges to repairing and patterns that are utilized when manually repairing DNNs. What challenges should automated repair tools address? What are the repair patterns whose automation could help developers? Which repair patterns should be assigned a higher priority for building automated bug repair tools? This work presents a comprehensive study of bug fix patterns to address these questions. We have studied 415 repairs from Stack Overflow and 555 repairs from GitHub for five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand challenges in repairs and bug repair patterns. Our key findings reveal that DNN bug fix patterns are distinctive compared to traditional bug fix patterns; the most common bug fix patterns are fixing data dimension and neural network connectivity; DNN bug fixes have the potential to introduce adversarial vulnerabilities; DNN bug fixes frequently introduce new bugs; and DNN bug localization, reuse of trained model, and coping with frequent releases are major challenges faced by developers when fixing bugs. We also contribute a benchmark of 667 DNN (bug, repair) instances.	https://doi.org/10.1145/3377811.3380378
312	Wessel, Mairieli Santos and Aniche, Maur\\'\\icio Finavaro and Oliva, Gustavo Ansaldi and Gerosa, Marco Aur\\'elio and Wiese, Igor Scaliante	Tweaking Association Rules to Optimize Software Change Recommendations	10.1145/3131151.3131163	2017	Past researchs have been trying to recommend artifacts that are likely to change together in a task to assist developers in making changes to a software system, often using techniques like association rules. Association rules learning is a data mining technique that has been frequently used to discover evolutionary couplings. These couplings constitute a fundamental piece of modern change prediction techniques. However, using association rules to detect evolutionary coupling requires a number of configuration parameters, such as measures of interest (e.g. support and confidence), their cut-off values, and the portion of the commit history from which co-change relationships will be extracted. To accomplish this set up, researchers have to carry out empirical studies for each project, testing a few variations of the parameters before choosing a configuration. This makes it difficult to use association rules in practice, since developers would need to perform experiments before applying the technique and would end up choosing non-optimal solutions that lead to wrong predictions. In this paper, we propose a fitness function for a Genetic Algorithm that optimizes the co-change recommendations and evaluate it on five open source projects (CPython, Django, Laravel, Shiny and Gson). The results indicate that our genetic algorithm is able to find optimized cut-off values for support and confidence, as well as to determine which length of commit history yields the best recommendations. We also find that, for projects with less commit history (5k commits), our approach produced better results than the regression function proposed in the literature. This result is particularly encouraging, because repositories such as GitHub host many young projects. Our results can be used by researchers when conducting co-change prediction studies and by tool developers to produce automated support to be used by practitioners.	https://doi.org/10.1145/3131151.3131163
313	Rigger, Manuel and Marr, Stefan and Kell, Stephen and Leopoldseder, David and M\\"ossenb\\"ock, Hanspeter	An Analysis of X86-64 Inline Assembly in C Programs	10.1145/3186411.3186418	2018	C codebases frequently embed nonportable and unstandardized elements such as inline assembly code. Such elements are not well understood, which poses a problem to tool developers who aspire to support C code. This paper investigates the use of x86-64 inline assembly in 1264 C projects from GitHub and combines qualitative and quantitative analyses to answer questions that tool authors may have. We found that 28.1% of the most popular projects contain inline assembly code, although the majority contain only a few fragments with just one or two instructions. The most popular instructions constitute a small subset concerned largely with multicore semantics, performance optimization, and hardware control. Our findings are intended to help developers of C-focused tools, those testing compilers, and language designers seeking to reduce the reliance on inline assembly. They may also aid the design of tools focused on inline assembly itself.	https://doi.org/10.1145/3186411.3186418
314	Rigger, Manuel and Marr, Stefan and Kell, Stephen and Leopoldseder, David and M\\"ossenb\\"ock, Hanspeter	An Analysis of X86-64 Inline Assembly in C Programs	10.1145/3296975.3186418	2018	C codebases frequently embed nonportable and unstandardized elements such as inline assembly code. Such elements are not well understood, which poses a problem to tool developers who aspire to support C code. This paper investigates the use of x86-64 inline assembly in 1264 C projects from GitHub and combines qualitative and quantitative analyses to answer questions that tool authors may have. We found that 28.1% of the most popular projects contain inline assembly code, although the majority contain only a few fragments with just one or two instructions. The most popular instructions constitute a small subset concerned largely with multicore semantics, performance optimization, and hardware control. Our findings are intended to help developers of C-focused tools, those testing compilers, and language designers seeking to reduce the reliance on inline assembly. They may also aid the design of tools focused on inline assembly itself.	https://doi.org/10.1145/3296975.3186418
315	Celik, Ahmet and Lee, Young Chul and Gligoric, Milos	Regression Test Selection for TizenRT	10.1145/3236024.3275527	2018	Regression testing - running tests after code modifications - is widely practiced in industry, including at Samsung. Regression Test Selection (RTS) optimizes regression testing by skipping tests that are not affected by recent code changes. Recent work has developed robust RTS tools, which mostly target managed languages, e.g., Java and C#, and thus are not applicable to large C projects, e.g., TizenRT, a lightweight RTOS-based platform.  We present Selfection, an RTS tool for projects written in C; we discuss the key challenges to develop Selfection and our design decisions. Selfection uses the objdump and readelf tools to statically build a dependency graph of functions from binaries and detect modified code elements. We integrated Selfection in TizenRT and evaluated its benefits if tests are run in an emulator and on a supported hardware platform (ARTIK 053). We used the latest 150 revisions of TizenRT available on GitHub. We measured the benefits of Selfection as the reduction in the number of tests and reduction in test execution time over running all tests at each revision (i.e., RetestAll). Our results show that Selfection can reduce, on average, the number of tests to 4.95% and end-to-end execution time to 7.04% when tests are executed in the emulator, and to 5.74% and 26.82% when tests are executed on the actual hardware. Our results also show that the time taken to maintain the dependency graph and detect modified functions is negligible.	https://doi.org/10.1145/3236024.3275527
316	Nguyen, Hoan Anh and Nguyen, Tien N. and Dig, Danny and Nguyen, Son and Tran, Hieu and Hilton, Michael	Graph-Based Mining of in-the-Wild, Fine-Grained, Semantic Code Change Patterns	10.1109/ICSE.2019.00089	2019	Prior research exploited the repetitiveness of code changes to enable several tasks such as code completion, bug-fix recommendation, library adaption, etc. These and other novel applications require accurate detection of semantic changes, but the state-of-the-art methods are limited to algorithms that detect specific kinds of changes at the syntactic level. Existing algorithms relying on syntactic similarity have lower accuracy, and cannot effectively detect semantic change patterns. We introduce a novel graph-based mining approach, CPatMiner, to detect previously unknown repetitive changes in the wild, by mining fine-grained semantic code change patterns from a large number of repositories. To overcome unique challenges such as detecting meaningful change patterns and scaling to large repositories, we rely on fine-grained change graphs to capture program dependencies.We evaluate CPatMiner by mining change patterns in a diverse corpus of 5,000+ open-source projects from GitHub across a population of 170,000+ developers. We use three complementary methods. First, we sent the mined patterns to 108 open-source developers. We found that 70% of respondents recognized those patterns as their meaningful frequent changes. Moreover, 79% of respondents even named the patterns, and 44% wanted future IDEs to automate such repetitive changes. We found that the mined change patterns belong to various development activities: adaptive (9%), perfective (20%), corrective (35%) and preventive (36%, including refactorings). Second, we compared our tool with the state-of-the-art, AST-based technique, and reported that it detects 2.1x more meaningful patterns. Third, we use CPatMiner to search for patterns in a corpus of 88 GitHub projects with longer histories consisting of 164M SLOCs. It constructed 322K fine-grained change graphs containing 3M nodes, and detected 17K instances of change patterns from which we provide unique insights on the practice of change patterns among individuals and teams. We found that a large percentage (75%) of the change patterns from individual developers are commonly shared with others, and this holds true for teams. Moreover, we found that the patterns are not intermittent but spread widely over time. Thus, we call for a community-based change pattern database to provide important resources in novel applications.	https://doi.org/10.1109/ICSE.2019.00089
317	Montalvillo, Leticia and D\\'\\iaz, Oscar	Tuning GitHub for SPL Development: Branching Models &amp; Repository Operations for Product Engineers	10.1145/2791060.2791083	2015	SPLs distinguish between domain engineering (DE) and application engineering (AE). Though each realm has its own lifecycle, they might need to be regularly synchronized to avoid SPL erosion during evolution. This introduces two sync paths: update propagation (from DE to AE) and feedback propagation (from AE to DE). This work looks at how to support sync paths in Version Control Systems (VCSs) using traditional VCS constructs (i.e. merge, branch, fork and pull). In this way, synchronization mismatches can be resolved \\`a la VCS, i.e. highlighting difference between distinct versions of the same artifact. However, this results in a conceptual gap between how propagations are conceived (i.e. update, feedback) and how propagation are realized (i.e. merge, branch, etc). To close this gap, we propose to enhance existing VCSs with SPL sync paths as first-class operations. As a proof-of-concept, we use Web Augmentation techniques to extend GitHub's Web pages with this extra functionality. Through a single click, product engineers can now (1) generate product repositories, (2) update propagating newer feature versions, or (3), feedback propagating product customizations amenable to be upgraded as core assets.	https://doi.org/10.1145/2791060.2791083
318	L\\"ammel, Ralf and Varanovich, Andrei	Interpretation of Linguistic Architecture	10.1007/978-3-319-09195-2_5	2014	The megamodeling language MegaL is designed to model the linguistic architecture of software systems: the relationships between software artifacts (e.g., files), software languages (e.g., programming languages), and software technologies (e.g., code generators) used in a system. The present paper delivers a form of interpretation for such megamodels: resolution of megamodel elements to resources (e.g., system artifacts) and evaluation of relationships, subject to designated programs (such as pluggable 'tools' for checking). Interpretation reduces concerns about the adequacy and meaning of megamodels, as it helps to apply the megamodels to actual systems. We leverage Linked Data principles for surfacing resolved megamodels by linking, for example, artifacts to GitHub repositories or concepts to DBpedia resources. We provide an executable specification (i.e., semantics) of interpreted megamodels and we discuss an implementation in terms of an object-oriented framework with dynamically loaded plugins.	https://doi.org/10.1007/978-3-319-09195-2_5
319	Sung, Chungha and Paulsen, Brandon and Wang, Chao	CANAL: A Cache Timing Analysis Framework via LLVM Transformation	10.1145/3238147.3240485	2018	A unified modeling framework for non-functional properties of a program is essential for research in software analysis and verification, since it reduces burdens on individual researchers to implement new approaches and compare existing approaches. We present CANAL, a framework that models the cache behaviors of a program by transforming its intermediate representation in the LLVM compiler. CANAL inserts auxiliary variables and instructions over these variables, to allow standard verification tools to handle a new class of cache related properties, e.g., for computing the worst-case execution time and detecting side-channel leaks. We demonstrate the effectiveness of using three verification tools: KLEE, SMACK and Crab-llvm. We confirm the accuracy of our cache model by comparing with CPU cycle-accurate simulation results of GEM5. CANAL is available on GitHub(https://github.com/canalcache/canal) and YouTube(https://youtu.be/JDou3F1j2nY).	https://doi.org/10.1145/3238147.3240485
320	Svyatkovskiy, Alexey and Zhao, Ying and Fu, Shengyu and Sundaresan, Neel	Pythia: AI-Assisted Code Completion System	10.1145/3292500.3330699	2019	In this paper, we propose a novel end-to-end approach for AI-assisted code completion called Pythia. It generates ranked lists of method and API recommendations which can be used by software developers at edit time. The system is currently deployed as part of Intellicode extension in Visual Studio Code IDE. Pythia exploits state-of-the-art large-scale deep learning models trained on code contexts extracted from abstract syntax trees. It is designed to work at a high throughput predicting the best matching code completions on the order of 100 ms. We describe the architecture of the system, perform comparisons to frequency-based approach and invocation-based Markov Chain language model, and discuss challenges serving Pythia models on lightweight client devices. The offline evaluation results obtained on 2700 Python open source software GitHub repositories show a top-5 accuracy of 92%, surpassing the baseline models by 20% averaged over classes, for both intra and cross-project settings.	https://doi.org/10.1145/3292500.3330699
321	Allamanis, Miltiadis	The Adverse Effects of Code Duplication in Machine Learning Models of Code	10.1145/3359591.3359735	2019	The field of big code relies on mining large corpora of code to perform some learning task towards creating better tools for software engineers. A significant threat to this approach was recently identified by Lopes et al. (2017) who found a large amount of near-duplicate code on GitHub. However, the impact of code duplication has not been noticed by researchers devising machine learning models for source code. In this work, we explore the effects of code duplication on machine learning models showing that reported performance metrics are sometimes inflated by up to 100% when testing on duplicated code corpora compared to the performance on de-duplicated corpora which more accurately represent how machine learning models of code are used by software engineers. We present a duplication index for widely used datasets, list best practices for collecting code corpora and evaluating machine learning models on them. Finally, we release tools to help the community avoid this problem in future research.	https://doi.org/10.1145/3359591.3359735
322	Kr\\"uger, Jacob	Tackling Knowledge Needs during Software Evolution	10.1145/3338906.3342505	2019	Developers use a large amount of their time to understand the system they work on, an activity referred to as program comprehension. Especially software evolution and forgetting over time lead to developers becoming unfamiliar with a system. To support them during program comprehension, we can employ knowledge recovery to reverse engineer implicit information from the system and the platform (e.g., GitHub) it is hosted on. However, to recover useful knowledge and to provide it in a useful way, we first need to understand what knowledge developers forget to what extent, what sources are reliable to recover knowledge, and how to trace knowledge to the features in a system. We tackle these three issues, aiming to provide empirical insights and tooling to support developers during software evolution and maintenance. The results help practitioners, as we support the analysis and understanding of systems, as well as researchers, showing opportunities to automate, for example, reverse-engineering techniques.	https://doi.org/10.1145/3338906.3342505
324	Ben, Xu and Beijun, Shen and Weicheng, Yang	Mining Developer Contribution in Open Source Software Using Visualization Techniques	10.1109/ISDEA.2012.223	2013	The research of developers' contribution is an important part of the software evolution area. It allows project owners to find potential long-term contributors earlier and helps the newcomers to improve their behaviors. In this paper, we examined the contribution characteristics of developers in open source environment based on visual analysis, and presented approaches from three aspects-influencing factors, time characteristics and region characteristics. Our analysis used data from github and revealed some regular patterns. We found that the code which newcomers started to contribute with more people engaged in would lead to less contribution in some degree. We also found that there's a relation between developers' early and later period contribution. In addition, developers from different regions were more likely to have dominant relationship. Our findings may provide some support for future research in the area of software evolution.	https://doi.org/10.1109/ISDEA.2012.223
325	Vu, Duc Ly and Pashchenko, Ivan and Massacci, Fabio and Plate, Henrik and Sabetta, Antonino	Towards Using Source Code Repositories to Identify Software Supply Chain Attacks	10.1145/3372297.3420015	2020	Increasing popularity of third-party package repositories, like NPM, PyPI, or RubyGems, makes them an attractive target for software supply chain attacks. By injecting malicious code into legitimate packages, attackers were known to gain more than 100,000 downloads of compromised packages. Current approaches for identifying malicious payloads are resource demanding. Therefore, they might not be applicable for the on-the-fly detection of suspicious artifacts being uploaded to the package repository. In this respect, we propose to use source code repositories (e.g., those in Github) for detecting injections into the distributed artifacts of a package. Our preliminary evaluation demonstrates that the proposed approach captures known attacks when malicious code was injected into PyPI packages. The analysis of the 2666 software artifacts (from all versions of the top ten most downloaded Python packages in PyPI) suggests that the technique is suitable for lightweight analysis of real-world packages.	https://doi.org/10.1145/3372297.3420015
326	West, Andrew G. and Lee, Insup	Towards Content-Driven Reputation for Collaborative Code Repositories	10.1145/2462932.2462950	2012	As evidenced by SourceForge and GitHub, code repositories now integrate Web 2.0 functionality that enables global participation with minimal barriers-to-entry. To prevent detrimental contributions enabled by crowdsourcing, reputation is one proposed solution. Fortunately this is an issue that has been addressed in analogous version control systems such as the wiki for natural language content. The WikiTrust algorithm ("content-driven reputation"), while developed and evaluated in wiki environments operates under a possibly shared collaborative assumption: actions that "survive" subsequent edits are reflective of good authorship.In this paper we examine WikiTrust's ability to measure author quality in collaborative code development. We first define a mapping from repositories to wiki environments and use it to evaluate a production SVN repository with 92,000 updates. Analysis is particularly attentive to reputation loss events and attempts to establish ground truth using commit comments and bug tracking. A proof-of-concept evaluation suggests the technique is promising (about two-thirds of reputation loss is justified) with false positives identifying areas for future refinement. Equally as important, these false positives exemplify differences in content evolution and the cooperative process between wikis and code repositories.	https://doi.org/10.1145/2462932.2462950
327	Liu, Bohong and Wang, Tao and Zhang, Xunhui and Fan, Qiang and Yin, Gang and Deng, Jinsheng	A Neural-Network Based Code Summarization Approach by Using Source Code and Its Call Dependencies	10.1145/3361242.3362774	2019	Code summarization aims at generating natural language abstraction for source code, and it can be of great help for program comprehension and software maintenance. The current code summarization approaches have made progress with neural-network. However, most of these methods focus on learning the semantic and syntax of source code snippets, ignoring the dependency of codes. In this paper, we propose a novel method based on neural-network model using the knowledge of the call dependency between source code and its related codes. We extract call dependencies from the source code, transform it as a token sequence of method names, and leverage the Seq2Seq model for code summarization using the combination of source code and call dependency information. About 100,000 code data is collected from 1,000 open source Java proejects on github for experiment. The large-scale code experiment shows that by considering not only the code itself but also the codes it called, the code summarization model can be improved with the BLEU score to 33.08.	https://doi.org/10.1145/3361242.3362774
328	Gelman, Ben and Hoyle, Bryan and Moore, Jessica and Saxe, Joshua and Slater, David	A Language-Agnostic Model for Semantic Source Code Labeling	10.1145/3243127.3243132	2018	Code search and comprehension have become more difficult in recent years due to the rapid expansion of available source code. Current tools lack a way to label arbitrary code at scale while maintaining up-to-date representations of new programming languages, libraries, and functionalities. Comprehensive labeling of source code enables users to search for documents of interest and obtain a high-level understanding of their contents. We use Stack Overflow code snippets and their tags to train a language-agnostic, deep convolutional neural network to automatically predict semantic labels for source code documents. On Stack Overflow code snippets, we demonstrate a mean area under ROC of 0.957 over a long-tailed list of 4,508 tags. We also manually validate the model outputs on a diverse set of unlabeled source code documents retrieved from Github, and obtain a top-1 accuracy of 86.6%. This strongly indicates that the model successfully transfers its knowledge from Stack Overflow snippets to arbitrary source code documents.	https://doi.org/10.1145/3243127.3243132
329	Criado, Javier and Mart\\'\\inez, Salvador and Iribarne, Luis and Cabot, Jordi	Enabling the Reuse of Stored Model Transformations Through Annotations	10.1007/978-3-319-21155-8_4	2015	With the increasing adoption of MDE, model transformations, one of its core concepts together with metamodeling, stand out as a valuable asset. Therefore, a mechanism to annotate and store existing model transformations appears as a critical need for their efficient exploitation and reuse. Unfortunately, although several reuse mechanisms have been proposed for software artifacts in general and models in particular, none of them is specially tailored to the domain of model transformations. In order to fill this gap, we present here such a mechanism. Our approach is composed by two elements 1 a new DSL specially conceived for describing model transformations in terms of their functional and non-functional properties 2 a semi-automatic process for annotating and querying repositories of model transformations using as criteria the properties of our DSL. We validate the feasibility of our approach through a prototype implementation that integrates our approach in a GitHub repository.	https://doi.org/10.1007/978-3-319-21155-8_4
330	Piech, Chris and Abu-El-Haija, Sami	Human Languages in Source Code: Auto-Translation for Localized Instruction	10.1145/3386527.3405916	2020	Computer science education has promised open access around the world, but access is largely determined by what human language you speak. As younger students learn computer science it is less appropriate to assume that they should learn English beforehand. To that end, we present CodeInternational, the first tool to translate code between human languages. To develop a theory of non-English code, and inform our translation decisions, we conduct a study of public code repositories on GitHub. The study is to the best of our knowledge the first on human-language in code and covers 2.9 million Java repositories. To demonstrate CodeInternational's educational utility, we build an interactive version of the popular English-language Karel reader and translate it into 100 spoken languages. Our translations have already been used in classrooms around the world, and represent a first step in an important open CS-education problem.	https://doi.org/10.1145/3386527.3405916
331	Alsaeed, Ziyad and Young, Michal	Extending Existing Inference Tools to Mine Dynamic APIs	10.1145/3194793.3194797	2018	APIs often feature dynamic relations between client and service provider, such as registering for notifications or establishing a connection to a service. Dynamic specification mining techniques attempt to fill gaps in missing or decaying documentation, but current miners are blind to relations established dynamically. Because they cannot recover properties involving these dynamic structures, they may produce incomplete or misleading specifications. We have devised an extension to current dynamic specification mining techniques that ameliorates this shortcoming. The key insight is to monitor not only values dynamically, but also properties to track dynamic data structures that establish new relations between client and service provider. We have implemented this approach as an extension to the instrumentation component of Daikon, the leading example of dynamic invariant mining in the research literature. We evaluated our tool by applying it to selected modules of widely used software systems published on GitHub.	https://doi.org/10.1145/3194793.3194797
332	Trockman, Asher and Zhou, Shurui and K\\"astner, Christian and Vasilescu, Bogdan	Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the <i>Npm</i> Ecosystem	10.1145/3180155.3180209	2018	In fast-paced, reuse-heavy, and distributed software development, the transparency provided by social coding platforms like GitHub is essential to decision making. Developers infer the quality of projects using visible cues, known as signals, collected from personal profile and repository pages. We report on a large-scale, mixed-methods empirical study of npm packages that explores the emerging phenomenon of repository badges, with which maintainers signal underlying qualities about their projects to contributors and users. We investigate which qualities maintainers intend to signal and how well badges correlate with those qualities. After surveying developers, mining 294,941 repositories, and applying statistical modeling and time-series analyses, we find that non-trivial badges, which display the build status, test coverage, and up-to-dateness of dependencies, are mostly reliable signals, correlating with more tests, better pull requests, and fresher dependencies. Displaying such badges correlates with best practices, but the effects do not always persist.	https://doi.org/10.1145/3180155.3180209
333	Escobar-Vel\\'asquez, Camilo and Riveros, Diego and Linares-V\\'asquez, Mario	MutAPK 2.0: A Tool for Reducing Mutation Testing Effort of Android Apps	10.1145/3368089.3417942	2020	Mutation testing is a time consuming process because large sets of fault-injected-versions of an original app are generated and executed with the purpose of evaluating the quality of a given test suite. In the case of Android apps, recent studies even suggest that mutant generation and mutation testing effort could be greater when the mutants are generated at the APK level. To reduce that effort, useless (e.g., equivalent) mutants should be avoided and mutant selection techniques could be used to reduce the set of mutants used with mutation testing. However, despite the existence of mutation testing tools, none of those tools provides features for removing useless mutants and sampling mutant sets. In this paper, we present MutAPK 2.0, an improved version of our open source mutant generation tool (MutAPK) for Android apps at APK level. To the best of our knowledge, MutAPK 2.0 is the first tool that enables the removal of dead-code mutants, provides a set of mutant selection strategies, and removes automatically equivalent and duplicate mutants. MutAPK 2.0 is publicly available at GitHub: https://thesoftwaredesignlab.github.io/MutAPK/ VIDEO: https://thesoftwaredesignlab.github.io/MutAPK/video.html	https://doi.org/10.1145/3368089.3417942
334	Nakamaru, Tomoki and Matsunaga, Tomomasa and Yamazaki, Tetsuro and Akiyama, Soramichi and Chiba, Shigeru	An Empirical Study of Method Chaining in Java	10.1145/3379597.3387441	2020	While some promote method chaining as a good practice for improving code readability, others refer to it as a bad practice that worsens code quality. In this paper, we first investigate whether method chaining is a programming style accepted by real-world programmers. To answer this question, we collected 2,814 Java repositories on GitHub and analyzed historical trends in the frequency of method chaining. The results of our analysis revealed the increasing use of method chaining; 23.1% of method invocations were part of method chains in 2018, whereas only 16.0% were such invocations in 2010. We then explore language features that are helpful to the method-chaining style but have not been supported yet in Java. For this aim, we conducted manual inspections of method chains that are randomly sampled from the collected repositories. We also estimated how effective they are to encourage the method-chaining style if they are adopted in Java.	https://doi.org/10.1145/3379597.3387441
335	Lukina, Anna and Kumar, Arjun and Schmittle, Matt and Singh, Abhijeet and Das, Jnaneshwar and Rees, Stephen and Buskirk, Christopher P. and Sztipanovits, Janos and Grosu, Radu and Kumar, Vijay	Formation Control and Persistent Monitoring in the OpenUAV Swarm Simulator on the NSF CPS-VO	10.1109/ICCPS.2018.00050	2018	Simulation tools offer a low barrier to entry and enable testing and validation before field trials. However, most of the well-known simulators today are challenging to use at scale due to the need for powerful computers and the time required for initial set up. The OpenUAV Swarm Simulator was developed to address these challenges, enabling multi-UAV simulations on the cloud through the NSF CPS-VO. We leverage the Containers as a Service (CaaS) technology to enable students and researchers carry out simulations on the cloud on demand. We have based our framework on open-source tools including ROS, Gazebo, Docker, and the PX4 flight stack, and we designed the simulation framework so that it has no special hardware requirements. The demo and poster will showcase UAV swarm trajectory optimization, and multi-UAV persistent monitoring on the CPS-VO. The code for the simulator is available on GitHub: https://github.com/Open-UAV.	https://doi.org/10.1109/ICCPS.2018.00050
336	Dietrich, Jens and Luczak-Roesch, Markus and Dalefield, Elroy	Man vs Machine: A Study into Language Identification of Stack Overflow Code Snippets	10.1109/MSR.2019.00041	2019	Software engineers produce large amounts of publicly accessible data that enables researchers to mine knowledge, fostering a better understanding of the field. Knowledge extraction often relies on meta data. This meta data can either be harvested from user-provided tags, or inferred by algorithms from the respective data. The question arises to which extent either type of meta data can be trusted and relied upon.We study this problem in the context of language identification of code snippets posted on Stack Overflow. We analyse the consistency between user-provided tags and the classification obtained with GitHub linguist, an industry-strength automated language recognition tool. We find that the results obtained by both approaches are often not consistent. This indicates that both have to be used with great care. Our results also suggest that developers may not follow the evolutionary path of programming languages beyond one step when seeking or providing answers to software engineering challenges encountered.	https://doi.org/10.1109/MSR.2019.00041
337	Lotfi Rezaabad, Ali and Vishwanath, Sriram	Long Short-Term Memory Spiking Networks and Their Applications	10.1145/3407197.3407211	2020	Recent advances in event-based neuromorphic systems have resulted in significant interest in the use and development of spiking neural networks (SNNs). However, the non-differentiable nature of spiking neurons makes SNNs incompatible with conventional backpropagation techniques. In spite of the significant progress made in training conventional deep neural networks (DNNs), training methods for SNNs still remain relatively poorly understood. In this paper, we present a novel framework for training recurrent SNNs. Analogous to the benefits presented by recurrent neural networks (RNNs) in learning time series models within DNNs, we develop SNNs based on long short-term memory (LSTM) networks. We show that LSTM spiking networks learn the timing of the spikes and temporal dependencies. We also develop a methodology for error backpropagation within LSTM-based SNNs. The developed architecture and method for backpropagation within LSTM-based SNNs enable them to learn long-term dependencies with comparable results to conventional LSTMs. Code is available on github; https://github.com/AliLotfi92/SNNLSTM 	https://doi.org/10.1145/3407197.3407211
338	Xu, Shengzhe and Dong, Ziqi and Meng, Na	Meditor: Inference and Application of API Migration Edits	10.1109/ICPC.2019.00052	2019	Developers build programs based on software libraries. When a library evolves, programmers need to migrate their client code from the library's old release(s) to new release(s). Due to the API backwards incompatibility issues, such code migration may require developers to replace API usage and apply extra edits (e.g., statement insertions or deletions) to ensure the syntactic or semantic correctness of migrated code. Existing tools extract API replacement rules without handling the additional edits necessary to fulfill a migration task. This paper presents our novel approach, Meditor, which extracts and applies the necessary edits together with API replacement changes.Meditor has two phases: inference and application of migration edits. For edit inference, Meditor mines open source repositories for migration-related (MR) commits, and conducts program dependency analysis on changed Java files to locate and cluster MR code changes. From these changes, Meditor further generalizes API migration edits by abstracting away unimportant details (e.g., concrete variable identifiers). For edit application, Meditor matches a given program with inferred edits to decide which edit is applicable, customizes each applicable edit, and produces a migrated version for developers to review.We applied Meditor to four popular libraries: Lucene, Craft-Bukkit, Android SDK, and Commons IO. By searching among 602,249 open source projects on GitHub, Meditor identified 1,368 unique migration edits. Among these edits, 885 edits were extracted from single updated statements, while the other 483 more complex edits were from multiple co-changed statements. We sampled 937 inferred edits for manual inspection and found all of them to be correct. Our evaluation shows that Meditor correctly applied code migrations in 218 out of 225 cases. This research will help developers automatically adapt client code to different library versions.	https://doi.org/10.1109/ICPC.2019.00052
339	Li, Yuanchun and Yang, Ziyue and Guo, Yao and Chen, Xiangqun	DroidBot: A Lightweight UI-Guided Test Input Generator for Android	10.1109/ICSE-C.2017.8	2017	As many automated test input generation tools for Android need to instrument the system or the app, they cannot be used in some scenarios such as compatibility testing and malware analysis. We introduce DroidBot, a lightweight UI-guided test input generator, which is able to interact with an Android app on almost any device without instrumentation. The key technique behind DroidBot is that it can generate UI-guided test inputs based on a state transition model generated on-the-fly, and allow users to integrate their own strategies or algorithms. DroidBot is lightweight as it does not require app instrumentation, thus no need to worry about the inconsistency between the tested version and the original version. It is compatible to most Android apps, and able to run on almost all Android-based systems, including customized sandboxes and commodity devices. Droidbot is released as an open-source tool on GitHub [1], and the demo video can be found at https://youtu.be/3-aHGSazMY.	https://doi.org/10.1109/ICSE-C.2017.8
340	Paolo, Giampiero Di and Malavolta, Ivano and Muccini, Henry	How Do You Feel Today? Buggy!	10.1109/SEAA.2014.63	2014	It is well-known that moods and emotions strongly affect our performances. Clearly, this holds also for software developers. Thus, modern managers, trainers, and coaches should be aware of moods and emotions of software developers in their teams. In this context, mining software repositories and social networks in combination can be an invaluable instrument for understanding how the moods and emotions of software developers impact their performance, even in real-time. In this paper, we propose our first steps in mining software repositories for (i) getting information about developers' moods and emotion throughout the development process, and (ii) investigating on the existence of the correlation between software developers' performance (in terms of their commits bugginess) and mood. For what concerns data sources, we use publicly-available information on GitHub for getting insights about the performance of software developers, while we semantically analyse developers' posts on Twitter for extracting their moods during the whole duration of the project.	https://doi.org/10.1109/SEAA.2014.63
346	Aierken, Ailifan and Davis, Delmar B. and Zhang, Qi and Gupta, Kriti and Wong, Alex and Asuncion, Hazeline U.	A Multi-Level Funneling Approach to Data Provenance Reconstruction	10.1109/eScience.2014.54	2014	When data are retrieved from a file storage system or the Internet, is there information about their provenance (i.e., their origin or history)? It is possible that data could have been copied from another source and then transformed. Often, provenance is not readily available for data sets created in the past. Solving such a problem is the motivation behind the 2014 Provenance Reconstruction Challenge. This challenge is aimed at recovering lost provenance for two data sets: one data set (WikiNews articles) in which a list of possible sources has been provided, and another data set (files from GitHub repositories) in which the file sources are not provided. To address this challenge, we present a multi-level funneling approach to provenance reconstruction, a technique that incorporates text processing techniques from different disciplines to approximate the provenance of a given data set. We built three prototypes using this technique and evaluated them using precision and recall metrics. Our preliminary results indicate that our technique is capable of reconstructing some of the lost provenance.	https://doi.org/10.1109/eScience.2014.54
341	Jaffe, Alan and Lacomis, Jeremy and Schwartz, Edward J. and Goues, Claire Le and Vasilescu, Bogdan	Meaningful Variable Names for Decompiled Code: A Machine Translation Approach	10.1145/3196321.3196330	2018	When code is compiled, information is lost, including some of the structure of the original source code as well as local identifier names. Existing decompilers can reconstruct much of the original source code, but typically use meaningless placeholder variables for identifier names. Using variable names which are more natural in the given context can make the code much easier to interpret, despite the fact that variable names have no effect on the execution of the program. In theory, it is impossible to recover the original identifier names since that information has been lost. However, most code is natural: it is highly repetitive and predictable based on the context. In this paper we propose a technique that assigns variables meaningful names by taking advantage of this naturalness property. We consider decompiler output to be a noisy distortion of the original source code, where the original source code is transformed into the decompiler output. Using this noisy channel model, we apply standard statistical machine translation approaches to choose natural identifiers, combining a translation model trained on a parallel corpus with a language model trained on unmodified C code. We generate a large parallel corpus from 1.2 TB of C source code obtained from GitHub. Under the most conservative assumptions, our technique is still able to recover the original variable names up to 16.2% of the time, which represents a lower bound for performance.	https://doi.org/10.1145/3196321.3196330
342	Singh, Rohit and Meduri, Vamsi and Elmagarmid, Ahmed and Madden, Samuel and Papotti, Paolo and Quian\\'e-Ruiz, Jorge-Arnulfo and Solar-Lezama, Armando and Tang, Nan	Generating Concise Entity Matching Rules	10.1145/3035918.3058739	2017	Entity matching (EM) is a critical part of data integration and cleaning. In many applications, the users need to understand why two entities are considered a match, which reveals the need for interpretable and concise EM rules. We model EM rules in the form of General Boolean Formulas (GBFs) that allows arbitrary attribute matching combined by conjunctions (∨), disjunctions (∧), and negations. (¬) GBFs can generate more concise rules than traditional EM rules represented in disjunctive normal forms (DNFs). We use program synthesis, a powerful tool to automatically generate rules (or programs) that provably satisfy a high-level specification, to automatically synthesize EM rules in GBF format, given only positive and negative matching examples.In this demo, attendees will experience the following features: (1) Interpretability -- they can see and measure the conciseness of EM rules defined using GBFs; (2) Easy customization -- they can provide custom experiment parameters for various datasets, and, easily modify a rich predefined (default) synthesis grammar, using a Web interface; and (3) High performance -- they will be able to compare the generated concise rules, in terms of accuracy, with probabilistic models (e.g., machine learning methods), and hand-written EM rules provided by experts. Moreover, this system will serve as a general platform for evaluating different methods that discover EM rules, which will be released as an open-source tool on GitHub.	https://doi.org/10.1145/3035918.3058739
343	Kakarla, Siva Kesava Reddy and Beckett, Ryan and Arzani, Behnaz and Millstein, Todd and Varghese, George	GRooT: Proactive Verification of DNS Configurations	10.1145/3387514.3405871	2020	The Domain Name System (DNS) plays a vital role in today's Internet but relies on complex distributed management of records. DNS misconfiguration related outages have rendered popular services like GitHub, HBO, LinkedIn, and Azure inaccessible for extended periods. This paper introduces GRoot, the first verifier that performs static analysis of DNS configuration files, enabling proactive and exhaustive checking for common DNS bugs; by contrast, existing solutions are reactive and incomplete. GRoot uses a new, fast verification algorithm based on generating and enumerating DNS query equivalence classes. GRoot symbolically executes the set of queries in each equivalence class to efficiently find (or prove the absence of) any bugs such as rewrite loops. To prove the correctness of our approach, we develop a formal semantic model of DNS resolution. Applied to the configuration files from a campus network with over a hundred thousand records, GRoot revealed 109 bugs within seconds. When applied to internal zone files consisting of over 3.5 million records from a large infrastructure service provider, GRoot revealed around 160k issues of blackholing, initiating a cleanup. Finally, on a synthetic dataset with over 65 million real records, we find GRoot can scale to networks with tens of millions of records.	https://doi.org/10.1145/3387514.3405871
344	H\\"artel, Johannes and Aksu, Hakan and L\\"ammel, Ralf	Classification of APIs by Hierarchical Clustering	10.1145/3196321.3196344	2018	APIs can be classified according to the programming domains (e.g., GUIs, databases, collections, or security) that they address. Such classification is vital in searching repositories (e.g., the Maven Central Repository for Java) and for understanding the technology stack used in software projects. We apply hierarchical clustering to a curated suite of Java APIs to compare the computed API clusters with preexisting API classifications. Clustering entails various parameters (e.g., the choice of IDF versus LSI versus LDA). We describe the corresponding variability in terms of a feature model. We exercise all possible configurations to determine the maximum correlation with respect to two baselines: i) a smaller suite of APIs manually classified in previous research; ii) a larger suite of APIs from the Maven Central Repository, thereby taking advantage of crowd-sourced classification while relying on a threshold-based approach for identifying important APIs and versions thereof, subject to an API dependency analysis on GitHub. We discuss the configurations found in this way and we examine the influence of particular features on the correlation between computed clusters and baselines. To this end, we also leverage interactive exploration of the parameter space and the resulting dendrograms. In this manner, we can also identify issues with the use of classifiers (e.g., missing classifiers) in the baselines and limitations of the clustering approach.	https://doi.org/10.1145/3196321.3196344
345	Saxena, Nikita	Efficient Downscaling of Satellite Oceanographic Data With Convolutional Neural Networks	10.1145/3397536.3429335	2020	Space-borne satellite radiometers measure Sea Surface Temperature (SST), which is pivotal to studies of air-sea interactions and ocean features. Under clear sky conditions, high resolution measurements are obtainable. But under cloudy conditions, data analysis is constrained to the available low resolution measurements. We assess the efficiency of Deep Learning (DL) architectures, particularly Convolutional Neural Networks (CNN) to downscale oceanographic data from low spatial resolution (SR) to high SR. With a focus on SST Fields of Bay of Bengal, this study proves that Very Deep Super Resolution CNN can successfully reconstruct SST observations from 15 km SR to 5km SR, and 5km SR to 1km SR. This outcome calls attention to the significance of DL models explicitly trained for the reconstruction of high SR SST fields by using low SR data. Inference on DL models can act as a substitute to the existing computationally expensive downscaling technique: Dynamical Downsampling. The complete code is available on this Github Repository.	https://doi.org/10.1145/3397536.3429335
347	Wang, Tao and Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	Who Will Become a Long-Term Contributor? A Prediction Model Based on the Early Phase Behaviors	10.1145/3275219.3275223	2018	The continuous contribution from peripheral participants is crucial for the success of open source projects. Thus, how to identify the potential Long-Term Contributors (LTC) early and retain them is of great importance. We propose a prediction model to measure the chance for an individual to become a LTC contributor through his capacity, willingness, and the opportunity to contribute at the time of joining. Using data of Rails hosted on GitHub, we find that the probability for a new joiner to become a LTC is associated with his willingness and environment. Specifically, future LTCs tend to be more active and show more community-oriented attitude than other joiners during their first month. This implies that the interaction between individual's attitude and project's climate are associated with the odds that an individual would become a valuable contributor or disengage from the project. We evaluated our prediction model by using the 10 cross-validation method. Results show that our model archives the mean AUC as 0.807, which is valuable for OSS projects to identify potential long-term contributors and adopt better strategies to retain them for continuous contribution.	https://doi.org/10.1145/3275219.3275223
348	Zhuang, Hao and Rahman, Rameez and Hui, Pan and Aberer, Karl	StoreSim: Optimizing Information Leakage in Multicloud Storage Services	10.1109/CloudCom.2015.26	2015	Many schemes have been recently advanced for storing data on multiple clouds. Distributing data over different cloud storage providers (CSPs) automatically provides users with a certain degree of information leakage control, as no single point of attack can leak all user's information. However, unplanned distribution of data chunks can lead to high information disclosure even while using multiple clouds. In this paper, to address this problem we present StoreSim, an information leakage aware storage system in multicloud. StoreSim aims to store syntactically similar data on the same cloud, thus minimizing the user's information leakage across multiple clouds. We design an approximate algorithm to efficiently generate similarity-preserving signatures for data chunks based on MinHash and Bloom filter, and also design a function to compute the information leakage based on these signatures. Next, we present an effective storage plan generation algorithm based on clustering for distributing data chunks with minimal information leakage across multiple clouds. Finally, we evaluate our scheme using two real datasets from Wikipedia and GitHub. We show that our scheme can reduce the information leakage by up to 60% compared to unplanned placement.	https://doi.org/10.1109/CloudCom.2015.26
349	Felsch, Dennis and Mainka, Christian and Mladenov, Vladislav and Schwenk, J\\"org	SECRET: On the Feasibility of a Secure, Efficient, and Collaborative Real-Time Web Editor	10.1145/3052973.3052982	2017	Real-time editing tools like Google Docs, Microsoft Office Online, or Etherpad have changed the way of collaboration. Many of these tools are based on Operational Transforms (OT), which guarantee that the views of different clients onto a document remain consistent over time. Usually, documents and operations are exposed to the server in plaintext -- and thus to administrators, governments, and potentially cyber criminals. Therefore, it is highly desirable to work collaboratively on encrypted documents. Previous implementations do not unleash the full potential of this idea: They either require large storage, network, and computation overhead, are not real-time collaborative, or do not take the structure of the document into account. The latter simplifies the approach since only OT algorithms for byte sequences are required, but the resulting ciphertexts are almost four times the size of the corresponding plaintexts.We present SECRET, the first secure, efficient, and collaborative real-time editor. In contrast to all previous works, SECRET is the first tool that (1.) allows the encryption of whole documents or arbitrary sub-parts thereof, (2.) uses a novel combination of tree-based OT with a structure preserving encryption, and (3.) requires only a modern browser without any extra software installation or browser extension.We evaluate our implementation and show that its encryption overhead is three times smaller in comparison to all previous approaches. SECRET can even be used by multiple users in a low-bandwidth scenario. The source code of SECRET is published on GitHub as an open-source project:https://github.com/RUB-NDS/SECRET/	https://doi.org/10.1145/3052973.3052982
350	Stephens, Conor and Exton, Dr. Chris	Assessing Multiplayer Level Design Using Deep Learning Techniques	10.1145/3402942.3409789	2020	This paper proposes a new framework to measure the fairness of asymmetric level-design in multiplayer games. This work achieves real time prediction of the degree to which asymmetric levels are balanced using deep learning. The proposed framework provides both cost and time savings, by removing the requirement of numerous designed levels and the need to gather player data samples. This advancement with the field is possible through the combination of deep reinforcement learning (made accessible to developers with Unity’s ML-Agents framework), and Procedural Content Generation (PCG). The result of this merger is the acquisition of accelerated training data, which is established using parallel simulations. This paper showcases the proposed approach on a simple two player top-down -shooter game implemented using MoreMountains: Top Down Engine an extension to Unity 3D a popular game engine. Levels are generated using the same PCG approaches found in ’Nuclear Throne’ a popular cross platform Roguelike published by Vlambeer. This approach is accessible and easy to implement allowing games developers to test human-designed content in real time using the predictions. This research is open source and available on Github: https://github.com/Taikatou/top-down-shooter.	https://doi.org/10.1145/3402942.3409789
351	Amin, Mohammad Ruhul and Yurovsky, Alisa and Tian, Yingtao and Skiena, Steven	DeepAnnotator: Genome Annotation with Deep Learning	10.1145/3233547.3233577	2018	Genome annotation is the process of labeling DNA sequences of an organism with its biological features, and is one of the fundamental problems in Bioinformatics. Public annotation pipelines such as NCBI integrate a variety of algorithms and homology searches on public and private databases. However, they build on the information of varying consistency and quality, produced over the last two decades. We identified 12,415 errors in NCBI RNA gene annotations, demonstrating the need for improved annotation programs. We use Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) to demonstrate the potential of deep learning networks to annotate genome sequences, and evaluate different approaches on prokaryotic sequences from NCBI database. Particularly, we evaluate DNA $K-$mer embeddings and the application of RNNs for genome annotation. We show how to improve the performance of our deep networks by incorporating intermediate objectives and downstream algorithms to achieve better accuracy. Our method, called DeepAnnotator, achieves an F-score of ~94%, and establishes a generalized computational approach for genome annotation using deep learning. Our results are very encouraging as our method eliminates the requirement of hand crafted features and motivates further research in application of deep learning to full genome annotation. DeepAnnotator algorithms and models can be accessed in Github: urlhttps://github.com/ruhulsbu/DeepAnnotator.	https://doi.org/10.1145/3233547.3233577
352	Steinhauer, Martin and Palomba, Fabio	Speeding up the Data Extraction of Machine Learning Approaches: A Distributed Framework	10.1145/3416505.3423562	2020	In the last decade, mining software repositories (MSR) has become one of the most important sources to feed machine learning models. Especially open-source projects on platforms like GitHub are providing a tremendous amount of data and make them easily accessible. Nevertheless, there is still a lack of standardized pipelines to extract data in an automated and fast way. Even though several frameworks and tools exist which can fulfill specific tasks or parts of the data extraction process, none of them allow neither building an automated mining pipeline nor the possibility for full parallelization. As a consequence, researchers interested in using mining software repositories to feed machine learning models are often forced to re-implement commonly used tasks leading to additional development time and libraries may not be integrated optimally.  This preliminary study aims to demonstrate current limitations of existing tools and Git itself which are threatening the prospects of standardization and parallelization. We also introduce the multi-dimensionality aspects of a Git repository and how they affect the computation time. Finally, as a proof of concept, we define an exemplary pipeline for predicting refactoring operations, assessing its performance. Finally, we discuss the limitations of the pipeline and further optimizations to be done.	https://doi.org/10.1145/3416505.3423562
353	David, Andrea and Souppe, Mariette and Jimenez, Ivo and Obraczka, Katia and Mansfield, Sam and Veenstra, Kerry and Maltzahn, Carlos	Reproducible Computer Network Experiments: A Case Study Using Popper	10.1145/3322790.3330596	2019	Computer network research experiments can be broadly grouped in three categories: simulated, controlled, and real-world experiments. Simulation frameworks, experiment testbeds and measurement tools, respectively, are commonly used as the platforms for carrying out network experiments. In many cases, given the nature of computer network experiments, properly configuring these platforms is a complex and time-consuming task, which makes replicating and validating research results quite challenging. This complexity can be reduced by leveraging tools that enable experiment reproducibility. In this paper, we show how a recently proposed reproducibility tool called Popper facilitates the reproduction of networking experiments. In particular, we detail the steps taken to reproduce results in two published articles that rely on simulations. The outcome of this exercise is a generic workflow for carrying out network simulation experiments. In addition, we briefly present two additional Popper workflows for running experiments on controlled testbeds, as well as studies that gather real-world metrics (all code is publicly available on Github). We close by providing a list of lessons we learned throughout this process.	https://doi.org/10.1145/3322790.3330596
354	Shakiba, Abbas and Green, Robert and Dyer, Robert	FourD: Do Developers Discuss Design? Revisited	10.1145/2989238.2989244	2016	Software repositories contain a variety of information that can be mined and utilized to enhance software engineering processes. Patterns stored in software repository meta-data can provide useful and informative information about different aspects of a project, particularly those that may not be obvious for developers. One such aspect is the role of software design in a project. The messages connected to each commit in the repository note not only what changes have been made to project files, but potentially if those changes have somehow manipulated the design of the software.In this paper, a sample of commit messages from a random sample of projects on GitHub and SourceForge are manually classified as "design" or "non-design" based on a survey. The resulting data is then used to train multiple machine learning algorithms in order to determine if it is possible to predict whether or not a single commit is discussing software design. Our results show the Random Forest classifier performed best on our combined data set with a G-mean of 75.01.	https://doi.org/10.1145/2989238.2989244
355	Dai, Meixi and Shen, Beijun and Zhang, Tao and Zhao, Min	Impact of Consecutive Changes on Later File Versions	10.1145/2627508.2627512	2014	By analyzing histories of program versions, many researches have shown that software quality is associated with history-related metrics, such as code-related metrics, commit-related metrics, developer-related metrics, process-related metrics, and organizational metrics etc. It has also been revealed that consecutive changes on commit-level are strongly associated with software defects. In this paper, we introduce two novel concepts of consecutive changes: CFC (chain of consecutive bug-fixing file versions) and CAC (chain of consecutive file versions where each pair of adjacent versions are submitted by different developers). And then several experiments are conducted to explore the correlation between consecutive changes and software quality by using three open-source projects from Github. Our main findings include: 1) CFCs and CACs widely exist in file version histories; 2) Consecutive changes have a negative and strong impact on the later file versions in a short term, especially when the length of consecutive change chain is 4 or 5. 	https://doi.org/10.1145/2627508.2627512
356	Ha, Duy-An and Chen, Ting-Hsuan and Yuan, Shyan-Ming	Unsupervised Methods for Software Defect Prediction	10.1145/3368926.3369711	2019	Software Defect Prediction (SDP) aims to assess software quality by using machine learning techniques. Recently, by proposing the connectivity-based unsupervised learning method, Zhang et al. have been proven that unsupervised classification has great potential to apply to this problem. Inspiring by this idea, in our work we try to replicate the results of Zhang et al.'s experiment and attempt to improve the performance by examining different techniques at each step of the approach using unsupervised learning methods to solve the SDP problem. Specifically, we try to follow the steps of the experiment described in their work strictly and examine three other clustering methods with four other ways for feature selection besides using all. To the best of our knowledge, these methods are first applied in SDP to evaluate their predictive power. For replicating the results, generally results in our experiments are not as good as the previous work. It may be due to we do not know which features are used in their experiment exactly. Fluid clustering and spectral clustering give better results than Newman clustering and CNM clustering in our experiments. Additionally, the experiments also show that using Kernel Principal Component Analysis (KPCA) or Non-Negative Matrix Factorization (NMF) for feature selection step gives better performance than using all features in the case of unlabeled data. Lastly, to make replicating our work easy, a lightweight framework is created and released on Github.	https://doi.org/10.1145/3368926.3369711
357	Horschig, Siegfried and Mattis, Toni and Hirschfeld, Robert	Do Java Programmers Write Better Python? Studying off-Language Code Quality on GitHub	10.1145/3191697.3214341	2018	There are style guides and best practices for many programming languages. Their goal is to promote uniformity and readability of code, consequentially reducing the chance of errors.  While programmers who are frequently using the same programming language tend to internalize most of its best practices eventually, little is known about what happens when they casually switch languages and write code in a less familiar language. Insights into the factors that lead to coding convention violations could help to improve tutorials for programmers switching languages, make teachers aware of mistakes they might expect depending on what language students have been using before, or influence the order in which programming languages are taught.  To approach this question, we make use of a large-scale data set representing a major part of the open source development activity happening on GitHub. In this data set, we search for Java and C++ programmers that occasionally program Python and study their Python code quality using a lint tool.  Comparing their defect rates to those from Python programmers reveals significant effects in both directions: We observe that some of Python's best practices have more widespread adoption among Java and C++ programmers than Python experts. At the same time, python-specific coding conventions, especially indentation, scoping, and the use of semicolons, are violated more frequently.  We conclude that programming off-language is not generally associated with better or worse code quality, but individual coding conventions are violated more or less frequently depending on whether they are more universal or language-specific. We intend to motivate a discussion and more research on what causes these effects, how we can mitigate or use them for good, and which related effects can be studied using the presented data set.	https://doi.org/10.1145/3191697.3214341
358	Beller, Moritz and Gousios, Georgios and Zaidman, Andy	Oops, My Tests Broke the Build: An Explorative Analysis of Travis CI with GitHub	10.1109/MSR.2017.62	2017	Continuous Integration (CI) has become a best practice of modern software development. Yet, at present, we have a shortfall of insight into the testing practices that are common in CI-based software development. In particular, we seek quantifiable evidence on how central testing is to the CI process, how strongly the project language influences testing, whether different integration environments are valuable and if testing on the CI can serve as a surrogate to local testing in the IDE. In an analysis of 2,640,825 Java and Ruby builds on Travis CI, we find that testing is the single most important reason why builds fail. Moreover, the programming language has a strong influence on both the number of executed tests, their run time, and proneness to fail. The use of multiple integration environments leads to 10% more failures being caught at build time. However, testing on Travis CI does not seem an adequate surrogate for running tests locally in the IDE. To further research on Travis CI with GitHub, we introduce TravisTorrent.	https://doi.org/10.1109/MSR.2017.62
359	Frid-Jimenez, Amber and Carson, Jesi and Scott, Alanna and Khantidhara, Paninee and Elza, Dethe	Designing Participedia: A Collaborative Research Platform	10.1145/3384772.3385125	2020	A transformation of democratic governance is occurring as public participation empowers citizens to have their voices heard beyond the vote.&nbsp;Participedia is a research community and online crowdsourcing platform designed to document and share emerging knowledge about participatory democracy. Participedia's women-led Design &amp; Technology (D&amp;T) team used participatory design (PD) and feminist human computer interaction (HCI) strategies to evaluate Participedia's formerly proprietary website and design and build a new, open source platform.By shifting Participedia to an open source technological approach, the D&amp;T team deliberately created opportunities for women and students and initiated new collaborations through channels like Github. Key design improvements, such as improved accessibility and reducing bias in the data model of Participedia, further align the project with feminist values of equity, diversity and inclusion (EDI). The D&amp;T team is part of a new generation of designers and developers contributing to interdisciplinary research through design and technology for social good.	https://doi.org/10.1145/3384772.3385125
360	Takizawa, Ryota and Kawashima, Hideyuki and Mitsuhashi, Ryuya and Tatebe, Osamu	Performing External Join Operator on PostgreSQL with Data Transfer Approach	10.1145/3149457.3149480	2018	With the development of sensing devices, the size of data managed by human being has been rapidly increasing. To manage such huge data, relational database management system (RDBMS) plays a key role. RDBMS models the real world data as n-ary relational tables. Join operator is one of the most important relational operators, and its acceleration has been studied widely and deeply. How can an RDBMS provide such an efficient join operator? The performance improvement of join operator has been deeply studied for a decade, and many techniques are proposed already. The problem that we face is how to actually use such excellent techniques in real RDBMSs. We propose to implement an efficient join technique by the data transfer approach. The approach makes a hook point inside an RDBMS internal, and pulls data streams from the operator pipeline in the RDBMS, and applies our original join operator to the data, and finally returns the result to the operator pipeline in the RDBMS. The result of the experiment showed that our proposed method achieved 1.42x speedup compared with PostgreSQL. Our code is available on GitHub.	https://doi.org/10.1145/3149457.3149480
361	Hua, Jinru and Zhang, Mengshi and Wang, Kaiyuan and Khurshid, Sarfraz	SketchFix: A Tool for Automated Program Repair Approach Using Lazy Candidate Generation	10.1145/3236024.3264600	2018	Manually locating and removing bugs in faulty program is often tedious and error-prone. A common automated program repair approach called generate-and-validate (G&amp;V) iteratively creates candidate fixes, compiles them, and runs these candidates against the given tests. This approach can be costly due to a large number of re-compilations and re-executions of the program. To tackle this limitation, recent work introduced the SketchFix approach that tightly integrates the generation and validation phases, and utilizes runtime behaviors to substantially prune a large amount of repair candidates. This tool paper describes our Java implementation of SketchFix, which is an open-source library that we released on Github. Our experimental evaluation using Defects4J benchmark shows that SketchFix can significantly reduce the number of re-compilations and re-executions compared to other approaches and work particularly well in repairing expression manipulation at the AST node-level granularity.The demo video is at: https://youtu.be/AO-YCH8vGzQ.	https://doi.org/10.1145/3236024.3264600
524	Guzman, Emitza and Az\\'ocar, David and Li, Yang	Sentiment Analysis of Commit Comments in GitHub: An Empirical Study	10.1145/2597073.2597118	2014	Emotions have a high impact in productivity, task quality, creativity, group rapport and job satisfaction. In this work we use lexical sentiment analysis to study emotions expressed in commit comments of different open source projects and analyze their relationship with different factors such as used programming language, time and day of the week in which the commit was made, team distribution and project approval. Our results show that projects developed in Java tend to have more negative commit comments, and that projects that have more distributed teams tend to have a higher positive polarity in their emotional content. Additionally, we found that commit comments written on Mondays tend to a more negative emotion. While our results need to be confirmed by a more representative sample they are an initial step into the study of emotions and related factors in open source projects. 	https://doi.org/10.1145/2597073.2597118
362	Nayebi, Maleknaz and Farrahi, Homayoon and Ruhe, Guenther	Which Version Should Be Released to App Store?	10.1109/ESEM.2017.46	2017	Background: Several mobile app releases do not find their way to the end users. Our analysis of 11,514 releases across 917 open source mobile apps revealed that 44.3% of releases created in GitHub never shipped to the app store (market). Aims: We introduce "marketability" of open source mobile apps as a new release decision problem. Considering app stores as a complex system with unknown treatments, we evaluate performance of predictive models and analogical reasoning for marketability decisions. Method: We performed a survey with 22 release engineers to identify the importance of marketability release decision. We compared different classifiers to predict release marketability. For guiding the transition of not successfully marketable releases into successful ones, we used analogical reasoning. We evaluated our results both internally (over time) and externally (by developers). Results: Random forest classification performed best with F1 score of 78%. Analyzing 58 releases over time showed that, for 81% of them, analogical reasoning could correctly identify changes in the majority of release attributes. A survey with seven developers showed the usefulness of our method for supporting real world decisions. Conclusions: Marketability decisions of mobile apps can be supported by using predictive analytics and by considering and adopting similar experience from the past.	https://doi.org/10.1109/ESEM.2017.46
363	Zhang, Mengshi and Li, Xia and Zhang, Lingming and Khurshid, Sarfraz	Boosting Spectrum-Based Fault Localization Using PageRank	10.1145/3092703.3092731	2017	Manual debugging is notoriously tedious and time consuming. Therefore, various automated fault localization techniques have been proposed to help with manual debugging. Among the existing fault localization techniques, spectrum-based fault localization (SBFL) is one of the most widely studied techniques due to being lightweight. A focus of existing SBFL techniques is to consider how to differentiate program source code entities (i.e., one dimension in program spectra); indeed, this focus is aligned with the ultimate goal of finding the faulty lines of code. Our key insight is to enhance existing SBFL techniques by additionally considering how to differentiate tests (i.e., the other dimension in program spectra), which, to the best of our knowledge, has not been studied in prior work.  We present PRFL, a lightweight technique that boosts spectrum-based fault localization by differentiating tests using PageRank algorithm. Given the original program spectrum information, PRFL uses PageRank to recompute the spectrum information by considering the contributions of different tests. Then, traditional SBFL techniques can be applied on the recomputed spectrum information to achieve more effective fault localization. Although simple and lightweight, PRFL has been demonstrated to outperform state-of-the-art SBFL techniques significantly (e.g., ranking 42% more real faults within Top-1 compared with the most effective traditional SBFL technique) with low overhead (e.g., around 2 minute average extra overhead on real faults) on 357 real faults from 5 Defects4J projects and 30692 artificial (i.e., mutation) faults from 87 GitHub projects, demonstrating a promising future for considering the contributions of different tests during fault localization. 	https://doi.org/10.1145/3092703.3092731
364	Song, Yang and Chaparro, Oscar	BEE: A Tool for Structuring and Analyzing Bug Reports	10.1145/3368089.3417928	2020	This paper introduces BEE, a tool that automatically analyzes user-written bug reports and provides feedback to reporters and developers about the system’s observed behavior (OB), expected behavior (EB), and the steps to reproduce the bug (S2R). BEE employs machine learning to (i) detect if an issue describes a bug, an enhancement, or a question; (ii) identify the structure of bug descriptions by automatically labeling the sentences that correspond to the OB, EB, or S2R; and (iii) detect when bug reports fail to provide these elements. BEE is integrated with GitHub and offers a public web API that researchers can use to investigate bug management tasks based on bug reports. We evaluated BEE’s underlying models on more than 5k existing bug reports and found they can correctly detect OB, EB, and S2R sentences as well as missing information in bug reports. BEE is an open-source project that can be found at <a>https://git.io/JfFnN</a>. A screencast showing the full capabilities of BEE can be found at <a>https://youtu.be/8pC48f_hClw</a>.	https://doi.org/10.1145/3368089.3417928
365	Zhu, Shaochen and Wang, Betty	Predicative Model for Uber Ridership in New York City	10.1145/3134271.3134292	2017	Objective: This study aimed to build a predictive model for Uber ridership in New York City.Data: Uber rides data is downloaded from GitHub. The data were collected during January 2015 to June 2015 and had ridership information for all the five boroughs of New York City. We used a random sample of 50% whole data to build a predictive model, and used the other 50% to validate the model and further used bootstrap data for model validation. Mean squared errors (MSE) were calculated. The predicted riders and the observed riders were compared to measure the performance of the predictive model. All the analysis was done using free statistical software R.Results: A total of 20490 observations including hourly ridership information were extracted for this study. A total of 10245 observations were selected in training sample for model building, and 10245 in test sample, and 500000 in bootstrap sample which was based on test sample were used for model validation. A total of 7171685 riders were in training sample, 7092530 in test sample, and 345936605 in bootstrap sample. The predicted risers were 7171685 riders in training sample, 7134560 in test sample, and 348357233 in bootstrap sample. The predictive model performed well in the split sample which was not used for model building and bootstrap sample. The MSE was 142,866 in training sample, and 141,142 in test sample and 141480 in bootstrap sample. The observed ridership and predicted ridership were close to each other in each month of Jan-June, in each hour, in each week day, and in each district in New York city.Conclusions: A predictive model was built and validated using public available data for Uber ridership in New York city. It could be used to predict the business opportunities for Uber and help to make an informed decision regarding resource allocation.	https://doi.org/10.1145/3134271.3134292
531	Ma, Yezhou and Li, Huiying and Hu, Jiyao and Xie, Rong and Chen, Yang	Mining the Network of the Programmers: A Data-Driven Analysis of GitHub	10.1145/3127404.3127431	2017	GitHub is a worldwide popular website for version control and source code management. In addition, since its users can follow each other, it also forms a professional social network of millions of users. In this work, we perform a data-driven study for analyzing the GitHub network. By introducing a distributed crawling framework, we first collect profiles and behavioral data of more than 2 million GitHub users. To the best of our knowledge, this is the largest and latest public dataset of GitHub. Then, we build the social graph of these users and conduct a thorough analysis of the network structure. Moreover, we investigate the user behavior patterns, particularly the patterns of the "commit" activities. Finally, we utilize machine learning methods to discover important users in the network with a high accuracy and a low overhead. Our inspiring findings are helpful for GitHub to provide better services for its users.	https://doi.org/10.1145/3127404.3127431
366	Wessel, Mairieli	Enhancing Developers’ Support on Pull Requests Activities with Software Bots	10.1145/3368089.3418539	2020	Software bots are employed to support developers' activities, serving as conduits between developers and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save development cost, time, and effort, the bots' presence can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers enhance existing bots. Toward this end, we are interviewing maintainers, contributors, and bot developers to understand the problems in the human-bot interaction and how they affect the collaboration in a project. Afterward, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.	https://doi.org/10.1145/3368089.3418539
367	Dunn, Tamsen and Berry, Gwenn and Emig-Agius, Dorothea and Jiang, Yu and Iyer, Anita and Udar, Nitin and Str\\"omberg, Michael	Pisces: An Accurate and Versatile Single Sample Somatic and Germline Variant Caller	10.1145/3107411.3108203	2017	A method for robustly and accurately detecting rare DNA mutations in tumor samples is critical to cancer research. Because many clinical tissue repositories have only FFPE-degraded tumor samples, and no matched normal sample from healthy tissue available, being able to discriminate low frequency mutations from background noise in the absence of a matched normal sample is of particular importance to research. Current state of the art variant callers such as GATK and VarScan focus on germline variant calling (used for detecting inherited mutations following a Mendelian inheritance pattern) or, in the case of FreeBayes and MuTect, focus on tumor-normal joint variant calling (using the normal sample to help discriminate low frequency somatic mutations from back ground noise). We present Pisces, a tumor-only variant caller exclusively developed at Illumina for detecting low frequency mutations from next generation sequencing data. Pisces has been an integral part of the Illumina Truseq Amplicon workflow since 2012, and is available on BaseSpace and on the MiSeq sequencing platforms. Pisces has been available to the public on github, since 2015. (https://github.com/Illumina/Pisces) Since that time, the Pisces variant calling team have continued to develop Pisces, and have made available a suite of variant calling tools, including a ReadStitcher, Variant Phaser, and Variant Quality Recalibration tool, to be used along with the core variant caller, Pisces. Here, we describe the Pisces variant calling tools and core algorithms. We describe the common use cases for Pisces (not necessarily restricted to somatic variant calling). We also evaluate Pisces performance on somatic and germline datasets, both from the titration of well characterized samples, and from a corpus of 500 FFPE-treated clinical trial tumor samples, against other variant callers. Our results show that Pisces gives highly accurate results in a variety of contexts. We recommend Pisces for amplicon somatic and germline variant calling.	https://doi.org/10.1145/3107411.3108203
368	Xu, Pingmei and Sugano, Yusuke and Bulling, Andreas	Spatio-Temporal Modeling and Prediction of Visual Attention in Graphical User Interfaces	10.1145/2858036.2858479	2016	We present a computational model to predict users' spatio-temporal visual attention on WIMP-style (windows, icons, menus, pointer) graphical user interfaces. Like existing models of bottom-up visual attention in computer vision, our model does not require any eye tracking equipment. Instead, it predicts attention solely using information available to the interface, specifically users' mouse and keyboard input as well as the UI components they interact with. To study our model in a principled way, we further introduce a method to synthesize user interface layouts that are functionally equivalent to real-world interfaces, such as from Gmail, Facebook, or GitHub. We first quantitatively analyze attention allocation and its correlation with user input and UI components using ground-truth gaze, mouse, and keyboard data of 18 participants performing a text editing task. We then show that our model predicts attention maps more accurately than state-of-the-art methods. Our results underline the significant potential of spatio-temporal attention modeling for user interface evaluation, optimization, or even simulation.	https://doi.org/10.1145/2858036.2858479
369	Nguyen, Ngoc-Hoa and Le, Viet-Ha and Phung, Van-On and Du, Phuong-Hanh	Toward a Deep Learning Approach for Detecting PHP Webshell	10.1145/3368926.3369733	2019	The most efficient way of securing Web applications is searching and eliminating threats therein (from both malwares and vulnerabilities). In case of having Web application source codes, Web security can be improved by performing the task to detecting malicious codes, such as Web shells. In this paper, we proposed a model using a deep learning approach to detect and identify the malicious codes inside PHP source files. Our method relies on (i) pattern matching techniques by applying Yara rules to build a malicious and benign datasets, (ii) converting the PHP source codes to a numerical sequence of PHP opcodes and (iii) applying the Convolutional Neural Network model to predict a PHP file whether embedding a malicious code such as a webshell. Thus, we validate our approach with different webshell collections from reliable source published in Github. The experiment results show that the proposed method achieved the accuracy of 99.02% with 0.85% false positive rate.	https://doi.org/10.1145/3368926.3369733
370	Beineke, Kevin and Nothaas, Stefan and Sch\\"ottner, Michael	Efficient Messaging for Java Applications Running in Data Centers	10.1109/CCGRID.2018.00090	2018	Big data and large-scale Java applications often aggregate the resources of many servers. Low-latency and high-throughput network communication is important, if the applications have to process many concurrent interactive queries. We designed DXNet to address these challenges providing fast object de-/serialization, automatic connection management and zero-copy messaging. The latter includes sending of asynchronous messages as well as synchronous requests/responses and an event-driven message receiving approach. DXNet is optimized for small messages (&lt; 64 bytes) in order to support highly interactive web applications, e.g., graph-based information retrieval, but works well with larger messages (e.g., 8 MB) as well. DXNet is available as standalone component on Github and its modular design is open for different transports currently supporting Ethernet and InfiniBand. The evaluation with micro benchmarks and YCSB using Ethernet and InfiniBand shows request-response latencies sub 10 μs (round-trip) including object de-/serialization, as well as a maximum throughput of more than 9 GByte/s.	https://doi.org/10.1109/CCGRID.2018.00090
551	Liu, Pei and Li, Li and Zhao, Yanjie and Sun, Xiaoyu and Grundy, John	AndroZooOpen: Collecting Large-Scale Open Source Android Apps for the Research Community	10.1145/3379597.3387503	2020	It is critical for research to have an open, well-curated, representative set of apps for analysis. We present a collection of open-source Android apps collected from several sources, including Github. Our dataset, AndroZooOpen, currently contains over 45,000 app artefacts, a representative picture of Github-hosted Android apps. For apps released on Google Play, metadata including categories, ratings and user reviews, are also stored. We share this new dataset as part of our ongoing research to better support and enable new research topics involving Android app artefact analysis, and as a supplement dataset for AndroZoo, a well-known app collection of close-sourced Android apps.	https://doi.org/10.1145/3379597.3387503
371	Rahman, Mohammad Masudur and Roy, Chanchal K. and Collins, Jason A.	CoRReCT: Code Reviewer Recommendation in GitHub Based on Cross-Project and Technology Experience	10.1145/2889160.2889244	2016	Peer code review locates common coding rule violations and simple logical errors in the early phases of software development, and thus reduces overall cost. However, in GitHub, identifying an appropriate code reviewer for a pull request is a non-trivial task given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation technique that considers not only the relevant cross-project work history (e.g., external library experience) but also the experience of a developer in certain specialized technologies associated with a pull request for determining her expertise as a potential code reviewer. We first motivate our technique using an exploratory study with 10 commercial projects and 10 associated libraries external to those projects. Experiments using 17,115 pull requests from 10 commercial projects and six open source projects show that our technique provides 85%-- 92% recommendation accuracy, about 86% precision and 79%--81% recall in code reviewer recommendation, which are highly promising. Comparison with the state-of-the-art technique also validates the empirical findings and the superiority of our recommendation technique.	https://doi.org/10.1145/2889160.2889244
372	Hauser, Frederik and Schmidt, Mark and Menth, Michael	XRAC: Execution and Access Control for Restricted Application Containers on Managed Hosts	10.1109/NOMS47738.2020.9110380	2020	We propose xRAC to permit users to run special applications on managed hosts and to grant them access to protected network resources. We use restricted application containers (RACs) for that purpose. A RAC is a virtualization container with only a selected set of applications. Authentication verifies the RAC user’s identity and the integrity of the RAC image. If the user is permitted to use the RAC on a managed host, launching the RAC is authorized and access to protected network resources may be given, e.g., to internal networks, servers, or the Internet. xRAC simplifies traffic control as the traffic of a RAC has a unique IPv6 address so that it can be easily identified in the network. The architecture of xRAC reuses standard technologies, protocols, and infrastructure. Those are the Docker virtualization platform and 802.1X including EAP-over-UDP and RADIUS. Thus, xRAC improves network security without modifying core parts of applications, hosts, and infrastructure. In this paper, we review the technological background of xRAC, explain its architecture, discuss selected use cases, and investigate on the performance. To demonstrate the feasibility of xRAC, we implement it based on standard components with only a few modifications. Finally, we validate xRAC through experiments. We publish the testbed setup guide and prototypical implementation on GitHub [1].	https://doi.org/10.1109/NOMS47738.2020.9110380
373	Rigger, Manuel and Marr, Stefan and Adams, Bram and M\\"ossenb\\"ock, Hanspeter	Understanding GCC Builtins to Develop Better Tools	10.1145/3338906.3338907	2019	C programs can use compiler builtins to provide functionality that the C language lacks. On Linux, GCC provides several thousands of builtins that are also supported by other mature compilers, such as Clang and ICC. Maintainers of other tools lack guidance on whether and which builtins should be implemented to support popular projects. To assist tool developers who want to support GCC builtins, we analyzed builtin use in 4,913 C projects from GitHub. We found that 37% of these projects relied on at least one builtin. Supporting an increasing proportion of projects requires support of an exponentially increasing number of builtins; however, implementing only 10 builtins already covers over 30% of the projects. Since we found that many builtins in our corpus remained unused, the effort needed to support 90% of the projects is moderate, requiring about 110 builtins to be implemented. For each project, we analyzed the evolution of builtin use over time and found that the majority of projects mostly added builtins. This suggests that builtins are not a legacy feature and must be supported in future tools. Systematic testing of builtin support in existing tools revealed that many lacked support for builtins either partially or completely; we also discovered incorrect implementations in various tools, including the formally verified CompCert compiler.	https://doi.org/10.1145/3338906.3338907
374	Chen, Huan and Fietkiewicz, Chris	Version Control Graphical Interface for Open OnDemand	10.1145/3219104.3229268	2018	Use of high performance computing (HPC) clusters is challenging for the average researcher who is not familiar with the necessary tools such as the Linux operating system and job management software. Of those using HPC systems, the majority are not trained specifically in computer programming. Nearly 70% of users on the NSF-funded XSEDE system are in fields other than computer science and computing science. The graphical user interfaces (GUIs) that most users rely on for common software on personal computers are typically not available on HPCs. The Ohio Supercomputer Center has addressed these issues through the development of an open source, web-based GUI called Open OnDemand. Because it is open source, administrators are free to deploy it on their own systems, and developers are free to enhance it. To improve workforce development and diversity, we sought to: (1) install Open OnDemand on a private cluster and (2) develop a custom add-on module for version control of HPC application software. We successfully installed and configured Open OnDemand for a private cluster at Case Western Reserve University in order to evaluate the difficulty level of deployment. Despite our lack of experience in HPC system administration, the installation process was straight forward due to a streamlined installer package and thorough documentation. In order to evaluate the extensibility of Open OnDemand, we developed a custom web-based interface for use of the popular Git version control system. Version control tools are important in maintaining software by easily tracking and accessing file changes in both single- and multi-developer projects. Our module successfully integrates with the existing Open OnDemand interface and provides common version control operations that can be used during typical HPC workflows. It is our hope that making version control software easier to use will encourage HPC users to adopt the use of version control into their own workflows to improve productivity and repeatability. Source code for the app will be made available on the author's github site.	https://doi.org/10.1145/3219104.3229268
375	Romo, Bilyaminu Auwal and Capiluppi, Andrea	Towards an Automation of the Traceability of Bugs from Development Logs: A Study Based on Open Source Software	10.1145/2745802.2745833	2015	Context: Information and tracking of defects can be severely incomplete in almost every Open Source project, resulting in a reduced traceability of defects into the development logs (i.e., version control commit logs). In particular, defect data often appears not in sync when considering what developers logged as their actions. Synchronizing or completing the missing data of the bug repositories, with the logs detailing the actions of developers, would benefit various branches of empirical software engineering research: prediction of software faults, software reliability, traceability, software quality, effort and cost estimation, bug prediction and bug fixing.Objective: To design a framework that automates the process of synchronizing and filling the gaps of the development logs and bug issue data for open source software projects.Method: We instantiate the framework with a sample of OSS projects from GitHub, and by parsing, linking and filling the gaps found in their bug issue data, and development logs. UML diagrams show the relevant modules that will be used to merge, link and connect the bug issue data with the development data.Results: Analysing a sample of over 300 OSS projects we observed that around 1/2 of bug-related data is present in either development logs or issue tracker logs: the rest of the data is missing from one or the other source. We designed an automated approach that fills the gaps of either source by making use of the available data, and we successfully mapped all the missing data of the analysed projects, when using one heuristics of annotating bugs. Other heuristics need to be investigated and implemented.Conclusion: In this paper a framework to synchronise the development logs and bug data used in empirical software engineering was designed to automatically fill the missing parts of development logs and bugs of issue data.	https://doi.org/10.1145/2745802.2745833
376	Alam, Aftab and Krombholz, Katharina and Bugiel, Sven	Poster: Let History Not Repeat Itself (This Time) -- Tackling WebAuthn Developer Issues Early On	10.1145/3319535.3363283	2019	The FIDO2 open authentication standard, developed jointly by the FIDO Alliance and the W3C, provides end-users with the means to use public-key cryptography in addition to or even instead of text-based passwords for authentication on the web. Its WebAuthn protocol has been adopted by all major browser vendors and recently also by major service providers (e.g., Google, GitHub, Dropbox, Microsoft, and others). Thus, FIDO2 is a very strong contender for finally tackling the problem of insecure user authentication on the web. However, there remain a number of open questions to be answered for FIDO2 to succeed as expected. In this poster, we focus specifically on the critical question of how well web-service developers can securely roll out WebAuthn in their own services and which issues have to be tackled to help developers in this task. The past has unfortunately shown that software developers struggle with correctly implementing or using security-critical APIs, such as TLS/SSL, password storage, or cryptographic APIs. We report here on ongoing work that investigates potential problem areas and concrete pitfalls for adopters of WebAuthn and tries to lay out a plan of how our community can help developers. We believe that raising awareness for foreseeable developer problems and calling for action to support developers early on is critical on the path for establishing FIDO2 as a de-facto authentication solution.	https://doi.org/10.1145/3319535.3363283
377	Wessel, Mairieli	Leveraging Software Bots to Enhance Developers' Collaboration in Online Programming Communities	10.1145/3406865.3418368	2020	Software bots are applications that are integrated into human communication channels, serving as an interface between users and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save developers' costs, time, and effort, the interaction of these bots can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers to enhance existing bots, thereby improving the partnership with contributors and maintainers. Toward this end, we are interviewing developers to understand what are the problems on the human-bot interaction and how they affect human collaboration. Afterwards, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.	https://doi.org/10.1145/3406865.3418368
378	Brown, Neil C.C. and Altadmri, Amjad	What's New in BlueJ 4: Git, Stride and More (Abstract Only)	10.1145/3017680.3017822	2017	BlueJ is a beginner's IDE for Java which has been in popular use for over ten years. But it continues to improve and evolve: BlueJ 4.0.0 was recently released with several new features. Git support has been added in a user-friendly way, and the support for writing JavaFX GUI applications has been improved. BlueJ 4 also includes the frame-based Stride editor (previously seen in Greenfoot), which allows for block-like programming. BlueJ 4 also retains all its existing functionality such as interactive object creation and method invocation, a "REPL"-like code pad, a debugger and testing support. This workshop, run by the developers of BlueJ, will take the participants, whether new to BlueJ and Java or long-time users, through the new features while also providing an introduction/refresher on the existing capabilities of the software. Participants will learn how to share BlueJ projects via Github, create a new JavaFX application, dabble with Stride and get a tour of the existing BlueJ functionality. A laptop with BlueJ 4.0 installed is required.	https://doi.org/10.1145/3017680.3017822
379	Yan, Haonan and Li, Hui and Xiao, Mingchi and Dai, Rui and Zheng, Xianchun and Zhao, Xingwen and Li, Fenghua	PGSM-DPI: Precisely Guided Signature Matching of Deep Packet Inspection for Traffic Analysis	10.1109/GLOBECOM38437.2019.9013941	2019	In the field of network traffic analysis, Deep Packet Inspection (DPI) technology is widely used at present. However, the increase in network traffic has brought tremendous processing pressure on the DPI. Consequently, detection speed has become the bottleneck of the entire application. In order to speed up the traffic detection of DPI, a lot of research works have been applied to improve signature matching algorithms, which is the most influential factor in DPI performance. In this paper, we present a novel method from a different angle called Precisely Guided Signature Matching (PGSM). Instead of matching packets with signature directly, we use supervised learning to automate the rules of specific protocol in PGSM. By testing the performance of a packet in the rules, the target packet could be decided when and which signatures should be matched with. Thus, the PGSM method reduces the number of aimless matches which are useless and numerous. After proposing PGSM, we build a framework called PGSM-DPI to verify the effectiveness of guidance rules. The PGSM-DPI framework consists of PGSM method and open source DPI library. The framework is running on a distributed platform with better throughput and computational performance. Finally, the experimental results demonstrate that our PGSM-DPI can reduce 59.23% original DPI time and increase 21.31% throughput. Besides, all source codes and experimental results can be accessed on our GitHub.	https://doi.org/10.1109/GLOBECOM38437.2019.9013941
380	Campos, Jos\\'e and Arcuri, Andrea and Fraser, Gordon and Abreu, Rui	Continuous Test Generation: Enhancing Continuous Integration with Automated Test Generation	10.1145/2642937.2643002	2014	In object oriented software development, automated unit test generation tools typically target one class at a time. A class, however, is usually part of a software project consisting of more than one class, and these are subject to changes over time. This context of a class offers significant potential to improve test generation for individual classes. In this paper, we introduce Continuous Test Generation (CTG), which includes automated unit test generation during continuous integration (i.e., infrastructure that regularly builds and tests software projects). CTG offers several benefits: First, it answers the question of how much time to spend on each class in a project. Second, it helps to decide in which order to test them. Finally, it answers the question of which classes should be subjected to test generation in the first place. We have implemented CTG using the EvoSuite unit test generation tool, and performed experiments using eight of the most popular open source projects available on GitHub, ten randomly selected projects from the SF100 corpus, and five industrial projects. Our experiments demonstrate improvements of up to +58% for branch coverage and up to +69% for thrown undeclared exceptions, while reducing the time spent on test generation by up to +83%.	https://doi.org/10.1145/2642937.2643002
381	Pfeiffer, Rolf-Helge	What Constitutes Software? An Empirical, Descriptive Study of Artifacts	10.1145/3379597.3387442	2020	The term software is ubiquitous, however, it does not seem as if we as a community have a clear understanding of what software actually is. Imprecise definitions of software do not help other professions, in particular those acquiring and sourcing software from third-parties, when deciding what precisely are potential deliverables. In this paper we investigate which artifacts constitute software by analyzing 23 715 repositories from Github, we categorize the found artifacts into high-level categories, such as, code, data, and documentation (and into 19 more concrete categories) and we can confirm the notion of others that software is more than just source code or programs, for which the term is often used synonymously. With this work we provide an empirical study of more than 13 million artifacts, we provide a taxonomy of artifact categories, and we can conclude that software most often consists of variously distributed amounts of code in different forms, such as source code, binary code, scripts, etc., data, such as configuration files, images, databases, etc., and documentation, such as user documentation, licenses, etc.	https://doi.org/10.1145/3379597.3387442
382	White, Laurie and Engelke, Charles	Serverless Distributed Architecture by Incremental Examples	10.1145/3349266.3351392	2019	Cloud computing has the potential to be a great equalizer, providing powerful and sophisticated computing tools to anyone with an internet connection and even a minimal budget. In fact, educational institutions can often get cloud grants providing access at no cost. Although any traditional computing paradigm can be implemented with cloud computing, there are now new and potentially more useful options available. This workshop is a hands-on exploration of several of those new paradigms in a single gamifiable system. Participants will explore cloud computing through a game-playing case study. Concepts covered include serverless computing, distributed systems, event-driven software, message passing, asynchronous communication, and non-relational databases. Each new idea will be used to advance the example system a step at a time. The workshop will emphasize ways to incorporate the case study in class and possibilities for extending it. All code for the system is available on GitHub for participants to work with to implement their own games or extend the concepts in other ways, such as a programming assignment submission and scoring system.	https://doi.org/10.1145/3349266.3351392
383	Rahman, Musfiqur and Rigby, Peter C and Palani, Dharani and Nguyen, Tien	Cleaning StackOverflow for Machine Translation	10.1109/MSR.2019.00021	2019	Generating source code API sequences from an English query using Machine Translation (MT) has gained much interest in recent years. For any kind of MT, the model needs to be trained on a parallel corpus. In this paper we clean StackOverflow, one of the most popular online discussion forums for programmers, to generate a parallel English-Code corpus from Android posts. We contrast three data cleaning approaches: standard NLP, title only, and software task extraction. We evaluate the quality of the each corpus for MT. To provide indicators of how useful each corpus will be for machine translation, we provide researchers with measurements of the corpus size, percentage of unique tokens, and per-word maximum likelihood alignment entropy. We have used these corpus cleaning approaches to translate between English and Code [22, 23], to compare existing SMT approaches from word mapping to neural networks [24], and to re-examine the "natural software" hypothesis [29]. After cleaning and aligning the data, we create a simple maximum likelihood MT model to show that English words in the corpus map to a small number of specific code elements. This model provides a basis for the success of using StackOverflow for search and other tasks in the software engineering literature and paves the way for MT. Our scripts and corpora are publicly available on GitHub [1] as well as at https://search.datacite.org/works/10.5281/zenodo.2558551.	https://doi.org/10.1109/MSR.2019.00021
384	Accioly, Paola and Borba, Paulo and Silva, L\\'euson and Cavalcanti, Guilherme	Analyzing Conflict Predictors in Open-Source Java Projects	10.1145/3196398.3196437	2018	In collaborative development environments integration conflicts occur frequently. To alleviate this problem, different awareness tools have been proposed to alert developers about potential conflicts before they become too complex. However, there is not much empirical evidence supporting the strategies used by these tools. Learning about what types of changes most likely lead to conflicts might help to derive more appropriate requirements for early conflict detection, and suggest improvements to existing conflict detection tools. To bring such evidence, in this paper we analyze the effectiveness of two types of code changes as conflict predictors. Namely, editions to the same method, and editions to directly dependent methods. We conduct an empirical study analyzing part of the development history of 45 Java projects from GitHub and Travis CI, including 5,647 merge scenarios, to compute the precision and recall for the conflict predictors aforementioned. Our results indicate that the predictors combined have a precision of 57.99% and a recall of 82.67%. Moreover, we conduct a manual analysis which provides insights about strategies that could further increase the precision and the recall.	https://doi.org/10.1145/3196398.3196437
385	Maurus, Samuel and Plant, Claudia	Let's See Your Digits: Anomalous-State Detection Using Benford's Law	10.1145/3097983.3098101	2017	Benford's Law explains a curious phenomenon in which the leading digits of "naturally-occurring" numerical data are distributed in a precise fashion. In this paper we begin by showing that system metrics generated by many modern information systems like Twitter, Wikipedia, YouTube and GitHub obey this law. We then propose a novel unsupervised approach called BenFound that exploits this property to detect anomalous system events. BenFound tracks the "Benfordness" of key system metrics, like the follower counts of tweeting Twitter users or the change deltas in Wikipedia page edits. It then applies a novel Benford-conformity test in real-time to identify "non-Benford events". We investigate a variety of such events, showing that they correspond to unnatural and often undesirable system interactions like spamming, hashtag-hijacking and denial-of-service attacks. The result is a technically-uncomplicated and effective "red flagging" technique that can be used to complement existing anomaly-detection approaches. Although not without its limitations, it is highly efficient and requires neither obscure parameters, nor text streams, nor natural-language processing.	https://doi.org/10.1145/3097983.3098101
386	Nowling, Ronald J. and Beal, Christopher R. and Emrich, Scott and Behura, Susanta K. and Halfon, Marc S. and Duman-Scheel, Molly	PeakMatcher: Matching Peaks Across Genome Assemblies	10.1145/3388440.3414907	2020	When reference genome assemblies are updated, the peaks from DNA enrichment assays such as ChIP-Seq and FAIRE-Seq need to be called again using the new genome assembly. PeakMatcher is an open-source package that aids in validation by matching peaks across two genome assemblies using the alignment of reads or within the same genome. PeakMatcher calculates recall and precision while also outputting lists of peak-to-peak matches.PeakMatcher uses read alignments to match peaks across genome assemblies. PeakMatcher finds all read aligned to one genome that overlap with a given list of peaks. PeakMatcher uses the read names to locate where those reads are aligned against a second genome. Lastly, all peaks called against the second genome that overlap with the aligned reads are found and output. PeakMatcher groups uses the peak-read-peak relationships to discover 1-to-1, 1-to-many, and many-to-many relationships. Overlap queries are performed with interval trees for maximum efficiency.We evaluated PeakMatcher on two data sets. The first data set was FAIRE-Seq (Formaldehyde-Assisted Isolation of Regulatory Elements Sequencing) of DNA isolated embyros of the mosquito Aedes aegypti [2, 4]. We implemented a peak calling pipeline and validated it on the older (highly fragmented) AaegL3 assembly [5]. PeakMatcher matched 92.9% (precision) of the 121,594 previously-called peaks from [2, 4] with 89.4% (recall) of the 124,959 peaks called with our new pipeline. Next, we applied the peak-calling pipeline to call FAIRE peaks using the newer, chromosome-complete AaegL5 assembly [3]. PeakMatcher found matches for 14 of the 16 experimentally-validated AaegL3 FAIRE peaks from [2, 4]. We validated the matches by comparing nearby genes across the genomes. Nearby genes were consistent for 11 of the 14 peaks; inconsistencies for at least two of the remaining peaks were clearly attributable to differences in assemblies. When applied to all of the peaks, Peak-Matcher matched 78.8% (precision) of the 124,959 AaegL3 peaks with 76.7% (recall) of the 128,307 AaegL5 peaks.The second data set was STARR-Seq (Self-Transcribing Active Regulatory Region Sequencing) of Drosophila melanogaster DNA in S2 culture cells [1]. We called STARR peaks against two versions (dm3 and r5.53) of the D. melanogaster genome [6]. PeakMatcher matched 77.4% (precision) of the 4,195 dm3 peaks with 94.8% (recall) of the 3,114 r5.53 peaks.PeakMatcher and associated documentation are available on GitHub (https://github.com/rnowling/peak-matcher) under the open-source Apache Software License v2. PeakMatcher was written in Python 3 using the intervaltree library.	https://doi.org/10.1145/3388440.3414907
387	Hariri, Farah and Shi, August	SRCIROR: A Toolset for Mutation Testing of C Source Code and LLVM Intermediate Representation	10.1145/3238147.3240482	2018	We present SRCIROR (pronounced “sorcerer“), a toolset for performing mutation testing at the levels of C/C++ source code (SRC) and the LLVM compiler intermediate representation (IR). At the SRC level, SRCIROR identifies program constructs for mutation by pattern-matching on the Clang AST. At the IR level, SRCIROR directly mutates the LLVM IR instructions through LLVM passes. Our implementation enables SRCIROR to (1) handle any program that Clang can handle, extending to large programs with a minimal overhead, and (2) have a small percentage of invalid mutants that do not compile. SRCIROR enables performing mutation testing using the same classes of mutation operators at both the SRC and IR levels, and it is easily extensible to support more operators. In addition, SRCIROR can collect coverage to generate mutants only for covered code elements. Our tool is publicly available on GitHub (https://github.com/TestingResearchIllinois/srciror). We evaluate SRCIROR on Coreutils subjects. Our evaluation shows interesting differences between SRC and IR, demonstrating the value of SRCIROR in enabling mutation testing research across different levels of code representation.	https://doi.org/10.1145/3238147.3240482
388	Verma, Amit Arjun and Iyengar, S. R.S. and Setia, Simran and Dubey, Neeru	KDAP: An Open Source Toolkit to Accelerate Knowledge Building Research	10.1145/3412569.3412575	2020	With the success of crowdsourced portals, such as Wikipedia, Stack Overflow, Quora, and GitHub, a class of researchers is driven towards understanding the dynamics of knowledge building on these portals. Even though collaborative knowledge building portals are known to be better than expert-driven knowledge repositories, limited research has been performed to understand the knowledge building dynamics in the former. This is mainly due to two reasons; first, unavailability of the standard data representation format, second, lack of proper tools and libraries to analyze the knowledge building dynamics.We describe Knowledge Data Analysis and Processing Platform (KDAP), a programming toolkit that is easy to use and provides high-level operations for analysis of knowledge data. We propose Knowledge Markup Language (Knol-ML), a standard representation format for the data of collaborative knowledge building portals. KDAP can process the massive data of crowdsourced portals like Wikipedia and Stack Overflow efficiently. As a part of this toolkit, a data-dump of various collaborative knowledge building portals is published in Knol-ML format. The combination of Knol-ML and the proposed open-source library will help the knowledge building community to perform benchmark analysis.URL:https://github.com/descentis/kdapSupplementary Material: https://bit.ly/2Z3tZK5	https://doi.org/10.1145/3412569.3412575
389	Schmittle, Matt and Lukina, Anna and Vacek, Lukas and Das, Jnaneshwar and Buskirk, Christopher P. and Rees, Stephen and Sztipanovits, Janos and Grosu, Radu and Kumar, Vijay	OpenUAV: A UAV Testbed for the CPS and Robotics Community	10.1109/ICCPS.2018.00021	2018	Multirotor Unmanned Aerial Vehicles (UAV) have grown in popularity for research and education, overcoming challenges associated with fixed wing and ground robots. Unfortunately, extensive physical testing can be expensive and time consuming because of short flight times due to battery constraints and safety precautions. Simulation tools offer a low barrier to entry and enable testing and validation before field trials. However, most of the well-known simulators today have a high barrier to entry due to the need for powerful computers and the time required for initial set up. In this paper, we present OpenUAV, an open source test bed for UAV education and research that overcomes these barriers. We leverage the Containers as a Service (CaaS) technology to enable students and researchers carry out simulations on the cloud. We have based our framework on open-source tools including ROS, Gazebo, Docker, PX4, and Ansible, we designed the simulation framework so that it has no special hardware requirements. Two use-cases are presented. First, we show how a UAV can navigate around obstacles, and second, we test a multi-UAV swarm formation algorithm. To our knowledge, this is the first open-source, cloud-enabled testbed for UAVs. The code is available on GitHub: https://github.com/Open-UAV.	https://doi.org/10.1109/ICCPS.2018.00021
399	Eslami, Taban and Saeed, Fahad	Similarity Based Classification of ADHD Using Singular Value Decomposition	10.1145/3203217.3203239	2018	Attention deficit hyperactivity disorder (ADHD) is one of the most common brain disorders among children. This disorder is considered as a big threat for public health and causes attention, focus and organizing difficulties for children and even adults. Since the cause of ADHD is not known yet, data mining algorithms are being used to help discover patterns which discriminate healthy from ADHD subjects. Numerous efforts are underway with the goal of developing classification tools for ADHD diagnosis based on functional and structural magnetic resonance imaging data of the brain. In this paper, we used Eros, which is a technique for computing similarity between two multivariate time series along with k-Nearest-Neighbor classifier, to classify healthy vs ADHD children. We designed a model selection scheme called J-Eros which is able to pick the optimum value of k for k-Nearest-Neighbor from the training data. We applied this technique to the public data provided by ADHD-200 Consortium competition and our results show that J-Eros is capable of discriminating healthy from ADHD children such that we outperformed the best results reported by ADHD-200 competition about 20 percent for two datasets.The implemented code is available as GPL license on GitHub portal of our lab at https://github.com/pcdslab/J-Eros.	https://doi.org/10.1145/3203217.3203239
390	Wan, Fang and Wang, Haokun and Liu, Xiaobo and Yang, Linhan and Song, Chaoyang	DeepClaw: A Robotic Hardware Benchmarking Platform for Learning Object Manipulation<sup>*</sup>	10.1109/AIM43001.2020.9159011	2020	We present DeepClaw as a reconfigurable benchmark of robotic hardware and task hierarchy for robot learning. The DeepClaw benchmark aims at a mechatronics perspective of the robot learning problem, which features a minimum design of robot cell that can be easily reconfigured to host robot hardware from various vendors, including manipulators, grippers, cameras, desks, and objects, aiming at a streamlined collection of physical manipulation data and evaluation of the learned skills for hardware benchmarking. We provide a detailed design of the robot cell with readily available parts to build the experiment environment that can host a wide range of robotic hardware commonly adopted for robot learning. We propose a hierarchical pipeline of software integration, including localization, recognition, grasp planning, and motion planning, to streamline learning-based robot control, data collection, and experiment validation towards shareability and reproducibility. We present benchmarking results of the DeepClaw system for a baseline Tic-Tac-Toe task, a bin-clearing task, and a jigsaw puzzle task using three sets of standard robotic hardware. Our results show that tasks defined in DeepClaw can be easily reproduced on three robot cells. Under the same task setup, the differences in robotic hardware used will present a non-negligible impact on the performance metrics of robot learning. All design layouts and codes are hosted on Github for open access (https://github.com/bionicdl-sustech/DeepClaw).	https://doi.org/10.1109/AIM43001.2020.9159011
391	Estep, Samuel	Gradual Program Analysis	10.1145/3359061.3361082	2019	The designers of static analyses for null safety often try to reduce the number of false positives reported by the analysis through increased engineering effort, user-provided annotations, and/or weaker soundness guarantees. To produce a null-pointer analysis with little engineering effort, reduced false positives, and strong soundness guarantees in a principled way, we adapt the “Abstracting Gradual Typing” framework to the abstract-interpretation based program analysis setting. In particular, a simple static dataflow analysis that relies on user-provided annotations and has nullability lattice N ⊑ ⊤ (where N means “definitely not null” and ⊤ means “possibly null”) is gradualized producing a new lattice N ⊑ ? ⊑ ⊤. Question mark explicitly represents “optimistic uncertainty” in the analysis itself, supporting a formal soundness property and the “gradual guarantees” laid out in the gradual typing literature. We then implement a prototype of our gradual null-pointer analysis as a Facebook Infer checker, and compare it to existing null-pointer analyses via a suite of GitHub repositories used originally by Uber to evaluate their NullAway tool. Our prototype has architecture and output very similar to these existing tools, suggesting the value of applying our approach to more sophisticated program analyses in the future.	https://doi.org/10.1145/3359061.3361082
392	Amreen, Sadika and Mockus, Audris	Experiences on Clustering High-Dimensional Data Using PbdR	10.1145/3144763.3144768	2017	Motivation: Software engineering for High Performace Computing (HPC) environments in general [1] and for big data in particular [5] faces a set of unique challenges including high complexity of middleware and of computing environments. Tools that make it easier for scientists to utilize HPC are, therefore, of paramount importance. We provide an experience report of using one of such highly effective middleware pbdR [9] that allow the scientist to use R programming language without, at least nominally, having to master many layers of HPC infrastructure, such as OpenMPI [4] and ScalaPACK [2]. Objective: to evaluate the extent to which middleware helps improve scientist productivity, we use pbdR to solve a real problem that we, as scientists, are investigating. Our big data comes from the commits on GitHub and other project hosting sites and we are trying to cluster developers based on the text of these commit messages. Context: We need to be able to identify developer for every commit and to identify commits for a single developer. Developer identifiers in the commits, such as login, email, and name are often spelled in multiple ways since that information may come from different version control systems (Git, Mercurial, SVN, ...) and may depend on which computer is used (what is specified in .git/config of the home folder). Method: We train Doc2Vec [7] model where existing credentials are used as a document identifier and then use the resulting 200-dimensional vectors for the 2.3M identifiers to cluster these identifiers so that each cluster represents a specific individual. The distance matrix occupies 32TB and, therefore, is a good target for HPC in general and pbdR in particular. pbdR allows data to be distributed over computing nodes and even has implemented K-means and mixture-model clustering techniques in the package pmclust. Results: We used strategic prototyping [3] to evaluate the capabilities of pbdR and discovered that a) the use of middleware required extensive understanding of its inner workings thus negating many of the expected benefits; b) the implemented algorithms were not suitable for the particular combination of n, p, and k (sample size, data dimension, and the number of clusters); c) the development environment based on batch jobs increases development time substantially. Conclusions: In addition to finding from Basili et al., we find that the quality of the implementation of HPC infrastructure and its development environment has a tremendous effect on development productivity.	https://doi.org/10.1145/3144763.3144768
393	Sandanayake, T. C. and Limesha, G. A. I. and Madhumali, T. S. S. and Mihirani, W. P. I. and Peiris, M. S. A.	Automated CV Analyzing and Ranking Tool to Select Candidates for Job Positions	10.1145/3301551.3301579	2018	Processing of CVs to find a suitable candidate is a challenging task for many organisations. Most of the time identifying potential candidates for a job post is a time consuming and costly task for HR Divisions. Different CV s consists of information in a many formats. This research study extracts the information from the CV and ranks the CVs according to a given criteria to screen them out from the vast number of received applications in an organization. This research solution also recommends the most appropriate job category for an applicant according to his/ her CV information. At the same time the study creates candidate profiles using data from external professional web sources like Stack overflow, GitHub and Blogs. This research has basically designed for the domain of Information Technology related job postings such as Software Engineering, Quality Assurance etc. This system can rank the CVs according to various aspects presented in the CV, thus saving an enormous amount of time and effort that is required for manual scanning by the recruiters.	https://doi.org/10.1145/3301551.3301579
400	Xie, Mulong and Feng, Sidong and Xing, Zhenchang and Chen, Jieshan and Chen, Chunyang	UIED: A Hybrid Tool for GUI Element Detection	10.1145/3368089.3417940	2020	Graphical User Interface (GUI) elements detection is critical for many GUI automation and GUI testing tasks. Acquiring the accurate positions and classes of GUI elements is also the very first step to conduct GUI reverse engineering or perform GUI testing. In this paper, we implement a User Iterface Element Detection (UIED), a toolkit designed to provide user with a simple and easy-to-use platform to achieve accurate GUI element detection. UIED integrates multiple detection methods including old-fashioned computer vision (CV) approaches and deep learning models to handle diverse and complicated GUI images. Besides, it equips with a novel customized GUI element detection methods to produce state-of-the-art detection results. Our tool enables the user to change and edit the detection result in an interactive dashboard. Finally, it exports the detected UI elements in the GUI image to design files that can be further edited in popular UI design tools such as Sketch and Photoshop. UIED is evaluated to be capable of accurate detection and useful for downstream works. Tool URL: <a>http://uied.online</a> Github Link: <a>https://github.com/MulongXie/UIED</a>	https://doi.org/10.1145/3368089.3417940
394	Duong-Trung, Nghia and Son, Ha Xuan and Le, Hai Trieu and Phan, Tan Tai	Smart Care: Integrating Blockchain Technology into the Design of Patient-Centered Healthcare Systems	10.1145/3377644.3377667	2020	Cross-institutional sharing of medical data is essential to provide e.ective collaborative treatment and clinical decisions for patients. Medical data privacy involves ensuring only authorized parties may access the health records under the awareness and approval of patients in any circumstances. This is crucial to any healthcare system because the protection of patients' clinical data is not only an ethical responsibility but also a legal mandate. Despite the importance of medical data sharing, today's healthcare systems have not provided enough protection of patients' sensitive information to be utilized deliberately or unintentionally. Hence, there is an urgent demand for a clinical transaction mechanism that allows patients to access, trace and control their health records. In this paper, the authors focus on several limitations in the literature and propose appropriate improvement in healthcare systems by (i) addressing information security and privacy, (ii) solving the lack of trust between providers, and (iii) encouraging scalability of healthcare interoperability. Building upon these key insights, we introduce several components of a patient-centered healthcare system using smart contracts via blockchain technology. A complete code solution is publicized on the authors' GitHub repository to engage further reproducibility and improvement.	https://doi.org/10.1145/3377644.3377667
395	Barnett, Jacob G. and Gathuru, Charles K. and Soldano, Luke S. and McIntosh, Shane	The Relationship between Commit Message Detail and Defect Proneness in Java Projects on GitHub	10.1145/2901739.2903496	2016	Just-In-Time (JIT) defect prediction models aim to predict the commits that will introduce defects in the future. Traditionally, JIT defect prediction models are trained using metrics that are primarily derived from aspects of the code change itself (e.g., the size of the change, the author's prior experience). In addition to the code that is submitted during a commit, authors write commit messages, which describe the commit for archival purposes. It is our position that the level of detail in these commit messages can provide additional explanatory power to JIT defect prediction models. Hence, in this paper, we analyze the relationship between the defect proneness of commits and commit message volume (i.e., the length of the commit message) and commit message content (approximated using spam filtering technology). Through analysis of JIT models that were trained using 342 GitHub repositories, we find that our JIT models outperform random guessing models, achieving AUC and Brier scores that range between 0.63-0.96 and 0.01-0.21, respectively. Furthermore, our metrics that are derived from commit message detail provide a statistically significant boost to the explanatory power to the JIT models in 43%-80% of the studied systems, accounting for up to 72% of the explanatory power. Future JIT studies should consider adding commit message detail metrics.	https://doi.org/10.1145/2901739.2903496
396	Nepomuceno, Vilmar and Soares, Sergio	Maintaining Systematic Literature Reviews: Benefits and Drawbacks	10.1145/3239235.3267432	2018	Background: Maintenance and traceability (versioning) are constant concerns in Software Engineering (SE), however, few works related to these topics in Systematic Literature Reviews (SLR) were found. Goal: The goal of this research is to elucidate how SLRs can be maintained and what are the benefits and drawbacks in this process. Method: This work presents a survey where experienced researchers that conducted SLRs between 2011 and 2015 answered questions about maintenance and traceability and, using software maintenance concepts, it addresses the SLRs maintenance process. From the 79 e-mails sent we reach 28 answers. Results: 19 of surveyed researchers have shown interest in keeping their SLRs up-to-date, but they have expressed concerns about the effort to be made to accomplish it. It was also observed that 20 participants would be willing to share their SLRs in common repositories, such as GitHub. Conclusions: There is a need to perform maintenance on SLRs. Thus, we are proposing a SLR maintenance process, taking into account some benefits and drawbacks identified during our study and presented through the paper.	https://doi.org/10.1145/3239235.3267432
397	Canas, Karen and Ubiera, Brandon and Liu, Xinlian and Liu, Yanling	Scalable Biomedical Image Synthesis with GAN	10.1145/3219104.3229261	2018	Despite the fast-paced progress in imaging techniques made possible by ubiquitous applications of convolutional neural networks, biomedical imaging has yet to benefit from the full potential of deep learning. An unresolved bottleneck is the lack of training set data. Some experimentally obtained data are kept and preserved by individual research groups where they were produced, out of the reach of the public; more often, high cost and rare occurrences simply mean not enough such images have been made. We propose to develop deep learning based workflow to overcome this barrier. Leveraging the largest radiology data (chest X-Ray) recently published by the NIH, we train a generative adversarial network (GAN) and use it to produce photorealistic images that retain pathological quality. We also explore porting our models to a range of supercomputing platforms and systems that we have access to, including XSEDE, NERSC, OLCF, Blue Waters, NIH Biowulf etc., to investigate and compare their performance. In addition to the obvious benefits of biomedical research, our work will help understand how current supercomputing infrastructure embraces machine learning demands. Our code and enhanced data set are available through GitHub/Binder.	https://doi.org/10.1145/3219104.3229261
398	Zhang, Huaizheng and Li, Yuanming and Huang, Yizheng and Wen, Yonggang and Yin, Jianxiong and Guan, Kyle	MLModelCI: An Automatic Cloud Platform for Efficient MLaaS	10.1145/3394171.3414535	2020	MLModelCI provides multimedia researchers and developers with a one-stop platform for efficient machine learning (ML) services. The system leverages DevOps techniques to optimize, test, and manage models. It also containerizes and deploys these optimized and validated models as cloud services (MLaaS). In its essence, MLModelCI serves as a housekeeper to help users publish models. The models are first automatically converted to optimized formats for production purpose and then profiled under different settings (e.g., batch size and hardware). The profiling information can be used as guidelines for balancing the trade-off between performance and cost of MLaaS. Finally, the system dockerizes the models for ease of deployment to cloud environments. A key feature of MLModelCI is the implementation of a controller, which allows elastic evaluation which only utilizes idle workers while maintaining online service quality. Our system bridges the gap between current ML training and serving systems and thus free developers from manual and tedious work often associated with service deployment. We release the platform as an open-source project on GitHub under Apache 2.0 license, with the aim that it will facilitate and streamline more large-scale ML applications and research projects.	https://doi.org/10.1145/3394171.3414535
401	Zampetti, Fiorella and Ponzanelli, Luca and Bavota, Gabriele and Mocci, Andrea and Di Penta, Massimiliano and Lanza, Michele	How Developers Document Pull Requests with External References	10.1109/ICPC.2017.30	2017	Online resources of formal and informal documentation-such as reference manuals, forum discussions and tutorials-have become an asset to software developers, as they allow them to tackle problems and to learn about new tools, libraries, and technologies. This study investigates to what extent and for which purpose developers refer to external online resources when they contribute changes to a repository by raising a pull request. Our study involved (i) a quantitative analysis of over 150k URLs occurring in pull requests posted in GitHub; (ii) a manual coding of the kinds of software evolution activities performed in commits related to a statistically significant sample of 2,130 pull requests referencing external documentation resources; (iii) a survey with 69 participants, who provided feedback on how they use online resources and how they refer to them when filing a pull request. Results of the study indicate that, on the one hand, developers find external resources useful to learn something new or to solve specific problems, and they perceive useful referring such resources to better document changes. On the other hand, both interviews and repository mining suggest that external resources are still rarely referred in document changes.	https://doi.org/10.1109/ICPC.2017.30
402	Kozma, Viktor and Broman, David	MORAP: A Modular Robotic Arm Platform for Teaching and Experimenting with Equation-Based Modeling Languages	10.1145/2904081.2904085	2016	Equation-based object-oriented (EOO) modeling and simulation techniques have in the last decades gained significant attention both in academia and industry. One of the key properties of EOO languages is modularity, where different components can be developed independently and then connected together to form a complete acausal model. However, extensive modeling without explicit model validation together with a real physical system can result in incorrect assumptions and false conclusions. In particular, in an educational and research setting, it is vital that students experiment both with equation-based models and the real system that is being modeled. In this work-in-progress paper, we present a physical experimental robotic arm platform that is designed for teaching and research. Similar to EOO models, the robotic arm is modular, meaning that its parts can be reconfigured and composed together in various settings, and used for different experiments. The platform is completely open source, where electronic schematics, CAD models for 3D printing, controller software, and component specifications are available on GitHub. The vision is to form a community, where new open source components are continuously added, to enable an open and freely available physical experimental platform for EOO languages.	https://doi.org/10.1145/2904081.2904085
403	Liang, Jie and Jiang, Yu and Chen, Yuanliang and Wang, Mingzhe and Zhou, Chijin and Sun, Jiaguang	PAFL: Extend Fuzzing Optimizations of Single Mode to Industrial Parallel Mode	10.1145/3236024.3275525	2018	Researchers have proposed many optimizations to improve the efficiency of fuzzing, and most optimized strategies work very well on their targets when running in single mode with instantiating one fuzzer instance. However, in real industrial practice, most fuzzers run in parallel mode with instantiating multiple fuzzer instances, and those optimizations unfortunately fail to maintain the efficiency improvements.  In this paper, we present PAFL, a framework that utilizes efficient guiding information synchronization and task division to extend those existing fuzzing optimizations of single mode to industrial parallel mode. With an additional data structure to store the guiding information, the synchronization ensures the information is shared and updated among different fuzzer instances timely. Then, the task division promotes the diversity of fuzzer instances by splitting the fuzzing task into several sub-tasks based on branch bitmap. We first evaluate PAFL using 12 different real-world programs from Google fuzzer-test-suite. Results show that in parallel mode, two AFL improvers–AFLFast and FairFuzz do not outperform AFL, which is different from the case in single mode. However, when augmented with PAFL, the performance of AFLFast and FairFuzz in parallel mode improves. They cover 8% and 17% more branches, trigger 79% and 52% more unique crashes. For further evaluation on more widely-used software systems from GitHub, optimized fuzzers augmented with PAFL find more real bugs, and 25 of which are security-critical vulnerabilities registered as CVEs in the US National Vulnerability Database.	https://doi.org/10.1145/3236024.3275525
404	Thompson, George and Sullivan, Allison K.	ProFL: A Fault Localization Framework for Prolog	10.1145/3395363.3404367	2020	Prolog is a declarative, first-order logic that has been used in a variety of domains to implement heavily rules-based systems. However, it is challenging to write a Prolog program correctly. Fortunately, the SWI-Prolog environment supports a unit testing framework, plunit, which enables developers to systematically check for correctness. However, knowing a program is faulty is just the first step. The developer then needs to fix the program which means the developer needs to determine what part of the program is faulty. ProFL is a fault localization tool that adapts imperative-based fault localization techniques to Prolog’s declarative environment. ProFL takes as input a faulty Prolog program and a plunit test suite. Then, ProFL performs fault localization and returns a list of suspicious program clauses to the user. Our toolset encompasses two different techniques: ProFLs, a spectrum-based technique, and ProFLm, a mutation-based technique. This paper describes our Python implementation of ProFL, which is a command-line tool, released as an open-source project on GitHub (https://github.com/geoorge1d127/ProFL). Our experimental results show ProFL is accurate at localizing faults in our benchmark programs.	https://doi.org/10.1145/3395363.3404367
410	Gyori, Alex and Lambeth, Ben and Shi, August and Legunsen, Owolabi and Marinov, Darko	NonDex: A Tool for Detecting and Debugging Wrong Assumptions on Java API Specifications	10.1145/2950290.2983932	2016	We present NonDex, a tool for detecting and debugging wrong assumptions on Java APIs. Some APIs have underdetermined specifications to allow implementations to achieve different goals, e.g., to optimize performance. When clients of such APIs assume stronger-than-specified guarantees, the resulting client code can fail. For example, HashSet’s iteration order is underdetermined, and code assuming some implementation-specific iteration order can fail. NonDex helps to proactively detect and debug such wrong assumptions. NonDex performs detection by randomly exploring different behaviors of underdetermined APIs during test execution. When a test fails during exploration, NonDex searches for the invocation instance of the API that caused the failure. NonDex is open source, well-integrated with Maven, and also runs from the command line. During our experiments with the NonDex Maven plugin, we detected 21 new bugs in eight Java projects from GitHub, and, using the debugging feature of NonDex, we identified the underlying wrong assumptions for these 21 new bugs and 54 previously detected bugs. We opened 13 pull requests; developers already accepted 12, and one project changed the continuous-integration configuration to run NonDex on every push. The demo video is at: https://youtu.be/h3a9ONkC59c 	https://doi.org/10.1145/2950290.2983932
405	Yan, Jiafei and Sun, Hailong and Wang, Xu and Liu, Xudong and Song, Xiaotao	Profiling Developer Expertise across Software Communities with Heterogeneous Information Network Analysis	10.1145/3275219.3275226	2018	Knowing developer expertise is critical for achieving effective task allocation. However, it is of great challenge to accurately profile the expertise of developers over the Internet as their activities often disperse across different online communities. In this regard, the existing works either merely concern a single community, or simply sum up the expertise in individual communities. The former suffers from low accuracy due to incomplete data, while the latter impractically assumes that developer expertise is completely independent and irrelavant across communities. To overcome those limitations, we propose a new approach to profile developer expertise across software communities through heterogeneous information network (HIN) analysis. A HIN is first built by analyzing the developer activities in various communities, where nodes represent objects like developers and skills, and edges represent the relations among objects. Second, as random walk with restart (RWR) is known for its ability to capture the global structure of the whole network, we adopt RWR over the HIN to estimate the proximity of developer nodes and skill nodes, which essentially reflects developer expertise. Based on the data of 72,645 common users of GitHub and Stack Overflow, we conducted an empirical study and evaluated developer expertise using proposed approach. To evaluate the effect of our approach, we use the obtained expertise to estimate the competency of developers in answering the questions posted in Stack Overflow. The experimental results demonstrate the superiority of our approach over existing methods.	https://doi.org/10.1145/3275219.3275226
406	Zhou, Yaqin and Sharma, Asankhaya	Automated Identification of Security Issues from Commit Messages and Bug Reports	10.1145/3106237.3117771	2017	The number of vulnerabilities in open source libraries is increasing rapidly. However, the majority of them do not go through public disclosure. These unidentified vulnerabilities put developers' products at risk of being hacked since they are increasingly relying on open source libraries to assemble and build software quickly. To find unidentified vulnerabilities in open source libraries and secure modern software development, we describe an efficient automatic vulnerability identification system geared towards tracking large-scale projects in real time using natural language processing and machine learning techniques. Built upon the latent information underlying commit messages and bug reports in open source projects using GitHub, JIRA, and Bugzilla, our K-fold stacking classifier achieves promising results on vulnerability identification. Compared to the state of the art SVM-based classifier in prior work on vulnerability identification in commit messages, we improve precision by 54.55% while maintaining the same recall rate. For bug reports, we achieve a much higher precision of 0.70 and recall rate of 0.71 compared to existing work. Moreover, observations from running the trained model at SourceClear in production for over 3 months has shown 0.83 precision, 0.74 recall rate, and detected 349 hidden vulnerabilities, proving the effectiveness and generality of the proposed approach. 	https://doi.org/10.1145/3106237.3117771
407	de Almeida Filho, Francisco Gon\\ccalves and Martins, Ant\\^onio Diogo Forte and Vinuto, Tiago da Silva and Monteiro, Jos\\'e Maria and de Sousa, \\'Italo Pereira and de Castro Machado, Javam and Rocha, Lincoln Souza	Prevalence of Bad Smells in PL/SQL Projects	10.1109/ICPC.2019.00025	2019	Code Smell can be defined as any feature in the source code of a software that may indicate possible problems. In database languages, the term Bad Smell has been used as a generalization of Code Smell, once some features that are not directly related to code also can indicate problems, such as, for instance, the inappropriate type of an index structure or a SQL query written inefficiently. Bearing in mind the recurrence of different Bad Smell, they were catalogued. Along with these catalogs, tools were developed to automatically identify Bad Smell occurrences in a given code. With the help of these tools, it has become possible to perform quick and effective analysis. In this context, this paper proposes an exploratory study about Bad Smell in PL/SQL codes, from free software projects, published on GitHub. We analyzed 20 open-source PL/SQL projects and empirically study the prevalence of bad smells. Our results showed that some smells occur together. Besides, some smells are more frequent than others. Based on this principle, this paper has the potential to aid professionals from the databases area to avoid future problems during the development of a PL/SQL project.	https://doi.org/10.1109/ICPC.2019.00025
408	Sahal, Emre and Tosun, Ayse	Identifying Bug-Inducing Changes for Code Additions	10.1145/3239235.3267440	2018	Background. SZZ algorithm has been popularly used to identify bug-inducing changes in version history. It is still limited to link a fixing change to an inducing one, when the fix constitutes of code additions only. Goal. We improve the original SZZ by proposing a way to link the code additions in a fixing change to a list of candidate inducing changes. Method. The improved version, A-SZZ, finds the code block encapsulating the new code added in a fixing change, and traces back to the historical changes of the code block. We mined the GitHub repositories of two projects, Angular.js and Vue, and ran A-SZZ to identify bug-inducing changes of code additions. We evaluated the effectiveness of A-SZZ in terms of inducing and fixing ratios, and time span between the two changes. Results. The approach works well for linking code additions with previous changes, although it still produces many false positives. Conclusions. Nearly a quarter of the files in fixing changes contain code additions only, and hence, new heuristics should be implemented to link those with inducing changes in a more efficient way.	https://doi.org/10.1145/3239235.3267440
409	Phan, Hung and Jannesari, Ali	Statistical Machine Translation Outperforms Neural Machine Translation in Software Engineering: Why and How	10.1145/3416506.3423576	2020	Neural Machine Translation (NMT) is the current trend approach in Natural Language Processing (NLP) to solve the problem of auto- matically inferring the content of target language given the source language. The ability of NMT is to learn deep knowledge inside lan- guages by deep learning approaches. However, prior works show that NMT has its own drawbacks in NLP and in some research problems of Software Engineering (SE). In this work, we provide a hypothesis that SE corpus has inherent characteristics that NMT will confront challenges compared to the state-of-the-art translation engine based on Statistical Machine Translation. We introduce a problem which is significant in SE and has characteristics that challenges the abil- ity of NMT to learn correct sequences, called Prefix Mapping. We implement and optimize the original SMT and NMT to mitigate those challenges. By the evaluation, we show that SMT outperforms NMT for this research problem, which provides potential directions to optimize the current NMT engines for specific classes of parallel corpus. By achieving the accuracy from 65% to 90% for code tokens generation of 1000 Github code corpus, we show the potential of using MT for code completion at token level.	https://doi.org/10.1145/3416506.3423576
411	Allamanis, Miltiadis and Sutton, Charles	Mining Idioms from Source Code	10.1145/2635868.2635901	2014	We present the first method for automatically mining code idioms from a corpus of previously written, idiomatic software projects. We take the view that a code idiom is a syntactic fragment that recurs across projects and has a single semantic purpose. Idioms may have metavariables, such as the body of a for loop. Modern IDEs commonly provide facilities for manually defining idioms and inserting them on demand, but this does not help programmers to write idiomatic code in languages or using libraries with which they are unfamiliar. We present Haggis, a system for mining code idioms that builds on recent advanced techniques from statistical natural language processing, namely, nonparametric Bayesian probabilistic tree substitution grammars. We apply Haggis to several of the most popular open source projects from GitHub. We present a wide range of evidence that the resulting idioms are semantically meaningful, demonstrating that they do indeed recur across software projects and that they occur more frequently in illustrative code examples collected from a Q&amp;A site. Manual examination of the most common idioms indicate that they describe important program concepts, including object creation, exception handling, and resource management. 	https://doi.org/10.1145/2635868.2635901
412	Ahmed, Iftekhar and Gopinath, Rahul and Brindescu, Caius and Groce, Alex and Jensen, Carlos	Can Testedness Be Effectively Measured?	10.1145/2950290.2950324	2016	Among the major questions that a practicing tester faces are deciding where to focus additional testing effort, and deciding when to stop testing. Test the least-tested code, and stop when all code is well-tested, is a reasonable answer. Many measures of "testedness" have been proposed; unfortunately, we do not know whether these are truly effective. In this paper we propose a novel evaluation of two of the most important and widely-used measures of test suite quality. The first measure is statement coverage, the simplest and best-known code coverage measure. The second measure is mutation score, a supposedly more powerful, though expensive, measure.  We evaluate these measures using the actual criteria of interest: if a program element is (by these measures) well tested at a given point in time, it should require fewer future bug-fixes than a "poorly tested" element. If not, then it seems likely that we are not effectively measuring testedness. Using a large number of open source Java programs from Github and Apache, we show that both statement coverage and mutation score have only a weak negative correlation with bug-fixes. Despite the lack of strong correlation, there are statistically and practically significant differences between program elements for various binary criteria. Program elements (other than classes) covered by any test case see about half as many bug-fixes as those not covered, and a similar line can be drawn for mutation score thresholds. Our results have important implications for both software engineering practice and research evaluation. 	https://doi.org/10.1145/2950290.2950324
413	Bart, Austin Cory and Kafura, Dennis	BlockPy Interactive Demo: Dual Text/Block Python Programming Environment for Guided Practice and Data Science (Abstract Only)	10.1145/3017680.3022383	2017	Introductory non-major learners face the challenge of mastering programming fundamentals while remaining sufficiently motivated to engage with the computing discipline. In particular, multi-disciplinary students struggle to find relevance in traditional computing curricula that tend to either emphasize abstract concepts, focus on entertainment (e.g., game and animation design), or rely on decontextualized settings. To address these issues, this demo introduces BlockPy, a web-based environment for Python (https://blockpy.com). The most powerful feature of BlockPy is a dual text/block view that beginners can freely move between, using advanced Mutual Language Translation techniques. The environment contextualizes introductory programming with data science by integrating real-world data including weather reports, classic book statistics, and historical crime data. A fusion of Blockly and Skulpt, the entire interface runs locally with no need for server sandboxing. BlockPy is also a platform for interactive, guided practice problems with automatic feedback that scaffolds learners. This demo will walk through the novel features of BlockPy's environment, including the instructor's perspective of creating new problems and how BlockPy can be embedded in modern LTI-compatible learning management systems. BlockPy is available online for free and is open-sourced on GitHub. This material is based on work supported by the NSF under Grants No. DGE-0822220, DUE-1444094, and DUE-1624320.	https://doi.org/10.1145/3017680.3022383
414	Ferenc, Rudolf and Hegedundefineds, P\\'eter and Gyimesi, P\\'eter and Antal, G\\'abor and B\\'an, D\\'enes and Gyim\\'othy, Tibor	Challenging Machine Learning Algorithms in Predicting Vulnerable JavaScript Functions	10.1109/RAISE.2019.00010	2019	The rapid rise of cyber-crime activities and the growing number of devices threatened by them place software security issues in the spotlight. As around 90% of all attacks exploit known types of security issues, finding vulnerable components and applying existing mitigation techniques is a viable practical approach for fighting against cyber-crime. In this paper, we investigate how the state-of-the-art machine learning techniques, including a popular deep learning algorithm, perform in predicting functions with possible security vulnerabilities in JavaScript programs.We applied 8 machine learning algorithms to build prediction models using a new dataset constructed for this research from the vulnerability information in public databases of the Node Security Project and the Snyk platform, and code fixing patches from GitHub. We used static source code metrics as predictors and an extensive grid-search algorithm to find the best performing models. We also examined the effect of various re-sampling strategies to handle the imbalanced nature of the dataset.The best performing algorithm was KNN, which created a model for the prediction of vulnerable functions with an F-measure of 0.76 (0.91 precision and 0.66 recall). Moreover, deep learning, tree and forest based classifiers, and SVM were competitive with F-measures over 0.70. Although the F-measures did not vary significantly with the re-sampling strategies, the distribution of precision and recall did change. No re-sampling seemed to produce models preferring high precision, while resampling strategies balanced the IR measures.	https://doi.org/10.1109/RAISE.2019.00010
596	Constantino, Kattiana and Zhou, Shurui and Souza, Mauricio and Figueiredo, Eduardo and K\\"astner, Christian	Understanding Collaborative Software Development: An Interview Study	10.1145/3372787.3390442	2020	In globally distributed software development, many software developers have to collaborate and deal with issues of collaboration. Although collaboration is challenging, collaborative development produces better software than any developer could produce alone. Unlike previous work which focuses on the proposal and evaluation of models and tools to support collaborative work, this paper presents an interview study aiming to understand (i) the motivations, (ii) how collaboration happens, and (iii) the challenges and barriers of collaborative software development. After interviewing twelve experienced software developers from GitHub, we found different types of collaborative contributions, such as in the management of requests for changes. Our analysis also indicates that the main barriers for collaboration are related to non-technical, rather than technical issues.	https://doi.org/10.1145/3372787.3390442
415	Tabassum, Sadia and Minku, Leandro L. and Feng, Danyi and Cabral, George G. and Song, Liyan	An Investigation of Cross-Project Learning in Online Just-in-Time Software Defect Prediction	10.1145/3377811.3380403	2020	Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers. Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project. Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data. However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers. It is unknown to what extent CP data can be helpful in such situation. In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time. This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario. For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time. We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years. The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects. For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods. Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.	https://doi.org/10.1145/3377811.3380403
416	Kirton, Travis	C4: Creative Coding for IOS	10.1145/2460625.2460716	2013	C4 is a new creative coding framework that focuses on interactivity, visualization and the relationship between various media. Designed for iOS, C4 makes it extremely easy to create apps for iPad, iPhone and iPod devices. Initially developed as a platform for quickly creating interactive artistic works, C4 is developing into a more broad-based language for other areas such as music and data visualization.In this workshop, participants will rapidly prototype interactive animated interfaces on iOS devices. Participants will have the opportunity to learn how to easily create dynamic animations, using all kinds of media including audio, video, shapes, OpenGL objects and more. In addition to this, participants will learn how to easily add the full suite of iOS gestural interaction to their applications and objects. Furthermore, C4 provides easy access to the camera, as well as access to the compass, motion, acceleration, proximity and light sensors. Along the way, participants will be introduced to the larger C4 community through their participation on various social networks, the Stackoverflow community-moderated Q&amp;A forum, and will also be shown how to access and share code on Github.	https://doi.org/10.1145/2460625.2460716
417	Yan, Cong and He, Yeye	Synthesizing Type-Detection Logic for Rich Semantic Data Types Using Open-Source Code	10.1145/3183713.3196888	2018	Given a table of data, existing systems can often detect basic atomic types (e.g., strings vs. numbers) for each column. A new generation of data-analytics and data-preparation systems are starting to automatically recognize rich semantic types such as date-time, email address, etc., for such metadata can bring an array of benefits including better table understanding, improved search relevance, precise data validation, and semantic data transformation. However, existing approaches only detect a limited number of types using regular-expression-like patterns, which are often inaccurate, and cannot handle rich semantic types such as credit card and ISBN numbers that encode semantic validations (e.g., checksum).We developed AUTOTYPE from open-source repositories like GitHub. Users only need to provide a set of positive examples for a target data type and a search keyword, our system will automatically identify relevant code, and synthesize type-detection functions using execution traces. We compiled a benchmark with 112 semantic types, out of which the proposed system can synthesize code to detect 84 such types at a high precision. Applying the synthesized type-detection logic on web table columns have also resulted in a significant increase in data types discovered compared to alternative approaches.	https://doi.org/10.1145/3183713.3196888
418	Tushev, Miroslav and Mahmoud, Anas	Linguistic Documentation of Software History	10.1145/3387904.3389288	2020	Open Source Software (OSS) projects start with an initial vocabulary, often determined by the first generation of developers. This vocabulary, embedded in code identifier names and internal code comments, goes through multiple rounds of change, influenced by the interrelated patterns of human (e.g., developers joining and departing) and system (e.g., maintenance activities) interactions. Capturing the dynamics of this change is crucial for understanding and synthesizing code changes over time. However, existing code evolution analysis tools, available in modern version control systems such as GitHub and SourceForge, often overlook the linguistic aspects of code evolution. To bridge this gap, in this paper, we propose to study code evolution in OSS projects through the lens of developers' language, also known as code lexicon. Our analysis is conducted using 32 OSS projects sampled from a broad range of application domains. Our results show that different maintenance activities impact code lexicon differently. These insights lay out a preliminary foundation for modeling the linguistic history of OSS projects. In the long run, this foundation will be utilized to provide support for basic program comprehension tasks and help researchers gain new insights into the complex interplay between linguistic change and various system and human aspects of OSS development.	https://doi.org/10.1145/3387904.3389288
419	Waller, Isaac and Anderson, Ashton	Generalists and Specialists: Using Community Embeddings to Quantify Activity Diversity in Online Platforms	10.1145/3308558.3313729	2019	In many online platforms, people must choose how broadly to allocate their energy. Should one concentrate on a narrow area of focus, and become a specialist, or apply oneself more broadly, and become a generalist? In this work, we propose a principled measure of how generalist or specialist a user is, and study behavior in online platforms through this lens. To do this, we construct highly accurate community embeddings that represent communities in a high-dimensional space. We develop sets of community analogies and use them to optimize our embeddings so that they encode community relationships extremely well. Based on these embeddings, we introduce a natural measure of activity diversity, the GS-score. Applying our embedding-based measure to online platforms, we observe a broad spectrum of user activity styles, from extreme specialists to extreme generalists, in both community membership on Reddit and programming contributions on GitHub. We find that activity diversity is related to many important phenomena of user behavior. For example, specialists are much more likely to stay in communities they contribute to, but generalists are much more likely to remain on platforms as a whole. We also find that generalists engage with significantly more diverse sets of users than specialists do. Furthermore, our methodology leads to a simple algorithm for community recommendation, matching state-of-the-art methods like collaborative filtering. Our methods and results introduce an important new dimension of online user behavior and shed light on many aspects of online platform use.	https://doi.org/10.1145/3308558.3313729
420	Griffith, Isaac and Izurieta, Clemente and Huvaere, Chris	An Industry Perspective to Comparing the SQALE and Quamoco Software Quality Models	10.1109/ESEM.2017.42	2017	Context: We investigate the different perceptions of quality provided by leading operational quality models when used to evaluate software systems from an industry perspective. Goal: To compare and evaluate the quality assessments of two competing quality models and to develop an extensible solution to meet the quality assurance measurement needs of an industry stakeholder -The Construction Engineering Research Laboratory (CERL). Method: In cooperation with our industry partner TechLink, we operationalize the Quamoco quality model and employ a multiple case study design comparing the results of Quamoco and SQALE, two implementations of well known quality models. The study is conducted across current versions of several open source software projects sampled from GitHub and commercial software for sustainment management systems implemented in the C# language from our industry partner. Each project represents a separate embedded unit of study in a given context -open source or commercial. We employ inter-rater agreement and correlation analysis to compare the results of both models, focusing on Maintainability, Reliability, and Security assessments. Results: Our observations suggest that there is a significant disconnect between the assessments of quality under both quality models. Conclusion: In order to support industry adoption, additional work is required to bring competing implementations of quality models into alignment. This exploratory case study helps us shed light into this problem.	https://doi.org/10.1109/ESEM.2017.42
421	Beller, Moritz	Toward an Empirical Theory of Feedback-Driven Development	10.1145/3183440.3190332	2018	Software developers today crave for feedback, be it from their peers or even bots in the form of code review, static analysis tools like their compiler, or the local or remote execution of their tests in the Continuous Integration (CI) environment. With the advent of social coding sites like GitHub and tight integration of CI services like Travis CI, software development practices have fundamentally changed. Despite a highly changed software engineering landscape, however, we still lack a suitable description of an individual's contemporary software development practices, that is how an individual code contribution comes to be. Existing descriptions like the v-model are either too coarse-grained to describe an individual contributor's workflow, or only regard a sub-part of the development process like Test-Driven Development. In addition, most existing models are pre- rather than de-scriptive. By contrast, in our thesis, we perform a series of empirical studies to describe the individual constituents of Feedback-Driven Development (FDD) and then compile the evidence into an initial framework on how modern software development works. Our thesis culminates in the finding that feedback loops are the characterizing criterion of contemporary software development. Our model is flexible enough to accommodate a broad bandwidth of contemporary workflows, despite large variances in how projects use and configure parts of FDD.	https://doi.org/10.1145/3183440.3190332
422	Chen, Guanliang and Davis, Dan and Lin, Jun and Hauff, Claudia and Houben, Geert-Jan	Beyond the MOOC Platform: Gaining Insights about Learners from the Social Web	10.1145/2908131.2908145	2016	Massive Open Online Courses (MOOCs) have enabled millions of learners across the globe to increase their levels of expertise in a wide variety of subjects. Research efforts surrounding MOOCs are typically focused on improving the learning experience, as the current retention rates (less than 7% of registered learners complete a MOOC) show a large gap between vision and reality in MOOC learning.Current data-driven approaches to MOOC adaptations rely on data traces learners generate within a MOOC platform such as edX or Coursera. As a MOOC typically lasts between five and eight weeks and with many MOOC learners being rather passive consumers of the learning material, this exclusive use of MOOC platform data traces limits the insights that can be gained from them.The Social Web potentially offers a rich source of data to supplement the MOOC platform data traces, as many learners are also likely to be active on one or more Social Web platforms. In this work, we present a first exploratory analysis of the Social Web platforms MOOC learners are active on --- we consider more than 320,000 learners that registered for 18 MOOCs on the edX platform and explore their user profiles and activities on StackExchange, GitHub, Twitter and LinkedIn.	https://doi.org/10.1145/2908131.2908145
423	Zaveri, Amrapali and Serrano, Pedro Hernandez and Desai, Manisha and Dumontier, Michel	CrowdED: Guideline for Optimal Crowdsourcing Experimental Design	10.1145/3184558.3191543	2018	Crowdsourcing involves the creating of HITs (Human Intelligent Tasks), submitting them to a crowdsourcing platform and providing a monetary reward for each HIT. One of the advantages of using crowdsourcing is that the tasks can be highly parallelized, that is, the work is performed by a high number of workers in a decentralized setting. The design also offers a means to cross-check the accuracy of the answers by assigning each task to more than one person and thus relying on majority consensus as well as reward the workers according to their performance and productivity. Since each worker is paid per task, the costs can significantly increase, irrespective of the overall accuracy of the results. Thus, one important question when designing such crowdsourcing tasks that arise is how many workers to employ and how many tasks to assign to each worker when dealing with large amounts of tasks. That is, the main research questions we aim to answer is: 'Can we a-priori estimate optimal workers and tasks' assignment to obtain maximum accuracy on all tasks'. Thus, we introduce a two-staged statistical guideline, CrowdED, for optimal crowdsourcing experimental design in order to a-priori estimate optimal workers and tasks' assignment to obtain maximum accuracy on all tasks. We describe the algorithm and present preliminary results and discussions. We implement the algorithm in Python and make it openly available on Github, provide a Jupyter Notebook and a R Shiny app for users to re-use, interact and apply in their own crowdsourcing experiments.	https://doi.org/10.1145/3184558.3191543
490	Spinellis, Diomidis and Kotti, Zoe and Mockus, Audris	A Dataset for GitHub Repository Deduplication	10.1145/3379597.3387496	2020	GitHub projects can be easily replicated through the site's fork process or through a Git clone-push sequence. This is a problem for empirical software engineering, because it can lead to skewed results or mistrained machine learning models. We provide a dataset of 10.6 million GitHub projects that are copies of others, and link each record with the project's ultimate parent. The ultimate parents were derived from a ranking along six metrics. The related projects were calculated as the connected components of an 18.2 million node and 12 million edge denoised graph created by directing edges to ultimate parents. The graph was created by filtering out more than 30 hand-picked and 2.3 million pattern-matched clumping projects. Projects that introduced unwanted clumping were identified by repeatedly visualizing shortest path distances between unrelated important projects. Our dataset identified 30 thousand duplicate projects in an existing popular reference dataset of 1.8 million projects. An evaluation of our dataset against another created independently with different methods found a significant overlap, but also differences attributed to the operational definition of what projects are considered as related.	https://doi.org/10.1145/3379597.3387496
424	Kanakis, Georgios and Fischer, Stefan and Khelladi, Djamel Eddine and Egyed, Alexander	Supporting a Flexible Grouping Mechanism for Collaborating Engineering Teams	10.1109/ICGSE.2019.00033	2019	Most engineering tools do not provide much support for collaborating teams and today's engineering knowledge repositories lack flexibility and are limited. Engineering teams have different needs and their team members have different preferences on how and when to collaborate. These needs may depend on the individual work style, the role an engineer has, and the tasks they have to perform within the collaborating group. However, individual collaboration is insufficient and engineers need to collaborate in groups. This work presents a collaboration framework for collaborating groups capable of providing synchronous and asynchronous mode of collaboration. Additionally, our approach enables engineers to mix these collaboration modes to meet the preferences of individual group members. We evaluate the scalability of this framework using four real life large collaboration projects. These projects were found from GitHub and they were under active development by the time of evaluation. We have tested our approach creating groups of different sizes for each project. The results showed that our approach scales to support every case for the groups created. Additionally, we scouted the literature and discovered studies that support the usefulness of different groups with collaboration styles.	https://doi.org/10.1109/ICGSE.2019.00033
425	Eslami, Taban and Awan, Muaaz Gul and Saeed, Fahad	GPU-PCC: A GPU Based Technique to Compute Pairwise Pearson's Correlation Coefficients for Big FMRI Data	10.1145/3107411.3108173	2017	Functional Magnetic Resonance Imaging (fMRI) is a non-invasive brain imaging technique for studying the brain's functional activities. Pearson's Correlation Coefficient is an important measure for capturing dynamic behaviors and functional connectivity between brain components. One bottleneck in computing Correlation Coefficients is the time it takes to process big fMRI data. In this paper, we propose GPU-PCC, a GPU based algorithm based on vector dot product, which is able to compute pairwise Pearson's Correlation Coefficients while performing computation once for each pair. Our method is able to compute Correlation Coefficients in an ordered fashion without the need to do post-processing reordering of coefficients. We evaluated GPU-PCC using synthetic and real fMRI data and compared it with sequential version of computing Correlation Coefficient on CPU and existing state-of-the-art GPU method. We show that our GPU-PCC runs 94.62x faster as compared to the CPU version and 4.28x faster than the existing GPU based technique on a real fMRI dataset of size 90k voxels. The implemented code is available as GPL license on GitHub portal of our lab at https://github.com/pcdslab/GPU-PCC.	https://doi.org/10.1145/3107411.3108173
426	Li, Yue and Nair, Pratheeksha and Wen, Zhi and Chafi, Imane and Okhmatovskaia, Anya and Powell, Guido and Shen, Yannan and Buckeridge, David	Global Surveillance of COVID-19 by Mining News Media Using a Multi-Source Dynamic Embedded Topic Model	10.1145/3388440.3412418	2020	As the COVID-19 pandemic continues to unfold, understanding the global impact of non-pharmacological interventions (NPI) is important for formulating effective intervention strategies, particularly as many countries prepare for future waves. We used a machine learning approach to distill latent topics related to NPI from large-scale international news media. We hypothesize that these topics are informative about the timing and nature of implemented NPI, dependent on the source of the information (e.g., local news versus official government announcements) and the target countries. Given a set of latent topics associated with NPI (e.g., self-quarantine, social distancing, online education, etc), we assume that countries and media sources have different prior distributions over these topics, which are sampled to generate the news articles. To model the source-specific topic priors, we developed a semi-supervised, multi-source, dynamic, embedded topic model. Our model is able to simultaneously infer latent topics and learn a linear classifier to predict NPI labels using the topic mixtures as input for each news article. To learn these models, we developed an efficient end-to-end amortized variational inference algorithm. We applied our models to news data collected and labelled by the World Health Organization (WHO) and the Global Public Health Intelligence Network (GPHIN). Through comprehensive experiments, we observed superior topic quality and intervention prediction accuracy, compared to the baseline embedded topic models, which ignore information on media source and intervention labels. The inferred latent topics reveal distinct policies and media framing in different countries and media sources, and also characterize reaction to COVID-19 and NPI in a semantically meaningful manner. Our PyTorch code is available on Github (htps://github.com/li-lab-mcgill/covid19_media).	https://doi.org/10.1145/3388440.3412418
427	Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun	Large-Scale and Language-Oblivious Code Authorship Identification	10.1145/3243734.3243738	2018	Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96% when experimenting with 1,600 authors for GCJ, and 94.38% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42% for a set of 120 authors.	https://doi.org/10.1145/3243734.3243738
428	Omran, Fouad Nasser A Al and Treude, Christoph	Choosing an NLP Library for Analyzing Software Documentation: A Systematic Literature Review and a Series of Experiments	10.1109/MSR.2017.42	2017	To uncover interesting and actionable information from natural language documents authored by software developers, many researchers rely on "out-of-the-box" NLP libraries. However, software artifacts written in natural language are different from other textual documents due to the technical language used. In this paper, we first analyze the state of the art through a systematic literature review in which we find that only a small minority of papers justify their choice of an NLP library. We then report on a series of experiments in which we applied four state-of-the-art NLP libraries to publicly available software artifacts from three different sources. Our results show low agreement between different libraries (only between 60% and 71% of tokens were assigned the same part-of-speech tag by all four libraries) as well as differences in accuracy depending on source: For example, spaCy achieved the best accuracy on Stack Overflow data with nearly 90% of tokens tagged correctly, while it was clearly outperformed by Google's SyntaxNet when parsing GitHub ReadMe files. Our work implies that researchers should make an informed decision about the particular NLP library they choose and that customizations to libraries might be necessary to achieve good results when analyzing software artifacts written in natural language.	https://doi.org/10.1109/MSR.2017.42
429	Thung, Ferdian and Le, Tien-Duy B. and Kochhar, Pavneet Singh and Lo, David	BugLocalizer: Integrated Tool Support for Bug Localization	10.1145/2635868.2661678	2014	To manage bugs that appear in a software, developers often make use of a bug tracking system such as Bugzilla. Users can report bugs that they encounter in such a system. Whenever a user reports a new bug report, developers need to read the summary and description of the bug report and manually locate the buggy files based on this information. This manual process is often time consuming and tedious. Thus, a number of past studies have proposed bug localization techniques to automatically recover potentially buggy files from bug reports. Unfortunately, none of these techniques are integrated to bug tracking systems and thus it hinders their adoption by practitioners. To help disseminate research in bug localization to practitioners, we develop a tool named BugLocalizer, which is implemented as a Bugzilla extension and builds upon a recently proposed bug localization technique. Our tool extracts texts from summary and description fields of a bug report and source code files. It then computes similarities of the bug report with source code files to find the buggy files. Developers can use our tool online from a Bugzilla web interface by providing a link to a git source code repository and specifying the version of the repository to be analyzed. We have released our tool publicly in GitHub, which is available at: https://github.com/smagsmu/buglocalizer. We have also provided a demo video, which can be accessed at: http://youtu.be/iWHaLNCUjBY. 	https://doi.org/10.1145/2635868.2661678
430	Tward, Daniel and Kolasny, Anthony and Khan, Fatima and Troncoso, Juan and Miller, Michael	Expanding the Computational Anatomy Gateway from Clinical Imaging to Basic Neuroscience Research	10.1145/3332186.3332217	2019	The Computational Anatomy Gateway, powered largely by the Comet (San Diego Super-computer Center) and Stampede (Texas Advanced Computing Center) clusters through XSEDE, provides software as a service tools for atlas based analysis of human brain magnetic resonance images. This includes deformable registration, automatic labeling of tissue types, and morphometric analysis. Our goal is to extend these services to the broader neuroscience community, accommodating multiple model organisms and imaging modalities, as well as low quality or missing data. We developed a new approach to multimodality registration: by predicting one modality from another, we can replace ad hoc image similarity metrics (such as mutual information or normalized cross correlation) with a log likelihood under a noise model. This statistical approach enables us to account for missing data using the Expectation Maximization algorithm. For portability and scalability we have implemented this algorithm in tensorflow. For accessibility we have compiled and many working examples for multiple model organisms, imaging systems, and missing tissue or image anomaly situations. These examples are made easily usable in the form of Jupyter notebooks, and made publicly available through github. This framework will significantly reduce the barrier to entry for basic neuroscientists, enabling the community to benefit from atlas based computational image analysis techniques.	https://doi.org/10.1145/3332186.3332217
431	Chibotaru, Victor and Bichsel, Benjamin and Raychev, Veselin and Vechev, Martin	Scalable Taint Specification Inference with Big Code	10.1145/3314221.3314648	2019	We present a new scalable, semi-supervised method for inferring taint analysis specifications by learning from a large dataset of programs. Taint specifications capture the role of library APIs (source, sink, sanitizer) and are a critical ingredient of any taint analyzer that aims to detect security violations based on information flow. The core idea of our method is to formulate the taint specification learning problem as a linear optimization task over a large set of information flow constraints. The resulting constraint system can then be efficiently solved with state-of-the-art solvers. Thanks to its scalability, our method can infer many new and interesting taint specifications by simultaneously learning from a large dataset of programs (e.g., as found on GitHub), while requiring few manual annotations. We implemented our method in an end-to-end system, called Seldon, targeting Python, a language where static specification inference is particularly hard due to lack of typing information. We show that Seldon is practically effective: it learned almost 7,000 API roles from over 210,000 candidate APIs with very little supervision (less than 300 annotations) and with high estimated precision (67%). Further, using the learned specifications, our taint analyzer flagged more than 20,000 violations in open source projects, 97% of which were undetectable without the inferred specifications.	https://doi.org/10.1145/3314221.3314648
432	Rahman, Md Mahmudur and Paudel, Roshan and Sharker, Monir H	Effects of Infusing Interactive and Collaborative Learning to Teach an Introductory Programming Course	10.1109/FIE43999.2019.9028657	2019	This Innovate Practice Full Paper presents positive effects in teaching an introductory programming course in Python by infusing both interactive and collaborative learning. For a dynamic classroom, we used an interactive computer programming environment, Repl.it, as a top-level shell and created several in-class exercises, assignments, small lab-based projects. In addition, we used an eBook, which offers an animation and software visualization tool where students can step through code line-by-line and a program editing and execution area where students can execute examples, change them, and execute the updated code. We also introduced collaborative learning at the beginning of this introductory programming course in the form of doing team projects submitted at the end of the semester. The students were instructed to commit code to GitHub which ensures that their work will not be lost as well as, provide them basic task management tools to collaborate. The proposed pedagogical approaches were applied in the Fall’2017 semester to teach an introductory CS course in Python. The traditional course instruction that has historically been used in the department are used as the control group. For evaluation and result analysis, thirteen sections of COSC 111 were included in this study over three semesters: Fall 2014, Fall 2016 and Fall 2017. The initial evaluation of summative assessment and analysis of the survey results enable us to conclude that the proposed instructional approach increased student motivation and engagement, facilitated learning, and contributed to the progress of students in this course as well as reduced the failure rates.	https://doi.org/10.1109/FIE43999.2019.9028657
597	Ring, Dan and Barbier, Johanna and Gales, Guillaume and Kent, Ben and Lutz, Sebastian	Jumping in at the Deep End: How to Experiment with Machine Learning in Post-Production Software	10.1145/3329715.3338880	2019	Recent years has seen an explosion in Machine Learning (ML) research. The challenge is now to transfer these new algorithms into the hands of artists and TD's in visual effects and animation studios, so that they can start experimenting with ML within their existing pipelines. This paper presents some of the current challenges to experimentation and deployment of ML frameworks in the post-production industry. It introduces our open-source "ML-Server" client / server system as an answer to enabling rapid prototyping, experimentation and development of ML models in post-production software. Data, code and examples for the system can be found on the GitHub repository page:https://github.com/TheFoundryVisionmongers/nuke-ML-server	https://doi.org/10.1145/3329715.3338880
433	Gu, Xiaodong and Zhang, Hongyu and Kim, Sunghun	Deep Code Search	10.1145/3180155.3180167	2018	To implement a program functionality, developers can reuse previously written code snippets by searching through a large-scale codebase. Over the years, many code search tools have been proposed to help developers. The existing approaches often treat source code as textual documents and utilize information retrieval models to retrieve relevant code snippets that match a given query. These approaches mainly rely on the textual similarity between source code and natural language query. They lack a deep understanding of the semantics of queries and source code.In this paper, we propose a novel deep neural network named CODEnn (Code-Description Embedding Neural Network). Instead of matching text similarity, CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space, in such a way that code snippet and its corresponding description have similar vectors. Using the unified vector representation, code snippets related to a natural language query can be retrieved according to their vectors. Semantically related words can also be recognized and irrelevant/noisy keywords in queries can be handled.As a proof-of-concept application, we implement a code search tool named DeepCS using the proposed CODEnn model. We empirically evaluate DeepCS on a large scale codebase collected from GitHub. The experimental results show that our approach can effectively retrieve relevant code snippets and outperforms previous techniques.	https://doi.org/10.1145/3180155.3180167
434	Maldeniya, Danaja and Budak, Ceren and Robert Jr., Lionel P. and Romero, Daniel M.	Herding a Deluge of Good Samaritans: How GitHub Projects Respond to Increased Attention	10.1145/3366423.3380272	2020	Collaborative crowdsourcing is a well-established model of work, especially in the case of open source software development. The structure and operation of these virtual and loosely-knit teams differ from traditional organizations. As such, little is known about how their behavior may change in response to an increase in external attention. To understand these dynamics, we analyze millions of actions of thousands of contributors in over 1100 open source software projects that topped the GitHub Trending Projects page and thus experienced a large increase in attention, in comparison to a control group of projects identified through propensity score matching. In carrying out our research, we use the lens of organizational change, which considers the challenges teams face during rapid growth and how they adapt their work routines, organizational structure, and management style. We show that trending results in an explosive growth in the effective team size. However, most newcomers make only shallow and transient contributions. In response, the original team transitions towards administrative roles, responding to requests and reviewing work done by newcomers. Projects evolve towards a more distributed coordination model with newcomers becoming more central, albeit in limited ways. Additionally, teams become more modular with subgroups specializing in different aspects of the project. We discuss broader implications for collaborative crowdsourcing teams that face attention shocks. 	https://doi.org/10.1145/3366423.3380272
435	Arya, Deeksha and Wang, Wenting and Guo, Jin L. C. and Cheng, Jinghui	Analysis and Detection of Information Types of Open Source Software Issue Discussions	10.1109/ICSE.2019.00058	2019	Most modern Issue Tracking Systems (ITSs) for open source software (OSS) projects allow users to add comments to issues. Over time, these comments accumulate into discussion threads embedded with rich information about the software project, which can potentially satisfy the diverse needs of OSS stakeholders. However, discovering and retrieving relevant information from the discussion threads is a challenging task, especially when the discussions are lengthy and the number of issues in ITSs are vast. In this paper, we address this challenge by identifying the information types presented in OSS issue discussions. Through qualitative content analysis of 15 complex issue threads across three projects hosted on GitHub, we uncovered 16 information types and created a labeled corpus containing 4656 sentences. Our investigation of supervised, automated classification techniques indicated that, when prior knowledge about the issue is available, Random Forest can effectively detect most sentence types using conversational features such as the sentence length and its position. When classifying sentences from new issues, Logistic Regression can yield satisfactory performance using textual features for certain information types, while falling short on others. Our work represents a nontrivial first step towards tools and techniques for identifying and obtaining the rich information recorded in the ITSs to support various software engineering activities and to satisfy the diverse needs of OSS stakeholders.	https://doi.org/10.1109/ICSE.2019.00058
436	Oliveira, Johnatan and Viggiato, Markos and Figueiredo, Eduardo	How Well Do You Know This Library? Mining Experts from Source Code Analysis	10.1145/3364641.3364648	2019	Third-party libraries have been widely adopted in modern software projects due to several benefits, such as code reuse and software quality. Software development is increasingly complex and requires specialists with knowledge in several technologies, such as the nowadays libraries. Such complexity turns it extremely challenging to deliver quality software given the time pressure. For this purpose, it is necessary to identify and hire qualified developers, to obtain a good team, both in open source and proprietary systems. For these reasons, enterprise and open source projects try to build teams composed of highly skilled developers in specific libraries. Developers with expertise in specific libraries may reduce the time spent on software development tasks and improve the quality of the final product. However, their identification may not be trivial. In this paper, we first argue that source code activities can be used to identify library experts. We then evaluate a mining-based strategy to identify library experts. To achieve our goal, we selected the 9 most popular Java libraries and identified the top-10 experts in each library by analyzing commits in 16,703 Java projects on GitHub. We validated the results by applying a survey with 137 library expert candidates and observed, on average, 88% of precision for the applied strategy.	https://doi.org/10.1145/3364641.3364648
497	Yu, Yue and Wang, Huaimin and Yin, Gang and Ling, Charles X.	Reviewer Recommender of Pull-Requests in GitHub	10.1109/ICSME.2014.107	2014	Pull-Request (PR) is the primary method for code contributions from thousands of developers in GitHub. To maintain the quality of software projects, PR review is an essential part of distributed software development. Assigning new PRs to appropriate reviewers will make the review process more effective which can reduce the time between the submission of a PR and the actual review of it. However, reviewer assignment is now organized manually in GitHub. To reduce this cost, we propose a reviewer recommender to predict highly relevant reviewers of incoming PRs. Combining information retrieval with social network analyzing, our approach takes full advantage of the textual semantic of PRs and the social relations of developers. We implement an online system to show how the reviewer recommender helps project managers to find potential reviewers from crowds. Our approach can reach a precision of 74% for top-1 recommendation, and a recall of 71% for top-10 recommendation.	https://doi.org/10.1109/ICSME.2014.107
437	Kim, William and Chung, Sam and Endicott-Popovsky, Barbara	Software Architecture Model Driven Reverse Engineering Approach to Open Source Software Development	10.1145/2656434.2656440	2014	Popular Open Source Software (OSS) development platforms like GitHub, Google Code, and Bitbucket take advantage of some best practices of traditional software development like version control and issue tracking. Current major open source software environments, including IDE tools and online code repositories, do not provide support for visual architecture modeling. Research has shown that visual modeling of complex software projects has benefits throughout the software lifecycle. Then why is it that software architecture modeling is so conspicuously missing from popular online open source code repositories? How can including visual documentation improve the overall quality of open source software projects? Our goal is to answer both of these questions and bridge the gap between traditional software engineering best practices and open source development by applying a software architecture documentation methodology using Unified Modeling Language, called 5W1H Re-Doc, on a real open source project for managing identity and access, MITREid Connect. We analyze the effect of a model-driven software engineering approach on collaboration of open source contributors, quality of specification conformance, and state-of-the-art of architecture modeling. Our informal experiment revealed that in some cases, having the visual documentation can significantly increase comprehension of an online OSS project over having only the textual information that currently exists for that project.	https://doi.org/10.1145/2656434.2656440
438	Mahajan, Sonal and Abolhassani, Negarsadat and Prasad, Mukul R.	Recommending Stack Overflow Posts for Fixing Runtime Exceptions Using Failure Scenario Matching	10.1145/3368089.3409764	2020	Using online Q&amp;A forums, such as Stack Overflow (SO), for guidance to resolve program bugs, among other development issues, is commonplace in modern software development practice. Runtime exceptions (RE) is one such important class of bugs that is actively discussed on SO. In this work we present a technique and prototype tool called MAESTRO that can automatically recommend an SO post that is most relevant to a given Java RE in a developer's code. MAESTRO compares the exception-generating program scenario in the developer's code with that discussed in an SO post and returns the post with the closest match. To extract and compare the exception scenario effectively, MAESTRO first uses the answer code snippets in a post to implicate a subset of lines in the post's question code snippet as responsible for the exception and then compares these lines with the developer's code in terms of their respective Abstract Program Graph (APG) representations. The APG is a simplified and abstracted derivative of an abstract syntax tree, proposed in this work, that allows an effective comparison of the functionality embodied in the high-level program structure, while discarding many of the low-level syntactic or semantic differences. We evaluate MAESTRO on a benchmark of 78 instances of Java REs extracted from the top 500 Java projects on GitHub and show that MAESTRO can return either a highly relevant or somewhat relevant SO post corresponding to the exception instance in 71% of the cases, compared to relevant posts returned in only 8% - 44% instances, by four competitor tools based on state-of-the-art techniques. We also conduct a user experience study of MAESTRO with 10 Java developers, where the participants judge MAESTRO reporting a highly relevant or somewhat relevant post in 80% of the instances. In some cases the post is judged to be even better than the one manually found by the participant.	https://doi.org/10.1145/3368089.3409764
439	Barowy, Daniel W. and Jannen, William K.	Infrastructor: Flexible, No-Infrastructure Tools for Scaling CS	10.1145/3328778.3366905	2020	Demand for computer science education has skyrocketed in the last decade. Although challenging everywhere, scaling up CS course capacities is especially painful at small, liberal arts colleges (SLACs). SLACs tend to have few instructors, few large-capacity classrooms, and little or no dedicated IT support staff. As CS enrollment growth continues to outpace the ability to hire instructional staff, maintaining the quality of the close, nurturing learning environment that SLACs advertise-and students expect-is a major challenge.We present Infrastructor, a workflow and collection of course scaling tools that address the needs of resource-strapped CS departments. Infrastructor removes unnecessary administrative burdens so that instructors can focus on teaching and mentoring students. Unlike a traditional learning management system (LMS), which is complex, monolithic, and usually administered by a campus-wide IT staff, instructors deploy Infrastructor themselves and can trivially tailor the software to suit their own needs. Notably, Infrastructor does not require local hardware resources or platform-specific tools. Instead, Infrastructor is built on top of version control systems. This design choice lets instructors host courses on commodity, cloud-based repositories like GitHub. Since developing Infrastructor two years ago, we have successfully deployed it in ten sections of CS courses (323 students), and over the next year, we plan to more than double its use in our CS program.	https://doi.org/10.1145/3328778.3366905
440	Thompson, Christopher and Wagner, David	A Large-Scale Study of Modern Code Review and Security in Open Source Projects	10.1145/3127005.3127014	2017	Background: Evidence for the relationship between code review process and software security (and software quality) has the potential to help improve code review automation and tools, as well as provide a better understanding of the economics for improving software security and quality. Prior work in this area has primarily been limited to case studies of a small handful of software projects. Aims: We investigate the effect of modern code review on software security. We extend and generalize prior work that has looked at code review and software quality. Method: We gather a very large dataset from GitHub (3,126 projects in 143 languages, with 489,038 issues and 382,771 pull requests), and use a combination of quantification techniques and multiple regression modeling to study the relationship between code review coverage and participation and software quality and security. Results: We find that code review coverage has a significant effect on software security. We confirm prior results that found a relationship between code review coverage and software defects. Most notably, we find evidence of a negative relationship between code review of pull requests and the number of security bugs reported in a project. Conclusions: Our results suggest that implementing code review policies within the pull request model of development may have a positive effect on the quality and security of software.	https://doi.org/10.1145/3127005.3127014
498	Lin, Xuanyi and Simon, Michelle and Niu, Nan	Releasing Scientific Software in GitHub: A Case Study on SWMM2PEST	10.1109/SE4Science.2019.00014	2019	Release engineering involves code development, integration, testing, and software delivery. It has been widely applied to deliver high-quality software to users. While release engineering is a widespread practice in the software industry, there have been very few studies on the release engineering pipeline of scientific software. To shorten this gap, we present a case study in this paper to show a GitHub-driven release workflow on SWMM2PEST, a software system automating parameter calibration for the U.S. EPA's Storm Water Management Model (SWMM). Moreover, we analyze software version updates and requirements changes to develop strategies for improving the ongoing releases. The feasibility of improvement strategies is demonstrated by our consecutively released versions of SWMM2PEST. The results offered insights into the continuous release of scientific software.	https://doi.org/10.1109/SE4Science.2019.00014
441	Campos, Uriel and Smethurst, Guilherme and Moraes, Jo\\~ao Pedro and Bonif\\'acio, Rodrigo and Pinto, Gustavo	Mining Rule Violations in JavaScript Code Snippets	10.1109/MSR.2019.00039	2019	Programming code snippets readily available on platforms such as StackOverflow are undoubtedly useful for software engineers. Unfortunately, these code snippets might contain issues such as deprecated, misused, or even buggy code. These issues could pass unattended, if developers do not have adequate knowledge, time, or tool support to catch them. In this work we expand the understanding of such issues (or the so called "violations") hidden in code snippets written in JavaScript, the programming language with the highest number of questions on StackOverflow. To characterize the violations, we extracted 336k code snippets from answers to JavaScript questions on StackOverflow and statically analyzed them using ESLinter, a JavaScript linter. We discovered that there is no single JavaScript code snippet without a rule violation. On average, our studied code snippets have 11 violations, but we found instances of more than 200 violations. In particular, rules related to stylistic issues are by far the most violated ones (82.9% of the violations pertain to this category). Possible errors, which developers might be more interested in, represent only 0.1% of the violations. Finally, we found a small fraction of code snippets flagged with possible errors being reused on actual GitHub software projects. Indeed, one single code snippet with possible errors was reused 1,261 times.	https://doi.org/10.1109/MSR.2019.00039
442	Cassee, Nathan and Pinto, Gustavo and Castor, Fernando and Serebrenik, Alexander	How Swift Developers Handle Errors	10.1145/3196398.3196428	2018	Swift is a new programming language developed by Apple as a replacement to Objective-C. It features a sophisticated error handling (EH) mechanism that provides the kind of separation of concerns afforded by exception handling mechanisms in other languages, while also including constructs to improve safety and maintainability. However, Swift also inherits a software development culture stemming from Objective-C being the de-facto standard programming language for Apple platforms for the last 15 years. It is, therefore, a priori unclear whether Swift developers embrace the novel EH mechanisms of the programming language or still rely on the old EH culture of Objective-C even working in Swift.In this paper, we study to what extent developers adhere to good practices exemplified by EH guidelines and tutorials, and what are the common bad EH practices particularly relevant to Swift code. Furthermore, we investigate whether perception of these practices differs between novices and experienced Swift developers.To answer these questions we employ a mixed-methods approach and combine 10 semi-structured interviews with Swift developers and quantitative analysis of 78,760 Swift 4 files extracted from 2,733 open-source GitHub repositories. Our findings indicate that there is ample opportunity to improve the way Swift developers use error handling mechanisms. For instance, some recommendations derived in this work are not well spread in the corpus of studied Swift projects. For example, generic catch handlers are common in Swift (even though it is not uncommon for them to share space with their counterparts: non empty catch handlers), custom, developerdefined error types are rare, and developers are mostly reactive when it comes to error handling, using Swift's constructs mostly to handle errors thrown by libraries, instead of throwing and handling application-specific errors.	https://doi.org/10.1145/3196398.3196428
443	Hippe, Kyle and Gbenro, Sola and Cao, Renzhi	ProLanGO2: Protein Function Prediction with Ensemble of Encoder-Decoder Networks	10.1145/3388440.3414701	2020	Predicting protein function from protein sequence is a main challenge in the computational biology field. Traditional methods that search protein sequences against existing databases may not work well in practice, particularly when little or no homology exists in the database. We introduce the ProLanGO2 method which utilizes the natural language processing and machine learning techniques to tackle the protein function prediction problem with protein sequence as input. Our method has been benchmarked blindly in the latest Critical Assessment of protein Function Annotation algorithms (CAFA 4) experiment. There are a few changes compared to the old version of ProLanGO. First of all, the latest version of the UniProt database is used. Second, the Uniprot database is filtered by the newly created fragment sequence database FSD to prepare for the protein sequence language. Third, the Encoder-Decoder network, a model consisting of two RNNs (encoder and decoder), is used to train models on the dataset. Fourth, if no k-mers of a protein sequence exist in the FSD, we select the top ten GO terms with the highest probability in all sequences from the Uniprot database that didn't contain any k-mers in FSD, and use those ten GO terms as back up for the prediction of new protein sequence. Finally, we selected the 100 best performing models and explored all combinations of those models to select the best performance ensemble model. We benchmark those different combinations of models on CAFA 3 dataset and select three top performance ensemble models for prediction in the latest CAFA 4 experiment as CaoLab. We have also evaluated the performance of our ProLanGO2 method on 253 unseen sequences taken from the UniProt database and compared with several other protein function prediction methods, the results show that our method achieves great performance among sequence-based protein function prediction methods. Our method is available in GitHub: https://github.com/caorenzhi/ProLanGO2.git.	https://doi.org/10.1145/3388440.3414701
444	Wilder, Nathan and Smith, Jared M. and Mockus, Audris	Exploring a Framework for Identity and Attribute Linking across Heterogeneous Data Systems	10.1145/2896825.2896833	2016	Online-activity-generated digital traces provide opportunities for novel services and unique insights as demonstrated in, for example, research on mining software repositories. The inability to link these traces within and among systems, such as Twitter, GitHub, or Reddit, inhibit the advances in this area. Furthermore, no single approach to integrate data from these disparate sources is likely to work. We aim to design Foreseer, an extensible framework, to design and evaluate identity matching techniques for public, large, and low-accuracy operational data. Foreseer consists of three functionally independent components designed to address the issues of discovery and preparation, storage and representation, and analysis and linking of traces from disparate online sources. The framework includes a domain specific language for manipulating traces, generating insights, and building novel services. We have applied it in a pilot study of roughly 10TB of data from Twitter, Reddit, and StackExchange including roughly 6M distinct entities and, using basic matching techniques, found roughly 83,000 matches among these sources. We plan to add additional entity extraction and identification algorithms, data from other sources, and design tools for facilitating dynamic ingestion and tagging of incoming data on a more robust infrastructure using Apache Spark or another distributed processing framework. We will then evaluate the utility and effectiveness of the framework in applications ranging from identifying malicious contributors in software repositories to the evaluation of the utility of privacy preservation schemes.	https://doi.org/10.1145/2896825.2896833
489	Vasilescu, Bogdan and Filkov, Vladimir and Serebrenik, Alexander	StackOverflow and GitHub: Associations between Software Development and Crowdsourced Knowledge	10.1109/SocialCom.2013.35	2013	Stack Overflow is a popular on-line programming question and answer community providing its participants with rapid access to knowledge and expertise of their peers, especially benefitting coders. Despite the popularity of Stack Overflow, its role in the work cycle of open-source developers is yet to be understood: on the one hand, participation in it has the potential to increase the knowledge of individual developers thus improving and speeding up the development process. On the other hand, participation in Stack Overflow may interrupt the regular working rhythm of the developer, hence also possibly slow down the development process. In this paper we investigate the interplay between Stack Overflow activities and the development process, reflected by code changes committed to the largest social coding repository, GitHub. Our study shows that active GitHub committers ask fewer questions and provide more answers than others. Moreover, we observe that active Stack Overflow askers distribute their work in a less uniform way than developers that do not ask questions. Finally, we show that despite the interruptions incurred, the Stack Overflow activity rate correlates with the code changing activity in GitHub.	https://doi.org/10.1109/SocialCom.2013.35
445	Alizadeh, Vahid and Ouali, Mohamed Amine and Kessentini, Marouane and Chater, Meriem	RefBot: Intelligent Software Refactoring Bot	10.1109/ASE.2019.00081	2019	The adoption of refactoring techniques for continuous integration received much less attention from the research community comparing to root-canal refactoring to fix the quality issues in the whole system. Several recent empirical studies show that developers, in practice, are applying refactoring incrementally when they are fixing bugs or adding new features. There is an urgent need for refactoring tools that can support continuous integration and some recent development processes such as DevOps that are based on rapid releases. Furthermore, several studies show that manual refactoring is expensive and existing automated refactoring tools are challenging to configure and integrate into the development pipelines with significant disruption cost.In this paper, we propose, for the first time, an intelligent software refactoring bot, called RefBot. Integrated into the version control system (e.g. GitHub), our bot continuously monitors the software repository, and it is triggered by any "open" or "merge" action on pull requests. The bot analyzes the files changed during that pull request to identify refactoring opportunities using a set of quality attributes then it will find the best sequence of refactorings to fix the quality issues if any. The bot recommends all these refactorings through an automatically generated pull-request. The developer can review the recommendations and their impacts in a detailed report and select the code changes that he wants to keep or ignore. After this review, the developer can close and approve the merge of the bot's pull request. We quantitatively and qualitatively evaluated the performance and effectiveness of RefBot by a survey conducted with experienced developers who used the bot on both open source and industry projects.	https://doi.org/10.1109/ASE.2019.00081
446	Pan, Linjie and Cui, Baoquan and Liu, Hao and Yan, Jiwei and Wang, Siqi and Yan, Jun and Zhang, Jian	Static Asynchronous Component Misuse Detection for Android Applications	10.1145/3368089.3409699	2020	Facing the limited resource of smartphones, asynchronous programming significantly improves the performance of Android applications. Android provides several packaged components to ease the development of asynchronous programming. Among them, the AsyncTask component is widely used by developers since it is easy to implement. However, the abuse of AsyncTask component can decrease responsiveness and even lead to crashes. By investigating the Android Developer Documentation and technical forums, we summarize five misuse patterns about AsyncTask. To detect them, we propose a flow, context, object and field-sensitive inter-procedural static analysis approach. Specifically, the static analysis includes typestate analysis, reference analysis and loop analysis. Based on the AsyncTask-related information obtained during static analysis, we check the misuse according to predefined detection rules. The proposed approach is implemented into a tool called AsyncChecker. We evaluate AsyncChecker on a self-designed benchmark suite called AsyncBench and 1,759 real-world apps. AsyncChecker finds 17,946 misused AsyncTask instances in 1,417 real-world apps (80.6%). The precision, recall and F-measure of AsyncChecker on real-world applications are 97.2%, 89.8% and 0.93, respectively. Compared with existing tools, AsyncChecker can detect more asynchronous problems. We report the misuse problems to developers via GitHub. Several developers have confirmed and fixed the problems found by AsyncChecker. The result implies that our approach is effective and developers do take the misuse of AsyncTask as a serious problem.	https://doi.org/10.1145/3368089.3409699
447	Sousa, Leonardo and Cedrim, Diego and Garcia, Alessandro and Oizumi, Willian and Bibiano, Ana C. and Oliveira, Daniel and Kim, Miryung and Oliveira, Anderson	Characterizing and Identifying Composite Refactorings: Concepts, Heuristics and Patterns	10.1145/3379597.3387477	2020	Refactoring consists of a transformation applied to improve the program internal structure, for instance, by contributing to remove code smells. Developers often apply multiple interrelated refactorings called composite refactoring. Even though composite refactoring is a common practice, an investigation from different points of view on how composite refactoring manifests in practice is missing. Previous empirical studies also neglect how different kinds of composite refactorings affect the removal, prevalence or introduction of smells. To address these matters, we provide a conceptual framework and two heuristics to respectively characterize and identify composite refactorings within and across commits. Then, we mined the commit history of 48 GitHub software projects. We identified and analyzed 24,911 composite refactorings involving 104,505 single refactorings. Amongst several findings, we observed that most composite refactorings occur in the same commit and have the same refactoring type. We found that several refactorings are semantically related to each other, which occur in different parts of the system but are still related to the same task. Our study is the first to reveal that many smells are introduced in a program due to "incomplete" composite refactorings. Our study is also the first to reveal 111 patterns of composite refactorings that frequently introduce or remove certain smell types. These patterns can be used as guidelines for developers to improve their refactoring practices as well as for designers of recommender systems.	https://doi.org/10.1145/3379597.3387477
448	Vendome, Christopher and Linares-Vasquez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and German, Daniel M. and Poshyvanyk, Denys	When and Why Developers Adopt and Change Software Licenses	10.1109/ICSM.2015.7332449	2015	Software licenses legally govern the way in which developers can use, modify, and redistribute a particular system. While previous studies either investigated licensing through mining software repositories or studied licensing through FOSS reuse, we aim at understanding the rationale behind developers' decisions for choosing or changing software licensing by surveying open source developers. In this paper, we analyze when developers consider licensing, the reasons why developers pick a license for their project, and the factors that influence licensing changes. Additionally, we explore the licensing-related problems that developers experienced and expectations they have for licensing support from forges (e.g., GitHub). Our investigation involves, on one hand, the analysis of the commit history of 16,221 Java open source projects to identify the commits where licenses were added or changed. On the other hand, it consisted of a survey—in which 138 developers informed their involvement in licensing-related decisions and 52 provided deeper insights about the rationale behind the actions that they had undertaken. The results indicate that developers adopt licenses early in the project's development and change licensing after some period of development (if at all). We also found that developers have inherent biases with respect to software licensing. Additionally, reuse—whether by a non-contributor or for commercial purposes—is a dominant reason why developers change licenses of their systems. Finally, we discuss potential areas of research that could ameliorate the difficulties that software developers are facing with regard to licensing issues of their software systems.	https://doi.org/10.1109/ICSM.2015.7332449
449	Vendome, Christopher and Linares-Vasquez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and German, Daniel M. and Poshyvanyk, Denys	When and Why Developers Adopt and Change Software Licenses	10.1109/ICSM.2015.7332449	2015	Software licenses legally govern the way in which developers can use, modify, and redistribute a particular system. While previous studies either investigated licensing through mining software repositories or studied licensing through FOSS reuse, we aim at understanding the rationale behind developers' decisions for choosing or changing software licensing by surveying open source developers. In this paper, we analyze when developers consider licensing, the reasons why developers pick a license for their project, and the factors that influence licensing changes. Additionally, we explore the licensing-related problems that developers experienced and expectations they have for licensing support from forges (e.g., GitHub). Our investigation involves, on one hand, the analysis of the commit history of 16,221 Java open source projects to identify the commits where licenses were added or changed. On the other hand, it consisted of a survey—in which 138 developers informed their involvement in licensing-related decisions and 52 provided deeper insights about the rationale behind the actions that they had undertaken. The results indicate that developers adopt licenses early in the project's development and change licensing after some period of development (if at all). We also found that developers have inherent biases with respect to software licensing. Additionally, reuse—whether by a non-contributor or for commercial purposes—is a dominant reason why developers change licenses of their systems. Finally, we discuss potential areas of research that could ameliorate the difficulties that software developers are facing with regard to licensing issues of their software systems.	https://doi.org/10.1109/ICSM.2015.7332449
450	Ray, Baishakhi and Posnett, Daryl and Filkov, Vladimir and Devanbu, Premkumar	A Large Scale Study of Programming Languages and Code Quality in Github	10.1145/2635868.2635922	2014	What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study, we gather a very large data set from GitHub (729 projects, 80 Million SLOC, 29,000 authors, 1.5 million commits, in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach, combining multiple regression modeling with visualization and text analytics, to study the effect of language features such as static v.s. dynamic typing, strong v.s. weak typing on software quality. By triangulating findings from different methods, and controlling for confounding effects such as team size, project size, and project history, we report that language design does have a significant, but modest effect on software quality. Most notably, it does appear that strong typing is modestly better than weak typing, and among functional languages, static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size, team size, and commit size. However, we hasten to caution the reader that even these modest effects might quite possibly be due to other, intangible process factors, e.g., the preference of certain personality types for functional, static and strongly typed languages. 	https://doi.org/10.1145/2635868.2635922
451	Guerrero, Alejandro and Fresno, Rafael and Ju, An and Fox, Armando and Fernandez, Pablo and Muller, Carlos and Ruiz-Cort\\'es, Antonio	Eagle: A Team Practices Audit Framework for Agile Software Development	10.1145/3338906.3341181	2019	Agile/XP (Extreme Programming) software teams are expected to follow a number of specific practices in each iteration, such as estimating the effort (”points”) required to complete user stories, properly using branches and pull requests to coordinate merging multiple contributors’ code, having frequent ”standups” to keep all team members in sync, and conducting retrospectives to identify areas of improvement for future iterations. We combine two observations in developing a methodology and tools to help teams monitor their performance on these practices. On the one hand, many Agile practices are increasingly supported by web-based tools whose ”data exhaust” can provide insight into how closely the teams are following the practices. On the other hand, some of the practices can be expressed in terms similar to those developed for expressing service level objectives (SLO) in software as a service; as an example, a typical SLO for an interactive Web site might be ”over any 5-minute window, 99% of requests to the main page must be delivered within 200ms” and, analogously, a potential Team Practice (TP) for an Agile/XP team might be ”over any 2-week iteration, 75% of stories should be ’1-point’ stories”. Following this similarity, we adapt a system originally developed for monitoring and visualizing service level agreement (SLA) compliance to monitor selected TPs for Agile/XP software teams. Specifically, the system consumes and analyzes the data exhaust from widely-used tools such as GitHub and Pivotal Tracker and provides team(s) and coach(es) a ”dashboard” summarizing the teams’ adherence to various practices. As a qualitative initial investigation of its usefulness, we deployed it to twenty student teams in a four-sprint software engineering project course. We find an improvement of the adherence to team practice and a positive students’ self-evaluations of their team practices when using the tool, compared to previous experiences using an Agile/XP methodology. The demo video is located at <a>https://youtu.be/A4xwJMEQh9c</a> and a landing page with a live demo at <a>https://isa-group.github.io/2019-05-eagle-demo/</a>.	https://doi.org/10.1145/3338906.3341181
452	Gao, Yihan and Huang, Silu and Parameswaran, Aditya	Navigating the Data Lake with DATAMARAN: Automatically Extracting Structure from Log Datasets	10.1145/3183713.3183746	2018	Organizations routinely accumulate semi-structured log datasets generated as the output of code; these datasets remain unused and uninterpreted, and occupy wasted space---this phenomenon has been colloquially referred to as "data lake'' problem. One approach to leverage these semi-structured datasets is to convert them into a structured relational format, following which they can be analyzed in conjunction with other datasets. We present DATAMARAN, an tool that extracts structure from semi-structured log datasets with no human supervision. DATAMARAN automatically identifies field and record endpoints, separates the structured parts from the unstructured noise or formatting, and can tease apart multiple structures from within a dataset, in order to efficiently extract structured relational datasets from semi-structured log datasets, at scale with high accuracy. Compared to other unsupervised log dataset extraction tools developed in prior work, DATAMARAN does not require the record boundaries to be known beforehand, making it much more applicable to the noisy log files that are ubiquitous in data lakes. DATAMARAN can successfully extract structured information from all datasets used in prior work, and can achieve 95% extraction accuracy on automatically collected log datasets from GitHub---a substantial 66% increase of accuracy compared to unsupervised schemes from prior work. Our user study further demonstrates that the extraction results of DATAMARAN are closer to the desired structure than competing algorithms.	https://doi.org/10.1145/3183713.3183746
453	Raychev, Veselin and Bielik, Pavol and Vechev, Martin	Probabilistic Model for Code with Decision Trees	10.1145/2983990.2984041	2016	In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).  The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy.  Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy. 	https://doi.org/10.1145/2983990.2984041
454	Raychev, Veselin and Bielik, Pavol and Vechev, Martin	Probabilistic Model for Code with Decision Trees	10.1145/3022671.2984041	2016	In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).  The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy.  Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy. 	https://doi.org/10.1145/3022671.2984041
455	Pellatt, Lloyd and Roggen, Daniel	CausalBatch: Solving Complexity/Performance Tradeoffs for Deep Convolutional and LSTM Networks for Wearable Activity Recognition	10.1145/3410530.3414365	2020	Deep neural networks consisting of a combination of convolutional feature extractor layers and Long Short Term Memory (LSTM) recurrent layers are widely used models for activity recognition from wearable sensors ---referred to as DeepConvLSTM architectures hereafter. However, the subtleties of training these models on sequential time series data is not often discussed in the literature. Continuous sensor data must be segmented into temporal 'windows', and fed through the network to produce a loss which is used to update the parameters of the network. If trained naively using batches of randomly selected data as commonly reported, then the temporal horizon (the maximum delay at which input samples can effect the output of the model) of the network is limited to the length of the window. An alternative approach, which we will call CausalBatch training, is to construct batches deliberately such that each consecutive batch contains windows which are contiguous in time with the windows of the previous batch, with only the first batch in the CausalBatch consisting of randomly selected windows. After a given number of consecutive batches (referred to as the CausalBatch duration τ), the LSTM states are reset, new random starting points are chosen from the dataset and a new CausalBatch is started. This approach allows us to increase the temporal horizon of the network without increasing the window size, which enables networks to learn data dependencies on a longer timescale without increasing computational complexity.We evaluate these two approaches on the Opportunity dataset. We find that using the CausalBatch method we can reduce the training time of DeepConvLSTM by up to 90%, while increasing the user-independent accuracy by up to 6.3% and the class weighted F1 score by up to 5.9% compared to the same model trained by random batch training with the best performing choice of window size for the latter. Compared to the same model trained using the same window length, and therefore the same computational complexity and almost identical training time, we observe an 8.4% increase in accuracy and 14.3% increase in weighted F1 score. We provide the source code for all experiments as well as a Pytorch reference implementation of DeepConvLSTM in a public github repository.	https://doi.org/10.1145/3410530.3414365
456	Li, Boao and Yan, Meng and Xia, Xin and Hu, Xing and Li, Ge and Lo, David	DeepCommenter: A Deep Code Comment Generation Tool with Hybrid Lexical and Syntactical Information	10.1145/3368089.3417926	2020	As the scale of software projects increases, the code comments are more and more important for program comprehension. Unfortunately, many code comments are missing, mismatched or outdated due to tight development schedule or other reasons. Automatic code comment generation is of great help for developers to comprehend source code and reduce their workload. Thus, we propose a code comment generation tool (DeepCommenter) to generate descriptive comments for Java methods. DeepCommenter formulates the comment generation task as a machine translation problem and exploits a deep neural network that combines the lexical and structural information of Java methods. We implement DeepCommenter in the form of an Integrated Development Environment (i.e., Intellij IDEA) plug-in. Such plug-in is built upon a Client/Server architecture. The client formats the code selected by the user, sends request to the server and inserts the comment generated by the server above the selected code. The server listens for client’s request, analyzes the requested code using the pre-trained model and sends back the generated comment to the client. The pre-trained model learns both the lexical and syntactical information from source code tokens and Abstract Syntax Trees (AST) respectively and combines these two types of information together to generate comments. To evaluate DeepCommenter, we conduct experiments on a large corpus built from a large number of open source Java projects on GitHub. The experimental results on different metrics show that DeepCommenter outperforms the state-of-the-art approaches by a substantial margin.	https://doi.org/10.1145/3368089.3417926
511	Vasilescu, Bogdan	Software Developers Are Humans, Too!	10.1145/2556420.2556833	2014	Open-source communities can be seen as knowledge-sharing ecosystems: participants learn from the community and from one another, and share their knowledge through contributions to the source code repositories or by offering support to users. With the emergence and growing popularity of social media sites targeting software developers (e.g., StackOverflow, GitHub), the paths through which knowledge flows within open-source software knowledge-sharing ecosystems are also beginning to change. My dissertation research seeks to raise our understanding of these changes.	https://doi.org/10.1145/2556420.2556833
457	Yan, Cong and He, Yeye	Auto-Suggest: Learning-to-Recommend Data Preparation Steps Using Data Science Notebooks	10.1145/3318464.3389738	2020	Data preparation is widely recognized as the most time-consuming process in modern business intelligence (BI) and machine learning (ML) projects. Automating complex data preparation steps (e.g., Pivot, Unpivot, Normalize-JSON, etc.)holds the potential to greatly improve user productivity, and has therefore become a central focus of research. We propose a novel approach to "auto-suggest" contextualized data preparation steps, by "learning" from how data scientists would manipulate data, which are documented by data science notebooks widely available today. Specifically, we crawled over 4M Jupyter notebooks on GitHub, and replayed them step-by-step, to observe not only full input/output tables (data-frames) at each step, but also the exact data-preparation choices data scientists make that they believe are best suited to the input data (e.g., how input tables are Joined/Pivoted/Unpivoted, etc.). By essentially "logging" how data scientists interact with diverse tables, and using the resulting logs as a proxy of "ground truth", we can learn-to-recommend data preparation steps best suited to given user data, just like how search engines (Google or Bing) leverage their click-through logs to learn-to-rank documents. This data-driven and log-driven approach leverages the "collective wisdom" of data scientists embodied in the notebooks, and is shown to significantly outperform strong baselines including commercial systems in terms of accuracy.	https://doi.org/10.1145/3318464.3389738
458	Perl, Henning and Dechand, Sergej and Smith, Matthew and Arp, Daniel and Yamaguchi, Fabian and Rieck, Konrad and Fahl, Sascha and Acar, Yasemin	VCCFinder: Finding Potential Vulnerabilities in Open-Source Projects to Assist Code Audits	10.1145/2810103.2813604	2015	Despite the security community's best effort, the number of serious vulnerabilities discovered in software is increasing rapidly. In theory, security audits should find and remove the vulnerabilities before the code ever gets deployed. However, due to the enormous amount of code being produced, as well as a the lack of manpower and expertise, not all code is sufficiently audited. Thus, many vulnerabilities slip into production systems. A best-practice approach is to use a code metric analysis tool, such as Flawfinder, to flag potentially dangerous code so that it can receive special attention. However, because these tools have a very high false-positive rate, the manual effort needed to find vulnerabilities remains overwhelming. In this paper, we present a new method of finding potentially dangerous code in code repositories with a significantly lower false-positive rate than comparable systems. We combine code-metric analysis with metadata gathered from code repositories to help code review teams prioritize their work. The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database. Second, based on this database, we trained a SVM classifier to flag suspicious commits. Compared to Flawfinder, our approach reduces the amount of false alarms by over 99 % at the same level of recall. Finally, we present a thorough quantitative and qualitative analysis of our approach and discuss lessons learned from the results. We will share the database as a benchmark for future research and will also provide our analysis tool as a web service.	https://doi.org/10.1145/2810103.2813604
459	Pearson, Antony	Extracting Structure from Contaminated Symbolic Data	10.1145/3307339.3343175	2019	Symbolic data is the epitome of modern biological datasets. Modern sequencing technologies produce millions of reads giving insights on genome sequence, transcription levels, epigenetic modifications, and much more. To analyze those sequences one usually makes assumptions on their underlying structure, e.g., that the number of reads has Poisson distribution, or that transcription factor binding events occur independently at nonoverlapping promoters. These types of assumptions are often not exactly correct in reality. In fact, even when they are valid, a small amount of data "contamination" may make them appear untrue. The traditional approach to questioning assumptions on data has been hypothesis testing. This approach has various shortcomings, however. Particularly, its Boolean nature does not give room for a null hypothesis to be "approximately true.'' This tutorial introduces a methodology to assess statistical assumptions on symbolic data that may be contaminated. It will give a general overview on how to approach these problems numerically, and present analytical results for some special classes of structured probability distributions. It will demonstrate the applicability of this rather new methodology with DNA methylation data to question the common but unconscious assumption that methylation of CpGs is exchangeable, and transcription factor binding site k-mers to question the use of logoplots in summarizing TFBS behaviour. Data and code for this tutorial, in the form an iPython Notebook, will be made available via GitHub. This work is in collaboration with M. E. Lladser.	https://doi.org/10.1145/3307339.3343175
460	Liu, Binbin and Dong, Wei and Zhang, Yating and Wang, Daiyan and Liu, Jiaxin	Boosting Component-Based Synthesis with Control Structure Recommendation	10.1145/3416506.3423579	2020	Component-based synthesis is an important research field in program synthesis. API-based synthesis is a subfield of component-based synthesis, the component library of which are Java APIs. Unlike existing work in API-based synthesis that can only generate loop-free programs constituted by APIs, state-of-the-art work FrAngel can generate programs with control structures. However, for the generation of control structures, it samples different types of control structures all at random. Given the information about the desired method (such as method name and input/output types), experienced programmers can have an initial thought about the possible control structures that could be used in implementing the desired method. The knowledge about control structures in the method can be learned from high-quality projects. In this paper, we propose a novel approach of recommending control structures for API-based synthesis based on deep learning. A neural network that can jointly embed the natural language description, method name, and input/output types into high-dimensional vectors to predict the possible control structures of the desired method is proposed. We integrate the prediction model into the synthesizer to improve the efficiency of synthesis. We train our model on a codebase of high-quality Java projects from GitHub. The prediction results of the neural network are fed to the API-based synthesizer to guide the sampling process of control structures. The experimental results on 40 programming tasks show that our approach can effectively improve the efficiency of synthesis.	https://doi.org/10.1145/3416506.3423579
461	Cutler, Barbara and Peveler, Matthew and Breese, Samuel and Maicus, Evan and Milanova, Ana and Holzbauer, Buster and Aikens, Andrew and Anderson, James and Barthelmess, Josh and Cyrus, Timothy and Lee, Marisa and Montealegre, Leon and Wang, Jessica	Supporting Team Submissions and Peer Grading within Submitty: (Abstract Only)	10.1145/3159450.3162206	2018	Submitty is an open source programming assignment submission system from the Rensselaer Center for Open Source Software (RCOS) at Rensselaer Polytechnic Institute (RPI) accessed via an online interface. Submitty allows students to submit their code through file upload or version control, such as an internal Git/SVN server or Github, where it is then tested with a highly configurable and customizable automated grader. For each assignment, instructors can specify whether or not students can work in teams. For team assignments, the instructor can either assign teammates or allow the students to choose. In addition to the auto-grading for submissions, Submitty supports human grading. The human graded rubric is developed by the graders as they work, allowing reuse of common feedback messages and partial credit points. The rubric can be searched and modified during and after grading is complete for consistency. By default, grading is handled by instructors and TAs who are assigned to sections of students, which can be rotated through the semester. However, an instructor can choose to incorporate peer grading, which will allow students to anonymously view and submit grades for each other, receiving multiple peer grades per assignment. Submitty has been used at RPI for several years for a variety of courses, serving over 1500 students and 50 instructors and TAs each semester, and has recently been used by several other universities. We will present "case studies" of assignment configurations for autograding and manual grading and demonstrate the grading interface in support of team submissions and peer grading.	https://doi.org/10.1145/3159450.3162206
462	Angstadt, Kevin and Jeannin, Jean-Baptiste and Weimer, Westley	Accelerating Legacy String Kernels via Bounded Automata Learning	10.1145/3373376.3378503	2020	The adoption of hardware accelerators, such as FPGAs, into general-purpose computation pipelines continues to rise, but programming models for these devices lag far behind their CPU counterparts. Legacy programs must often be rewritten at very low levels of abstraction, requiring intimate knowledge of the target accelerator architecture. While techniques such as high-level synthesis can help port some legacy software, many programs perform poorly without manual, architecture-specific optimization.We propose an approach that combines dynamic and static analyses to learn a model of functional behavior for off-the-shelf legacy code and synthesize a hardware description from this model. We develop a framework that transforms Boolean string kernels into hardware descriptions using techniques from both learning theory and software verification. These include Angluin-style state machine learning algorithms, bounded software model checking with incremental loop unrolling, and string decision procedures. Our prototype implementation can correctly learn functionality for kernels that recognize regular languages and provides a near approximation otherwise. We evaluate our prototype tool on a benchmark suite of real-world, legacy string functions mined from GitHub repositories and demonstrate that we are able to learn fully-equivalent hardware designs in 72% of cases and close approximations in another 11%. Finally, we identify and discuss challenges and opportunities for more general adoption of our proposed framework to a wider class of function types.	https://doi.org/10.1145/3373376.3378503
463	Falessi, Davide and Smith, Wyatt and Serebrenik, Alexander	STRESS: A Semi-Automated, Fully Replicabile Approach for Project Selection	10.1109/ESEM.2017.22	2017	The mining of software repositories has provided significant advances in a multitude of software engineering fields, including defect prediction. Several studies show that the performance of a software engineering technology (e.g., prediction model) differs across different project repositories. Thus, it is important that the project selection is replicable. The aim of this paper is to present STRESS, a semi-automated and fully replicable approach that allows researchers to select projects by configuring the desired level of diversity, fit, and quality. STRESS records the rationale behind the researcher decisions and allows different users to re-run or modify such decisions. STRESS is open-source and it can be used used locally or even online (www.falessi.com/STRESS/). We perform a systematic mapping study that considers studies that analyzed projects managed with JIRA and Git to asses the project selection replicability of past studies. We validate the feasible application of STRESS in realistic research scenarios by applying STRESS to select projects among the 211 Apache Software Foundation projects. Our systematic mapping study results show that none of the 68 analyzed studies is completely replicable. Regarding STRESS, it successfully supported the project selection among all 211 ASF projects. It also supported the measurement of 100 projects characteristics, including the 32 criteria of the studies analyzed in our mapping study. The mapping study and STRESS are, to our best knowledge, the first attempt to investigate and support the replicability of project selection. We plan to extend them to other technologies such as GitHub.	https://doi.org/10.1109/ESEM.2017.22
464	Wittern, Erik and Ying, Annie T. T. and Zheng, Yunhui and Dolby, Julian and Laredo, Jim A.	Statically Checking Web API Requests in JavaScript	10.1109/ICSE.2017.30	2017	Many JavaScript applications perform HTTP requests to web APIs, relying on the request URL, HTTP method, and request data to be constructed correctly by string operations. Traditional compile-time error checking, such as calling a non-existent method in Java, are not available for checking whether such requests comply with the requirements of a web API. In this paper, we propose an approach to statically check web API requests in JavaScript. Our approach first extracts a request's URL string, HTTP method, and the corresponding request data using an inter-procedural string analysis, and then checks whether the request conforms to given web API specifications. We evaluated our approach by checking whether web API requests in JavaScript files mined from GitHub are consistent or inconsistent with publicly available API specifications. From the 6575 requests in scope, our approach determined whether the request's URL and HTTP method was consistent or inconsistent with web API specifications with a precision of 96.0%. Our approach also correctly determined whether extracted request data was consistent or inconsistent with the data requirements with a precision of 87.9% for payload data and 99.9% for query data. In a systematic analysis of the inconsistent cases, we found that many of them were due to errors in the client code. The here proposed checker can be integrated with code editors or with continuous integration tools to warn programmers about code containing potentially erroneous requests.	https://doi.org/10.1109/ICSE.2017.30
599	K\\"ohler, Mirko and Salvaneschi, Guido	Automated Refactoring to Reactive Programming	10.1109/ASE.2019.00082	2019	Reactive programming languages and libraries, such as ReactiveX, have been shown to significantly improve software design and have seen important industrial adoption over the last years. Asynchronous applications - which are notoriously error-prone to implement and to maintain - greatly benefit from reactive programming because they can be defined in a declarative style, which improves code clarity and extensibility.In this paper, we tackle the problem of refactoring existing software that has been designed with traditional abstractions for asynchronous programming. We propose 2Rx, a refactoring approach to automatically convert asynchronous code to reactive programming. Our evaluation on top-starred GitHub projects shows that 2Rx is effective with common asynchronous constructs and it can provide a refactoring for 91.7% of their occurrences.	https://doi.org/10.1109/ASE.2019.00082
465	Wang, Cong and Gao, Jian and Jiang, Yu and Xing, Zhenchang and Zhang, Huafeng and Yin, Weiliang and Gu, Ming and Sun, Jiaguang	Go-Clone: Graph-Embedding Based Clone Detector for Golang	10.1145/3293882.3338996	2019	Golang (short for Go programming language) is a fast and compiled language, which has been increasingly used in industry due to its excellent performance on concurrent programming. Golang redefines concurrent programming grammar, making it a challenge for traditional clone detection tools and techniques. However, there exist few tools for detecting duplicates or copy-paste related bugs in Golang. Therefore, an effective and efficient code clone detector on Golang is especially needed.  In this paper, we present Go-Clone, a learning-based clone detector for Golang. Go-Clone contains two modules -- the training module and the user interaction module. In the training module, firstly we parse Golang source code into llvm IR (Intermediate Representation). Secondly, we calculate LSFG (labeled semantic flow graph) for each program function automatically. Go-Clone trains a deep neural network model to encode LSFGs for similarity classification. In the user interaction module, users can choose one or more Golang projects. Go-Clone identifies and presents a list of function pairs, which are most likely clone code for user inspection. To evaluate Go-Clone's performance, we collect 6,110 commit versions from 48 Github projects to construct a Golang clone detection data set. Go-Clone can reach the value of AUC (Area Under Curve) and ACC (Accuracy) for 89.61% and 83.80% in clone detection. By testing several groups of unfamiliar data, we also demonstrates the generility of Go-Clone. The address of the abstract demo video: https://youtu.be/o5DogtYGbeo	https://doi.org/10.1145/3293882.3338996
466	Malan, David J. and Lloyd, Doug and Zidane, Kareem	Interactive Programming Environments for Teachers and Students	10.1145/3287324.3287554	2019	We present in this hands-on workshop a suite of interactive programming environments for teachers and students, each of them cloud-based and free. The first is CS50 Sandbox, a web app at sandbox.cs50.io that enables teachers and students to create temporary programming environments quickly and share copies of those sandboxes with others. With this app can a teacher start programs in class that students can then finish, distribute starter code for problems, and post interactive solutions. The second tool is CS50 Lab, a web app at lab.cs50.io that enables teachers to create step-by-step programming lessons, providing incremental feedback at each step, and enables students to progress from an empty file (or starter code) to working code, with hints and feedback along the way. Via this app can teachers author their own Codecademy-style lessons using just a GitHub repository of their own. And third in the suite is CS50 IDE, a web app at ide.cs50.io built atop Cloud9 that provides students with their own cloud-based Linux environment. Each of these environments offers a built-in file browser and code editor and, most importantly, an interactive terminal window with shell access to their very own container. And each enables students to write programs in any language. Throughout this workshop will we discuss lessons learned from having deployed these tools in CS50 at Harvard to hundreds of students on campus and thousands of students online. And we'll discuss challenges encountered and best practices adopted.	https://doi.org/10.1145/3287324.3287554
467	Kessentini, Marouane and Ouni, Ali	Detecting Android Smells Using Multi-Objective Genetic Programming	10.1109/MOBILESoft.2017.29	2017	The evolution rate of mobile applications is much higher than regular software applications having shorter release deadlines and smaller code base. Mobile applications tend to be evolved quickly by developers to meet several new customer requirements and fix discovered bugs. However, evolving the existing features and design may introduce bad design practices, also called code smells, which can highly decrease the maintainability and performance of these mobile applications. However, unlike the area of object-oriented software systems, the detection of code smells in mobile applications received a very little of attention. Recent, few studies defined a set of quality metrics for Android applications and proposed a support to manually write a set of rules to detect code smells by combining these quality metrics. However, finding the best combination of metrics and their thresholds to identify code smells is left to the developer as a manual process. In this paper, we propose to automatically generate rules for the detection of code smells in Android applications using a multi-objective genetic programming algorithm (MOGP). The MOGP algorithm aims at finding the best set of rules that cover a set of code smell examples of Android applications based on two conflicting objective functions of precision and recall. We evaluate our approach on 184 Android projects with source code hosted in GitHub. The statistical test of our results show that the generated detection rules identified 10 Android smell types on these mobile applications with an average correctness higher than 82% and an average relevance of 77% based on the feedback of active developers of mobile apps.	https://doi.org/10.1109/MOBILESoft.2017.29
468	Businge, John and Kawuma, Simon and Bainomugisha, Engineer and Khomh, Foutse and Nabaasa, Evarist	Code Authorship and Fault-Proneness of Open-Source Android Applications: An Empirical Study	10.1145/3127005.3127009	2017	Context: In recent years, many research studies have shown how human factors play a significant role in the quality of software components. Code authorship metrics have been introduced to establish a chain of responsibility and simplify management when assigning tasks in large and distributed software development teams. Researchers have investigated the relationship between code authorship metrics and fault occurrences in software systems. However, we have observed that these studies have only been carried on large software systems having hundreds to thousands of contributors. In our preliminary investigations on Android applications that are considered to be relatively small, we observed that applications systems are not totally owned by a single developer (as one could expect) and that cases of no clear authorship also exist like in large systems. To this end, we do believe that the Android applications could face the same challenges faced by large software systems and could also benefit from such studies.Goal: We investigate the extent to which the findings obtained on large software systems applies to Android applications. Approach: Building on the designs of previous studies, we analyze 278 Android applications carefully selected from GitHub. We extract code authorship metrics from the applications and examine the relationship between code authorship metrics and faults using statistical modeling.Results: Our analyses confirm most of the previous findings, i.e., Android applications with higher levels of code authorship among contributors experience fewer faults.	https://doi.org/10.1145/3127005.3127009
469	Liu, Han and Sun, Chengnian and Su, Zhendong and Jiang, Yu and Gu, Ming and Sun, Jiaguang	Stochastic Optimization of Program Obfuscation	10.1109/ICSE.2017.28	2017	Program obfuscation is a common practice in software development to obscure source code or binary code, in order to prevent humans from understanding the purpose or logic of software. It protects intellectual property and deters malicious attacks. While tremendous efforts have been devoted to the development of various obfuscation techniques, we have relatively little knowledge on how to most effectively use them together. The biggest challenge lies in identifying the most effective combination of obfuscation techniques.This paper presents a unified framework to optimize program obfuscation. Given an input program P and a set T of obfuscation transformations, our technique can automatically identify a sequence seq = 〈t2, t2, ... , tn〉 (∀i ε [1, n]. ti ε T), such that applying ti in order on P yields the optimal obfuscation performance. We model the process of searching for seq as a mathematical optimization problem. The key technical contributions of this paper are: (1) an obscurity language model to assess obfuscation effectiveness/optimality, and (2) a guided stochastic algorithm based on Markov chain Monte Carlo methods to search for the optimal solution seq.We have realized the framework in a tool Closure* for JavaScript, and evaluated it on 25 most starred JavaScript projects on GitHub (19K lines of code). Our machinery study shows that Closure* outperforms the well-known Google Closure Compiler by defending 26% of the attacks initiated by JSNice. Our human study also reveals that Closure* is practical and can reduce the human attack success rate by 30%.	https://doi.org/10.1109/ICSE.2017.28
470	Madeyski, Lech and Lewowski, Tomasz	MLCQ: Industry-Relevant Code Smell Data Set	10.1145/3383219.3383264	2020	Context Research on code smells accelerates and there are many studies that discuss them in the machine learning context. However, while data sets used by researchers vary in quality, all which we encountered share visible shortcomings---data sets are gathered from a rather small number of often outdated projects by single individuals whose professional experience is unknown.Aim This study aims to provide a new data set that addresses the aforementioned issues and, additionally, opens new research opportunities.Method We collaborate with professional software developers (including the code quest company behind the codebeat automated code review platform integrated with GitHub) to review code samples with respect to bad smells. We do not provide additional hints as to what do we mean by a given smell, because our goal is to extract professional developers' contemporary understanding of code smells instead of imposing thresholds from the legacy literature. We gather samples from active open source projects manually verified for industry-relevance and provide repository links and revisions. Records in our MLCQ data set contain the type of smell, its severity and the exact location in source code, but do not contain any source code metrics which can be calculated using various tools. To open new research opportunities, we provide results of an extensive survey of developers involved in the study including a wide range of details concerning their professional experience in software development and many other characteristics. This allows us to track each code review to the developer's background. To the best of our knowledge, this is a unique trait of the presented data set.Conclusions The MLCQ data set with nearly 15000 code samples was created by software developers with professional experience who reviewed industry-relevant, contemporary Java open source projects. We expect that this data set should stay relevant for a longer time than data sets that base on code released years ago and, additionally, will enable researchers to investigate the relationship between developers' background and code smells' perception.	https://doi.org/10.1145/3383219.3383264
471	Ortu, Marco and Pinna, Andrea and Tonelli, Roberto and Marchesi, Michele and Bowes, David and Destefanis, Giuseppe	Angry-Builds: An Empirical Study of Affect Metrics and Builds Success on Github Ecosystem	10.1145/3234152.3234160	2018	Automatic and repeatable builds are an established software engineering practices for achieving continuous integration and continuous delivery processes. The building phase of modern software systems is an important part of the development process such that dedicated roles as "Release Engineer" are more and more required. Software development is a collaborative activity, and when multiple developers work on the same project, they will be changing a shared master development branch at overlapping intervals. This overlap occurs because developers create parallel branches for working and then merge these branches when features are completed. Continuous integration, CI, is a workflow strategy which helps ensure everyone\\^a\\uAundefineds changes will integrate with the current version of the project. This activity allows developers to catch bugs and reduce merge conflicts. Improving the building process leads to higher productivity and therefore shorter time to market, but understanding or measuring such a delicate phase is a big challenge. Open Source Communities provide valuable empirical data such as GitHub an Travis CI. These repositories represent a golden mine containing important data which can help researchers understanding the process behind the manufacturing of a software artifact. By analyzing Travis CI logs, we can directly connect a particular build with the development process behind it, not only regarding code changes but also regarding human activities, such as discussions about the implementation of a specific feature or bug resolution. Thanks to this information we can analyze the social activities of the build process enabling us to apply the same approach used for the development process.	https://doi.org/10.1145/3234152.3234160
472	Foo, Darius and Chua, Hendy and Yeo, Jason and Ang, Ming Yi and Sharma, Asankhaya	Efficient Static Checking of Library Updates	10.1145/3236024.3275535	2018	Software engineering practices have evolved to the point where a developer writing a new application today doesn’t start from scratch, but reuses a number of open source libraries and components. These third-party libraries evolve independently of the applications in which they are used, and may not maintain stable interfaces as bugs and vulnerabilities in them are fixed. This in turn causes API incompatibilities in downstream applications which must be manually resolved. Oversight here may manifest in many ways, from test failures to crashes at runtime. To address this problem, we present a static analysis for automatically and efficiently checking if a library upgrade introduces an API incompatibility. Our analysis does not rely on reported version information from library developers, and instead computes the actual differences between methods in libraries across different versions. The analysis is scalable, enabling real-time diff queries involving arbitrary pairs of library versions. It supports a vulnerability remediation product which suggests library upgrades automatically and is lightweight enough to be part of a continuous integration/delivery (CI/CD) pipeline. To evaluate the effectiveness of our approach, we determine semantic versioning adherence of a corpus of open source libraries taken from Maven Central, PyPI, and RubyGems. We find that on average, 26% of library versions are in violation of semantic versioning. We also analyze a collection of popular open source projects from GitHub to determine if we can automatically update libraries in them without causing API incompatibilities. Our results indicate that we can suggest upgrades automatically for 10% of the libraries.	https://doi.org/10.1145/3236024.3275535
598	Williams, James R. and Di Ruscio, Davide and Matragkas, Nicholas and Di Rocco, Juri and Kolovos, Dimitris S.	Models of OSS Project Meta-Information: A Dataset of Three Forges	10.1145/2597073.2597132	2014	The process of selecting open-source software (OSS) for adoption is not straightforward as it involves exploring various sources of information to determine the quality, maturity, activity, and user support of each project. In the context of the OSSMETER project, we have developed a forge-agnostic metamodel that captures the meta-information common to all OSS projects. We specialise this metamodel for popular OSS forges in order to capture forge-specific meta-information. In this paper we present a dataset conforming to these metamodels for over 500,000 OSS projects hosted on three popular OSS forges: Eclipse, SourceForge, and GitHub. The dataset enables different kinds of automatic analysis and supports objective comparisons of cross-forge OSS alternatives with respect to a user's needs and quality requirements. 	https://doi.org/10.1145/2597073.2597132
473	Mostafa, Shaikh and Rodriguez, Rodney and Wang, Xiaoyin	NetDroid: Summarizing Network Behavior of Android Apps for Network Code Maintenance	10.1109/ICPC.2017.3	2017	Network access is one of the most common features of Android applications. Statistics show that almost 80% of Android apps ask for network permission and thus may have some network-related features. Android apps may access multiple servers to retrieve or post various types of data, and the code to handle such network features often needs to change as a result of server API evolution or the content change of data transferred. Since various network code is used by multiple features, maintenance of network-related code is often difficult because the code may scatter in different places in the code base, and it may not be easy to predict the impact of a code change to the network behavior of an Android app. In this paper, we present an approach to statically summarize network behavior from the byte code of Android apps. Our approach is based on string taint analysis, and generates a summary of network requests by statically estimating the possible values of network API arguments. To evaluate our technique, we applied our technique to top 500 android apps from the official Google Play market, and the result shows that our approach is able to summarize network behavior for most apps efficiently (averagely less than 50 second for an app). Furthermore, we performed an empirical evaluation on 8 real-world maintenance tasks extracted from bug reports of open-source Android projects on Github. The empirical evaluation shows that our technique is effective in locating relevant network code.	https://doi.org/10.1109/ICPC.2017.3
474	Shrestha, Prasha and Maharjan, Suraj and Arendt, Dustin and Volkova, Svitlana	Learning from Dynamic User Interaction Graphs to Forecast Diverse Social Behavior	10.1145/3357384.3358043	2019	Most of the existing graph analytics for understanding social behavior focuses on learning from static rather than dynamic graphs using hand-crafted network features or recently emerged graph embeddings learned independently from a downstream predictive task, and solving predictive (e.g., link prediction) rather than forecasting tasks directly. To address these limitations, we propose (1) a novel task -- forecasting user interactions over dynamic social graphs, and (2) a novel deep learning, multi-task, node-aware attention model that focuses on forecasting social interactions, going beyond recently emerged approaches for learning dynamic graph embeddings. Our model relies on graph convolutions and recurrent layers to forecast future social behavior and interaction patterns in dynamic social graphs. We evaluate our model on the ability to forecast the number of retweets and mentions of a specific news source on Twitter (focusing on deceptive and credible news sources) with R^2 of 0.79 for retweets and 0.81 for mentions. An additional evaluation includes model forecasts of user-repository interactions on GitHub and comments to a specific video on YouTube with a mean absolute error close to 2% and R^2 exceeding 0.69. Our results demonstrate that learning from connectivity information over time in combination with node embeddings yields better forecasting results than when we incorporate the state-of-the-art graph embeddings e.g., Node2Vec and DeepWalk into our model. Finally, we perform in-depth analyses to examine factors that influence model performance across tasks and different graph types e.g., the influence of training and forecasting windows as well as graph topological properties.	https://doi.org/10.1145/3357384.3358043
475	Markovtsev, Vadim and Long, Waren and Mougard, Hugo and Slavnov, Konstantin and Bulychev, Egor	STYLE-ANALYZER: Fixing Code Style Inconsistencies with Interpretable Unsupervised Algorithms	10.1109/MSR.2019.00073	2019	Source code reviews are manual, time-consuming, and expensive. Human involvement should be focused on analyzing the most relevant aspects of the program, such as logic and maintainability, rather than amending style, syntax, or formatting defects. Some tools with linting capabilities can format code automatically and report various stylistic violations for supported programming languages. They are based on rules written by domain experts, hence, their configuration is often tedious, and it is impractical for the given set of rules to cover all possible corner cases. Some machine learning-based solutions exist, but they remain uninterpretable black boxes.This paper introduces style-analyzer, a new open source tool to automatically fix code formatting violations using the decision tree forest model which adapts to each codebase and is fully unsupervised. style-analyzer is built on top of our novel assisted code review framework, Lookout. It accurately mines the formatting style of each analyzed Git repository and expresses the found format patterns with compact human-readable rules. style-analyzer can then suggest style inconsistency fixes in the form of code review comments. We evaluate the output quality and practical relevance of style-analyzer by demonstrating that it can reproduce the original style with high precision, measured on 19 popular JavaScript projects, and by showing that it yields promising results in fixing real style mistakes. style-analyzer includes a web application to visualize how the rules are triggered. We release style-analyzer as a reusable and extendable open source software package on GitHub for the benefit of the community.	https://doi.org/10.1109/MSR.2019.00073
476	Enck, William	Analysis of Access Control Enforcement in Android	10.1145/3381991.3395396	2020	Over the past decade, the Android operating system install-base has proliferated to billions of devices, rivaling Microsoft Windows as a top computing platform. One of the most attractive aspects of Android is its vast collection of applications, available from application stores such as Google's Play Store. Developers have been drawn to Android due to its semantically-rich runtime APIs, which simplify the creation of third-party applications. Many of these APIs provide access to security- and privacy-sensitive information and resources such as the device's geographic location, audio recorded from the device's microphone, and the ability to send and receive SMS messages. In providing these APIs to third-party applications, the Android OS has implicitly taken responsibility for their protection, increasing its access control burden. As a result, current versions of Android have thousands of manually placed access control checks throughout the platform. The goal of this talk is to motivate the need for and utility of semi-automated tools to analyze and validate the access control checks that occur within Android's system code. The challenges are two-fold. First, analysis of Android's middleware code is more challenging than that of third-party applications, which has been studied in-depth over the past decade [3-5]. The code spans hundreds of system services, which are implemented in a combination of Java, C++, and C. The system services also have heavy inter-dependencies with one another, frequently invoking entry points in each other using Android's Binder inter-process communication (IPC) framework within the Linux kernel. Second, identifying what is an access control check is nontrivial. While there are well-known checks based on user-authorized permissions and Linux-layer user and group identifiers, system services also use an array of different service-specific checks that must be captured and modeled to assess the correctness of access control enforcement. In this talk, we will discuss these challenges in the context of two case studies. We will begin by discussing ACMiner [6], a tool designed to assess the correctness of access control checks in Android's middleware using consistency analysis. For each Binder entry point in each system service, ACMiner statically analyzes the code to identify all potential access control checks. To do so, ACMiner uses the names of methods and variables and the values of constant strings used in conditional statements to infer the security-semantics of each check on the control-flow path to instructions that throw a SecurityException. ACMiner then uses association rule mining to identify not only which entry points have inconsistent access control checks, but also to suggest what checks should be added. In applying ACMiner to the Android Open Source Project (AOSP), we found the suggestions to be invaluable when determining whether or not an inconsistency was a vulnerability. Next, we discuss the Android Re-Delegation Finder (ARF) [7]. When designing ACMiner, we optimized our static program analysis by terminating the control-flow analysis of an entry point when the execution reaches another entry point in the same or different system service. Upon further study, we found that entry points frequently call one another, often changing the protection domain of execution when they do (e.g., by explicitly clearing the calling identity, or calling the entry point of a system service executing in a different process). As with most modern operating systems, Android uses deputies (i.e., system services) to safely perform privileged functionality on behalf of third-party applications. Deputies are inherently necessary for the protection of system resources. However, by losing the calling identity, entry points to Android's system services can become confused deputies. ARF builds on the access control policy extracted by ACMiner to identify potential confused deputy vulnerabilities. Neither ACMiner or ARF were designed to eliminate all false positives. In a code-base as vast as Android, it is unrealistic to expect every nuance can be captured programmatically. Instead, ACMiner and ARF were designed to be semi-automated. Our goal is to drastically reduce the amount of time it takes for a security analyst with domain expertise to identify and fix vulnerabilities. Over the course of our research, we have applied our tools to AOSP versions~7, 8, and 9, discovering many vulnerabilities, seven of which have been assigned CVEs by Google. Moving forward, we hope that our tools can be used not only to identify new vulnerabilities, but also to aid regression testing as new versions of Android are released. Both tools have been made open-source and are hosted on Github [1,2].	https://doi.org/10.1145/3381991.3395396
477	Beheshti, Seyed-Mehdi-Reza and Tabebordbar, Alireza and Benatallah, Boualem and Nouri, Reza	On Automating Basic Data Curation Tasks	10.1145/3041021.3054726	2017	Big data analytics is firmly recognized as a strategic priority for modern enterprises. At the heart of big data analytics lies the data curation process, consists of tasks that transform raw data (unstructured, semi-structured and structured data sources) into curated data, i.e. contextualized data and knowledge that is maintained and made available for use by end-users and applications. To achieve this, the data curation process may involve techniques and algorithms for extracting, classifying, linking, merging, enriching, sampling, and the summarization of data and knowledge. To facilitate the data curation process and enhance the productivity of researchers and developers, we identify and implement a set of basic data curation APIs and make them available as services to researchers and developers to assist them in transforming their raw data into curated data. The curation APIs enable developers to easily add features - such as extracting keyword, part of speech, and named entities such as Persons, Locations, Organizations, Companies, Products, Diseases, Drugs, etc.; providing synonyms and stems for extracted information items leveraging lexical knowledge bases for the English language such as WordNet; linking extracted entities to external knowledge bases such as Google Knowledge Graph and Wikidata; discovering similarity among the extracted information items, such as calculating similarity between string and numbers; classifying, sorting and categorizing data into various types, forms or any other distinct class; and indexing structured and unstructured data - into their data applications. These services can be accessed via a REST API, and the data is returned as a JSON file that can be integrated into data applications. The curation APIs are available as an open source project on GitHub.	https://doi.org/10.1145/3041021.3054726
478	Turk, Erdem and Arit, Turkan and Susus, Delikanli Mertcan and Ucar, Ilayda and Suzek, Baris E.	ProSetComp: A Platform for Protein Set Comparisons	10.1145/3233547.3233628	2018	The amount of data available in public bioinformatics resources and the complexity of user interfaces they are served through often challenges appreciation and effective utilization of these valuable resources. While education, documentation and training activities mitigate this problem, there is still a need to develop user interfaces to serve simple day-to-day needs of scientists. To this end, we developed ProSetComp; a simple web-based platform to create and compare protein sets, following a traditional software development process; from requirement analysis to implementation. First, we interviewed and collected user scenarios from wet lab scientists with seniority, research interests and backgrounds. Reviewing the user scenarios, we identified one high impact need that drove the development of ProSetComp; ability to 1) create protein sets by searching databases, 2) compare these protein sets in different dimensions such as functional domains, pathways, molecular functions and biological processes, and 3) visualize results graphically. Next, we collected and integrated necessary data from several bioinformatics resources including UniProt, Reactome, Gene Ontology and PFAM in a local relational database. Finally, we designed user interfaces that facilitate the creation of protein sets by using form-based query generators and exploring the relationship between created protein sets using tabular and graphical representations. The current internal release of the platform contains ~120 million protein entries. The user interface supports &gt;50 search criteria to create up-to four protein sets and comparison of these sets in four dimensions; protein domains, molecular functions, biological processes, and pathways. The commonality and differences between protein sets, along with tables, can be explored using novel user interface components such as Venn and UpSet diagrams. The first public release of ProSetComp (http://ceng.mu.edu.tr/labs/bioinfo/prosetcomp) is targeted for mid-August, 2018 and planned to be updated monthly thereafter. Upon public release, source code ProSetComp will become available through GitHub. The database content and user interface will be expanded as per community needs. The ProSetComp project is supported by The Scientific and Technological Research Council of Turkey (TUBITAK, Grant number: 216Z111).	https://doi.org/10.1145/3233547.3233628
479	Yao, Yao and Liu, Zheng and Singh, Satpreet and Wei, Qi and Ramsey, Stephen A.	CERENKOV: Computational Elucidation of the Regulatory Noncoding Variome	10.1145/3107411.3107414	2017	We describe a novel computational approach, CERENKOV (Computational Elucidation of the REgulatory NonKOding Variome), for discriminating regulatory single nucleotide polymorphisms (rSNPs) from non-regulatory SNPs within noncoding genetic loci. CERENKOV is specifically designed for recognizing rSNPs in the context of a post-analysis of a genome-wide association study (GWAS); it includes a novel accuracy scoring metric (which we call average rank, or AVGRANK) and a novel cross-validation strategy (locus-based sampling) that both correctly account for the "sparse positive bag" nature of the GWAS post-analysis rSNP recognition problem. We trained and validated CERENKOV using a reference set of 15,331 SNPs (the OSU17 SNP set) whose composition is based on selection criteria (linkage disequilibrium and minor allele frequency) that we designed to ensure relevance to GWAS post-analysis. CERENKOV is based on a machine-learning algorithm (gradient boosted decision trees) incorporating 246 SNP annotation features that we extracted from genomic, epigenomic, phylogenetic, and chromatin datasets. CERENKOV includes novel features based on replication timing and DNA shape. We found that tuning a classifier for AUPVR performance does not guarantee optimality for AVGRANK. We compared the validation performance of CERENKOV to nine other methods for rSNP recognition (including GWAVA, RSVP, DeltaSVM, DeepSEA, Eigen, and DANQ), and found that CERENKOV's validation performance is the strongest out of all of the classifiers that we tested, by both traditional global rank-based measures (〈AUPVR〉 = 0.506; 〈AUROC〉 = 0.855) and AVGRANK (〈AVGRANK〉 = 3.877). The source code for CERENKOV is available on GitHub and the SNP feature data files are available for download via the CERENKOV website.	https://doi.org/10.1145/3107411.3107414
480	Campos, Eduardo C. and Maia, Marcelo A.	Common Bug-Fix Patterns: A Large-Scale Observational Study	10.1109/ESEM.2017.55	2017	[Background]: There are more bugs in real-world programs than human programmers can realistically address. Several approaches have been proposed to aid debugging. A recent research direction that has been increasingly gaining interest to address the reduction of costs associated with defect repair is automatic program repair. Recent work has shown that some kind of bugs are more suitable for automatic repair techniques. [Aim]: The detection and characterization of common bug-fix patterns in software repositories play an important role in advancing the field of automatic program repair. In this paper, we aim to characterize the occurrence of known bug-fix patterns in Java repositories at an unprecedented large scale. [Method]: The study was conducted for Java GitHub projects organized in two distinct data sets: the first one (i.e., Boa data set) contains more than 4 million bug-fix commits from 101,471 projects and the second one (i.e., Defects4J data set) contains 369 real bug fixes from five open-source projects. We used a domain-specific programming language called Boa in the first data set and conducted a manual analysis on the second data set in order to confront the results. [Results]: We characterized the prevalence of the five most common bug-fix patterns (identified in the work of Pan et al.) in those bug fixes. The combined results showed direct evidence that developers often forget to add IF preconditions in the code. Moreover, 76% of bug-fix commits associated with the IF-APC bug-fix pattern are isolated from the other four bug-fix patterns analyzed. [Conclusion]: Targeting on bugs that miss preconditions is a feasible alternative in automatic repair techniques that would produce a relevant payback.	https://doi.org/10.1109/ESEM.2017.55
481	Cabral, George G. and Minku, Leandro L. and Shihab, Emad and Mujahid, Suhaib	Class Imbalance Evolution and Verification Latency in Just-in-Time Software Defect Prediction	10.1109/ICSE.2019.00076	2019	Just-in-Time Software Defect Prediction (JIT-SDP) is an SDP approach that makes defect predictions at the software change level. Most existing JIT-SDP work assumes that the characteristics of the problem remain the same over time. However, JIT-SDP may suffer from class imbalance evolution. Specifically, the imbalance status of the problem (i.e., how much underrepresented the defect-inducing changes are) may be intensified or reduced over time. If occurring, this could render existing JIT-SDP approaches unsuitable, including those that rebuild classifiers over time using only recent data. This work thus provides the first investigation of whether class imbalance evolution poses a threat to JIT-SDP. This investigation is performed in a realistic scenario by taking into account verification latency - the often overlooked fact that labeled training examples arrive with a delay. Based on 10 GitHub projects, we show that JIT-SDP suffers from class imbalance evolution, significantly hindering the predictive performance of existing JIT-SDP approaches. Compared to state-of-the-art class imbalance evolution learning approaches, the predictive performance of JIT-SDP approaches was up to 97.2% lower in terms of g-mean. Hence, it is essential to tackle class imbalance evolution in JIT-SDP. We then propose a novel class imbalance evolution approach for the specific context of JIT-SDP. While maintaining top ranked g-means, this approach managed to produce up to 63.59% more balanced recalls on the defect-inducing and clean classes than state-of-the-art class imbalance evolution approaches. We thus recommend it to avoid overemphasizing one class over the other in JIT-SDP.	https://doi.org/10.1109/ICSE.2019.00076
482	Walkinshaw, Neil and Minku, Leandro	Are 20% of Files Responsible for 80% of Defects?	10.1145/3239235.3239244	2018	Background: Over the past two decades a mixture of anecdote from the industry and empirical studies from academia have suggested that the 80:20 rule (otherwise known as the Pareto Principle) applies to the relationship between source code files and the number of defects in the system: a small minority of files (roughly 20%) are responsible for a majority of defects (roughly 80%).Aims: This paper aims to establish how widespread the phenomenon is by analysing 100 systems (previous studies have focussed on between one and three systems), with the goal of whether and under what circumstances this relationship does hold, and whether the key files can be readily identified from basic metrics.Method: We devised a search criterion to identify defect fixes from commit messages and used this to analyse 100 active Github repositories, spanning a variety of languages and domains. We then studied the relationship between files, basic metrics (churn and LOC), and defect fixes.Results: We found that the Pareto principle does hold, but only if defects that incur fixes to multiple files count as multiple defects. When we investigated multi-file fixes, we found that key files (belonging to the top 20%) are commonly fixed alongside other much less frequently-fixed files. We found LOC to be poorly correlated with defect proneness, Code Churn was a more reliable indicator, but only for extremely high values of Churn.Conclusions: It is difficult to reliably identify the "most fixed" 20% of files from basic metrics. However, even if they could be reliably predicted, focussing on them would probably be misguided. Although fixes will naturally involve files that are often involved in other fixes too, they also tend to include other less frequently-fixed files.	https://doi.org/10.1145/3239235.3239244
483	Yan, Jiwei and Liu, Hao and Pan, Linjie and Yan, Jun and Zhang, Jian and Liang, Bin	Multiple-Entry Testing of Android Applications by Constructing Activity Launching Contexts	10.1145/3377811.3380347	2020	Existing GUI testing approaches of Android apps usually test apps from a single entry. In this way, the marginal activities far away from the default entry are difficult to be covered. The marginal activities may fail to be launched due to requiring a great number of activity transitions or involving complex user operations, leading to uneven coverage on activity components. Besides, since the test space of GUI programs is infinite, it is difficult to test activities under complete launching contexts using single-entry testing approaches.In this paper, we address these issues by constructing activity launching contexts and proposing a multiple-entry testing framework. We perform an inter-procedural, flow-, context- and path-sensitive analysis to build activity launching models and generate complete launching contexts. By activity exposing and static analysis, we could launch activities directly under various contexts without performing long event sequence on GUI. Besides, to achieve an in-depth exploration, we design an adaptive exploration framework which supports the multiple-entry exploration and dynamically assigns weights to entries in each turn.Our approach is implemented in a tool called Fax, with an activity launching strategy Faxla and an exploration strategy Faxex. The experiments on 20 real-world apps show that Faxla can cover 96.4% and successfully launch 60.6% activities, based on which Faxex further achieves a relatively 19.7% improvement on method coverage compared with the most popular tool Monkey. Our tool also behaves well in revealing hidden bugs. Fax can trigger over seven hundred unique crashes, including 180 Errors and 539 Warnings, which is significantly higher than those of other tools. Among the 46 bugs reported to developers on Github, 33 have been fixed up to now.	https://doi.org/10.1145/3377811.3380347
484		Outstanding Doctoral Dissertation Award	10.1145/3225151.3264698	2018	Dr. Jun-Yan Zhu is a pioneer in the use of modern machine learning in computer graphics. His dissertation is arguably the first to systematically attack the problem of natural image synthesis using deep neural networks. As such, his work has already had an enormous impact on the field, with several of his contributions, most notably CycleGAN, becoming widely-used tools not just for researchers in computer graphics and beyond, but also for visual artists.A key open problem in data-driven image synthesis is how to make sure that the synthesized image looks realistic, i.e., lies on the manifold of natural images? In Part I of his thesis, Zhu takes a discriminative approach to address a particular instance of this problem, training a classifier to estimate the realism of spliced image composites. Since it is difficult to obtain enough human-labeled training data to learn what looks realistic, he instead learned to classify between real images and automatically-generated composites, whether they look realistic or not. The surprising finding: resulting classifier can actually predict how realistic a new composite would look to a human. Moreover, this realism score can be used to improve the composite realism by iteratively updating the image via a learned transform. This work could be thought of as an early precursor to the conditional Generative Adversarial Network (GAN) architectures. He also developed a similar discriminative learning approach for improving the photograph aesthetics of portraits (SIGAsia'14).In Part II, Zhu takes the opposite, generative approach to modeling natural images and constrains the output of a photo editing tool to lie on this manifold. He built real-time data-driven exploration and editing interfaces based on both classic image averaging models (SIGGRAPH'14) and more recent Generative Adversarial Networks. The latter work and the associated software iGAN was the first use of GANs in a real-time application, and it contributed to the popularization of GANs in the community. In Part III, Zhu combines the lessons learned from his earlier work for developing a novel set of image-to-image translation algorithms. Of particular importance is the CycleGAN framework (ICCV'17), which revolutionized image-based computer graphics as a general-purpose framework for transferring the visual style from one set of images onto another, e.g., translating summer into winter and horses into zebras, generating real photographs from computer graphics renderings, etc. It was the first to show artistic collection style transfer (e.g., using all of Van Gogh paintings instead of only the "Starry Night"), and translating a painting into a photograph. In the short time since CycleGAN was published, it has already been applied to many different problems far beyond computer graphics, from generating synthetic training data (computer vision), to converting MRIs into CT scans (medical imaging), to applications in NLP and speech synthesis. In addition to his dissertation work, he also contributed to learning-based methods for interactive colorization (SIGGRAPH'17) and light field videography (SIGGRAPH'17).Apart from several well-cited papers in top graphics and vision venues, Zhu's work has an impact in other ways as well. His research has been repeatedly featured in the popular press, including New Yorker, Economist, Forbes, Wired, etc. Jun-Yun is also exemplary in facilitating the reproducibility of research and making it easy for researchers and practitioners to build on his contributions. He has open-sourced many of his projects and, as a sign of his impact, he has earned over 22,000 GitHub stars and 1,900 followers. Most impressively, his code has been used widely not just by researchers and developers, but also by visual artists (e.g. see #cycleGAN on Twitter).Bio: Jun-Yan Zhu received his B.E in Computer Sciences from Tsinghua University in 2012. He obtained his Ph.D. in Electrical Engineering and Computer Sciences from UC Berkeley in 2017 supervised by Alexei Efros, after spending five years at CMU and UC Berkeley. His Ph.D. work was supported by a Facebook Fellowship. Jun-Yan is currently a postdoctoral researcher at MIT CSAIL.	https://doi.org/10.1145/3225151.3264698
485	Sorensen, Tyler and Pai, Sreepathi and Donaldson, Alastair F.	Performance Evaluation of OpenCL Standard Support (and Beyond)	10.1145/3318170.3318177	2019	In this talk, we will discuss how support (or lack of it) for various OpenCL (OCL) features affects performance of graph applications executing on GPU platforms. Given that adoption of OCL features varies widely across vendors, our results can help quantify the performance benefits and potentially motivate the timely adoption of these OCL features.Our findings are drawn from the experience of developing an OCL backend for a state-of-the-art graph application DSL, IrGL, originally developed with a CUDA backend [1]. IrGL allows competitive algorithms for applications such as breadth-first-search, page-rank, and single-source-shortest-path to be written at a high level. A series of optimisations can then be applied by the compiler to generate OCL code. These user-selectable optimisations exercise various features of OCL: on one end of the spectrum, applications compiled without optimisations require only core OCL version 1.1 features; on the other end, a certain optimisation requires inter-workgroup forward progress guarantees, which are yet to be officially supported by OCL, but have been empirically validated and are relied upon e.g. to achieve global device-wide synchronisation [3]. Other optimisations require OCL features such as: fine-grained memory consistency guarantees (added in OCL 2.0) and subgroup primitives (added to core in OCL 2.1).Our compiler can apply 6 independent optimisations (Table 1), each of which requires an associated minimum version of OCL to be supported. Increased OCL support enables more and more optimisations: 2 optimisations are supported with OCL 1.x; 1 additional optimization with OCL 2.0; and a further 2 with OCL 2.1. Using OCL FP to denote v2.1 extended with forward progress guarantees (not officially supported at present), the last optimisation is enabled. We will discuss the OCL features required for each optimisation and the idioms in which the features are used. Use-case discussions of these features (e.g. memory consistency and subgroup primitives) are valuable as there appear to be very few open-source examples: a GitHub search yields only a small number of results.Our compiler enables us to carry out a large and controlled study, in which the performance benefit of various levels of OCL support can be evaluated. We gather runtime data exhaustively on all combinations across: all optimisations, 17 applications, 3 graph inputs, 6 different GPUs, spanning 4 vendors: Nvidia, AMD, Intel and ARM (Table 2).We show two notable results in this abstract: our first result, summarised in Figure 1, shows that all optimizations can be beneficial across a range of GPUs, despite significant architectural differences (e.g. subgroup size as seen in Table 2). This provides motivation that previous vendor specific approaches (e.g. for Nvidia) can be ported to OCL and achieve speedups on range of devices.Our second result, summarised in Figure 2, shows that if feature support is limited to OCL 2.0 (or below), the available optimisations (fg wg sz256) fail to achieve any speedups in over 70% of the chip/application/input benchmarks. If support for OCL 2.1 (adding the optimizations: sg coop-cv) is considered, this number drops to 60% but observed speedups are modest, rarely exceeding 2x. Finally, if forward progress guarantees are assumed (adding the oitergb optimization), speedups are observed in over half of the cases, including impressive speedups of over 14x for AMD and Intel GPUs. This provides compelling evidence for forward progress properties to be considered for adoption for a future OCL version.An extended version of this material can be found in [2, ch. 5].	https://doi.org/10.1145/3318170.3318177
486	Sharma, Abhishek and Thung, Ferdian and Kochhar, Pavneet Singh and Sulistya, Agus and Lo, David	Cataloging GitHub Repositories	10.1145/3084226.3084287	2017	GitHub is one of the largest and most popular repository hosting service today, having about 14 million users and more than 54 million repositories as of March 2017. This makes it an excellent platform to find projects that developers are interested in exploring. GitHub showcases its most popular projects by cataloging them manually into categories such as DevOps tools, web application frameworks, and game engines. We propose that such cataloging should not be limited only to popular projects. We explore the possibility of developing such cataloging system by automatically extracting functionality descriptive text segments from readme files of GitHub repositories. These descriptions are then input to LDA-GA, a state-of-the-art topic modeling algorithm, to identify categories. Our preliminary experiments demonstrate that additional meaningful categories which complement existing GitHub categories can be inferred. Moreover, for inferred categories that match GitHub categories, our approach can identify additional projects belonging to them. Our experimental results establish a promising direction in realizing automatic cataloging system for GitHub.	https://doi.org/10.1145/3084226.3084287
487	Sheoran, Jyoti and Blincoe, Kelly and Kalliamvakou, Eirini and Damian, Daniela and Ell, Jordan	Understanding "Watchers" on GitHub	10.1145/2597073.2597114	2014	Users on GitHub can watch repositories to receive notifications about project activity. This introduces a new type of passive project membership. In this paper, we investigate the behavior of watchers and their contribution to the projects they watch. We find that a subset of project watchers begin contributing to the project and those contributors account for a significant percentage of contributors on the project. As contributors, watchers are more confident and contribute over a longer period of time in a more varied way than other contributors. This is likely attributable to the knowledge gained through project notifications. 	https://doi.org/10.1145/2597073.2597114
488	Gousios, Georgios and Vasilescu, Bogdan and Serebrenik, Alexander and Zaidman, Andy	Lean GHTorrent: GitHub Data on Demand	10.1145/2597073.2597126	2014	In recent years, GitHub has become the largest code host in the world, with more than 5M developers collaborating across 10M repositories. Numerous popular open source projects (such as Ruby on Rails, Homebrew, Bootstrap, Django or jQuery) have chosen GitHub as their host and have migrated their code base to it. GitHub offers a tremendous research potential. For instance, it is a flagship for current open source development, a place for developers to showcase their expertise to peers or potential recruiters, and the platform where social coding features or pull requests emerged. However, GitHub data is, to date, largely underexplored. To facilitate studies of GitHub, we have created GHTorrent, a scalable, queriable, offline mirror of the data offered through the GitHub REST API. In this paper we present a novel feature of GHTorrent designed to offer customisable data dumps on demand. The new GHTorrent data-on-demand service offers users the possibility to request via a web form up-to-date GHTorrent data dumps for any collection of GitHub repositories. We hope that by offering customisable GHTorrent data dumps we will not only lower the "barrier for entry" even further for researchers interested in mining GitHub data (thus encourage researchers to intensify their mining efforts), but also enhance the replicability of GitHub studies (since a snapshot of the data on which the results were obtained can now easily accompany each study). 	https://doi.org/10.1145/2597073.2597126
491	Xu, Wenyuan and Sun, Xiaobing and Xia, Xin and Chen, Xiang	Scalable Relevant Project Recommendation on GitHub	10.1145/3131704.3131706	2017	GitHub, one of the largest social coding platforms, fosters a flexible and collaborative development process. In practice, developers in the open source software platform need to find projects relevant to their development work to reuse their function, explore ideas of possible features, or analyze the requirements for their projects. Recommending relevant projects to a developer is a difficult problem considering that there are millions of projects hosted on GitHub, and different developers may have different requirements on relevant projects. In this paper, we propose a scalable and personalized approach to recommend projects by leveraging both developers' behaviors and project features. Based on the features of projects created by developers and their behaviors to other projects, our approach automatically recommends top N most relevant software projects to developers. Moreover, to improve the scalability of our approach, we implement our approach in a parallel processing frame (i.e., Apache Spark) to analyze large-scale data on GitHub for efficient recommendation. We perform an empirical study on the data crawled from GitHub, and the results show that our approach can efficiently recommend relevant software projects with a relatively high precision fit for developers' interests.	https://doi.org/10.1145/3131704.3131706
492	Oliveira, Gabriel P. and Batista, Nat\\'ercia A. and Brand\\~ao, Michele A. and Moro, Mirella M.	Tie Strength in GitHub Heterogeneous Networks	10.1145/3243082.3243101	2018	In social networks, the relationship between individuals is defined by many forms of interaction. Here, our goal is to measure the strength of the relationship between GitHub users by considering social and technical features. Thus, we model GitHub's heterogeneous collaboration network with different types of interaction and propose new metrics to the strength of relationships. The results show the new metrics are not correlated, bringing new information to the table. Finally, these metrics may become important tools to determine users' influence and popularity.	https://doi.org/10.1145/3243082.3243101
493	Dabbish, Laura and Stuart, Colleen and Tsay, Jason and Herbsleb, Jim	Social Coding in GitHub: Transparency and Collaboration in an Open Software Repository	10.1145/2145204.2145396	2012	Social applications on the web let users track and follow the activities of a large number of others regardless of location or affiliation. There is a potential for this transparency to radically improve collaboration and learning in complex knowledge-based activities. Based on a series of in-depth interviews with central and peripheral GitHub users, we examined the value of transparency for large-scale distributed collaborations and communities of practice. We find that people make a surprisingly rich set of social inferences from the networked activity information in GitHub, such as inferring someone else's technical goals and vision when they edit code, or guessing which of several similar projects has the best chance of thriving in the long term. Users combine these inferences into effective strategies for coordinating work, advancing technical skills and managing their reputation.	https://doi.org/10.1145/2145204.2145396
494	Batista, Nat\\'ercia A. and Brand\\~ao, Michele A. and Alves, Gabriela B. and da Silva, Ana Paula Couto and Moro, Mirella M.	Collaboration Strength Metrics and Analyses on GitHub	10.1145/3106426.3106480	2017	We perform social analyses over an important community: the open code collaboration network. Specifically, we study the correlation among features that measure the strength of social coding collaboration on GitHub - a Web-based source code repository that can be modeled as a social coding network. We also make publicly available a curated dataset called GitSED, GitHub Socially Enhanced Dataset. Our results have many practical applications such as to improve the recommendation of developers, the evaluation of team formation and existing analysis algorithms.	https://doi.org/10.1145/3106426.3106480
495	Yu, Yue and Yin, Gang and Wang, Huaimin and Wang, Tao	Exploring the Patterns of Social Behavior in GitHub	10.1145/2666539.2666571	2014	Social coding paradigm is reshaping the distributed software development with a surprising speed in recent years. Github, a remarkable social coding community, attracts a huge number of developers in a short time. Various kinds of social networks are formed based on social activities among developers. Why this new paradigm can achieve such a great success in attracting external developers, and how they are connected in such a massive community, are interesting questions for revealing power of social coding paradigm. In this paper, we firstly compare the growth curves of project and user in GitHub with three traditional open source software communities to explore differences of their growth modes. We find an explosive growth of the users in GitHub and introduce the Diffusion of Innovation theory to illustrate intrinsic sociological basis of this phenomenon. Secondly, we construct follow-networks according to the follow behaviors among developers in GitHub. Finally, we present four typical social behavior patterns by mining follow-networks containing independence-pattern, group-pattern, star-pattern and hub-pattern. This study can provide several instructions of crowd collaboration to newcomers. According to the typical behavior patterns, the community manager could design corresponding assistive tools for developers. 	https://doi.org/10.1145/2666539.2666571
496	Destefanis, Giuseppe and Ortu, Marco and Bowes, David and Marchesi, Michele and Tonelli, Roberto	On Measuring Affects of Github Issues' Commenters	10.1145/3194932.3194936	2018	In this study, we analyzed issues and comments on GitHub projects and built collaboration networks dividing contributors into two categories: users and commenters. We identified as commenters those users who only post comments without posting any issues nor committing changes in the source code. Since previous studies showed that there is a link between a positive environment (regarding affectiveness) and productivity, our goal was to investigate commenters' contribution to the project concerning affectiveness.We analyzed more than 370K comments from 100K issues of 25K contributors from 3 open source projects. We then calculated and compared the affectiveness of the issues' comments written by users and commenters in terms of sentiment, politeness, and emotions. We provide empirical evidence that commenters are less polite, less positive and in general they express a lower level of emotions in their comments than users. Our results also confirm that GitHub's contributors consist of different groups which behave differently, and this provides useful information for future studies in the field.	https://doi.org/10.1145/3194932.3194936
499	Badashian, Ali Sajedi and Stroulia, Eleni	Measuring User Influence in GitHub: The Million Follower Fallacy	10.1145/2897659.2897663	2016	Influence in social networks has been extensively studied for collaborative-filtering recommendations and marketing purposes. We are interested in the notion of influence in Software Social Networks (SSNs); more specifically, we want to answer the following questions: 1) What does "influence" mean in SSNs? Given the variety of types of interactions supported in these networks and the abundance of centrality-type metrics, what is the nature of the influence captured by these matrics? 2) Are there silos of influence in these platforms or does influence span across thematic boundaries?To investigate these two questions, we first conducted an in-depth comparison of three influence metrics, number of followers, number of forked projects, and number of project watchers in GitHub1 (the largest code-sharing and version-control system). Next, we examined how the influence of the most influential software-engineering people in GitHub is spread over different programming languages.Our results indicate (a) that the three influence metrics capture two major characteristics: popularity and content value (code reusability) and (b) that the influence of influentials is spread over more than one programming language, but there is no specific trend toward any two programming languages.	https://doi.org/10.1145/2897659.2897663
500	Robles, Gregorio and Ho-Quang, Truong and Hebig, Regina and Chaudron, Michel R. V. and Fernandez, Miguel Angel	An Extensive Dataset of UML Models in GitHub	10.1109/MSR.2017.48	2017	The Unified Modeling Language (UML) is widely taught in academia and has good acceptance in industry. However, there is not an ample dataset of UML diagrams publicly available. Our aim is to offer a dataset of UML files, together with meta-data of the software projects where the UML files belong to. Therefore, we have systematically mined over 12 million GitHub projects to find UML files in them. We present a semi-automated approach to collect UML stored in images, .xmi, and .uml files. We offer a dataset with over 93,000 UML diagrams from over 24,000 projects in GitHub.	https://doi.org/10.1109/MSR.2017.48
501	Hu, Zhewei and Gehringer, Edward F.	Improving Feedback on GitHub Pull Requests: A Bots Approach	10.1109/FIE43999.2019.9028685	2019	Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student’s work. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check different aspects of the code. However, these tools have some limitations. In this paper, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. These bots are either open source or free for OSS projects and can be easily integrated with any GitHub repositories. One-hundred one Computer Science and Computer Engineering masters students participated in our study. The survey results showed that more than 84% of students thought bots can help them to contribute code with better quality. We analyzed 396 pull requests. Results revealed that bots can provide more timely feedback than teaching staff. The Danger Bot is associated with a significant reduction system-specific guideline violations (by 39%), and the Code Climate Bot is associated with a significant 60% decrease of code smells in student contributions. However, we found that the Travis CI Bot did not help student contributions pass automated tests.	https://doi.org/10.1109/FIE43999.2019.9028685
502	Ubayashi, Naoyasu and Muraoka, Hokuto and Muramoto, Daiki and Kamei, Yasutaka and Sato, Ryosuke	Exploring Uncertainty in GitHub OSS Projects: When and How Do Developers Face Uncertainty?	10.1145/3183440.3194966	2018	Recently, many developers begin to notice that uncertainty is a crucial problem in software development. Unfortunately, no one knows how often uncertainty appears or what kinds of uncertainty exist in actual projects, because there are no empirical studies on uncertainty. To deal with this problem, we conduct a large-scale empirical study analyzing commit messages and revision histories of 1,444 OSS projects selected from the GitHub repositories.	https://doi.org/10.1145/3183440.3194966
503	McDonald, Nora and Goggins, Sean	Performance and Participation in Open Source Software on GitHub	10.1145/2468356.2468382	2013	A few studies have attempted to provide metrics of success in open source software (OSS) projects but the role a code hosting workspace plays in how performance is viewed and measured is little examined. We conducted qualitative, exploratory research with lead and core developers on three successful projects on GitHub to understand how OSS communities on GitHub measure success. These results were obtained in connection with a larger project that is designed to understand the structure of code hosting platforms in relation to participation and performance. We report two main findings. First, lead and core members of the projects we interviewed display a nuanced understanding of community participation in their assessment of success. Second, they attribute increased participation on their projects to the features and usability provided by GitHub.	https://doi.org/10.1145/2468356.2468382
504	Maqsood, Junaid and Eshraghi, Iman and Ali, Syed Sarmad	Success or Failure Identification for GitHub's Open Source Projects	10.1145/3034950.3034957	2017	In this research we have tried to identify successful and unsuccessful projects on GitHub from a sample of 5000 randomly picked projects in a number of randomly selected languages (Java, PHP, JavaScript, C#/C++, HTML). We have selected 1000 projects for each of these languages through the publicly available GitHub API, refined our dataset, and applied different machine learning algorithms to achieve our aim. We initially implemented numerous queries against the dataset and found meaningful relationships and correlations between some of the fetched attributes which have an effect on the popularity of these projects. Later we could develop an application that will determine the success or failure of a specific open source project.	https://doi.org/10.1145/3034950.3034957
512	Middleton, Justin and Murphy-Hill, Emerson and Green, Demetrius and Meade, Adam and Mayer, Roger and White, David and McDonald, Steve	Which Contributions Predict Whether Developers Are Accepted into Github Teams	10.1145/3196398.3196429	2018	Open-source software (OSS) often evolves from volunteer contributions, so OSS development teams must cooperate with their communities to attract new developers. However, in view of the myriad ways that developers interact over platforms for OSS development, observers of these communities may have trouble discerning, and thus learning from, the successful patterns of developer-to-team interactions that lead to eventual team acceptance. In this work, we study project communities on GitHub to discover which forms of software contribution characterize developers who begin as development team outsiders and eventually join the team, in contrast to developers who remain team outsiders. From this, we identify and compare the forms of contribution, such as pull requests and several forms of discussion comments, that influence whether new developers join OSS teams, and we discuss the implications that these behavioral patterns have for the focus of designers and educators.	https://doi.org/10.1145/3196398.3196429
505	Tan, Xin and Zhou, Minghui and Sun, Zeyu	A First Look at Good First Issues on GitHub	10.1145/3368089.3409746	2020	Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time. To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers. However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain. To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices. By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results. We find that more and more projects are applying this mechanism in the past decade, especially the popular projects. Compared to common issues, GFIs usually need more days to be solved. While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers. We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective. We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc. Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.	https://doi.org/10.1145/3368089.3409746
506	Pletea, Daniel and Vasilescu, Bogdan and Serebrenik, Alexander	Security and Emotion: Sentiment Analysis of Security Discussions on GitHub	10.1145/2597073.2597117	2014	Application security is becoming increasingly prevalent during software and especially web application development. Consequently, countermeasures are continuously being discussed and built into applications, with the goal of reducing the risk that unauthorized code will be able to access, steal, modify, or delete sensitive data. In this paper we gauged the presence and atmosphere surrounding security-related discussions on GitHub, as mined from discussions around commits and pull requests. First, we found that security related discussions account for approximately 10% of all discussions on GitHub. Second, we found that more negative emotions are expressed in security-related discussions than in other discussions. These findings confirm the importance of properly training developers to address security concerns in their applications as well as the need to test applications thoroughly for security vulnerabilities in order to reduce frustration and improve overall project atmosphere. 	https://doi.org/10.1145/2597073.2597117
507	Schermann, Gerald and Zumberi, Sali and Cito, J\\"urgen	Structured Information on State and Evolution of Dockerfiles on Github	10.1145/3196398.3196456	2018	Docker containers are standardized, self-contained units of applications, packaged with their dependencies and execution environment. The environment is defined in a Dockerfile that specifies the steps to reach a certain system state as infrastructure code, with the aim of enabling reproducible builds of the container. To lay the groundwork for research on infrastructure code, we collected structured information about the state and the evolution of Dockerfiles on GitHub and release it as a PostgreSQL database archive (over 100,000 unique Dockerfiles in over 15,000 GitHub projects). Our dataset enables answering a multitude of interesting research questions related to different kinds of software evolution behavior in the Docker ecosystem.	https://doi.org/10.1145/3196398.3196456
508	Aggarwal, Karan and Hindle, Abram and Stroulia, Eleni	Co-Evolution of Project Documentation and Popularity within Github	10.1145/2597073.2597120	2014	Github is a very popular collaborative software-development platform that provides typical source-code management and issue tracking features augmented by strong social-networking features such as following developers and watching projects. These features help ``spread the word'' about individuals and projects, building the reputation of the former and increasing the popularity of the latter. In this paper, we investigate the relation between project popularity and regular, consistent documentation updates. We found strong indicators that consistently popular projects exhibited consistent documentation effort and that this effort tended to attract more documentation collaborators. We also found that frameworks required more documentation effort than libraries to achieve similar adoption success, especially in the initial phase. 	https://doi.org/10.1145/2597073.2597120
509	Ortu, Marco and Marchesi, Michele and Tonelli, Roberto	Empirical Analysis of Affect of Merged Issues on GitHub	10.1109/SEmotion.2019.00017	2019	Pull-request based workflows are popular trends of modern software development platform such as GitHub. A pull-request notifies other developers that new changes are proposed, a code review process follows the pull-request that may be merged in the main branch if other developers accept the changes. Many factors influence the acceptance of pull-requests. Since open source software is based on collaboration, it is essential to discover how the affect expressed by developer discussing pull-request issues, namely how they collaborate, influences the acceptance of the pull-request proposed. In this study we analysed the relations with the affect expressed in pull-request issues' comments and whether an issue is merged in the main branch or not. We focused on pull-request issues and we found that issues with higher level anger, sadness, arousal and valence are less likely to be merged while issues with higher level of valence, joy are more likely to be merged. Positive affect indicates a good collaboration environment, and our finding shows that this healthy collaboration is likely to increase the acceptance of pull-requests.	https://doi.org/10.1109/SEmotion.2019.00017
510	Kahlon, Amardeep and MacKellar, Bonnie and Kurdia, Anastasia	GitHub, Tutors, Relatives, and Friends: The Wide Web of Plagiarism (Abstract Only)	10.1145/3017680.3022363	2017	Plagiarism is of great concern to faculty in all fields, including computer science as it leads to one certain outcome -- a compromise not just in student learning but also in the entire academic process. Faculty attempt to deal with this epidemic in varied ways such as by writing new course materials each semester, putting a larger or entire grade focus on exams, or even asking individual students to explain their assignments. However, plagiarism remains a source of frustration for both faculty and administrators. This BoF will bring interested faculty together to discuss the various and surprising ways in which students plagiarize, the methods of countering plagiarism, and the currently available tools for detecting plagiarism. Questions we will be discussing include: Do students understand plagiarism in the context of writing software? How can we create an atmosphere that discourages plagiarism, yet fosters collaboration and encourages learning from multiple sources? To what extent can one make an assignment "plagiarism-proof"?	https://doi.org/10.1145/3017680.3022363
513	Tsay, Jason and Dabbish, Laura and Herbsleb, James	Let's Talk about It: Evaluating Contributions through Discussion in GitHub	10.1145/2635868.2635882	2014	Open source software projects often rely on code contributions from a wide variety of developers to extend the capabilities of their software. Project members evaluate these contributions and often engage in extended discussions to decide whether to integrate changes. These discussions have important implications for project management regarding new contributors and evolution of project requirements and direction. We present a study of how developers in open work environments evaluate and discuss pull requests, a primary method of contribution in GitHub, analyzing a sample of extended discussions around pull requests and interviews with GitHub developers. We found that developers raised issues around contributions over both the appropriateness of the problem that the submitter attempted to solve and the correctness of the implemented solution. Both core project members and third-party stakeholders discussed and sometimes implemented alternative solutions to address these issues. Different stakeholders also influenced the outcome of the evaluation by eliciting support from different communities such as dependent projects or even companies. We also found that evaluation outcomes may be more complex than simply acceptance or rejection. In some cases, although a submitter's contribution was rejected, the core team fulfilled the submitter's technical goals by implementing an alternative solution. We found that the level of a submitter's prior interaction on a project changed how politely developers discussed the contribution and the nature of proposed alternative solutions. 	https://doi.org/10.1145/2635868.2635882
514	Di Sipio, Claudio and Rubei, Riccardo and Di Ruscio, Davide and Nguyen, Phuong T.	A Multinomial Na\\"\\ive Bayesian (MNB) Network to Automatically Recommend Topics for GitHub Repositories	10.1145/3383219.3383227	2020	GitHub has become a precious service for storing and managing software source code. Over the last year, 10M new developers have joined the GitHub community, contributing to more than 44M repositories. In order to help developers increase the reachability of their repositories, in 2017 GitHub introduced the possibility to classify them by means of topics. However, assigning wrong topics to a given repository can compromise the possibility of helping other developers approach it, and thus preventing them from contributing to its development.In this paper we investigate the application of Multinomial Na\\"\\ive Bayesian (MNB) networks to automatically classify GitHub repositories. By analyzing the README file(s) of the repository to be classified and the source code implementing it, the conceived approach is able to recommend GitHub topics. To the best of our knowledge, this is the first supervised approach addressing the considered problem. Consequently, since there exists no suitable baseline for the comparison, we validated the approach by considering different metrics, aiming to study various quality aspects.	https://doi.org/10.1145/3383219.3383227
515	van Tonder, Rijnard and Trockman, Asher and Goues, Claire Le	A Panel Data Set of Cryptocurrency Development Activity on GitHub	10.1109/MSR.2019.00037	2019	Cryptocurrencies are a significant development in recent years, featuring in global news, the financial sector, and academic research. They also hold a significant presence in open source development, comprising some of the most popular repositories on GitHub. Their openly developed software artifacts thus present a unique and exclusive avenue to quantitatively observe human activity, effort, and software growth for cryptocurrencies. Our data set marks the first concentrated effort toward high-fidelity panel data of cryptocurrency development for a wide range of metrics. The data set is foremost a quantitative measure of developer activity for budding open source cryptocurrency development. We collect metrics like daily commits, contributors, lines of code changes, stars, forks, and subscribers. We also include financial data for each cryptocurrency: the daily price and market capitalization. The data set includes data for 236 cryptocurrencies for 380 days (roughly January 2018 to January 2019). We discuss particularly interesting research opportunities for this combination of data, and release new tooling to enable continuing data collection for future research opportunities as development and application of cryptocurrencies mature.	https://doi.org/10.1109/MSR.2019.00037
516	Biazzini, Marco and Baudry, Benoit	"May the Fork Be with You": Novel Metrics to Analyze Collaboration on GitHub	10.1145/2593868.2593875	2014	Multi-repository software projects are becoming more and more popular, thanks to web-based facilities such as Github. Code and process metrics generally assume a single repository must be analyzed, in order to measure the characteristics of a codebase. Thus they are not apt to measure how much relevant information is hosted in multiple repositories contributing to the same codebase. Nor can they feature the characteristics of such a distributed development process. We present a set of novel metrics, based on an original classification of commits, conceived to capture some interesting aspects of a multi-repository development process. We also describe an efficient way to build a data structure that allows to compute these metrics on a set of Git repositories. Interesting outcomes, obtained by applying our metrics on a large sample of projects hosted on Github, show the usefulness of our contribution. 	https://doi.org/10.1145/2593868.2593875
517	Rastogi, Ayushi and Nagappan, Nachiappan and Gousios, Georgios and van der Hoek, Andr\\'e	Relationship between Geographical Location and Evaluation of Developer Contributions in Github	10.1145/3239235.3240504	2018	Background Open source software projects show gender bias suggesting that other demographic characteristics of developers, like geographical location, can negatively influence evaluation of contributions too. Aim This study contributes to this emerging body of knowledge in software development by presenting a quantitative analysis of the relationship between the geographical location of developers and evaluation of their contributions on GitHub. Method We present an analysis of 70,000+ pull requests selected from 17 most actively participating countries to model the relationship between the geographical location of developers and pull request acceptance decision. Results and Conclusion We observed structural differences in pull request acceptance rates across 17 countries. Countries with no apparent similarities such as Switzerland and Japan had one of the highest pull request acceptance rates while countries like China and Germany had one of the lowest pull request acceptance rates. Notably, higher acceptance rates were observed for all but one country when pull requests were evaluated by developers from the same country.	https://doi.org/10.1145/3239235.3240504
518	Casalnuovo, Casey and Vasilescu, Bogdan and Devanbu, Premkumar and Filkov, Vladimir	Developer Onboarding in GitHub: The Role of Prior Social Links and Language Experience	10.1145/2786805.2786854	2015	The team aspects of software engineering have been a subject of great interest since early work by Fred Brooks and others: how well do people work together in teams? why do people join teams? what happens if teams are distributed? Recently, the emergence of project ecosystems such as GitHub have created an entirely new, higher level of organization. GitHub supports numerous teams; they share a common technical platform (for work activities) and a common social platform (via following, commenting, etc). We explore the GitHub evidence for socialization as a precursor to joining a project, and how the technical factors of past experience and social factors of past connections to team members of a project affect productivity both initially and in the long run. We find developers preferentially join projects in GitHub where they have pre-existing relationships; furthermore, we find that the presence of past social connections combined with prior experience in languages dominant in the project leads to higher productivity both initially and cumulatively. Interestingly, we also find that stronger social connections are associated with slightly less productivity initially, but slightly more productivity in the long run. 	https://doi.org/10.1145/2786805.2786854
519	Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	Investigating Social Media in GitHub's Pull-Requests: A Case Study on Ruby on Rails	10.1145/2666539.2666572	2014	In GitHub, pull-request mechanism is an outstanding social development method by integrating with many social media. Many studies have explored that social media has an important effect on software development. @-mention as a typical social media, is a useful tool in social platform. In this paper, we made a quantitative analysis of @-mention in pull-requests of the project Ruby on Rails. First, we make a convictive statistics of the popularity of pull-request mechanism in GitHub. Then we investigate the current situation of @-mention in the Ruby on Rails. Our empirical analysis results find some insights of @-mention. 	https://doi.org/10.1145/2666539.2666572
520	Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	A Exploratory Study of @-Mention in GitHub's Pull-Requests	10.1109/APSEC.2014.58	2014	Pull-request mechanism is an outstanding social development method in Git Hub. @-mention is a social media tool that deeply integrated with pull-request mechanism. Recently, many research results show that social media tools can promote the collaborative software development, but few work focuses on the impacts of @-mention. In this paper, we conduct an exploratory study of @-mention in pull-request based software development, including its current situation and benefits. We obtain some interesting findings which indicate that @-mention is beneficial to the processing of pull-request. Our work also proposes some possible research directions and problems of the @-mention. It helps the developers and researchers notice the significance of @-mention in the pull-request based software development.	https://doi.org/10.1109/APSEC.2014.58
521	Padhye, Rohan and Mani, Senthil and Sinha, Vibha Singhal	A Study of External Community Contribution to Open-Source Projects on GitHub	10.1145/2597073.2597113	2014	Open-source software projects are primarily driven by community contribution. However, commit access to such projects' software repositories is often strictly controlled. These projects prefer to solicit external participation in the form of patches or pull requests. In this paper, we analyze a set of 89 top-starred GitHub projects and their forks in order to explore the nature and distribution of such community contribution. We first classify commits (and developers) into three categories: core, external and mutant, and study the relative sizes of each of these classes through a ring-based visualization. We observe that projects written in mainstream scripting languages such as JavaScript and Python tend to include more external participation than projects written in upcoming languages such as Scala. We also visualize the geographic spread of these communities via geocoding. Finally, we classify the types of pull requests submitted based on their labels and observe that bug fixes are more likely to be merged into the main projects as compared to feature enhancements. 	https://doi.org/10.1145/2597073.2597113
522	Golubev, Yaroslav and Eliseeva, Maria and Povarov, Nikita and Bryksin, Timofey	A Study of Potential Code Borrowing and License Violations in Java Projects on GitHub	10.1145/3379597.3387455	2020	With an ever-increasing amount of open-source software, the popularity of services like GitHub that facilitate code reuse, and common misconceptions about the licensing of open-source software, the problem of license violations in the code is getting more and more prominent. In this study, we compile an extensive corpus of popular Java projects from GitHub, search it for code clones, and perform an original analysis of possible code borrowing and license violations on the level of code fragments. We chose Java as a language because of its popularity in industry, where the plagiarism problem is especially relevant because of possible legal action. We analyze and discuss distribution of 94 different discovered and manually evaluated licenses in files and projects, differences in the licensing of files, distribution of potential code borrowing between licenses, various types of possible license violations, most violated licenses, etc. Studying possible license violations in specific blocks of code, we have discovered that 29.6% of them might be involved in potential code borrowing and 9.4% of them could potentially violate original licenses.	https://doi.org/10.1145/3379597.3387455
523	Yu, Liguo and Mishra, Alok and Mishra, Deepti	An Empirical Study of the Dynamics of GitHub Repository and Its Impact on Distributed Software Development	10.1007/978-3-662-45550-0_46	2014	GitHub is a distributed code repository and project hosting web site. It is becoming one of the most popular web-based services to host both open-source projects and closed-source projects. In this paper, we review different kinds of version control systems and study the dynamics of GitHub, i.e., the ability and scalability of GitHub to process different requests and provide different services to different GitHub projects and GitHub users. Our study shows that GitHub could handle hundreds of thousands of requests a day for all the projects and thousands of requests for one project. This capability of GitHub makes it suitable for supporting distributed software development.	https://doi.org/10.1007/978-3-662-45550-0_46
525	Cito, J\\"urgen and Schermann, Gerald and Wittern, John Erik and Leitner, Philipp and Zumberi, Sali and Gall, Harald C.	An Empirical Analysis of the Docker Container Ecosystem on GitHub	10.1109/MSR.2017.67	2017	Docker allows packaging an application with its dependencies into a standardized, self-contained unit (a so-called container), which can be used for software development and to run the application on any system. Dockerfiles are declarative definitions of an environment that aim to enable reproducible builds of the container. They can often be found in source code repositories and enable the hosted software to come to life in its execution environment. We conduct an exploratory empirical study with the goal of characterizing the Docker ecosystem, prevalent quality issues, and the evolution of Dockerfiles. We base our study on a data set of over 70000 Dockerfiles, and contrast this general population with samplings that contain the Top-100 and Top-1000 most popular Docker-using projects. We find that most quality issues (28.6%) arise from missing version pinning (i.e., specifying a concrete version for dependencies). Further, we were not able to build 34% of Dockerfiles from a representative sample of 560 projects. Integrating quality checks, e.g., to issue version pinning warnings, into the container build process could result into more reproducible builds. The most popular projects change more often than the rest of the Docker population, with 5.81 revisions per year and 5 lines of code changed on average. Most changes deal with dependencies, that are currently stored in a rather unstructured manner. We propose to introduce an abstraction that, for instance, could deal with the intricacies of different package managers and could improve migration to more light-weight images.	https://doi.org/10.1109/MSR.2017.67
526	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	How Has Forking Changed in the Last 20 Years? A Study of Hard Forks on GitHub	10.1145/3377812.3390911	2020	The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub. Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community. Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks. To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories. We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive non-competitive alternative to the original project.	https://doi.org/10.1145/3377812.3390911
527	Subramanian, Vikram N.	An Empirical Study of the First Contributions of Developers to Open Source Projects on GitHub	10.1145/3377812.3382165	2020	The popularity of Open Source Software (OSS) is at an all-time high and for it to remain so it is vital for new developers to continually join and contribute to the OSS community. In this paper, to better understand the first time contributor, we study the characteristics of the first pull request (PR) made to an OSS project by developers. We mine GitHub for the first OSS PR of 3501 developers to study certain characteristics of PRs like language and size. We find that over 1/3rd of the PRs were in Java while C++ was very unpopular. A large fraction of PRs didn't even involve writing code, and were a mixture of trivial and non-trivial changes.	https://doi.org/10.1145/3377812.3382165
528	Coppola, Riccardo and Ardito, Luca and Torchiano, Marco	Characterizing the Transition to Kotlin of Android Apps: A Study on F-Droid, Play Store, and GitHub	10.1145/3340496.3342759	2019	Context: Kotlin is a novel language that represents an alternative to Java, and has been recently adopted as a first-class programming language for Android applications. Kotlin is achieving a significant diffusion among developers, and several studies have highlighted various advantages of the language when compared to Java.  Goal: The objective of this paper is to analyze a set of open-source Android apps, to evaluate their transition to the Kotlin programming language throughout their lifespan and understand whether the adoption of Kotlin has impacts on the success of Android apps.  Methods: We mined all the projects from the F-Droid repository of Android open-source applications, and we found the corresponding projects on the official Google Play Store and on the GitHub platform. We defined a set of eight metrics to quantify the relevance of Kotlin code in the latest update and through all releases of an application. Then, we statistically analyzed the correlation between the presence of Kotlin code in a project and popularity metrics mined from the platforms where the apps were released.  Results: Of a set of 1232 projects that were updated after October 2017, near 20% adopted Kotlin and about 12% had more Kotlin code than Java; most of the projects that adopted Kotlin quickly transitioned from Java to the new language. The projects featuring Kotlin had on average higher popularity metrics; a statistically significant correlation has been found between the presence of Kotlin and the number of stars on the GitHub repository.  Conclusion: The Kotlin language seems able to guarantee a seamless migration from Java for Android developers. With an inspection on a large set of open-source Android apps, we observed that the adoption of the Kotlin language is rapid (when compared to the average lifespan of an Android project) and seems to come at no cost in terms of popularity among the users and other developers.	https://doi.org/10.1145/3340496.3342759
529	Portugal, Roxana Lisette Quintanilla and do Prado Leite, Julio Cesar Sampaio and Almentero, Eduardo	Time-Constrained Requirements Elicitation: Reusing GitHub Content	10.1109/JITRE.2015.7330171	2015	Requirements elicitation is the activity of identifying facts that compose the system requirements. One of the steps of this activity is the identification of information sources, which is a time-consuming task. Text documents are typically an important and abundant information source. However, their analysis to gather useful information is also time consuming and hard to automate. Because of its characteristics, the identification of information sources and analysis of text documents are critical in time-constrained projects, which are typically addressed through agile approaches. This paper presents a strategy for time-constrained elicitation, which is based on mining GitHub content. The strategy aims the identification of information sources (similar projects) and the automatic analysis of textual documents (projects content) through text mining techniques. Furthermore, it maintains the traceability between the data mined and its sources, boosting the reuse of existing information. A tool is being created to support the strategy.	https://doi.org/10.1109/JITRE.2015.7330171
530	Ren, Luyao and Zhou, Shurui and K\\"astner, Christian	Forks Insight: Providing an Overview of GitHub Forks	10.1145/3183440.3195085	2018	Fork-based development allows developers to start development from existing software repository by copying the code files. However, when the number of forks grows, contributions are not always visible to others, unless an explicit merge-back attempt is made. To solve this problem, we implemented Forks Insight (www.forks-insight.com) to help developers get an overview of forks on GitHub. The current release version focuses on simple analytics for the high level overview which is lightweight, scalable and practical. It has a user-friendly interactive web interface with features like searching and tagging.	https://doi.org/10.1145/3183440.3195085
532	Mo, Wenkai and Shen, Beijun and He, Yuming and Zhong, Hao	GEMiner: Mining Social and Programming Behaviors to Identify Experts in Github	10.1145/2875913.2875924	2015	Hosting over 10 million repositories, GitHub becomes the largest open source community in the world. Besides sharing code, Github is also a social network, in which developers can follow others or keep track of their interested projects. Considering the multi-roles of Github, integrating heterogenous data of each developer to identify experts is a challenging task. In this paper, we propose GEMiner, a novel approach to identify experts for some specific programming languages in Github. Different from previous approaches, GEMiner analyzes the social behaviors and programming behaviors of a developer to determine the expertise of the developer. When modeling social behaviors of developers, to integrate heterogenous social networks in Github, GEMiner implements a Multi-Sources PageRank algorithm. Also, GEMiner analyzes the behaviors of developers when they are programming (e.g., their commit activities and their preferred programming languages) to model programming behaviors of them. Based on our expertise models and our extracted programming languages data, GEMiner can then identify experts for some specific programming languages in Github. We conducted experiments on a real data set, and our results show that GEMiner identifies experts with 60% accuracy higher than the state-of-the-art algorithms.	https://doi.org/10.1145/2875913.2875924
533	Ortu, Marco and Hall, Tracy and Marchesi, Michele and Tonelli, Roberto and Bowes, David and Destefanis, Giuseppe	Mining Communication Patterns in Software Development: A GitHub Analysis	10.1145/3273934.3273943	2018	Background: Studies related to human factors in software engineering are providing insightful information on the emotional state of contributors and the impact this has on the code. The open source software development paradigm involves different roles, and previous studies about emotions in software development have not taken into account what different roles might play when people express their feelings. Aim: We present an analysis of issues and commits on five GitHub projects distinguishing contributors between users and developers, and between one-commit and multi-commit developers. Method: We analyzed more than 650K comments from 130K issues of 64K contributors. We calculated emotions (love, joy, anger, sadness) and politeness of the comments related to the issues of the considered projects and introduced the definition of contributor fan-in and fan-out. Results: Results show that users and developers communicate differently as well as multi-commit developers and one-commit developers do. Conclusions: We provide empirical evidence that one-commit developers are more active and more polite in posting comments. Multi-commit developers are less active in posting comments, and while commenting, they are less polite than when commented.	https://doi.org/10.1145/3273934.3273943
534	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	How Has Forking Changed in the Last 20 Years? A Study of Hard Forks on GitHub	10.1145/3377811.3380412	2020	The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub. Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks. To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories. We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project.	https://doi.org/10.1145/3377811.3380412
535	Vasilescu, Bogdan and Blincoe, Kelly and Xuan, Qi and Casalnuovo, Casey and Damian, Daniela and Devanbu, Premkumar and Filkov, Vladimir	The Sky is Not the Limit: Multitasking across GitHub Projects	10.1145/2884781.2884875	2016	Software development has always inherently required multitasking: developers switch between coding, reviewing, testing, designing, and meeting with colleagues. The advent of software ecosystems like GitHub has enabled something new: the ability to easily switch between projects. Developers also have social incentives to contribute to many projects; prolific contributors gain social recognition and (eventually) economic rewards. Multitasking, however, comes at a cognitive cost: frequent context-switches can lead to distraction, sub-standard work, and even greater stress. In this paper, we gather ecosystem-level data on a group of programmers working on a large collection of projects. We develop models and methods for measuring the rate and breadth of a developers' context-switching behavior, and we study how context-switching affects their productivity. We also survey developers to understand the reasons for and perceptions of multitasking. We find that the most common reason for multitasking is interrelationships and dependencies between projects. Notably, we find that the rate of switching and breadth (number of projects) of a developer's work matter. Developers who work on many projects have higher productivity if they focus on few projects per day. Developers that switch projects too much during the course of a day have lower productivity as they work on more projects overall. Despite these findings, developers perceptions of the benefits of multitasking are varied.	https://doi.org/10.1145/2884781.2884875
536	Saxena, Rohit and Pedanekar, Niranjan	I Know What You Coded Last Summer: Mining Candidate Expertise from GitHub Repositories	10.1145/3022198.3026354	2017	Resumes and social recommendations are often high-level indicators of a candidate's technical skillset. In this paper, we present a method to create a more detailed technology skill profile of a candidate based on her code repository contributions. For this purpose, we annotate user contributions to GitHub code repositories with technology tags found in Stack Overflow questions and answers (Q&amp;A) in an unsupervised manner. We also present SkillMap, a visual representation of candidate skill profile, for quick review and comparison with other candidate profiles. We create SkillMaps for 66 Java programmers and present a preliminary qualitative assessment though manual analysis and interviews of technical recruiters.	https://doi.org/10.1145/3022198.3026354
537	Ying, Haochao and Chen, Liang and Liang, Tingting and Wu, Jian	EARec: Leveraging Expertise and Authority for Pull-Request Reviewer Recommendation in GitHub	10.1145/2897659.2897660	2016	Pull-Request (PR) is a primary way of code contribution from developers to improve quality of software projects in GitHub. For a popular GitHub project, tens of PR are submitted daily, while only a small number of developers, i.e core developers, have the grant to judge whether to merge these changes into the main branches or not. Due to the time-consumption of PR review and the diversity of PR aspects, it is becoming a big challenge for core developers to quickly discover the useful PR. Currently, recommending appropriate reviewers (developers) for incoming PR to quickly collect meaningful comments, is treated as an effective and crowdsourced way to help core developers to make decisions and thus accelerate project development. In this paper, we propose a reviewer recommendation approach (EARec) which simultaneously considers developer expertise and authority. Specifically, we first construct a graph of incoming PR and possible reviewers, and then take advantage of text similarity of PR and social relations of reviewers to find the appropriate reviewers. The experimental analysis on MSR Mining Challenge Dataset provides good evaluation for our approach in terms of precision and recall.	https://doi.org/10.1145/2897659.2897660
538	Joshi, Saket Dattatray and Chimalakonda, Sridhar	RapidRelease: A Dataset of Projects and Issues on Github with Rapid Releases	10.1109/MSR.2019.00088	2019	In the recent years, there has been a surge in the adoption of agile development model and continuous integration (CI) in software development. Recent trends have reduced average release cycle lengths to as low as 1--2 weeks, leading to an extensive number of studies in release engineering. Open-source development (OSD) has also witnessed a rapid increase in release rates, however, no large dataset of open-source projects exists which features high release rates. In this paper, we introduce the RapidRelease dataset, a data showcase of high release frequency open-source projects. The dataset hosts 994 projects from Github, with over 2 million issue reports. To the best of our knowledge, this is the first dataset that can facilitate researchers to empirically study release engineering and agile software development in open-source projects with rapid releases.	https://doi.org/10.1109/MSR.2019.00088
539	Ma, Wanwangying and Chen, Lin and Zhang, Xiangyu and Zhou, Yuming and Xu, Baowen	How Do Developers Fix Cross-Project Correlated Bugs? A Case Study on the GitHub Scientific Python Ecosystem	10.1109/ICSE.2017.42	2017	GitHub, a popular social-software-development platform, has fostered a variety of software ecosystems where projects depend on one another and practitioners interact with each other. Projects within an ecosystem often have complex inter-dependencies that impose new challenges in bug reporting and fixing. In this paper, we conduct an empirical study on cross-project correlated bugs, i.e., causally related bugs reported to different projects, focusing on two aspects: 1) how developers track the root causes across projects; and 2) how the downstream developers coordinate to deal with upstream bugs. Through manual inspection of bug reports collected from the scientific Python ecosystem and an online survey with developers, this study reveals the common practices of developers and the various factors in fixing cross-project bugs. These findings provide implications for future software bug analysis in the scope of ecosystem, as well as shed light on the requirements of issue trackers for such bugs.	https://doi.org/10.1109/ICSE.2017.42
540	Thomas, Pamela Bilo and Krohn, Rachel and Weninger, Tim	Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs	10.1145/3341161.3342928	2019	When a group of people strives to understand new information, struggle ensues as various ideas compete for attention. Steep learning curves are surmounted as teams learn together. To understand how these team dynamics play out in software development, we explore Git logs, which provide a complete change history of software repositories. In these repositories, we observe code additions, which represent successfully implemented ideas, and code deletions, which represent ideas that have failed or been superseded. By examining the patterns between these commit types, we can begin to understand how teams adopt new information. We specifically study what happens after a software library is adopted by a project, i.e., when a library is used for the first time in the project. We find that a variety of factors, including team size, library popularity, and prevalence on Stack Overflow are associated with how quickly teams learn and successfully adopt new software libraries.	https://doi.org/10.1145/3341161.3342928
541	Marlow, Jennifer and Dabbish, Laura and Herbsleb, Jim	Impression Formation in Online Peer Production: Activity Traces and Personal Profiles in Github	10.1145/2441776.2441792	2013	In this paper we describe a qualitative investigation of impression formation in an online distributed software development community with social media functionality. We find that users in this setting seek out additional information about each other to explore the project space, inform future interactions, and understand the potential future value of a new person. They form impressions around other users' expertise based on history of activity across projects, and successful collaborations with key high status projects in the community. These impressions influence their receptivity to strangers' work contributions.	https://doi.org/10.1145/2441776.2441792
542	Thangavelu, Senthilkumar and Jyotishi, Amalendu	Determinants of Open Source Software Project Performance: A Stage-Wise Analysis of GitHub Projects	10.1145/3209626.3209723	2018		https://doi.org/10.1145/3209626.3209723
543	Provensi, Lucas Luiz and Costa, F\\'abio Moreira and Sacramento, Vagner	Uma Arquitetura de Middleware Para Suporte a Aplica\\cc\\~oEs Colaborativas de Tinta Digital	10.1109/SBSC.2008.30	2008	A comunica\\cc\\~ao \\'e um dos aspectos fundamentais em sistemas colaborativos, e deve possibilitar uma intera\\cc\\~ao efetiva e de qualidade entre os usu\\'arios. Solu\\cc\\~oes convencionais de comunica\\cc\\~ao para aplica\\cc\\~oes colaborativas n\\~ao tratam o dinamismo de alguns ambientes de rede, como o ambiente de computa\\cc\\~ao m\\'ovel. Este artigo apresenta uma infra-estrutura de middleware capaz de se adaptar a varia\\cc\\~oes em seu ambiente de execu\\cc\\~ao para manter a qualidade da comunica\\cc\\~ao em sistemas colaborativos, com interesse espec\\'\\ifico em aplica\\cc\\~oes de tinta digital em tablet PCs.	https://doi.org/10.1109/SBSC.2008.30
544	Wang, Ben and Zhou, Xingshe and Yang, Gang and Yang, Yalei	DS Theory-Based Software Trustworthiness Classification Assessment	10.1109/UIC-ATC.2010.111	2010	Software trustworthiness Evaluation has become a research focus nowadays. Referencing the TRUSTIE Software Trust Classification Specification and Trust Evidence Framework Specification, we proposed a software trustworthiness classification assessment method based on DS theory. In this method, the uncertainty and evidences combination which are important during the evaluation but rarely considered by existing studies are taken into account, and DS combination rule and Shannon entropy are applied to address the problems. The simple example shows that this method is effective for ranking trustworthiness of software which is deve	https://doi.org/10.1109/UIC-ATC.2010.111
545	Santos, Adriano and Souza, Maur\\'\\icio and Oliveira, Johnatan and Figueiredo, Eduardo	Mining Software Repositories to Identify Library Experts	10.1145/3267183.3267192	2018	Programming is multi-faceted, inherently involving several different skills. With the advent of collaboration platforms like GitHub, developers have the opportunity to contribute to projects from different organizations and collaborate with various developers from around the world. With GitHub data, new opportunities to identify developers abilities become possible. From GitHub, it is possible to infer several skills from a developer, for instance, the user of libraries. In this paper, we propose a method to identify library experts, based on the knowledge they produce on GitHub. We evaluated our method in an experiment to identify possible experts in three Java libraries. Our method ranked the top 100 developers for each technology. Then we compared the selected profiles from GitHub with profiles of these developers on the social network LinkedIn to see if what they report in LinkedIn matches what they produce in GitHub. We also surveyed students to compare the results of our method to the manual analysis. Our results showed that 89% of selected GitHub developers reported their skills in social networking sites as LinkedIn, according to the ranking made by our method and that the ranking produced by our method is related to the classification made by survey participants.	https://doi.org/10.1145/3267183.3267192
546	Han-xia, Liu and Rong-jun, Li	Responsibility of Net-Bank in Electronic Payment	10.1109/ISECS.2008.133	2008	This paper investigates five electronic payment tools which are prevalent in the virtual world nowadays. It is demonstrated that the net-banks play an important role in the process of electronic payment, and that they are also facing greater legal risks than ever before because consumer-protection regulations are pervasive in deve-loped countries that govern net-banks' activities and impose more liabilities on them. This paper analyses the responsibilities of net-banks in handling electronic payments under the framework of law in the U.S. and recommends that China enact similar laws defining net-bank's liabilities and responsibilities to ensure the sustainable development of electronic payment.	https://doi.org/10.1109/ISECS.2008.133
547	Rivett, Roger	Technology, Society and Risk	10.1007/978-3-540-87698-4_3	2008	There remains a healthy debate among those working in the fun-ctional safety field over issues that appear to be fundamental to the discipline. Coming from an industry that is a relative newcomer to this discipline I look to the more established industries to give a lead. Not only are they in debate about key issues, the approaches taken do not always transfer easily to a mass market product, developed within very tight business constraints. Key issues that are debated include:What is meant by risk, what is acceptable risk and who does the accepting?How do we justify that an acceptable risk has been, or will be, achieved?What role does the development process play?What is meant by the concept of a Safety Integrity Level?In this talk I will air some views on these questions based on my experience of deve-loping automotive systems and authoring industry sector guidelines and standards in the hope that this will provoke informed discussion.	https://doi.org/10.1007/978-3-540-87698-4_3
548	dos Reis Costa, Jean Marcel and de Souza, Cleidson Ronald Botelho	Analyzing the Scalability of Awareness Networks in a Distributed Software Development Project	10.1109/SBSC.2010.22	2010	Ao longo dos anos muitos trabalhos sobre o conceito de awareness foram publicados. Diversas formas de representar este conceito, bem como defini\\cc\\~oes divergentes ou complementares foram apresentadas. De um modo geral, a id\\'eia de awareness se refere ao fato de que um ator precisa, ao mesmo tempo, estar ciente do trabalho de seus colegas e informar seus colegas sobre seu pr\\'oprio trabalho. Esta percep\\cc\\~ao sobre o trabalho dos colegas facilita a coordena\\cc\\~ao de atividades colaborativas. Apesar das diferentes defini\\cc\\~oes, nenhuma delas aborda diretamente o n\\'umero de atores sobre os quais um ator precisa estar ciente e, de maneira similar, o n\\'umero de atores para os quais este mesmo ator deve informar suas atividades. Baseado em nossos trabalhos anteriores, estes atores formam as chamadas redes de awareness. Esse artigo visa reduzir essa limita\\cc\\~ao dos trabalhos anteriores, apresentando dados sobre a escala destas redes de awareness. Estes dados s\\~ao baseados em um estudo de caso com um projeto distribu\\'\\ido de desenvolvimento de software, o Jazz. Os resultados da an\\'alise permitir\\~ao entender melhor a escalabilidade das redes de awareness ao longo de um projeto e podem nortear futuras pesquisas nessa \\'area.	https://doi.org/10.1109/SBSC.2010.22
549	Fan, Qiang and Yu, Yue and Yin, Gang and Wang, Tao and Wang, Huaimin	Where is the Road for Issue Reports Classification Based on Text Mining?	10.1109/ESEM.2017.19	2017	Currently, open source projects receive various kinds of issues daily, because of the extreme openness of Issue Tracking System (ITS) in GitHub. ITS is a labor-intensive and time-consuming task of issue categorization for project managers. However, a contributor is only required a short textual abstract to report an issue in GitHub. Thus, most traditional classification approaches based on detailed and structured data (e.g., priority, severity, software version and so on) are difficult to adopt.In this paper, issue classification approaches on a large-scale dataset, including 80 popular projects and over 252,000 issue reports collected from GitHub, were investigated. First, four traditional text-based classification methods and their performances were discussed. Semantic perplexity (i.e., an issues description confuses bug-related sentences with nonbug-related sentences) is a crucial factor that affects the classification performances based on quantitative and qualitative study. Finally, A two-stage classifier framework based on the novel metrics of semantic perplexity of issue reports was designed. Results show that our two-stage classification can significantly improve issue classification performances.	https://doi.org/10.1109/ESEM.2017.19
550	Queiroz, Paulo G. G. and Braga, Rosana T. V.	Domain Engineering of Software Product Lines with Service-Oriented Architecture	10.1109/SBCARS.2010.18	2010	Software product lines (SPL) have been established as one of the best ways to promote reuse of both requirements and software architecture, even with a high cost when compared to the development of single systems. Service-oriented architecture (SOA) can further facilitate the development of SPL, since several features of the SPL can be implemented by services available on a network. This paper presents SoProL-WS, which is a deve-lopment approach for SPL using SOA. The focus of this article is in the domain engineering phase, where the SPL architecture is developed based on services. From this architecture, one can derive products in the subsequent application engineering phase. The goal of SoProL-WS is to reduce SPL development costs and time, facilitating its maintenance, evolution and derivation of its members. Additionally, this paper presents a case study where SoProl-WS is applied to develop a product line for Web auctions.	https://doi.org/10.1109/SBCARS.2010.18
552	Yu, Haizi and Deka, Biplab and Talton, Jerry O. and Kumar, Ranjitha	Accounting for Taste: Ranking Curators and Content in Social Networks	10.1145/2858036.2858219	2016	Ranking users in social networks is a well-studied problem, typically solved by algorithms that leverage network structure to identify influential users and recommend people to follow. In the last decade, however, curation --- users sharing and promoting content in a network --- has become a central social activity, as platforms like Facebook, Twitter, Pinterest, and GitHub drive growth and engagement by connecting users through content and content to users. While existing algorithms reward users that are highly active with higher rankings, they fail to account for users' curatorial taste. This paper introduces CuRank, an algorithm for ranking users and content in social networks by explicitly modeling three characteristics of a good curator: discerning taste, high activity, and timeliness. We evaluate CuRank on datasets from two popular social networks --- GitHub and Vine --- and demonstrate its efficacy at ranking content and identifying good curators.	https://doi.org/10.1145/2858036.2858219
553	Trockman, Asher	Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the <i>Npm</i> Ecosystem	10.1145/3183440.3190335	2018	Contemporary software development is characterized by increased reuse and speed. Open source software forges such as GitHub host millions of repositories of libraries and tools, which developers reuse liberally [6], creating complex and often fragile networks of interdependencies [1]. Hence, developers must make more decisions at a higher speed, finding which libraries to depend on and which projects to contribute to. This decision making process is supported by the transparency provided by social coding platforms like GitHub [4, 5], where user profile pages display information on a one's contributions, and repository pages provide information on a project's social standing (e.g., through stars and watchers).	https://doi.org/10.1145/3183440.3190335
554	Gousios, Georgios and Zaidman, Andy	A Dataset for Pull-Based Development Research	10.1145/2597073.2597122	2014	Pull requests form a new method for collaborating in distributed software development. To study the pull request distributed development model, we constructed a dataset of almost 900 projects and 350,000 pull requests, including some of the largest users of pull requests on Github. In this paper, we describe how the project selection was done, we analyze the selected features and present a machine learning tool set for the R statistics environment. 	https://doi.org/10.1145/2597073.2597122
555	Bayati, Shahab	Understanding Newcomers Success in Open Source Community	10.1145/3183440.3195073	2018	Newcomers and volunteers contributions play an effective role the open source software (OSS) success. This role is confirmed through a rigor set of studies in software engineering discipline. As Open source projects are developed based on social and technical efforts, then it is very important for newcomers to empower their socio-technical skills. This paper focuses on newcomers' success in open source community by analyzing newcomers' reputation on their initial activities in a social coding environment such as GitHub. By applying mining software repositories (MSR) techniques on GitHub data we found the main projects' attributes where successful newcomers contributed to them. These attributes can help other newcomers to select the right project for their initial activities.	https://doi.org/10.1145/3183440.3195073
556	Nam, Jaechang and Wang, Song and Xi, Yuan and Tan, Lin	Designing Bug Detection Rules for Fewer False Alarms	10.1145/3183440.3194987	2018	One of the challenging issues of the existing static analysis tools is the high false alarm rate. To address the false alarm issue, we design bug detection rules by learning from a large number of real bugs from open-source projects from GitHub. Specifically, we build a framework that learns and refines bug detection rules for fewer false positives. Based on the framework, we implemented ten patterns, six of which are new ones to existing tools. To evaluate the framework, we implemented a static analysis tool, FeeFin, based on the framework with the ten bug detection rules and applied the tool for 1,800 open-source projects in GitHub. The 57 detected bugs by FeeFin has been confirmed by developers as true positives and 44 bugs out of the detected bugs were actually fixed.	https://doi.org/10.1145/3183440.3194987
557	Spielmann, Simon and Helzle, Volker	Augmented Reality for Virtual Set Extension	10.1145/3214745.3214783	2018	We introduce an intuitive workflow where Augmented Reality can be applied on the fly to extend a real set with virtual extensions. The work on intuitive Virtual Production technology at Filmakademie Baden-W\\"urttemberg has focused on an open platform tied to existing film creation pipelines. The Virtual Production Editing Tools (VPET) are published and constantly updated on the open source software development platform Github as a result of a former project on Virtual Production funded by the European Union.	https://doi.org/10.1145/3214745.3214783
558	Diamantopoulos, Themistoklis and Papamichail, Michail D. and Karanikiotis, Thomas and Chatzidimitriou, Kyriakos C. and Symeonidis, Andreas L.	Employing Contribution and Quality Metrics for Quantifying the Software Development Process	10.1145/3379597.3387490	2020	The full integration of online repositories in contemporary software development promotes remote work and collaboration. Apart from the apparent benefits, online repositories offer a deluge of data that can be utilized to monitor and improve the software development process. Towards this direction, we have designed and implemented a platform that analyzes data from GitHub in order to compute a series of metrics that quantify the contributions of project collaborators, both from a development as well as an operations (communication) perspective. We analyze contributions throughout the projects' lifecycle and track the number of coding violations, this way aspiring to identify cases of software development that need closer monitoring and (possibly) further actions to be taken. In this context, we have analyzed the 3000 most popular GitHub Java projects and provide the data to the community.	https://doi.org/10.1145/3379597.3387490
559	Golzadeh, Mehdi	Analysing Socio-Technical Congruence in the Package Dependency Network of Cargo	10.1145/3338906.3342497	2019	Software package distributions form large dependency networks maintained by large communities of contributors. My PhD research will consist of analysing the evolution of the socio-technical congruence of these package dependency networks, and studying its impact on the health of the ecosystem and its community. I have started a longitudinal empirical study of Cargo's dependency network and the social (commenting) and technical (development) activities in Cargo's package repositories on GitHub, and present some preliminary findings.	https://doi.org/10.1145/3338906.3342497
560	Liao, Zhifang and Wu, Zexuan and Wu, Jinsong and Zhang, Yan and Liu, Junyi and Long, Jun	TIRR: A Code Reviewer Recommendation Algorithm with Topic Model and Reviewer Influence	10.1109/GLOBECOM38437.2019.9014249	2019	Code review is an important way to improve software quality and ensure project security. Pull Request (PR), as an important method of collaborative code modification in GitHub open source software community platform, is very important to find a suitable code reviewer to improve code modification efficiency for Pull Request submitted by code modifiers. In order to solve this problem, we have proposed a review recommendation algorithm based on Pull Request topic model and reviewer's influence. This algorithm has not only extracted the topic information of PR through Latent Dirichlet Allocation (LDA) method, but also analyzed the professional knowledge influence of reviewers through influence network. Whatâ€™s more, it has combined the topic information of reviewers to find the appropriate PR reviewers. The experimental results based on GitHub show that the algorithm is more efficient, which can effectively reduce the time of code review and improve the recommendation accuracy.	https://doi.org/10.1109/GLOBECOM38437.2019.9014249
561	Gasparini, Mattia and Claris\\'o, Robert and Brambilla, Marco and Cabot, Jordi	Participation Inequality and the 90-9-1 Principle in Open Source	10.1145/3412569.3412582	2020	Participation inequality is a major challenge in any shared-resource system. This is known as the "volunteer's dilemma": everybody wants to benefit from a resource without contributing, expecting others will do the work. This paper explores whether this problem also arises in open source development. In particular, we analyze the behaviour of GitHub users to assess whether the 90-9-1 principle applies to open source. We study it both from a qualitative (ratio of activity types) and a quantitative (total number of activities) perspective and we show that the principle does not hold if we consider the GitHub platform as a whole. Surprisingly, results are reversed depending on the specific projects we look at. We believe these results are useful to project managers to better understand and optimize the behaviour of the community around their projects and, as a side effect, they show the importance of diversity in sample selection.	https://doi.org/10.1145/3412569.3412582
562	Anderson, Paul and Kot, Lucja and Gilmore, Neil and Vitek, David	SARIF-Enabled Tooling to Encourage Gradual Technical Debt Reduction	10.1109/TechDebt.2019.00024	2019	SARIF is an emerging standard for representing the results of program analysis tools. This tool demo shows how it can enable integration between static analysis tools and version control systems such as GitHub, and by doing so, encourage developers to reduce technical debt in a gradual non-invasive fashion.	https://doi.org/10.1109/TechDebt.2019.00024
563	Sam, Garming and Cameron, Nick and Potanin, Alex	Automated Refactoring of Rust Programs	10.1145/3014812.3014826	2017	Rust is a modern systems programming language developed by Mozilla Research and the Rust community. Rust supports modern constructs such as ownership, lifetimes, traits, and macros, whilst supporting systems programming idioms with low-cost abstractions and memory safety without garbage collection.We describe a new refactoring tool for Rust developers, including discussing the issues and unusual decisions encountered due to the complexities of modern systems languages. We outline lessons learned and hope our paper will help inform design of future programming languages and refactoring tools. The resulting refactoring tool is written in Rust and available from Github under an MIT license [8].	https://doi.org/10.1145/3014812.3014826
564	Iacob, Claudia and Faily, Shamal and Harrison, Rachel	MARAM: Tool Support for Mobile App Review Management	10.4108/eai.30-11-2016.2266941	2016	Mobile apps today have millions of user reviews available online. Such reviews cover a large broad of themes and are usually expressed in an informal language. They provide valuable information to developers, such as feature requests, bug reports, and detailed descriptions of one's interaction with the app. Due to the overwhelmingly large number of reviews apps usually get associated with, managing and making sense of reviews is difficult. In this paper, we address this problem by introducing MARAM, a tool designed to provide support for managing and integrating online reviews with other software management tools available, such as GitHub, JIRA and Bugzilla. The tool is designed to a) automatically extract app development relevant information from online reviews, b) support developers' queries on (subsets of) the user generated content available on app stores, namely online reviews, feature requests, and bugs, and c) support the management of online reviews and their integration with other software management tools available, namely GitHub, JIRA or Bugzilla.	https://doi.org/10.4108/eai.30-11-2016.2266941
565	Kononenko, Oleksii and Rose, Tresa and Baysal, Olga and Godfrey, Michael and Theisen, Dennis and de Water, Bart	Studying Pull Request Merges: A Case Study of Shopify's Active Merchant	10.1145/3183519.3183542	2018	Pull-based development has become a popular choice for developing distributed projects, such as those hosted on GitHub. In this model, contributions are pulled from forked repositories, modified, and then later merged back into the main repository. In this work, we report on two empirical studies that investigate pull request (PR) merges of Active Merchant, a commercial project developed by Shopify Inc. In the first study, we apply data mining techniques on the project's GitHub repository to explore the nature of merges, and we conduct a manual inspection of pull requests; we also investigate what factors contribute to PR merge time and outcome. In the second study, we perform a qualitative analysis of the results of a survey of developers who contributed to Active Merchant. The study addresses the topic of PR review quality and developers' perception of it. The results provide insights into how these developers perform pull request merges, and what factors they find contribute to how they review and merge pull requests.	https://doi.org/10.1145/3183519.3183542
566	Yan, Bei	Large Scale, Open Cognitive Collaboration of Distributed Crowds	10.1145/2789853.2806214	2015	Drawing on communication, sociology and social psychology theories, my research focuses on large scale, open cognitive collaboration of distributed crowds. I study how individuals interact and collaborate with each other via mediated communication channels, applying social network analysis, conducting online experiments and utilizing big data dumps of online communities, such as Wikipedia, Stack Overflow, Github and Threadless.com.	https://doi.org/10.1145/2789853.2806214
567	Chen, Guanliang and Davis, Dan and Hauff, Claudia and Houben, Geert-Jan	Learning Transfer: Does It Take Place in MOOCs? An Investigation into the Uptake of Functional Programming in Practice	10.1145/2876034.2876035	2016	The rising number of Massive Open Online Courses (MOOCs) enable people to advance their knowledge and competencies in a wide range of fields. Learning though is only the first step, the transfer of the taught concepts into practice is equally important and often neglected in the investigation of MOOCs. In this paper, we consider the specific case of FP101x (a functional programming MOOC on edX) and the extent to which learners alter their programming behaviour after having taken the course. We are able to link about one third of all FP101x learners to GitHub, the most popular social coding platform to date and contribute a first exploratory analysis of learner behaviour beyond the MOOC platform. A detailed longitudinal analysis of GitHub log traces reveals that (i) more than 8% of engaged learners transfer, and that (ii) most existing transfer learning findings from the classroom setting are indeed applicable in the MOOC setting as well.	https://doi.org/10.1145/2876034.2876035
568	Ding, Aaron Yi and Liu, Yanhe and Tarkoma, Sasu and Flinck, Hannu and Crowcroft, Jon	Demo: An Open-Source Software Defined Platform for Collaborative and Energy-Aware WiFi Offloading	10.1145/2789168.2789174	2015	This demonstration presents a novel software defined platform for achieving collaborative and energy-aware WiFi offloading. The platform consists of an extensible central controller, programmable offloading agents, and offloading extensions on mobile devices. Driven by our extensive measurements of energy consumption on smartphones, we propose an effective energy-aware offloading algorithm and integrate it to our platform. By enabling collaboration between wireless networks and mobile users, our solution can make optimal offloading decisions that improve offloading efficiency for network operators and achieve energy saving for mobile users. To enhance deployability, we have released our platform under open-source licenses on GitHub.	https://doi.org/10.1145/2789168.2789174
569	Markovtsev, Vadim and Long, Waren	Public Git Archive: A Big Code Dataset for All	10.1145/3196398.3196464	2018	The number of open source software projects has been growing exponentially. The major online software repository host, GitHub, has accumulated tens of millions of publicly available Git version-controlled repositories. Although the research potential enabled by the available open source code is clearly substantial, no significant large-scale open source code datasets exist. In this paper, we present the Public Git Archive - dataset of 182,014 top-bookmarked Git repositories from GitHub. We describe the novel data retrieval pipeline to reproduce it. We also elaborate on the strategy for performing dataset updates and legal issues. The Public Git Archive occupies 3.0 TB on disk and is an order of magnitude larger than the current source code datasets. The dataset is made available through HTTP and provides the source code of the projects, the related metadata, and development history. The data retrieval pipeline employs an optimized worker queue model and an optimized archive format to efficiently store forked Git repositories, reducing the amount of data to download and persist. Public Git Archive aims to open a myriad of new opportunities for "Big Code" research.	https://doi.org/10.1145/3196398.3196464
570	Liu, Chao and Yang, Dan and Zhang, Xiaohong and Hu, Haibo and Barson, Jed and Ray, Baishakhi	A Recommender System for Developer Onboarding	10.1145/3183440.3194989	2018	Successfully onboarding open source projects in GitHub is difficult for developers, because it is time-consuming for them to search an expected project by a few query words from numerous repositories, and developers suffer from various social and technical barriers in joined projects. Frequently failed onboarding postpones developers' development schedule, and the evolutionary progress of open source projects. To mitigate developers' costly efforts for onboarding, we propose a ranking model NNLRank (Neural Network for List-wise Ranking) to recommend projects that developers are likely to contribute many commits. Based on 9 measured project features, NNLRank learns a ranking function (represented by a neural network, optimized by a list-wise ranking loss function) to score a list of candidate projects, where top-n scored candidates are recommended to a target developer. We evaluate NNLRank by 2044 succeeded onboarding decisions from GitHub developers, comparing with a related model LP (Link Prediction), and 3 other typical ranking models. Results show that NNLRank can provide developers with effective recommendation, substantially outperforming baselines.	https://doi.org/10.1145/3183440.3194989
571	Proksch, Sebastian and Amann, Sven and Nadi, Sarah and Mezini, Mira	A Dataset of Simplified Syntax Trees for C#	10.1145/2901739.2903507	2016	In this paper, we present a curated collection of 2833 C# solutions taken from Github. We encode the data in a new intermediate representation (IR) that facilitates further analysis by restricting the complexity of the syntax tree and by avoiding implicit information. The dataset is intended as a standardized input for research on recommendation systems for software engineering, but is also useful in many other areas that analyze source code.	https://doi.org/10.1145/2901739.2903507
572	Chishiro, Hiroyuki and Tsuchiya, Yosuke and Chubachi, Yoshihide and Abu Bakar, Muhammad Saifullah and De Silva, Liyanage C.	Global PBL for Environmental IoT	10.1145/3108421.3108437	2017	Advanced Institute of Industrial Technology has performed the global Project Based Learning (PBL) for environmental IoT with Universiti Brunei Darussalam (Brunei) and Unitec Institute of Technology (New Zealand) in 2015-2016, in order to address environmental monitoring in Brunei. We evaluate the effectiveness of this global PBL from various metrics including questionnaire and GitHub. Finally, we learn some lessons from this global PBL and suggest the direction of future global PBL.	https://doi.org/10.1145/3108421.3108437
573	Doherty, Stanley	Leveraging Industry Onboarding Materials in the Curriculum	10.1145/3121113.3121241	2017	Delivers a resource-sharing project between undergraduate technical writing programs and industry technical documentation groups that provides: 1) Crisp descriptions of the top five content development skills, 2) Industry college-hire and new-employee training materials (conceptuals), 3) Real-world, sample technical content in substantial breadth and depth, 4) Multiple content markup formats (Word, Markdown, XML DITA), 5) Detailed writing exercises based on the sample content and assessment guidelines, and 6) Community-sourced content development, maintenance, and curation (GitHub).	https://doi.org/10.1145/3121113.3121241
574	Decan, Alexandre and Mens, Tom and Claes, Maelick and Grosjean, Philippe	On the Development and Distribution of R Packages: An Empirical Analysis of the R Ecosystem	10.1145/2797433.2797476	2015	This paper explores the ecosystem of software packages for R, one of the most popular environments for statistical computing today. We empirically study how R packages are developed and distributed on different repositories: CRAN, BioConductor, R-Forge and GitHub. We also explore the role and size of each repository, the inter-repository dependencies, and how these repositories grow over time. With this analysis, we provide a deeper insight into the extent and the evolution of the R package ecosystem.	https://doi.org/10.1145/2797433.2797476
575	Chakraborty, Partha and Shahriyar, Rifat and Iqbal, Anindya and Bosu, Amiangshu	Understanding the Software Development Practices of Blockchain Projects: A Survey	10.1145/3239235.3240298	2018	Background: The application of the blockchain technology has shown promises in various areas, such as smart-contracts, Internet of Things, land registry management, identity management, etc. Although Github currently hosts more than three thousand active blockchain software (BCS) projects, a few software engineering research has been conducted on their software engineering practices. Aims: To bridge this gap, we aim to carry out the first formal survey to explore the software engineering practices including requirement analysis, task assignment, testing, and verification of blockchain software projects. Method: We sent an online survey to 1,604 active BCS developers identified via mining the Github repositories of 145 popular BCS projects. The survey received 156 responses that met our criteria for analysis. Results: We found that code review and unit testing are the two most effective software development practices among BCS developers. The results suggest that the requirements of BCS projects are mostly identified and selected by community discussion and project owners which is different from requirement collection of general OSS projects. The results also reveal that the development tasks in BCS projects are primarily assigned on voluntary basis, which is the usual task assignment practice for OSS projects. Conclusions: Our findings indicate that standard software engineering methods including testing and security best practices need to be adapted with more seriousness to address unique characteristics of blockchain and mitigate potential threats.	https://doi.org/10.1145/3239235.3240298
576	Huang, Shengyi (Costa) and Healy, Chris	StreetTraffic: A Library for Traffic Flow Data Collection and Analysis	10.1145/3190645.3190710	2018	This extended abstract introduces StreetTraffic, an open-sourced server library that collects and analyzes traffic flow data. By utilizing REST APIs provided by HERE.com, StreetTraffic allows the users to crawl traffic flow data of interested regions or routes. Then, the users could see the visualized traffic flow history of the crawled data, empowering them to understand the historical traffic pattern of their interested routes, which could be valuable to commuters or someone who wants to optimize a trip. The library is currently hosted at Github (https://github.com/streettraffic/streettraffic), along with its documentation and tutorials.	https://doi.org/10.1145/3190645.3190710
577	Duarte, Paulo A.S. and Peixoto, Maria J.P. and Frota, Yuri S.F. and Viana, Windson	Generating Context Acquisition Code Using Awareness API	10.1145/3126858.3131586	2017	Development of Context-Aware and Mobile applications have significant challenges, such as the complexity of sensor access code and the heterogeneity of devices. The Google Awareness API is an initiative to mitigate this complexity. This paper presents an analysis of GitHub projects involving Awareness API. However, the results showed that the spread of this API among the developers community is still incipient. We propose to extend a tool to allow high-level modeling of context acquisition and code generation compatible with Awareness API. It reduces the complexity of acquiring contextual information and managing contextual rules.	https://doi.org/10.1145/3126858.3131586
578	Spielmann, Simon and Helzle, Volker and Schuster, Andreas and Trottnow, Jonas and G\\"otz, Kai and Rohr, Patricia	VPET: Virtual Production Editing Tools	10.1145/3214907.3233760	2018	The work on intuitive Virtual Production tools at Filmakademie Baden-W\\"urttemberg has focused on an open platform tied to existing film creation pipelines. The Virtual Production Editing Tools (VPET) started in a former project on Virtual Production funded by the European Union and are published and constantly updated on the open source software development platform Github. We introduce an intuitive workflow where Augmented Reality, inside-out tracking and real-time color keying can be applied on the fly to extend a real movie set with editable, virtual extensions in a collaborative setup.	https://doi.org/10.1145/3214907.3233760
579	Sarker, Farhana and Vasilescu, Bogdan and Blincoe, Kelly and Filkov, Vladimir	Socio-Technical Work-Rate Increase Associates with Changes in Work Patterns in Online Projects	10.1109/ICSE.2019.00099	2019	Software developers work on a variety of tasks ranging from the technical, e.g., writing code, to the social, e.g., participating in issue resolution discussions. The amount of work developers perform per week (their work-rate) also varies and depends on project needs and developer schedules. Prior work has shown that while moderate levels of increased technical work and multitasking lead to higher productivity, beyond a certain threshold, they can lead to lowered performance.Here, we study how increases in the short-term work-rate along both the technical and social dimensions are associated with changes in developers' work patterns, in particular communication sentiment, technical productivity, and social productivity. We surveyed active and prolific developers on GitHub to understand the causes and impacts of increased work-rates. Guided by the responses, we developed regression models to study how communication and committing patterns change with increased work-rates and fit those models to large-scale data gathered from traces left by thousands of GitHub developers. From our survey and models, we find that most developers do experience work-rate-increase-related changes in behavior. Most notably, our models show that there is a sizable effect when developers comment much more than their average: the negative sentiment in their comments increases, suggesting an increased level of stress. Our models also show that committing patterns do not change with increased commenting, and vice versa, suggesting that technical and social activities tend not to be multitasked.	https://doi.org/10.1109/ICSE.2019.00099
580	Geiger, Franz-Xaver and Malavolta, Ivano and Pascarella, Luca and Palomba, Fabio and Di Nucci, Dario and Bacchelli, Alberto	A Graph-Based Dataset of Commit History of Real-World Android Apps	10.1145/3196398.3196460	2018	Obtaining a good dataset to conduct empirical studies on the engineering of Android apps is an open challenge. To start tackling this challenge, we present AndroidTimeMachine, the first, self-contained, publicly available dataset weaving spread-out data sources about real-world, open-source Android apps. Encoded as a graph-based database, AndroidTimeMachine concerns 8,431 real open-source Android apps and contains: (i) metadata about the apps' GitHub projects, (ii) Git repositories with full commit history and (iii) metadata extracted from the Google Play store, such as app ratings and permissions.	https://doi.org/10.1145/3196398.3196460
581	Verhaeghe, Beno\\^\\it and Fuhrman, Christopher and Guerrouj, Latifa and Anquetil, Nicolas and Ducasse, St\\'ephane	Empirical Study of Programming to an Interface	10.1109/ASE.2019.00083	2019	A popular recommendation to programmers in object-oriented software is to "program to an interface, not an implementation" (PTI). Expected benefits include increased simplicity from abstraction, decreased dependency on implementations, and higher flexibility. Yet, interfaces must be immutable, excessive class hierarchies can be a form of complexity, and "speculative generality" is a known code smell. To advance the empirical knowledge of PTI, we conducted an empirical investigation that involves 126 Java projects on GitHub, aiming to measuring the decreased dependency benefits (in terms of cochange).	https://doi.org/10.1109/ASE.2019.00083
582	Wang, Qingye and Xu, Bowen and Xia, Xin and Wang, Ting and Li, Shanping	Duplicate Pull Request Detection: When Time Matters	10.1145/3361242.3361254	2019	In open source communities (e.g., GitHub), developers frequently submit pull requests to fix bugs or add new features during development process. Since the process of pull request is uncoordinated and distributed, it causes massive duplication. Usually, only the first pull request qualified by reviewers can be merged to the main branch of the repository, and the others are regarded as duplication by maintainers. Since the duplication largely aggravates workloads of project reviewers and maintainers, the evolutionary process of open source repositories is delayed. To identify the duplicate pull requests automatically, Ren et al. proposed a state-of-the-art approach that models a pull request by nine features and determine whether a given request is duplicate with the other existing requests or not. Nevertheless, we notice that their approach overlooked the time factor which is a significant feature for the task. In this study, we investigate the influence of time factor and improve the pull request representation. We assume that two pull requests are more likely duplicate when their created time are close to each other. We verify the assumption based on 26 open source repositories from GitHub with over 100,000 pairs of pull requests. We integrate the time feature to the nine features proposed by Ren et al. and the experimental results show that it can substantially improve the performance of Ren et al.'s work by 14.36% and 11.93% in terms of F1-score@1 and F1-score@5, respectively.	https://doi.org/10.1145/3361242.3361254
583	Marques, Oge and Carson, Joseph	Selfie Search: Image Retrieval and Face Recognition in IOS: [Invited Paper]	10.1145/2983402.2983420	2016	This paper describes the design and development of an iOS app for selfie search, which combines face detection and recognition capabilities with content-based image retrieval techniques. The app works offline, since all processing takes place entirely on the device. It was implemented in Objective-C and it leverages functionality from Apple's Core Image API for image processing tasks and CouchbaseLite for the database layer. For face recognition, the app employs local binary patterns -- encoded as spatially enhanced histograms, with weight maps that indicate preferred areas within the cropped image containing the face. The source code is available on GitHub.	https://doi.org/10.1145/2983402.2983420
584	Li, Ziqiang and Tan, Shin Hwei	Bugine: A Bug Report Recommendation System for Android Apps	10.1145/3377812.3390906	2020	Many automated test generation tools were proposed for finding bugs in Android apps. However, a recent study revealed that developers prefer reading automated test generation cased written in natural language. We present Bugine, a new bug recommendation system that automatically selects relevant bug reports from other applications that have similar bugs. Bugine (1) searches for GitHub issues that mentioned common UI components shared between the app under test and the apps in our database, and (2) ranks the quality and relevance of issues. Our results show that Bugine could find 34 new bugs in five evaluated apps.	https://doi.org/10.1145/3377812.3390906
585	Ali, Rao Hamza and Parlett-Pelleriti, Chelsea and Linstead, Erik	Cheating Death: A Statistical Survival Analysis of Publicly Available Python Projects	10.1145/3379597.3387511	2020	We apply survival analysis methods to a dataset of publicly-available software projects in order to examine the attributes that might lead to their inactivity over time. We ran a Kaplan-Meier analysis and fit a Cox Proportional-Hazards model to a subset of Software Heritage Graph Dataset, consisting of 3052 popular Python projects hosted on GitLab/GitHub, Debian, and PyPI, over a period of 165 months. We show that projects with repositories on multiple hosting services, a timeline of publishing major releases, and a good network of developers, remain healthy over time and should be worthy of the effort put in by developers and contributors.	https://doi.org/10.1145/3379597.3387511
586	Felderer, Michael and Jeschko, Fabian	A Process for Evidence-Based Engineering of Domain-Specific Languages	10.1145/3210459.3210479	2018	Domain-specific languages (DSLs) are mainly designed ad-hoc and gut feeling resulting in languages that are often not well suited for their users and engineers. In this paper we develop a process for evidence-based language engineering to design domain-specific languages based on empirical evidence to support decision in language engineering. The developed process comprises an iterative execution of the phases DSL engineering, issue identification, data collection and evidence appraisal. We exemplify the concept by designing a DSL for Gherkin, a language test-driven acceptance testing in Xtext. The required evidence is derived by mining and analyzing all GitHub projects until July 1, 2017 that apply Gherkin.	https://doi.org/10.1145/3210459.3210479
587	Choi, Joohee and Choi, Junghong and Moon, Jae Yun and Hahn, Jungpil and Kim, Jinwoo	Herding in Open Source Software Development: An Exploratory Study	10.1145/2441955.2441989	2013	In spite of the lack of organizational control, a large number of these self-organized groups have successfully developed high quality software in open source software projects. We examined the process through which coordinated action emerges from the collection of individual developers' choices, i.e., how bottom-up coordination occurs and argue that developer herding on a social coding platform may have a positive impact on OSSD outcomes. As an exploratory study, we analyzed the participation patterns in 10 randomly sampled OSSD projects on a social open source code foundry, Github. Based on the findings we generate theoretical propositions regarding developer herding behavior in OSSD.	https://doi.org/10.1145/2441955.2441989
588	Vasilescu, Bogdan	Human Aspects, Gamification, and Social Media in Collaborative Software Engineering	10.1145/2591062.2591091	2014	Software engineering is inherently a collaborative venture. In open-source software (OSS) development, such collaborations almost always span geographies and cultures. Because of the decentralised and self-directed nature of OSS as well as the social diversity inherent to OSS communities, the success of an OSS project depends to a large extent on the social aspects of distributed collaboration and achieving coordination over distance. The goal of this dissertation research is to raise our understanding of how human aspects (e.g., gender or cultural diversity), gamification and social media (e.g., participation in social environments such as Stack Overflow or GitHub) impact distributed collaboration in OSS. 	https://doi.org/10.1145/2591062.2591091
589	Agrawal, Amritanshu and Rahman, Akond and Krishna, Rahul and Sobran, Alexander and Menzies, Tim	We Don't Need Another Hero? The Impact of "Heroes" on Software Development	10.1145/3183519.3183549	2018	A software project has "Hero Developers" when 80% of contributions are delivered by 20% of the developers. Are such heroes a good idea? Are too many heroes bad for software quality? Is it better to have more/less heroes for different kinds of projects? To answer these questions, we studied 661 open source projects from Public open source software (OSS) Github and 171 projects from an Enterprise Github.We find that hero projects are very common. In fact, as projects grow in size, nearly all projects become hero projects. These findings motivated us to look more closely at the effects of heroes on software development. Analysis shows that the frequency to close issues and bugs are not significantly affected by the presence of heroes or project type (Public or Enterprise). Similarly, the time needed to resolve an issue/bug/enhancement is not affected by heroes or project type. This is a surprising result since, before looking at the data, we expected that increasing heroes on a project will slow down how fast that project reacts to change. However, we do find a statistically significant association between heroes, project types, and enhancement resolution rates. Heroes do not affect enhancement resolution rates in Public projects. However, in Enterprise projects, heroes increase the rate at which projects complete enhancements.In summary, our empirical results call for a revision of a long-held truism in software engineering. Software heroes are far more common and valuable than suggested by the literature, particularly for medium to large Enterprise developments. Organizations should reflect on better ways to find and retain more of these heroes.	https://doi.org/10.1145/3183519.3183549
590	Wang, Qi and Lai, Jingxiang and Xu, Kai and Liu, Wenyin and Lei, Liang	Beauty Product Image Retrieval Based on Multi-Feature Fusion and Feature Aggregation	10.1145/3240508.3266431	2018	We propose a beauty product image retrieval method based on multi-feature fusion and feature aggregation. The key idea is representing the image with the feature vector obtained by multi-feature fusion and feature aggregation. VGG16 and ResNet50 are chosen to extract image features, and Crow is adopted to perform deep feature aggregation. Benefited from the idea of transfer learning, we fine turn VGG16 on the Perfect-500K data set to improve the performance of image retrieval. The proposed method won the third price in Perfect Corp. Challenge 2018 with the best result 0.270676 mAP. We released our code on GitHub: https://github.com/wangqi12332155/ACMMM-beauty-AI-challenge.	https://doi.org/10.1145/3240508.3266431
591	Hauser, Frederik and Menth, Michael	Demo: Execution and Access Control for Restricted Application Containers on Managed Hosts (XRAC)	10.1109/NOMS47738.2020.9110350	2020	Restricted application containers (RACs) encapsulate applications with their dependencies and configuration for execution on a hypervisor host. xRAC [1] is a novel approach for execution control and network access control (NAC). That is, a RAC can be executed only after successful authentication and authorization (AA) and obtain limited access to network resources. A RAC has a unique IPv6 address so that its traffic is identifiable and controllable by network components. For AA, xRAC adopts and extends components and procedures of 802.1X. We publish its source code and a testbed setup guide on GitHub [2]. In this paper, we give a brief overview on the architecture and functionality of xRAC, describe the prototypical implementation, a testbed, and four demo scenarios.	https://doi.org/10.1109/NOMS47738.2020.9110350
592	Steiner, Thomas	Wikipedia Tools for Google Spreadsheets	10.1145/2872518.2891112	2016	In this paper, we introduce the Wikipedia Tools for Google Spreadsheets. Google Spreadsheets is part of a free, Web-based software office suite offered by Google within its Google Docs service. It allows users to create and edit spreadsheets online, while collaborating with other users in realtime. Wikipedia is a free-access, free-content Internet encyclopedia, whose content and data is available, among other means, through an API. With the Wikipedia Tools for Google Spreadsheets, we have created a toolkit that facilitates working with Wikipedia data from within a spreadsheet context. We make these tools available as open-source on GitHub [https://github.com/tomayac/wikipedia-tools-for-google-spreadsheets], released under the permissive Apache 2.0 license.	https://doi.org/10.1145/2872518.2891112
593	Moin, Armin and R\\"ossler, Stephan and Sayih, Marouane and G\\"unnemann, Stephan	From Things' Modeling Language (ThingML) to Things' Machine Learning (ThingML2)	10.1145/3417990.3420057	2020	In this paper, we illustrate how to enhance an existing state-of-the-art modeling language and tool for the Internet of Things (IoT), called ThingML, to support machine learning on the modeling level. To this aim, we extend the Domain-Specific Language (DSL) of ThingML, as well as its code generation framework. Our DSL allows one to define things, which are in charge of carrying out data analytics. Further, our code generators can automatically produce the complete implementation in Java and Python. The generated Python code is responsible for data analytics and employs APIs of machine learning libraries, such as Keras, Tensorflow and Scikit Learn. Our prototype is available as open source software on Github.	https://doi.org/10.1145/3417990.3420057
594	Hayashi, Junichi and Higo, Yoshiki and Matsumoto, Shinsuke and Kusumoto, Shinji	Impacts of Daylight Saving Time on Software Development	10.1109/MSR.2019.00076	2019	Daylight saving time (DST) is observed in many countries and regions. DST is not considered on some software systems at the beginning of their developments, for example, software systems developed in regions where DST is not observed. However, such systems may have to consider DST at the requests of their users. Before now, there has been no study about the impacts of DST on software development. In this paper, we study the impacts of DST on software development by mining the repositories on GitHub. We analyze the date when the code related to DST is changed, and we analyze the regions where the developers applied the changes live. Furthermore, we classify the changes into some patterns.	https://doi.org/10.1109/MSR.2019.00076
595	Choi, Junghong and Ferwerda, Bruce and Hahn, Jungpil and Kim, Jinwoo and Moon, Jae Yun	Impact of Social Features Implemented in Open Collaboration Platforms on Volunteer Self-Organization: Case Study of Open Source Software Development	10.1145/2491055.2491081	2013	The promise of collective intelligence emerging from voluntary participation, contribution and knowledge sharing brought about by ubiquitous information and communication technologies has recently attracted the attention of academics and practitioners alike. Of many related phenomena, open source software (OSS) development has been touted as one of the leading examples that speak to the potential of collective intelligence. Recently, the advent of novel open collaboration platforms for open source software development, such as Github, has prompted researchers to examine the impact of increased work transparency induced by the introduction of social features on voluntary self-organization and allocation of resources to projects. We present both qualitative and quantitative analyses from which we derive some initial propositions regarding the impact of transparency on voluntary self-organization processes and decision mechanisms.	https://doi.org/10.1145/2491055.2491081
600	Kolovos, Dimitris and Neubauer, Patrick and Barmpis, Konstantinos and Matragkas, Nicholas and Paige, Richard	Crossflow: A Framework for Distributed Mining of Software Repositories	10.1109/MSR.2019.00032	2019	Large-scale software repository mining typically requires substantial storage and computational resources, and often involves a large number of calls to (rate-limited) APIs such as those of GitHub and StackOverflow. This creates a growing need for distributed execution of repository mining programs to which remote collaborators can contribute computational and storage resources, as well as API quotas (ideally without sharing API access tokens or credentials). In this paper we introduce CROSSFLOW, a novel framework for building distributed repository mining programs. We demonstrate how CROSSFLOW can delegate mining jobs to remote workers and cache their results, and how workers can implement advanced behaviour such as load balancing and rejecting jobs they cannot perform (e.g. due to lack of space, credentials for a specific API).	https://doi.org/10.1109/MSR.2019.00032
601	Treude, Christoph and Aniche, Maur\\'\\icio	Where Does Google Find API Documentation?	10.1145/3194793.3194796	2018	The documentation of popular APIs is spread across many formats, from vendor-curated reference documentation to Stack Overflow threads. For developers, it is often not obvious from where a particular piece of information can be retrieved. To understand this documentation landscape, we systematically conducted Google searches for the elements of ten popular APIs. We found that their documentation is widely dispersed among many sources, that GitHub and Stack Overflow play a prominent role among the search results, and that most sources are quick to document new API functionalities. These findings inform API vendors about where developers find documentation about their products, they inform developers about places to look for documentation, and they enable researchers to further study the software documentation landscape.	https://doi.org/10.1145/3194793.3194796
602	Golagha, Mojdeh and Raisuddin, Abu Mohammed and Mittag, Lennart and Hellhake, Dominik and Pretschner, Alexander	Aletheia: A Failure Diagnosis Toolchain	10.1145/3183440.3183486	2018	Testing and debugging are time-consuming, tedious and costly. As many automated test generation tools are being applied in practice nowadays, there is a growing need for automated failure diagnosis. We introduce Aletheia, a failure diagnosis toolchain, which aims to help developers and testers reduce failure analysis time. The key ideas include: data generation to provide the relevant data for further analysis, failure clustering to group failing tests based on the hypothesized faults, and fault localization to pinpoint suspicious elements of the code. We evaluated Aletheia in a large-scale industrial case study as well as two open-source projects. Aletheia is released as an open-source tool on Github, and a demo video can be found at: https://youtu.be/BP9D68D02ZI	https://doi.org/10.1145/3183440.3183486
603	Cito, J\\"urgen and Leitner, Philipp and Bosshard, Christian and Knecht, Markus and Mazlami, Genc and Gall, Harald C.	PerformanceHat: Augmenting Source Code with Runtime Performance Traces in the IDE	10.1145/3183440.3183481	2018	Performance problems observed in production environments that have their origin in program code are immensely hard to localize and prevent. Data that can help solve such problems is usually found in external dashboards and is thus not integrated into the software development process. We propose an approach that augments source code with runtime traces to tightly integrate runtime performance traces into developer workflows. Our goal is to create operational awareness of performance problems in developers' code and contextualize this information to tasks they are currently working on. We implemented this approach as an Eclipse IDE plugin for Java applications that is available as an open source project on GitHub. A video of PerformanceHat in action is online: https://youtu.be/fTBBiylRhag	https://doi.org/10.1145/3183440.3183481
604	Badashian, Ali Sajedi and Hindle, Abram and Stroulia, Eleni	Crowdsourced Bug Triaging	10.1109/ICSM.2015.7332503	2015	Bug triaging and assignment is a time-consuming task in big projects. Most research in this area examines the developers' prior development and bug-fixing activities in order to recognize their areas of expertise and assign to them relevant bug fixes. We propose a novel method that exploits a new source of evidence for the developers' expertise, namely their contributions to Q&amp;A platforms such as Stack Overflow. We evaluated this method in the context of the 20 largest GitHub projects, considering 7144 bug reports. Our results demonstrate that our method exhibits superior accuracy to other state-of-the-art methods, and that future bug-assignment algorithms should consider exploring other sources of expertise, beyond the project's version-control system and bug tracker.	https://doi.org/10.1109/ICSM.2015.7332503
605	Shen, Yuju and Jiang, Yanyan and Xu, Chang and Yu, Ping and Ma, Xiaoxing and Lu, Jian	ReScue: Crafting Regular Expression DoS Attacks	10.1145/3238147.3238159	2018	Regular expression (regex) with modern extensions is one of the most popular string processing tools. However, poorly-designed regexes can yield exponentially many matching steps, and lead to regex Denial-of-Service (ReDoS) attacks under well-conceived string inputs. This paper presents Rescue, a three-phase gray-box analytical technique, to automatically generate ReDoS strings to highlight vulnerabilities of given regexes. Rescue systematically seeds (by a genetic search), incubates (by another genetic search), and finally pumps (by a regex-dedicated algorithm) for generating strings with maximized search time. We implemenmted the Rescue tool and evaluated it against 29,088 practical regexes in real-world projects. The evaluation results show that Rescue found 49% more attack strings compared with the best existing technique, and applying Rescue to popular GitHub projects discovered ten previously unknown ReDoS vulnerabilities.	https://doi.org/10.1145/3238147.3238159
606	Pirker, Johanna and Punz, Andreas and Kopf, Johannes	Social Interactions in Game Jams: A Jammer Recommender Tool	10.1145/3337722.3341843	2019	In game jams, the jammer constellations and teams are essential elements for successful and engaging game jams and game jam outcomes. In this paper, we discuss and analyze group forming behavior in jam environments but also look at jammers who want to prefer to jam by themselves. In jam environments, especially the group forming task at the beginning of every game jam is essential for the success of the event and the outcomes. However, it is also one of the most challenging tasks. For this paper, we analyzed the data of the Global Game Jams between 2015-2018 with a focus on the formed groups as well as the linked Github profiles. Based on first results, we build an early prototype for recommending groups for the Global Game Jam automatically.	https://doi.org/10.1145/3337722.3341843
607	Pietri, Antoine and Spinellis, Diomidis and Zacchiroli, Stefano	The Software Heritage Graph Dataset: Large-Scale Analysis of Public Software Development History	10.1145/3379597.3387510	2020	Software Heritage is the largest existing public archive of software source code and accompanying development history. It spans more than five billion unique source code files and one billion unique commits, coming from more than 80 million software projects. These software artifacts were retrieved from major collaborative development platforms (e.g., GitHub, GitLab) and package repositories (e.g., PyPI, Debian, NPM), and stored in a uniform representation linking together source code files, directories, commits, and full snapshots of version control systems (VCS) repositories as observed by Software Heritage during periodic crawls. This dataset is unique in terms of accessibility and scale, and allows to explore a number of research questions on the long tail of public software development, instead of solely focusing on "most starred" repositories as it often happens.	https://doi.org/10.1145/3379597.3387510
608	Hernandez, Anthony and Ng, Kin and Iamnitchi, Adriana	Using Deep Learning for Temporal Forecasting of User Activity on Social Media: Challenges and Limitations	10.1145/3366424.3382184	2020	The recent advances in neural network-based machine learning algorithms promise a revolution in prediction-based tasks in a variety of domains. Of these, forecasting user activity in social media is particularly relevant for problems such as modeling and predicting information diffusion and designing intervention techniques to mitigate disinformation campaigns. Social media seems an ideal context for applying neural network techniques, as they provide large datasets and challenging prediction objectives. Yet, our experiments find a number of limitations in the power of deep neural networks and traditional machine learning approaches in predicting user activity on social media platforms. These limitations are related to dataset characteristics due to temporal aspects of user behavior. This work describes the challenges we encountered while attempting to forecast user activity on two popular social interaction sites: Twitter and GitHub.	https://doi.org/10.1145/3366424.3382184
609	Hardin, Ashley R.	Building Bridges to Customer Needs in Open Source Documentation	10.1145/3328020.3353917	2019	The Red Hat OpenShift documentation repository is situated in a unique open source environment in which anybody with a GitHub account can contribute directly to the documentation set. One of the primary contributors to the documentation repository are developers, which presents a challenge. The technical writers on the Red Hat OpenShift documentation team who collaboratively write, edit, and merge these contributions are faced with the challenge of maintaining user-centered rather than engineering- centered documentation. Furthermore, the technical writers lack direct interaction with external customers. Considering these challenges, this industry insight report discusses several methods that can be employed to maintain a customer-centric focus and improve the documentation set: focus on user stories, network with internal customers and stakeholders who work closest with external customers, and seek opportunities to work on customer cases.	https://doi.org/10.1145/3328020.3353917
610	Wang, Kaiyuan and Sullivan, Allison and Khurshid, Sarfraz	MuAlloy: A Mutation Testing Framework for Alloy	10.1145/3183440.3183488	2018	Creating models of software systems and analyzing the models helps develop more reliable systems. A well-known software modeling tool-set is embodied by the declarative language Alloy and its automatic SAT-based analyzer. Recent work introduced a novel approach to testing Alloy models to validate their correctness in the spirit of traditional software testing: A Unit defined the foundations of testing (unit tests, test execution, and model coverage) for Alloy, and MuAlloy defined mutation testing (mutation operators, mutant generation, and equivalent mutant checking) for Alloy. This tool paper describes our Java implementation of MuAlloy, which is a command-line tool that we released as an open-source project on GitHub. Our experimental results show that MuAlloy is efficient and practical. The demo video for MuAlloy can be found at https://youtu.be/3lvnQKiLcLE.	https://doi.org/10.1145/3183440.3183488
611	Zhang, Yuhao and Chen, Yifan and Cheung, Shing-Chi and Xiong, Yingfei and Zhang, Lu	An Empirical Study on TensorFlow Program Bugs	10.1145/3213846.3213866	2018	Deep learning applications become increasingly popular in important domains such as self-driving systems and facial identity systems. Defective deep learning applications may lead to catastrophic consequences. Although recent research efforts were made on testing and debugging deep learning applications, the characteristics of deep learning defects have never been studied. To fill this gap, we studied deep learning applications built on top of TensorFlow and collected program bugs related to TensorFlow from StackOverflow QA pages and Github projects. We extracted information from QA pages, commit messages, pull request messages, and issue discussions to examine the root causes and symptoms of these bugs. We also studied the strategies deployed by TensorFlow users for bug detection and localization. These findings help researchers and TensorFlow users to gain a better understanding of coding defects in TensorFlow programs and point out a new direction for future research.	https://doi.org/10.1145/3213846.3213866
612	Coelho, Jailton and Valente, Marco Tulio	Why Modern Open Source Projects Fail	10.1145/3106237.3106246	2017	Open source is experiencing a renaissance period, due to the appearance of modern platforms and workflows for developing and maintaining public code. As a result, developers are creating open source software at speeds never seen before. Consequently, these projects are also facing unprecedented mortality rates. To better understand the reasons for the failure of modern open source projects, this paper describes the results of a survey with the maintainers of 104 popular GitHub systems that have been deprecated. We provide a set of nine reasons for the failure of these open source projects. We also show that some maintenance practices---specifically the adoption of contributing guidelines and continuous integration---have an important association with a project failure or success. Finally, we discuss and reveal the principal strategies developers have tried to overcome the failure of the studied projects. 	https://doi.org/10.1145/3106237.3106246
613	Wu, Mingyuan and Ouyang, Yicheng and Zhou, Husheng and Zhang, Lingming and Liu, Cong and Zhang, Yuqun	Simulee: Detecting CUDA Synchronization Bugs via Memory-Access Modeling	10.1145/3377811.3380358	2020	While CUDA has become a mainstream parallel computing platform and programming model for general-purpose GPU computing, how to effectively and efficiently detect CUDA synchronization bugs remains a challenging open problem. In this paper, we propose the first lightweight CUDA synchronization bug detection framework, namely Simulee, to model CUDA program execution by interpreting the corresponding LLVM bytecode and collecting the memory-access information for automatically detecting general CUDA synchronization bugs. To evaluate the effectiveness and efficiency of Simulee, we construct a benchmark with 7 popular CUDA-related projects from GitHub, upon which we conduct an extensive set of experiments. The experimental results suggest that Simulee can detect 21 out of the 24 manually identified bugs in our preliminary study and also 24 previously unknown bugs among all projects, 10 of which have already been confirmed by the developers. Furthermore, Simulee significantly outperforms state-of-the-art approaches for CUDA synchronization bug detection.	https://doi.org/10.1145/3377811.3380358
614	Bass, Len and Holz, Ralph and Rimba, Paul and Tran, An Binh and Zhu, Liming	Securing a Deployment Pipeline	10.1109/RELENG.2015.11	2015	At the RELENG 2014 Q&amp;A, the question was asked, "What is your greatest concern?" and the response was "someone subverting our deployment pipeline". That is the motivation for this paper. We explore what it means to subvert a pipeline and provide several different scenarios of subversion. We then focus on the issue of securing a pipeline. As a result, we provide an engineering process that is based on having trustworthy components mediate access to sensitive portions of the pipeline from other components, which can remain untrustworthy. Applying our process to a pipeline involving Chef, Jenkins, Docker, Github, and AWS, we find that some aspects of our process result in easy to make changes to the pipeline, whereas others are more difficult. Consequently, we have developed a design that hardens the pipeline, although it does not yet completely secure it.	https://doi.org/10.1109/RELENG.2015.11
615	Cheng, Jinghui and Guo, Jin L. C.	Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics	10.1109/CHASE.2019.00011	2019	Contributors to open source software (OSS) communities assume diverse roles to take different responsibilities. One major limitation of the current OSS tools and platforms is that they provide a uniform user interface regardless of the activities performed by the various types of contributors. This paper serves as a non-trivial first step towards resolving this challenge by demonstrating a methodology and establishing knowledge to understand how the contributors' roles and their dynamics, reflected in the activities contributors perform, are exhibited in OSS communities. Based on an analysis of user action data from 29 GitHub projects, we extracted six activities that distinguished four Active roles and five Supporting roles of OSS contributors, as well as patterns in role changes. Through the lens of the Activity Theory, these findings provided rich design guidelines for OSS tools to support diverse contributor roles.	https://doi.org/10.1109/CHASE.2019.00011
616	Ashouri, Mohammadreza	Kaizen: A Scalable Concolic Fuzzing Tool for Scala	10.1145/3426426.3428487	2020	Scala is an open-source programming language created by Martin Odersky in 2001 and released under the BSD or Berkeley Software Distribution license. The language consolidates object-oriented and functional programming in one high-level and robust language. Scala also maintains static types that help to reduce tricky errors during the execution time. In this paper, we introduce ”Kaizen” as a practical security analysis tool that works based on concolic fuzzing for evaluating real-world Scala applications. To evaluated our approach, we analyzed 1,000 popular Scala projects existing on GitHub. As a result, Kaizen could report and exploit 101 security issues; some of those have not been reported before. Furthermore, our performance analysis outcome on the ScalaBench test suite demonstrates a 49% runtime overhead that proves Kaizen’s usefulness for security testing in the Scala ecosystem.	https://doi.org/10.1145/3426426.3428487
617	Cheng, Jinghui and Guo, Jin L.C.	How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study	10.1145/3170427.3188467	2018	Usability and user experience (UX) issues are often not well emphasized and addressed in open source software (OSS) development. There is an imperative need for supporting OSS communities to collaboratively identify, understand, and fix UX design issues in a distributed environment. In this paper, we provide an initial step towards this effort and report on an exploratory study that investigated how the OSS communities currently reported, discussed, negotiated, and eventually addressed usability and UX issues. We conducted in-depth qualitative analysis of selected issue tracking threads from three OSS projects hosted on GitHub. Our findings indicated that discussions about usability and UX issues in OSS communities were largely influenced by the personal opinions and experiences of the participants. Moreover, the characteristics of the community may have greatly affected the focus of such discussion.	https://doi.org/10.1145/3170427.3188467
618	Wang, Zhendong	Assisting the Elite-Driven Open Source Development through Activity Data	10.1145/3368089.3418541	2020	Elite developers, who own the administrative privileges for a project, maintain a diverse profile of contributing activities, and drive the development of open source software (OSS). To advance our understanding and further support the OSS community, I present a fresh approach to investigate developers’ public activities from the fine-grained event data provided by GitHub. Further, I develop this approach into an analysis framework for collecting, modeling, and analyzing elite developers’ online contributing activities. Employing this framework, I have conducted empirical studies on various OSS projects and ecosystems to characterize elite developers’ full-spectrum activities and their dynamics, and also unveil relationships between their effort allocation and projects’ technical outcomes. Finally, I propose to design and implement a toolset based on this framework and my results to date, which supports individual developers’ decision-making and assists their routine workflows with automation.	https://doi.org/10.1145/3368089.3418541
619	Onoue, Saya and Hata, Hideaki and Matsumoto, Kenichi	Software Population Pyramids: The Current and the Future of OSS Development Communities	10.1145/2652524.2652565	2014	Context: Since human power is an essential resource, the number of contributors in a software development community is one of the health indicators of an open source software (OSS) project. For maintaining and increasing the populations in software development communities, both attracting new contributors and retaining existing contributors are important. Goal: Our goal is understanding the current status of projects' population, especially the different experienced contributors' composition of the projects. Method: We propose software population pyramids, a graphical illustration of the distribution of various experience groups in a software development community. Results: From the study with OSS projects in GitHub, we found that the shapes of software population pyramids varies depending on the current status of OSS development communities. Conclusions: This paper present a software population pyramid of the distribution of various experience groups in a software community population. Our results can be considered as predictors of the near future of a project.	https://doi.org/10.1145/2652524.2652565
620	Yang, Tong and Gong, Junzhi and Zhang, Haowei and Zou, Lei and Shi, Lei and Li, Xiaoming	HeavyGuardian: Separate and Guard Hot Items in Data Streams	10.1145/3219819.3219978	2018	Data stream processing is a fundamental issue in many fields, such as data mining, databases, network traffic measurement. There are five typical tasks in data stream processing: frequency estimation, heavy hitter detection, heavy change detection, frequency distribution estimation, and entropy estimation. Different algorithms are proposed for different tasks, but they seldom achieve high accuracy and high speed at the same time. To address this issue, we propose a novel data structure named HeavyGuardian. The key idea is to intelligently separate and guard the information of hot items while approximately record the frequencies of cold items. We deploy HeavyGuardian on the above five typical tasks. Extensive experimental results show that HeavyGuardian achieves both much higher accuracy and higher speed than the state-of-the-art solutions for each of the five typical tasks. The source codes of HeavyGuardian and other related algorithms are available at GitHub.	https://doi.org/10.1145/3219819.3219978
621	Gong, Jiong and Shen, Haihao and Zhang, Guoming and Liu, Xiaoli and Li, Shane and Jin, Ge and Maheshwari, Niharika and Fomenko, Evarist and Segal, Eden	Highly Efficient 8-Bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe	10.1145/3229762.3229763	2018	High throughput and low latency inference of deep neural networks are critical for the deployment of deep learning applications. This paper presents the efficient inference techniques of IntelCaffe, the first Intel(R) optimized deep learning framework that supports efficient 8-bit low precision inference and model optimization techniques of convolutional neural networks on Intel(R) Xeon(R) Scalable Processors. The 8-bit optimized model is automatically generated with a calibration process from FP32 model without the need of fine-tuning or retraining. We show that the inference throughput and latency with ResNet-50, Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively with neglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and 26X-37X from BVLC Caffe. All these techniques have been open-sourced on IntelCaffe GitHub (https://github.com/intel/caffe), and the artifact is provided to reproduce the result on Amazon AWS Cloud.	https://doi.org/10.1145/3229762.3229763
622	Murgia, Alessandro and Concas, Giulio and Tonelli, Roberto and Ortu, Marco and Demeyer, Serge and Marchesi, Michele	On the Influence of Maintenance Activity Types on the Issue Resolution Time	10.1145/2639490.2639506	2014	The ISO/IEC 14764 standard specifies four types of software maintenance activities spanning the different motivations that software engineers have while performing changes to an existing software system. Undoubtedly, this classification has helped in organizing the workflow within software projects, however for planning purposes the relative time differences for the respective tasks remains largely unexplored.In this empirical study, we investigate the influence of the maintenance type on issue resolution time. From GitHub's issue repository, we analyze more than 14000 issue reports taken from 34 open source projects and classify them as corrective, adaptive, perfective or preventive maintenance. Based on this data, we show that the issue resolution time depends on the maintenance type. Moreover, we propose a statistical model to describe the distribution of the issue resolution time for each type of maintenance activity. Finally, we demonstrate the usefulness of this model for scheduling the maintenance workload.	https://doi.org/10.1145/2639490.2639506
623	Wang, Zhendong	Assisting the Elite-Driven Open Source Development through Activity Data	10.1145/3368089.3418541	2020	Elite developers, who own the administrative privileges for a project, maintain a diverse profile of contributing activities, and drive the development of open source software (OSS). To advance our understanding and further support the OSS community, I present a fresh approach to investigate developers’ public activities from the fine-grained event data provided by GitHub. Further, I develop this approach into an analysis framework for collecting, modeling, and analyzing elite developers’ online contributing activities. Employing this framework, I have conducted empirical studies on various OSS projects and ecosystems to characterize elite developers’ full-spectrum activities and their dynamics, and also unveil relationships between their effort allocation and projects’ technical outcomes. Finally, I propose to design and implement a toolset based on this framework and my results to date, which supports individual developers’ decision-making and assists their routine workflows with automation.	https://doi.org/10.1145/3368089.3418541
624	Bissyand\\'e, Tegawend\\'e F. and Thung, Ferdian and Lo, David and Jiang, Lingxiao and R\\'eveill\\`ere, Laurent	Popularity, Interoperability, and Impact of Programming Languages in 100,000 Open Source Projects	10.1109/COMPSAC.2013.55	2013	Programming languages have been proposed even before the era of the modern computer. As years have gone, computer resources have increased and application domains have expanded, leading to the proliferation of hundreds of programming languages, each attempting to improve over others or to address new programming paradigms. These languages range from procedural languages like C, object-oriented languages like Java, and functional languages such as ML and Haskell. Unfortunately, there is a lack of large scale and comprehensive studies that examine the "popularity", "interoperability", and "impact" of various programming languages. To fill this gap, this study investigates a hundred thousands of open source software projects from GitHub to answer various research questions on the "popularity", "interoperability" and "impact" of various languages measured in different ways (e.g., in terms of lines of code, development teams, issues, etc.).	https://doi.org/10.1109/COMPSAC.2013.55
625	Zhang, Hongyu and Jain, Anuj and Khandelwal, Gaurav and Kaushik, Chandrashekhar and Ge, Scott and Hu, Wenxiang	Bing Developer Assistant: Improving Developer Productivity by Recommending Sample Code	10.1145/2950290.2983955	2016	In programming practice, developers often need sample code in order to learn how to solve a programming-related problem. For example, how to reuse an Application Programming Interface (API) of a large-scale software library and how to implement a certain functionality. We believe that previously written code can help developers understand how others addressed the similar problems and can help them write new programs. We develop a tool called Bing Developer Assistant (BDA), which improves developer productivity by recommending sample code mined from public software repositories (such as GitHub) and web pages (such as Stack Overflow). BDA can automatically mine code snippets that implement an API or answer a code search query. It has been implemented as a free-downloadable extension of Microsoft Visual Studio and has received more than 670K downloads since its initial release in December 2014. BDA is publicly available at: http://aka.ms/devassistant. 	https://doi.org/10.1145/2950290.2983955
626	Jia, Ruipeng and Cao, Yanan and Shi, Haichao and Fang, Fang and Liu, Yanbing and Tan, Jianlong	DistilSum: Distilling the Knowledge for Extractive Summarization	10.1145/3340531.3412078	2020	A popular choice for extractive summarization is to conceptualize it as sentence-level classification, supervised by binary labels. While the common metric ROUGE prefers to measure the text similarity, instead of the performance of classifier. For example, BERTSUMEXT, the best extractive classifier so far, only achieves a precision of 32.9% at the top 3 extracted sentences (P@3) on CNN/DM dataset. It is obvious that current approaches cannot model the complex relationship of sentences exactly with 0/1 targets. In this paper, we introduce DistilSum, which contains teacher mechanism and student model. Teacher mechanism produces high entropy soft targets at a high temperature. Our student model is trained with the same temperature to match these informative soft targets and tested with temperature of 1 to distill for ground-truth labels. Compared with large version of BERTSUMEXT, our experimental result on CNN/DM achieves a substantial improvement of 0.99 ROUGE-L score (text similarity) and 3.95 P@3 score (performance of classifier). Our source code will be available on Github.	https://doi.org/10.1145/3340531.3412078
627	Brandt, Carolin E. and Panichella, Annibale and Zaidman, Andy and Beller, Moritz	LogChunks: A Data Set for Build Log Analysis	10.1145/3379597.3387485	2020	Build logs are textual by-products that a software build process creates, often as part of its Continuous Integration (CI) pipeline. Build logs are a paramount source of information for developers when debugging into and understanding a build failure. Recently, attempts to partly automate this time-consuming, purely manual activity have come up, such as rule- or information-retrieval-based techniques.We believe that having a common data set to compare different build log analysis techniques will advance the research area. It will ultimately increase our understanding of CI build failures. In this paper, we present LogChunks, a collection of 797 annotated Travis CI build logs from 80 GitHub repositories in 29 programming languages. For each build log, LogChunks contains a manually labeled log part (chunk) describing why the build failed. We externally validated the data set with the developers who caused the original build failure.The width and depth of the LogChunks data set are intended to make it the default benchmark for automated build log analysis techniques.	https://doi.org/10.1145/3379597.3387485
628	Fischer-Nielsen, Anders and Fu, Zhoulai and Su, Ting and W\\kasowski, Andrzej	The Forgotten Case of the Dependency Bugs: On the Example of the Robot Operating System	10.1145/3377813.3381364	2020	A dependency bug is a software fault that manifests itself when accessing an unavailable asset. Dependency bugs are pervasive and we all hate them. This paper presents a case study of dependency bugs in the Robot Operating System (ROS), applying mixed methods: a qualitative investigation of 78 dependency bug reports, a quantitative analysis of 1354 ROS bug reports against 19553 reports in the top 30 GitHub projects, and a design of three dependency linters evaluated on 406 ROS packages.The paper presents a definition and a taxonomy of dependency bugs extracted from data. It describes multiple facets of these bugs and estimates that as many as 15% (!) of all reported bugs are dependency bugs. We show that lightweight tools can find dependency bugs efficiently, although it is challenging to decide which tools to build and difficult to build general tools. We present the research problem to the community, and posit that it should be feasible to eradicate it from software development practice.	https://doi.org/10.1145/3377813.3381364
629	Babur, \\"Onder and Cleophas, Loek and Brand, Mark	Hierarchical Clustering of Metamodels for Comparative Analysis and Visualization	10.1007/978-3-319-42061-5_1	2016	Many applications in Model-Driven Engineering involve processing multiple models or metamodels. A good example is the comparison and merging of metamodel variants into a common metamodel in domain model recovery. Although there are many sophisticated techniques to process the input dataset, little attention has been given to the initial data analysis, visualization and filtering activities. These are hard to ignore especially in the case of a large dataset, possibly with outliers and sub-groupings. In this paper we present a generic approach for metamodel comparison, analysis and visualization as an exploratory first step for domain model recovery. We propose representing metamodels in a vector space model, and applying hierarchical clustering techniques to compare and visualize them as a tree structure. We demonstrate our approach on two Ecore datasets: a collection of 50 state machine metamodels extracted from GitHub as top search results; and $$sim $$~100 metamodels from 16 different domains, obtained from AtlanMod Metamodel Zoo.	https://doi.org/10.1007/978-3-319-42061-5_1
630	McDonald, Nora	Distributed Leadership in OSS	10.1145/2660398.2660435	2014	Open-source software (OSS) is software whose source code is available to view, change, and distribute without cost, and is typically developed in a collaborative manner that has captured the imagination of those who view the web as enabling more "democratic" models of governance. Researchers have, for years, debated the social structure of OSS projects -- in particular, the extent to which they represent decentralized forms of organization. Many have argued that the significant concentration of code development responsibility raises doubts about whether the level of power-sharing truly qualifies as "distributed" in the way early observers predicted. This research will investigate how changes in the technology that supports these projects -- specifically the greater visibility that characterizes the GitHub workspace may lead to a more broadly and quantifiably distributed leadership. Over the course of several studies employing several methodologies, it will examine leadership in OSS projects when visibility is a feature of the workspace.	https://doi.org/10.1145/2660398.2660435
631	Gousios, Georgios and Pinzger, Martin and Deursen, Arie van	An Exploratory Study of the Pull-Based Software Development Model	10.1145/2568225.2568260	2014	The advent of distributed version control systems has led to the development of a new paradigm for distributed software development; instead of pushing changes to a central repository, developers pull them from other repositories and merge them locally. Various code hosting sites, notably Github, have tapped on the opportunity to facilitate pull-based development by offering workflow support tools, such as code reviewing systems and integrated issue trackers. In this work, we explore how pull-based software development works, first on the GHTorrent corpus and then on a carefully selected sample of 291 projects. We find that the pull request model offers fast turnaround, increased opportunities for community engagement and decreased time to incorporate contributions. We show that a relatively small number of factors affect both the decision to merge a pull request and the time to process it. We also examine the reasons for pull request rejection and find that technical ones are only a small minority. 	https://doi.org/10.1145/2568225.2568260
632	Tsay, Jason T. and Dabbish, Laura and Herbsleb, James	Social Media and Success in Open Source Projects	10.1145/2141512.2141583	2012	Social media are being integrated into work environments. They have the potential to provide essential context and awareness, and increase work performance as a result. However, the specific effects of social media that impact productivity are not well understood. We perform a quantitative analysis of project success of over 5,000 open source software projects hosted on GitHub, a website that provides extensive social media functionality. Adapted from the open source literature, we develop two measures of project success, Developer Attention and Work Contribution. We find that projects with highly socially connected developers are not necessarily the most active or popular projects. Oddly, projects with a high level of developer multitasking, i.e., splitting effort equally across multiple projects, tend to receive less Developer Attention, but greater Work Contribution. Success on both measures is strongly positively associated with greater concentration of work among a small number of developers. We discuss the implications of the findings for social media in online production.	https://doi.org/10.1145/2141512.2141583
633	Hassan, Foyzul and Mostafa, Shaikh and Lam, Edmund S. L. and Wang, Xiaoyin	Automatic Building of Java Projects in Software Repositories: A Study on Feasibility and Challenges	10.1109/ESEM.2017.11	2017	Despite the advancement in software build tools such as Maven and Gradle, human involvement is still often required in software building. To enable large-scale advanced program analysis and data mining of software artifacts, software engineering researchers need to have a large corpus of built software, so automatic software building becomes essential to improve research productivity. In this paper, we present a feasibility study on automatic software building. Particularly, we first put state-of-the-art build automation tools (Ant, Maven and Gradle) to the test by automatically executing their respective default build commands on top 200 Java projects from GitHub. Next, we focus on the 86 projects that failed this initial automated build attempt, manually examining and determining correct build sequences to build each of these projects. We present a detailed build failure taxonomy from these build results and show that at least 57% build failures can be automatically resolved.	https://doi.org/10.1109/ESEM.2017.11
634	Gupta, Yash and Khan, Yusaira and Gallaba, Keheliya and McIntosh, Shane	The Impact of the Adoption of Continuous Integration on Developer Attraction and Retention	10.1109/MSR.2017.37	2017	Open-source projects rely on attracting new and retaining old contributors for achieving sustainable success. One may suspect that adopting new development practices like Continuous Integration (CI) should improve the attractiveness of a project. However, little is known about the impact that adoption of CI has on developer attraction and retention. To bridge this gap, we study how the introduction of Travis CI---a popular CI service provider---impacts developer attraction and retention in 217 GitHub repositories. Surprisingly, we find that heuristics that estimate the developer attraction and retention of a project are higher in the year before adopting Travis CI than they are in the year following Travis CI adoption. Moreover, the results are statistically significant (Wilcoxon signed rank test, α = 0.05), with small but non-negligible effect sizes (Cliff's delta). Although we do not suspect a causal link, our results are worrisome. More work is needed to ascertain the relationship between CI and developer attraction and retention.	https://doi.org/10.1109/MSR.2017.37
635	Malavolta, Ivano and Lewis, Grace and Schmerl, Bradley and Lago, Patricia and Garlan, David	How Do You Architect Your Robots? State of the Practice and Guidelines for ROS-Based Systems	10.1145/3377813.3381358	2020	The Robot Operating System (ROS) is the de-facto standard for robotic software. If on one hand ROS is helping roboticists, e.g., by providing a standardized communication platform, on the other hand ROS-based systems are getting larger and more complex and could benefit from good software architecture practices. This paper presents an observational study aimed at (i) unveiling the state-of-the-practice for architecting ROS-based systems and (ii) providing guidance to roboticists about how to properly architect ROS-based systems. To achieve these goals, we (i) build a dataset of 335 GitHub repositories containing real open-source ROS-based systems, (ii) mine the repositories for extracting the state of the practice about how roboticists are architecting them, and (iii) synthesize a catalog of 49 evidence-based guidelines for architecting ROS-based systems. The guidelines have been validated by 77 roboticists working on real-world open-source ROS-based systems.	https://doi.org/10.1145/3377813.3381358
636	Park, Yubin and Ho, Joyce C.	CaliForest: Calibrated Random Forest for Health Data	10.1145/3368555.3384461	2020	Real-world predictive models in healthcare should be evaluated in terms of discrimination, the ability to differentiate between high and low risk events, and calibration, or the accuracy of the risk estimates. Unfortunately, calibration is often neglected and only discrimination is analyzed. Calibration is crucial for personalized medicine as they play an increasing role in the decision making process. Since random forest is a popular model for many healthcare applications, we propose CaliForest, a new calibrated random forest. Unlike existing calibration methodologies, CaliForest utilizes the out-of-bag samples to avoid the explicit construction of a calibration set. We evaluated CaliForest on two risk prediction tasks obtained from the publicly-available MIMIC-III database. Evaluation on these binary prediction tasks demonstrates that CaliForest can achieve the same discriminative power as random forest while obtaining a better-calibrated model evaluated across six different metrics. CaliForest will be published on the standard Python software repository and the code will be openly available on Github.	https://doi.org/10.1145/3368555.3384461
637	Jiang, Jyun-Yu and Cheng, Pu-Jen and Wang, Wei	Open Source Repository Recommendation in Social Coding	10.1145/3077136.3080753	2017	Social coding and open source repositories have become more and more popular. Software developers have various alternatives to contribute themselves to the communities and collaborate with others. However, nowadays there is no effective recommender suggesting developers appropriate repositories in both the academia and the industry. Although existing one-class collaborative filtering (OCCF) approaches can be applied to this problem, they do not consider particular constraints of social coding such as the programming languages, which, to some extent, associate the repositories with the developers. The aim of this paper is to investigate the feasibility of leveraging user programming language preference to improve the performance of OCCF-based repository recommendation. Based on matrix factorization, we propose language-regularized matrix factorization (LRMF), which is regularized by the relationships between user programming language preferences. Extensive experiments have been conducted on the real-world dataset of GitHub. The results demonstrate that our framework significantly outperforms five competitive baselines.	https://doi.org/10.1145/3077136.3080753
638	McMillion, Brendan and Sullivan, Nick	Attacking White-Box AES Constructions	10.1145/2995306.2995314	2016	A white-box implementation of the Advanced Encryption Standard (AES) is a software implementation which aims to prevent recovery of the block cipher's master secret key. This paper refines the design criteria for white-box AES constructions by describing new attacks on past proposals which are conceptually very simple and introduces a new family of white-box AES constructions. Our attacks have a decomposition phase, followed by a disambiguation phase. The decomposition phase applies an SASAS-style cryptanalysis to convert the implementation into a simpler form, while the disambiguation phase converts the simpler form into a unique canonical form. It's then trivial to recover the master secret key of the implementation from its canonical form. We move on to discuss the hardness of SPN disambiguation as a problem on its own, and how to construct white-boxes from it. Implementations of all described attacks and constructions are provided on GitHub at https://github.com/OpenWhiteBox/	https://doi.org/10.1145/2995306.2995314
639	Yu, Yue and Wang, Huaimin and Yin, Gang and Ling, Charles X.	Who Should Review This Pull-Request: Reviewer Recommendation to Expedite Crowd Collaboration	10.1109/APSEC.2014.57	2014	Github facilitates the pull-request mechanism as an outstanding social coding paradigm by integrating with social media. The review process of pull-requests is a typical crowd sourcing job which needs to solicit opinions of the community. Recommending appropriate reviewers can reduce the time between the submission of a pull-request and the actual review of it. In this paper, we firstly extend the traditional Machine Learning (ML) based approach of bug triaging to reviewer recommendation. Furthermore, we analyze social relations between contributors and reviewers, and propose a novel approach to recommend highly relevant reviewers by mining comment networks (CN) of given projects. Finally, we demonstrate the effectiveness of these two approaches with quantitative evaluations. The results show that CN-based approach achieves a significant improvement over the ML-based approach, and on average it reaches a precision of 78% and 67% for top-1 and top-2 recommendation respectively, and a recall of 77% for top-10 recommendation.	https://doi.org/10.1109/APSEC.2014.57
640	Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor	Caffe: Convolutional Architecture for Fast Feature Embedding	10.1145/2647868.2654889	2014	Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.	https://doi.org/10.1145/2647868.2654889
641	Tourani, Reza and Torres, George and Misra, Satyajayant	PERSIA: A PuzzlE-Based InteReSt FloodIng Attack Countermeasure	10.1145/3405656.3418709	2020	With the proliferation of smart and connected mobile, wireless devices at the edge, Distributed Denial of Service (DDoS) attacks are increasing. Weak security, improper commissioning, and the fast, non-standardized growth of the IoT industry are the major contributors to the recent DDoS attacks, e.g., Mirai Botnet attack on Dyn and Memcached attack on GitHub. Similar to UDP/TCP flooding (common DDoS attack vector), request flooding attack is the primary DDoS vulnerability in the Named-Data Networking (NDN) architecture.In this paper, we propose PERSIA, a distributed request flooding prevention and mitigation framework for NDN-enabled ISPs, to ward-off attacks at the edge. PERSIA's edge-centric attack prevention mechanism eliminates the possibility of successful attacks from malicious end hosts. In the presence of compromised infrastructure (routers), PERSIA dynamically deploys an in-network mitigation strategy to minimize the attack's magnitude. Our experimentation demonstrates PERSIA's resiliency and effectiveness in preventing and mitigating DDoS attacks while maintaining legitimate users' quality of experience (&gt; 99.92% successful packet delivery rate).	https://doi.org/10.1145/3405656.3418709
642	Li, Renqiang and Liu, Hong and Wang, Xiangdong and Qian, Yueliang	DSBI: Double-Sided Braille Image Dataset and Algorithm Evaluation for Braille Dots Detection	10.1145/3301506.3301532	2018	Braille is an effective way for the visually impaired to learn knowledge and obtain information. Braille image recognition aims to automatically detect Braille dots in the whole Braille image. There is no available public datasets for Braille image recognition to push relevant research and evaluate algorithms. This paper constructs a large-scale Double-Sided Braille Image dataset DSBI with detailed Braille recto dots, verso dots and Braille cells annotation. To quickly annotate Braille images, an auxiliary annotation strategy is proposed, which adopts initial automatic detection of Braille dots and modifies annotation results by convenient human-computer interaction method. This labeling strategy can averagely increase label efficiency by six times for recto dots annotation in one Braille image. Braille dots detection is the core and basic step for Braille image recognition. This paper also evaluates some Braille dots detection methods on our dataset DSBI and gives the benchmark performance of recto dots detection. We have released our Braille images dataset on the GitHub website.	https://doi.org/10.1145/3301506.3301532
643	Murthy, Sean and Figueroa, Andrew and Rollo, Steven	Toward a Large-Scale Open Learning System for Data Management	10.1145/3231644.3231673	2018	This paper describes ClassDB, a free and open source system to enable large-scale learning of data management. ClassDB is different from existing solutions in that the same system supports a wide range of data-management topics from introductory SQL to advanced "native analytics" where code in SQL and non-SQL languages (Python and R) run inside a database management system. Each student/team maintains their own sandbox which instructors can read and provide feedback. Both students and instructors can review activity logs to analyze progress and determine future course of action. ClassDB is currently in its second pilot and is scheduled for a larger trial later this year. After the trials, ClassDB will be made available to about 4,000 students in the university system, which comprises four universities and 12 community colleges. ClassDB is built in collaboration with students employing modern DevOps processes. Its source code and documentation are available in a public GitHub repository. ClassDB is work in progress.	https://doi.org/10.1145/3231644.3231673
644	Xu, Guanshuo	Deep Convolutional Neural Network to Detect J-UNIWARD	10.1145/3082031.3083236	2017	This paper presents an empirical study on applying convolutional neural networks (CNNs) to detecting J-UNIWARD -- one of the most secure JPEG steganographic method. Experiments guiding the architectural design of the CNNs have been conducted on the JPEG compressed BOSSBase containing 10,000 covers of size 512\\texttimes512. Results have verified that both the pooling method and the depth of the CNNs are critical for performance. Results have also proved that a 20-layer CNN, in general, outperforms the most sophisticated feature-based methods, but its advantage gradually diminishes on hard-to-detect cases. To show that the performance generalizes to large-scale databases and to different cover sizes, one experiment has been conducted on the CLS-LOC dataset of ImageNet containing more than one million covers cropped to unified size of 256\\texttimes256. The proposed 20-layer CNN has cut the error achieved by a CNN recently proposed for large-scale JPEG steganalysis by 35%. Source code is available via GitHub: https://github.com/GuanshuoXu/deep_cnn_jpeg_steganalysis	https://doi.org/10.1145/3082031.3083236
645	Wressnegger, Christian and Yamaguchi, Fabian and Maier, Alwin and Rieck, Konrad	Twice the Bits, Twice the Trouble: Vulnerabilities Induced by Migrating to 64-Bit Platforms	10.1145/2976749.2978403	2016	Subtle flaws in integer computations are a prime source for exploitable vulnerabilities in system code. Unfortunately, even code shown to be secure on one platform can be vulnerable on another, making the migration of code a notable security challenge. In this paper, we provide the first study on how code that works as expected on 32-bit platforms can become vulnerable on 64-bit platforms. To this end, we systematically review the effects of data model changes between platforms. We find that the larger width of integer types and the increased amount of addressable memory introduce previously non-existent vulnerabilities that often lie dormant in program code. We empirically evaluate the prevalence of these flaws on the source code of Debian stable ("Jessie") and 200 popular open-source projects hosted on GitHub. Moreover, we discuss 64-bit migration vulnerabilities that have been discovered as part of our study, including vulnerabilities in Chromium, the Boost C++ Libraries, libarchive, the Linux Kernel, and zlib.	https://doi.org/10.1145/2976749.2978403
646	Yan, Yan and Menarini, Massimiliano and Griswold, William	Mining Software Contracts for Software Evolution	10.1109/ICSME.2014.76	2014	Maintenance and evolution are important parts for all successful software projects. In recent years, version control systems have played a key role in software development process. Not only do they provide a means to coordinate programmers, organize and manage source code, but they also persist the evolution history of the source code into their software repositories. Mining software repositories has provided many insights on the evolution of software, both for researchers and practitioners. In this paper we propose that versioned software contracts--mined from software repositories--can be a powerful tool for better understanding and supporting software evolution. Tooling support is critical, due to the complexities of configuring, compiling, and running the software to produce meaningful inferred contracts. This paper contributes both techniques and tool support for downloading, building, and analyzing open source software from social coding sites like GitHub. The tool automatically produces a description of software evolution represented by versions of program invariants.	https://doi.org/10.1109/ICSME.2014.76
647	Gasparini, Mattia and Izquierdo, Javier Luis C\\'anovas and Claris\\'o, Robert and Brambilla, Marco and Cabot, Jordi	Analyzing Rich-Club Behavior in Open Source Projects	10.1145/3306446.3340825	2019	The network of collaborations in an open source project can reveal relevant emergent properties that influence its prospects of success. In this work, we analyze open source projects to determine whether they exhibit a rich-club behavior, i.e., a phenomenon where contributors with a high number of collaborations (i.e., strongly connected within the collaboration network) are likely to cooperate with other well-connected individuals. The presence or absence of a rich-club has an impact on the sustainability and robustness of the project.For this analysis, we build and study a dataset with the 100 most popular projects in GitHub, exploiting connectivity patterns in the graph structure of collaborations that arise from commits, issues and pull requests. Results show that rich-club behavior is present in all the projects, but only few of them have an evident club structure. We compute coefficients both for single source graphs and the overall interaction graph, showing that rich-club behavior varies across different layers of software development. We provide possible explanations of our results, as well as implications for further analysis.	https://doi.org/10.1145/3306446.3340825
648	Manglaviti, Marco and Coronado-Montoya, Eduardo and Gallaba, Keheliya and McIntosh, Shane	An Empirical Study of the Personnel Overhead of Continuous Integration	10.1109/MSR.2017.31	2017	Continuous Integration (CI) is a software development practice where changes to the codebase are compiled and automatically checked for software quality issues. Like any software artifact (e.g., production code, build specifications), CI systems require an investment of development resources in order to keep them running smoothly.In this paper, we examine the human resources that are associated with developing and maintaining CI systems. Through the analysis of 1,279 GitHub repositories that adopt Travis CI (a popular CI service provider), we observe that: (i) there are 0 to 6 unique contributors to CI-related development in any 30-day period, regardless of project size; and (ii) the total number of CI developers has an upper bound of 15 for 99.2% of the studied projects, regardless of overall team size. These results indicate that service-based CI systems only require a small proportion of the development team to contribute. These costs are almost certainly outweighed by the reported benefits of CI (e.g., team communication and time-to-market for new content).	https://doi.org/10.1109/MSR.2017.31
649	Miao, Hui and Li, Ang and Davis, Larry S. and Deshpande, Amol	On Model Discovery For Hosted Data Science Projects	10.1145/3076246.3076252	2017	Alongside developing systems for scalable machine learning and collaborative data science activities, there is an increasing trend toward publicly shared data science projects, hosted in general or dedicated hosting services, such as GitHub and DataHub. The artifacts of the hosted projects are rich and include not only text files, but also versioned datasets, trained models, project documents, etc. Under the fast pace and expectation of data science activities, model discovery, i.e., finding relevant data science projects to reuse, is an important task in the context of data management for end-to-end machine learning. In this paper, we study the task and present the ongoing work on ModelHub Discovery, a system for finding relevant models in hosted data science projects. Instead of prescribing a structured data model for data science projects, we take an information retrieval approach by decomposing the discovery task into three major steps: project query and matching, model comparison and ranking, and processing and building ensembles with returned models. We describe the motivation and desiderata, propose techniques, and present opportunities and challenges for model discovery for hosted data science projects.	https://doi.org/10.1145/3076246.3076252
650	Setia, Simran and Iyengar, S. R.S. and Verma, Amit Arjun	QWiki: Need for QnA &amp; Wiki to Co-Exist	10.1145/3412569.3412576	2020	Access to knowledge has never been as easy and quick as it has been in the 21st century. With the advent of the Internet and crowd-sourced knowledge building portals such as Wikipedia, Stack Exchange, Quora, and GitHub, information is just a click away. It is interesting to observe that the crowd builds these information repositories and not the experts. Information accumulation on a wiki-like portal and discussions on the QnA forum function independently as collaborative knowledge building practices. There is a need to understand the best possible practices to acquire and maintain knowledge in such crowdsourced portals. In this paper, we introduce QWiki, a novel approach of integrating a wiki-like portal and a QnA forum, seeking the union of aforementioned independent collaborative practices. The experimental analysis demonstrates that QWiki helps in knowledge acquisition and knowledge building process. The proposed model highlights the importance of interaction between a wiki-like portal and a QnA forum.	https://doi.org/10.1145/3412569.3412576
651	Freudenstein, Dietmar and Radduenz, Jeannette and Junker, Maximilian and Eder, Sebastian and Hauptmann, Benedikt	Automated Test-Design from Requirements: The Specmate Tool	10.1145/3195538.3195543	2018	Designing a small set of tests that nonetheless cover the requirements sufficiently is tantamount to keep costs for testing at bay while still maintaining the necessary quality. Engineering an optimal test-suite requires both, insight into the domain and the system under test, but also carefully examining the combinatorics inherent in the requirements. Especially the second part is a cognitive challenge and systematic methods are cumbersome when performed by hand. In this paper, we present Specmate, a tool that supports and partly automates the design of tests from requirements. It provides light-weight modeling techniques to capture requirements, test generation facilities to create test specifications and further supporting functions to derive test procedures or test-scripts from specifications. Specmate has been developed and evaluated in the context of one of the core business systems of Allianz Deutschland, a large insurance company. The source code is freely available at GitHub and an online-demo of Specmate is available at http://specmate.in.tum.de.	https://doi.org/10.1145/3195538.3195543
652	Lin, Yuzhen and Wang, Rangding and Yan, Diqun and Dong, Li and Zhang, Xueyuan	Audio Steganalysis with Improved Convolutional Neural Network	10.1145/3335203.3335736	2019	Deep learning, especially the convolutional neural network (CNN), has enjoyed significant success in many fields, e.g., image recognition. Recently, CNN has successfully applied to multimedia steganalysis. However, the detection performance is still unsatisfactory. In this work, we propose an improved CNN-based method for audio steganalysis. Specifically, a special convolutional layer is first carefully designed, which could capture the minor steganographic noise. Then, a truncated linear unit is adapted to activate the output of shallow convolutional layer. In addition, we employ the average pooling to minimize the over-fitting risk. Finally, a parameter transfer strategy is adopted, aiming to boost the detection performance for the low embedding-rate cases. The experimental results evaluated on 30,000 audio clips verify the effectiveness of our method for a variety of embedding rates. Compared with the existing CNN-based steganalysis methods, our proposed method could achieve superior performance. To facilitate the reproducible research, the source code will be released at GitHub.	https://doi.org/10.1145/3335203.3335736
653	Soto, Mauricio and Coker, Zack and Goues, Claire Le	Analyzing the Impact of Social Attributes on Commit Integration Success	10.1109/MSR.2017.34	2017	As the software development community makes it easier to contribute to open source projects, the number of commits and pull requests keep increasing. However, this exciting growth renders it more difficult to only accept quality contributions. Recent research has found that both technical and social factors predict the success of project contributions on GitHub. We take this question a step further, focusing on predicting continuous integration build success based on technical and social factors involved in a commit. Specifically, we investigated if social factors (such as being a core member of the development team, having a large number of followers, or contributing a large number of commits) improve predictions of build success. We found that social factors cause a noticeable increase in predictive power (12%), core team members are more likely to pass the build tests (10%), and users with 1000 or more followers are more likely to pass the build tests (10%).	https://doi.org/10.1109/MSR.2017.34
654	Treude, Christoph and Figueira Filho, Fernando and Kulesza, Uir\\'a	Summarizing and Measuring Development Activity	10.1145/2786805.2786827	2015	Software developers pursue a wide range of activities as part of their work, and making sense of what they did in a given time frame is far from trivial as evidenced by the large number of awareness and coordination tools that have been developed in recent years. To inform tool design for making sense of the information available about a developer's activity, we conducted an empirical study with 156 GitHub users to investigate what information they would expect in a summary of development activity, how they would measure development activity, and what factors influence how such activity can be condensed into textual summaries or numbers. We found that unexpected events are as important as expected events in summaries of what a developer did, and that many developers do not believe in measuring development activity. Among the factors that influence summarization and measurement of development activity, we identified development experience and programming languages. 	https://doi.org/10.1145/2786805.2786827
655	Mandal, Amit and Ferrara, Pietro and Khlyebnikov, Yuliy and Cortesi, Agostino and Spoto, Fausto	Cross-Program Taint Analysis for IoT Systems	10.1145/3341105.3373924	2020	Cross-program propagation of tainted data (such as sensitive information or user input) in an interactive IoT system is listed among the OWASP IoT top 10 most critical security risks. When programs run on distinct devices, as it occurs in IoT systems, they communicate through different channels in order to implement some functionality. Hence, in order to prove the overall system secure, an analysis must consider how these components interact. Standard taint analyses detect if a value coming from a source (such as methods that retrieve user input or sensitive data) flows into a sink (typically, methods that execute SQL queries or send data into the Internet), unsanitized (that is, not properly escaped). This work devises a cross-program taint analysis that leverages an existing intra-program taint analysis to detect security vulnerabilities in multiple communicating programs. The proposed framework has been implemented above the intra-program taint analysis of the Julia static analyzer. Preliminary experimental results on multi-program IoT systems, publicly available on GitHub, show that the technique is effective and detects inter-program flows of tainted data that could not be discovered by analyzing each program in isolation.	https://doi.org/10.1145/3341105.3373924
656	Zhou, Yang and Yang, Tong and Jiang, Jie and Cui, Bin and Yu, Minlan and Li, Xiaoming and Uhlig, Steve	Cold Filter: A Meta-Framework for Faster and More Accurate Stream Processing	10.1145/3183713.3183726	2018	Approximate stream processing algorithms, such as Count-Min sketch, Space-Saving, etc., support numerous applications in databases, storage systems, networking, and other domains. However, the unbalanced distribution in real data streams poses great challenges to existing algorithms. To enhance these algorithms, we propose a meta-framework, called Cold Filter (CF), that enables faster and more accurate stream processing.Different from existing filters that mainly focus on hot items, our filter captures cold items in the first stage, and hot items in the second stage. Also, existing filters require two-direction communication - with frequent exchanges between the two stages; our filter on the other hand is one-direction - each item enters one stage at most once. Our filter can accurately estimate both cold and hot items, giving it a genericity that makes it applicable to many stream processing tasks. To illustrate the benefits of our filter, we deploy it on three typical stream processing tasks and experimental results show speed improvements of up to 4.7 times, and accuracy improvements of up to 51 times. All source code is made publicly available at Github.	https://doi.org/10.1145/3183713.3183726
657	Rahman, Mohammad Masudur and Roy, Chanchal K. and Lo, David	RACK: Code Search in the IDE Using Crowdsourced Knowledge	10.1109/ICSE-C.2017.11	2017	Traditional code search engines often do not perform well with natural language queries since they mostly apply keyword matching. These engines thus require carefully designed queries containing information about programming APIs for code search. Unfortunately, existing studies suggest that preparing an effective query for code search is both challenging and time consuming for the developers. In this paper, we propose a novel code search tool-RACK-that returns relevant source code for a given code search query written in natural language text. The tool first translates the query into a list of relevant API classes by mining keyword-API associations from the crowdsourced knowledge of Stack Overflow, and then applies the reformulated query to GitHub code search API for collecting relevant results. Once a query related to a programming task is submitted, the tool automatically mines relevant code snippets from thousands of open-source projects, and displays them as a ranked list within the context of the developer's programming environment-the IDE. Tool page: http://www.usask.ca/?masud.rahman/rack	https://doi.org/10.1109/ICSE-C.2017.11
658	Zhang, Huaizheng and Li, Yuanming and Ai, Qiming and Luo, Yong and Wen, Yonggang and Jin, Yichao and Ta, Nguyen Binh Duong	Hysia: Serving DNN-Based Video-to-Retail Applications in Cloud	10.1145/3394171.3414536	2020	Combining video streaming and online retailing (V2R) has been a growing trend recently. In this paper, we provide practitioners and researchers in multimedia with a cloud-based platform named Hysia for easy development and deployment of V2R applications. The system consists of: 1) a back-end infrastructure providing optimized V2R related services including data engine, model repository, model serving and content matching; and 2) an application layer which enables rapid V2R application prototyping. Hysia addresses industry and academic needs in large-scale multimedia by: 1) seamlessly integrating state-of-the-art libraries including NVIDIA video SDK, Facebook faiss, and gRPC; 2) efficiently utilizing GPU computation; and 3) allowing developers to bind new models easily to meet the rapidly changing deep learning (DL) techniques. On top of that, we implement an orchestrator for further optimizing DL model serving performance. Hysia has been released as an open source project on GitHub, and attracted considerable attention. We have published Hysia to DockerHub as an official image for seamless integration and deployment in current cloud environments.	https://doi.org/10.1145/3394171.3414536
659	Rossetto, Luca and Giangreco, Ivan and Tanase, Claudiu and Schuldt, Heiko	Vitrivr: A Flexible Retrieval Stack Supporting Multiple Query Modes for Searching in Multimedia Collections	10.1145/2964284.2973797	2016	vitrivr is an open source full-stack content-based multimedia retrieval system with focus on video. Unlike the majority of the existing multimedia search solutions, vitrivr is not limited to searching in metadata, but also provides content-based search and thus offers a large variety of different query modes which can be seamlessly combined: Query by sketch, which allows the user to draw a sketch of a query image and/or sketch motion paths, Query by example, keyword search, and relevance feedback. The vitrivr architecture is self-contained and addresses all aspects of multimedia search, from offline feature extraction, database management to frontend user interaction. The system is composed of three modules: a web-based frontend which allows the user to input the query (e.g., add a sketch) and browse the retrieved results (vitrivr-ui), a database system designed for interactive search in large-scale multimedia collections (ADAM), and a retrieval engine that handles feature extraction and feature-based retrieval (Cineast). The vitrivr source is available on GitHub under the MIT open source (and similar) licenses and is currently undergoing several upgrades as part of the Google Summer of Code 2016.	https://doi.org/10.1145/2964284.2973797
660	Tian, Shi and Kashyap, Abhinav Ramesh and Kan, Min-Yen	ServiceMarq: Extracting Service Contributions from Call for Papers	10.1145/3395027.3419596	2020	In an era, where large numbers of academic research papers are submitted to conferences and journals, the voluntary services of academicians to manage them, is indispensable. The call for contributions of research papers -- through an e-mail or as a webpage, not only solicits research works from scientists, but also lists the names of the researchers and their roles in managing the conference. Tracking such information which showcases the researchers' leadership qualities is becoming increasingly important. Here we present ServiceMarq - a system which proactively tracks service contributions to conferences. It performs focused crawling for website-based call for papers, and integrates archival and natural language processing libraries to achieve both high precision and recall in extracting information. Our results indicate that aggregated service contribution gives an alternative but correlated picture of institutional quality compared against standard bibliometrics. In addition, we have developed a proof of concept website to track service contributions and is available at https://cfp-mining-fe.herokuapp.com and our github repo is available at https://github.com/shitian007/cfp-mining	https://doi.org/10.1145/3395027.3419596
661	Claes, Ma\\"elick and M\\"antyl\\"a, Mika V.	20-MAD: 20 Years of Issues and Commits of Mozilla and Apache Development	10.1145/3379597.3387487	2020	Data of long-lived and high profile projects is valuable for research on successful software engineering in the wild. Having a dataset with different linked software repositories of such projects, enables deeper diving investigations. This paper presents 20-MAD, a dataset linking the commit and issue data of Mozilla and Apache projects. It includes over 20 years of information about 765 projects, 3.4M commits, 2.3M issues, and 17.3M issue comments, and its compressed size is over 6 GB. The data contains all the typical information about source code commits (e.g., lines added and removed, message and commit time) and issues (status, severity, votes, and summary). The issue comments have been pre-processed for natural language processing and sentiment analysis. This includes emoticons and valence and arousal scores. Linking code repository and issue tracker information, allows studying individuals in two types of repositories and provide more accurate time zone information for issue trackers as well. To our knowledge, this the largest linked dataset in size and in project lifetime that is not based on GitHub.	https://doi.org/10.1145/3379597.3387487
662	Qiu, Huilian Sophie and Nolte, Alexander and Brown, Anita and Serebrenik, Alexander and Vasilescu, Bogdan	Going Farther Together: The Impact of Social Capital on Sustained Participation in Open Source	10.1109/ICSE.2019.00078	2019	Sustained participation by contributors in open-source software is critical to the survival of open-source projects and can provide career advancement benefits to individual contributors. However, not all contributors reap the benefits of open-source participation fully, with prior work showing that women are particularly underrepresented and at higher risk of disengagement. While many barriers to participation in open-source have been documented in the literature, relatively little is known about how the social networks that open-source contributors form impact their chances of long-term engagement. In this paper we report on a mixed-methods empirical study of the role of social capital (i.e., the resources people can gain from their social connections) for sustained participation by women and men in open-source GitHub projects. After combining survival analysis on a large, longitudinal data set with insights derived from a user survey, we confirm that while social capital is beneficial for prolonged engagement for both genders, women are at disadvantage in teams lacking diversity in expertise.	https://doi.org/10.1109/ICSE.2019.00078
663	Moreno, David and Due\\~nas, Santiago and Cosentino, Valerio and Fernandez, Miguel Angel and Zerouali, Ahmed and Robles, Gregorio and Gonzalez-Barahona, Jesus M.	SortingHat: Wizardry on Software Project Members	10.1109/ICSE-Companion.2019.00036	2019	Nowadays, software projects and in particular open source ones heavily rely on a plethora of tools (e.g., Git, GitHub) to support and coordinate development activities. Despite their paramount value, they foster to fragment members' contribution, since members can access them with different identities (e.g., email, username). Thus, researchers and practitioners willing to evaluate individual members contributions are often forced to develop ad-hoc scripts or perform manual work to merge identities. This comes at the risk of obtaining wrong results and hindering replication of their work. In this demo we present SortingHat, which helps to track unique identities of project members and their related information such as gender, country and organization enrollments. It allows to manipulate identities interactively as well as to load bulks of identities via batch files (useful for projects with large communities). SortingHat is a component of GrimoireLab, an industry strong free platform developed by Bitergia, which offers commercial software analytics and is part of the CHAOSS project of the Linux Foundation. A video showing SortingHat is available at https://youtu.be/724I1XcQV6c.	https://doi.org/10.1109/ICSE-Companion.2019.00036
664	Das, Dipto and Semaan, Bryan	Quoras: A Python API for Quora Data Collection to Increase Multi-Language Social Science Research	10.1145/3406865.3418333	2020	Quora is a fast growing crowdsourced Q/A site that also creates online social networks and community practices among the users. Operating in several regional languages, it catalyzes more contextual discussions on local incidents and issues. To understand how language-specific social communities conduct Q/A-based discussions on online forums, we need to study Quora platform. As the first step to that, we need a data collection API. We introduce quoras, a Python API for collecting data from Quora. The API relies on Selenium, which is an open-source cross platform web automation framework. The API operates by creating custom HTTPS requests to Quora and parsing responses from it. It has the ability to perform many types of advanced searches that are otherwise only available on the Quora website, and not through any other existing APIs. The quoras API is released under an open-source MIT license and available along with the full API reference on GitHub. The latest stable release is also available on Python Package Index (PyPI).	https://doi.org/10.1145/3406865.3418333
665	Brown, Chris and Parnin, Chris	Comparing Different Developer Behavior Recommendation Styles	10.1145/3387940.3391481	2020	Research shows that one of the most effective ways software engineers discover useful developer behaviors, or tools and practices designed to help developers complete programming tasks, is through human-to-human recommendations from coworkers during work activities. However, due to the increasingly distributed nature of the software industry and development teams, opportunities for these peer interactions are in decline. To overcome the deprecation of peer interactions in software engineering, we explore the impact of several system-to-human recommendation systems, including the recently introduced suggested changes feature on GitHub which allows users to propose code changes to developers on contributions to repositories, to discover their impact on developer recommendations. In this work, we aim to study the effectiveness of suggested changes for recommending developer behaviors by performing a user study with professional software developers to compare static analysis tool recommendations from emails, pull requests, issues, and suggested changes. Our results provide insight into creating systems for recommendations between developers and design implications for improving automated recommendations to software engineers.	https://doi.org/10.1145/3387940.3391481
666	Jia, Ang and Fan, Ming and Xu, Xi and Cui, Di and Wei, Wenying and Yang, Zijiang and Ye, Kai and Liu, Ting	From Innovations to Prospects: What Is Hidden Behind Cryptocurrencies?	10.1145/3379597.3387439	2020	The great influence of Bitcoin has promoted the rapid development of blockchain-based digital currencies, especially the altcoins, since 2013. However, most altcoins share similar source codes, resulting in concerns about code innovations. In this paper, an empirical study on existing altcoins is carried out to offer a thorough understanding of various aspects associated with altcoin innovations. Firstly, we construct the dataset of altcoins, including source code repository, GitHub fork relation, and market capitalization (cap). Then, we analyze the altcoin innovations from the perspective of source code similarities. The results demonstrate that more than 85% of altcoin repositories present high code similarities. Next, a temporal clustering algorithm is proposed to mine the inheritance relationship among various altcoins. The family pedigrees of altcoin are constructed, in which the altcoin presents similar evolution features as biology, such as power-law in family size, variety in family evolution, etc. Finally, we investigate the correlation between code innovations and market capitalization. Although we fail to predict the price of altcoins based on their code similarities, the results show that altcoins with higher innovations reflect better market prospects.	https://doi.org/10.1145/3379597.3387439
667	Liu, Qin and Liu, Zihe and Zhu, Hongming and Fan, Hongfei and Du, Bowen and Qian, Yu	Generating Commit Messages from Diffs Using Pointer-Generator Network	10.1109/MSR.2019.00056	2019	The commit messages in source code repositories are valuable but not easy to be generated manually in time for tracking issues, reporting bugs, and understanding codes. Recently published works indicated that the deep neural machine translation approaches have drawn considerable attentions on automatic generation of commit messages. However, they could not deal with out-of-vocabulary (OOV) words, which are essential context-specific identifiers such as class names and method names in code diffs. In this paper, we propose PtrGNCMsg, a novel approach which is based on an improved sequence-to-sequence model with the pointer-generator network to translate code diffs into commit messages. By searching the smallest identifier set with the highest probability, PtrGNCMsg outperforms recent approaches based on neural machine translation, and first enables the prediction of OOV words. The experimental results based on the corpus of diffs and manual commit messages from the top 2,000 Java projects in GitHub show that PtrGNCMsg outperforms the state-of-the-art approach with improved BLEU by 1.02, ROUGE-1 by 4.00 and ROUGE-L by 3.78, respectively.	https://doi.org/10.1109/MSR.2019.00056
668	Benni, Benjamin and Mosser, S\\'ebastien and Collet, Philippe and Riveill, Michel	Supporting Micro-Services Deployment in a Safer Way: A Static Analysis and Automated Rewriting Approach	10.1145/3167132.3167314	2018	The SOA ecosystem has drastically evolved since its childhood in the early 2000s. From monolithic services, micro-services now cooperate together in ultra-large scale systems. In this context, there is a tremendous need to deploy frequently new services, or new version of existing services. Container-based technologies (e.g., Docker) emerged recently to tool such deployments, promoting a black-box reuse mechanism to support off-the-shelf deployments. Unfortunately, from the service deployment point of view, such form of black-box reuse prevent to ensure what is really shipped inside the container with the service to deploy. In this paper, we propose a formalism to model and statically analyze service deployment artifacts based on state of the art deployment platforms. The static analysis mechanism leverages the hierarchy of deployment descriptors to verify a given deployment, as well as rewrite it to automatically fix common errors. The approach is validated through the automation of the guidelines provided by the user community associated to the reference Docker engine, and the analysis of 20,000 real deployment descriptors (hosted on GitHub).	https://doi.org/10.1145/3167132.3167314
669	Masek, Pavel and Fujdiak, Radek and Zeman, Krystof and Hosek, Jiri and Muthanna, Ammar	Remote Networking Technology for IoT: Cloud-Based Access for AllJoyn-Enabled Devices	10.1109/FRUCT-ISPIT.2016.7561528	2016	The Internet of Things (IoT) represents a vision of a future communication between users, systems, and daily objects performing sensing and actuating capabilities with the goal to bring unprecedented convenience and economical benefits. Today, a wide variety of developed solutions for IoT can be seen through the all industry fields. Each of the developed systems is based on the proprietary SW implementation unable (in most cases) to share collected data with others. Trying to offer common communication platform for IoT, AllSeen Alliance introduced Alljoyn framework - interoperable platform for devices (sensors, actuators, etc.) and applications to communicate among themselves regardless of brands, transport technologies, and operating systems. In this paper, we discuss an application for remote management of light systems built as an extension of Alljoyn Framework - developed application is independent on communication technologies (e.g., ZigBee or WiFi). Besides provided communication independence, the presented framework can run on both major SoC architectures ARM and MIPS. To this end, we believe that our application (available as open source on GitHub) can serve as building block in future IoT / Smart home implementations.	https://doi.org/10.1109/FRUCT-ISPIT.2016.7561528
670	Arora, Ritu and Wani, Anand and Vineet, Ankur and Dhandhalya, Bhavik and Sharma, Yashvardhan and Goel, Sanjay	Continuous Conflict Prediction during Collaborative Software Development: A Step-before Continuous Integration	10.1145/3378936.3378951	2020	Concurrent activities of collaborative developers over shared project repositories might lead to direct and indirect conflicts. Software Configuration Management systems are designed to capture direct or merge conflicts which arise due to concurrent editing of same shared artifact. However, inconsistencies caused owing to indirect conflicts which arise because of concurrent editing of related artifacts might enter the codebase, since SCM systems have limited capabilities to capture these. Although, Continuous Integration process which is deployed to build the entire codebase with every commit, is quite effective in capturing several type of inconsistencies. However, still few categories of behavioral semantic inconsistencies might evade the build process and penetrate into codebase. In this paper, we propose the Continuous Conflict Prediction Framework which describes a cyclic, real-time, continuous process for conflict prediction which is executed during the process of code creation by collaborative developers. This framework entails a critical conflict-prediction and awareness-generation process which helps in capturing conflicts during development process itself and hence minimizes the number of conflicts entering the project codebase. The proposed framework is realized through implementation of the tool named Collaboration Over GitHub.	https://doi.org/10.1145/3378936.3378951
671	Bucchiarone, Antonio and Cicchetti, Antonio	Towards an Adaptive City Journey Planner with MDE	10.1145/3270112.3270127	2018	Although there are many city journey planners already available in the market and involving various transportation services, there is none yet that allows city mobility operators and local government municipalities to be an active part of the city's mobility.In this demonstrator, we present our first attempt towards multi-view based modelling of adaptive and multimodal city journey planners. In particular, by exploiting Model-Driven Engineering (MDE) techniques, the different stakeholders involved in the city mobility are able to provide their own updated information or promote their own challenges at higher levels of abstraction. Such information is then automatically translated into code-based artefacts that implement/ensure the desired journey planning behaviour, notably to filter travel routes and to make the city mobility more sustainable.The journey planner prototype, implementing the proposed solution, is demonstrated in the context of Trento city mobility. A supporting video illustrating the main features and a demonstration of our solution can be found at: https://youtu.be/KM21WD2dQGs, while the related artefacts and the details on how to create your own prototype are available at the demo GitHub repository, reachable at https://github.com/modelsconf2018/artifact-evaluation/tree/master/bucchiarone.	https://doi.org/10.1145/3270112.3270127
672	Iglesias, Enrique and Jozashoori, Samaneh and Chaves-Fraga, David and Collarana, Diego and Vidal, Maria-Esther	SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs	10.1145/3340531.3412881	2020	In recent years, the amount of data has increased exponentially, and knowledge graphs have gained attention as data structures to integrate data and knowledge harvested from myriad data sources. However, data complexity issues like large volume, high-duplicate rate, and heterogeneity usually characterize these data sources, being required data management tools able to address the negative impact of these issues on the knowledge graph creation process. In this paper, we propose the SDM-RDFizer, an interpreter of the RDF Mapping Language (RML), to transform raw data in various formats into an RDF knowledge graph. SDM-RDFizer implements novel algorithms to execute the logical operators between mappings in RML, allowing thus to scale up to complex scenarios where data is not only broad but has a high-duplication rate. We empirically evaluate the SDM-RDFizer performance against diverse testbeds with diverse configurations of data volume, duplicates, and heterogeneity. The observed results indicate that SDM-RDFizer is two orders of magnitude faster than state of the art, thus, meaning that SDM-RDFizer an interoperable and scalable solution for knowledge graph creation. SDM-RDFizer is publicly available as a resource through a Github repository and a DOI.	https://doi.org/10.1145/3340531.3412881
673	Santos, Jo\\~ao Pedro and Rocha, Tha\\'\\is and Borba, Paulo	Improving the Prediction of Files Changed by Programming Tasks	10.1145/3357141.3357145	2019	Integration conflicts often damage software quality and developers' productivity in a collaborative development environment. For reducing merge conflicts, we could avoid asking developers to execute potentially conflicting tasks in parallel, as long as we can predict the files to be changed by each task. As manually predicting that is hard, the TAITI tool tries to do that in the context of BDD (Behaviour-Driven Development) projects, by statically analysing the automated acceptance tests that validate each task. TAITI computes the set of files that might be executed by the tests of a task (a so called test-based task interface), approximating the files that developers will change when performing the task. Although TAITI performs better than a random task interface, there is space for accuracy improvements. In this paper, we extend the interfaces computed by TAITI by including the dependences of the application files reached by the task tests. To understand the potential benefits of our extension, we evaluate precision and recall of 60 task interfaces from 8 Rails GitHub projects. The results bring evidence that the extended interface improves recall by slightly compromising precision.	https://doi.org/10.1145/3357141.3357145
674	Albano, Alice and Guillaume, Jean-Loup and Heymann, S\\'ebastien and Grand, B\\'en\\'edicte Le	A Matter of Time - Intrinsic or Extrinsic - for Diffusion in Evolving Complex Networks	10.1145/2492517.2492634	2013	Diffusion phenomena occur in many kinds of real-world complex networks, e.g., biological, information or social networks. Because of this diversity, several types of diffusion models have been proposed in the literature: epidemiological models, threshold models, innovation adoption models, among others. Many studies aim at investigating diffusion as an evolving phenomenon but mostly occurring on static networks, and much remains to be done to understand diffusion on evolving networks. In order to study the impact of graph dynamics on diffusion, we propose in this paper an innovative approach based on a notion of intrinsic time, where the time unit corresponds to the appearance of a new link in the graph. This original notion of time allows us to isolate somehow the diffusion phenomenon from the evolution of the network. The objective is to compare the diffusion features observed with this intrinsic time concept from those obtained with traditional (extrinsic) time, based on seconds. The comparison of these time concepts is easily understandable yet completely new in the study of diffusion phenomena. We experiment our approach on synthetic graphs, as well as on a dataset extracted from the Github sofware sharing platform.	https://doi.org/10.1145/2492517.2492634
675	Zeng, Yirui and Ma, Zhengming	A Lightweight Channel-Spatial Attention Network for Real-Time Image De-Raining	10.1145/3379299.3379305	2019	Image de-raining aims to eliminate rain streaks captured by outdoor equipment such as video surveillance, remote sensor and automatic pilot. Recently, a de-raining method called non-locally enhanced encoder-decoder network (NLEDN) has achieved reliability performance. Nevertheless, it is very time consuming (2.2571s per image) and takes up memory so that it cannot be applied to mobile devices to process image in real-time. To solve this problem, we design a lightweight channel-spatial attention network that is 55 times faster (41ms per image) and memory saving. The most advanced performances are achieved in most de-raining data sets. More specifically, we design a channel-spatial attention dense block (CSADB). The channel attention operation will be carried out together with the spatial attention. Our experiments demonstrate that the network can learn more effective features by this way. In order to make our proposed method more lightweight, the depthwise convolutions are adapted in each block to reduce parameters. We conduct experiments on four public synthetic datasets to demonstrate the effectiveness of our proposed method, which achieve excellent performance. And the real-world de-raining results are also tacked into comparison. Moreover, an additional experiment demonstrates that our method also works well on face hallucination task. The relevant code and trained models will be available in GitHub soon.	https://doi.org/10.1145/3379299.3379305
676	Amreen, Sadika and Karnauch, Andrey and Mockus, Audris	Developer Reputation Estimator (DRE)	10.1109/ASE.2019.00107	2019	Evidence shows that developer reputation is extremely important when accepting pull requests or resolving reported issues. It is particularly salient in Free/Libre Open Source Software since the developers are distributed around the world, do not work for the same organization and, in most cases, never meet face to face. The existing solutions to expose developer reputation tend to be forge specific (GitHub), focus on activity instead of impact, do not leverage social or technical networks, and do not correct often misspelled developer identities. We aim to remedy this by amalgamating data from all public Git repositories, measuring the impact of developer work, expose developer's collaborators, and correct notoriously problematic developer identity data. We leverage World of Code (WoC), a collection of an almost complete (and continuously updated) set of Git repositories by first allowing developers to select which of the 34 million(M) Git commit author IDs belong to them and then generating their profiles by treating the selected collection of IDs as that single developer. As a side-effect, these selections serve as a training set for a supervised learning algorithm that merges multiple identity strings belonging to a single individual. As we evaluate the tool and the proposed impact measure, we expect to build on these findings to develop reputation badges that could be associated with pull requests and commits so developers could easier trust and prioritize them.	https://doi.org/10.1109/ASE.2019.00107
677	Javed, Omar and Villaz\\'on, Alex and Binder, Walter	JUniVerse: Large-Scale JUnit-Test Analysis in the Wild	10.1145/3297280.3297453	2019	Current approaches for analyzing large number of open-source projects mainly focus on data mining or on static analysis techniques. On the contrary, research applying dynamic analyses such as Runtime Verification (RV) to open-source projects is scarce. This is due to lack of automatic means for executing arbitrary pieces of software that rely on complex dependencies and input parameters. In this paper, we present a fully automated infrastructure, JUniVerse, to conduct large-scale studies on unit tests in open-source projects in the wild. The proposed infrastructure runs on a cluster for parallel execution. We demonstrate the effectiveness of JUniVerse by conducting a large-scale study on Java projects hosted on GitHub. We apply a selection criteria based on static analysis to select 3 490 active projects. To show the feasibility of JUniVerse, we choose RV as a case study, and investigate the applicability of 182 publicly available JavaMOP specifications to the code exercised by unit tests. Our study reveals that 37 (out of 182) specifications (i.e., 20%) are not applicable to the code exercised by unit tests of real-world projects. Finally, with JUniVerse, we are able to identify a set of specs and projects for future RV studies.	https://doi.org/10.1145/3297280.3297453
678	Redmiles, Elissa and Abad, Mary Allison and Coronado, Isabella and Kross, Sean and Malone, Amelia	A Classroom Tested Accessible Multimedia Resource for Engaging Underrepresented Students in Computing: The University of Maryland Curriculum In A Box	10.1145/2676723.2691870	2015	In 2012, women earned 18% of computer science degrees; African American and Hispanic students made up less than 20% of computing degree holders that year. Research shows that relatable role models and engaging curriculum are required to engage underrepresented students in computing. There is a need for engaging and relatable curriculum to be delivered to students at the middle school level, when these students first begin to lose interest in computing. Thus, based on the results of a survey of current and former middle school computing teachers and a comprehensive literature review, we developed the University of Maryland Curriculum In A Box (CIAB). The CIAB includes profiles of relatable computing role models, accessible video and text curriculum and challenge projects for HTML/CSS. To simulate a "real world" programming environment, the CIAB guides students through programming within open source social media frameworks and Github. The CIAB also includes teacher enablement resources such as assessments and a week-by-week implementation guide. The CIAB was successfully implemented with a group of 6th and 7th grade students in Prince Georges (PG) County, a majority minority county in Maryland. Our demo will provide a walk-through of the CIAB assets, accessibility features and design process, as well as implementation advice informed by our CIAB implementation in PG County.	https://doi.org/10.1145/2676723.2691870
679	Robbins, David E. and Gr\\"uneberg, Alexander and Deus, Helena F. and Tanik, Murat M. and Almeida, Jonas	TCGA Toolbox: An Open Web App Framework for Distributing Big Data Analysis Pipelines for Cancer Genomics	10.1145/2506583.2506595	2013	The diversity and volume of data generated by the cancer genome atlas (TCGA) has been increasing exponentially, with the number of data files hosted by NHI, currently 3/4 million, doubling every 7 months since January 2010. The proponents have recently developed a browser-based self-updating mechanism to catalog this dynamic big data repository. In this report, that foundation is built upon to devise a web app framework to distribute TCGA analytical pipelines in a manner that can be fully reproducible without the usual requirement for a pre-installed specialized computational statistics environment. The solution found relies exclusively of sandboxed code injection (JavaScript) and on access permission configuration by the browser's app store. This framework was devised with an open architecture such that third party analyses, ideally hosted with web-facing version control in a repository such as GitHub, SourceForge, Bitbucket, or Google Code, can be distributed to the toolbox. The openness of the framework developed is specifically reflected by enabling the user to invoke the third party analysis simply by inputing the corresponding URL. Similarly, the toolbox also mediates the ability of the user to then distribute the result of the analysis as a reproducible procedure, also fully invoked as a Universal Resource Locator (URL).	https://doi.org/10.1145/2506583.2506595
680	Aneja, Deepali and McDuff, Daniel and Czerwinski, Mary	Conversational Error Analysis in Human-Agent Interaction	10.1145/3383652.3423901	2020	Conversational Agents (CAs) present many opportunities for changing how we interact with information and computer systems in a more natural, accessible way. Building on research in machine learning and HCI, it is now possible to design and test multi-turn CA that is capable of extended interactions. However, there are many ways in which these CAs can "fail" and fall short of human expectations. We systematically analyzed how five different types of conversational errors impacted perceptions of an embodied CA. Not all errors negatively impacted perceptions of the agent. Repetitions by the agent and clarifications by the human significantly decreased the perceived intelligence and anthropomorphism of the agent. Turn-taking errors significantly decreased the likability of the agent. However, coherence errors significantly positively increased likability, and these errors were also associated with positive valence via facial expressions, suggesting that the users found them amusing. We believe this work is the first to identify that turn-taking, repetition, clarification, and coherence errors directly affect users' acceptance of an embodied CA, and are worth taking note by designers of such systems during dialog configuration. We release the Agent Conversational Error (ACE) dataset, a set of transcripts and error annotations of human-agent conversations. The dataset can be found at the GITHUB link: https://github.com/deepalianeja/ACE-dataset	https://doi.org/10.1145/3383652.3423901
681	Zhang, Jianwei and Zeng, Jia and Yuan, Mingxuan and Rao, Weixiong and Yan, Jianfeng	LDA Revisited: Entropy, Prior and Convergence	10.1145/2983323.2983794	2016	Inference algorithms of latent Dirichlet allocation (LDA), either for small or big data, can be broadly categorized into expectation-maximization (EM), variational Bayes (VB) and collapsed Gibbs sampling (GS). Looking for a unified understanding of these different inference algorithms is currently an important open problem. In this paper, we revisit these three algorithms from the entropy perspective, and show that EM can achieve the best predictive perplexity (a standard performance metric for LDA accuracy) by minimizing directly the cross entropy between the observed word distribution and LDA's predictive distribution. Moreover, EM can change the entropy of LDA's predictive distribution through tuning priors of LDA, such as the Dirichlet hyperparameters and the number of topics, to minimize the cross entropy with the observed word distribution. Finally, we propose the adaptive EM (AEM) algorithm that converges faster and more accurate than the current state-of-the-art SparseLDA [20] and AliasLDA [12] from small to big data and LDA models. The core idea is that the number of active topics, measured by the residuals between E-steps at successive iterations, decreases significantly, leading to the amortized σ(1) time complexity in terms of the number of topics. The open source code of AEM is available at GitHub.	https://doi.org/10.1145/2983323.2983794
682	Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan	Improving Code Search with Co-Attentive Representation Learning	10.1145/3387904.3389269	2020	Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.	https://doi.org/10.1145/3387904.3389269
683	Zhang, Yang and Vasilescu, Bogdan and Wang, Huaimin and Filkov, Vladimir	One Size Does Not Fit All: An Empirical Study of Containerized Continuous Deployment Workflows	10.1145/3236024.3236033	2018	Continuous deployment (CD) is a software development practice aimed at automating delivery and deployment of a software product, following any changes to its code. If properly implemented, CD together with other automation in the development process can bring numerous benefits, including higher control and flexibility over release schedules, lower risks, fewer defects, and easier on-boarding of new developers. Here we focus on the (r)evolution in CD workflows caused by containerization, the virtualization technology that enables packaging an application together with all its dependencies and execution environment in a light-weight, self-contained unit, of which Docker has become the de-facto industry standard. There are many available choices for containerized CD workflows, some more appropriate than others for a given project. Owing to cross-listing of GitHub projects on Docker Hub, in this paper we report on a mixed-methods study to shed light on developers' experiences and expectations with containerized CD workflows. Starting from a survey, we explore the motivations, specific workflows, needs, and barriers with containerized CD. We find two prominent workflows, based on the automated builds feature on Docker Hub or continuous integration services, with different trade-offs. We then propose hypotheses and test them in a large-scale quantitative study.	https://doi.org/10.1145/3236024.3236033
684	Lv, Fei and Zhang, Hongyu and Lou, Jian-guang and Wang, Shaowei and Zhang, Dongmei and Zhao, Jianjun	CodeHow: Effective Code Search Based on API Understanding and Extended Boolean Model	10.1109/ASE.2015.42	2015	Over the years of software development, a vast amount of source code has been accumulated. Many code search tools were proposed to help programmers reuse previously-written code by performing free-text queries over a large-scale codebase. Our experience shows that the accuracy of these code search tools are often unsatisfactory. One major reason is that existing tools lack of query understanding ability. In this paper, we propose CodeHow, a code search technique that can recognize potential APIs a user query refers to. Having understood the potentially relevant APIs, CodeHow expands the query with the APIs and performs code retrieval by applying the Extended Boolean model, which considers the impact of both text similarity and potential APIs on code search. We deploy the backend of CodeHow as a Microsoft Azure service and implement the frontend as a Visual Studio extension. We evaluate CodeHow on a large-scale codebase consisting of 26K C# projects downloaded from GitHub. The experimental results show that when the top 1 results are inspected, CodeHow achieves a precision score of 0.794 (i.e., 79.4% of the first returned results are relevant code snippets). The results also show that CodeHow outperforms conventional code search tools. Furthermore, we perform a controlled experiment and a survey of Microsoft developers. The results confirm the usefulness and effectiveness of CodeHow in programming practices.	https://doi.org/10.1109/ASE.2015.42
685	Steinmacher, Igor and Pinto, Gustavo and Wiese, Igor Scaliante and Gerosa, Marco A.	Almost There: A Study on Quasi-Contributors in Open Source Software Projects	10.1145/3180155.3180208	2018	Recent studies suggest that well-known OSS projects struggle to find the needed workforce to continue evolving---in part because external developers fail to overcome their first contribution barriers. In this paper, we investigate how and why quasi-contributors (external developers who did not succeed in getting their contributions accepted to an OSS project) fail. To achieve our goal, we collected data from 21 popular, non-trivial GitHub projects, identified quasi-contributors, and analyzed their pull-requests. In addition, we conducted surveys with quasi-contributors, and projects' integrators, to understand their perceptions about nonacceptance. We found 10,099 quasi-contributors --- about 70% of the total actual contributors --- that submitted 12,367 nonaccepted pull-requests. In five projects, we found more quasi-contributors than actual contributors. About one-third of the developers who took our survey disagreed with the nonacceptance, and around 30% declared the nonacceptance demotivated or prevented them from placing another pull-request. The main reasons for pull-request nonacceptance from the quasi-contributors' perspective were "superseded/duplicated pull-request" and "mismatch between developer's and team's vision/opinion." A manual analysis of a representative sample of 263 pull-requests corroborated with this finding. We also found reasons related to the relationship with the community and lack of experience or commitment from the quasi-contributors. This empirical study is particularly relevant to those interested in fostering developers' participation and retention in OSS communities.	https://doi.org/10.1145/3180155.3180208
686	Garbervetsky, Diego and Zoppi, Edgardo and Livshits, Benjamin	Toward Full Elasticity in Distributed Static Analysis: The Case of Callgraph Analysis	10.1145/3106237.3106261	2017	In this paper we present the design and implementation of a distributed, whole-program static analysis framework that is designed to scale with the size of the input. Our approach is based on the actor programming model and is deployed in the cloud. Our reliance on a cloud cluster provides a degree of elasticity for CPU, memory, and storage resources. To demonstrate the potential of our technique, we show how a typical call graph analysis can be implemented in a distributed setting. The vision that motivates this work is that every large-scale software repository such as GitHub, BitBucket, or Visual Studio Online will be able to perform static analysis on a large scale. We experimentally validate our implementation of the distributed call graph analysis using a combination of both synthetic and real benchmarks. To show scalability, we demonstrate how the analysis presented in this paper is able to handle inputs that are almost 10 million lines of code (LOC) in size, without running out of memory. Our results show that the analysis scales well in terms of memory pressure independently of the input size, as we add more virtual machines (VMs). As the number of worker VMs increases, we observe that the analysis time generally improves as well. Lastly, we demonstrate that querying the results can be performed with a median latency of 15 ms. 	https://doi.org/10.1145/3106237.3106261
687	Sakor, Ahmad and Singh, Kuldeep and Patel, Anery and Vidal, Maria-Esther	Falcon 2.0: An Entity and Relation Linking Tool over Wikidata	10.1145/3340531.3412777	2020	The Natural Language Processing (NLP) community has significantly contributed to the solutions for entity and relation recognition from a natural language text, and possibly linking them to proper matches in Knowledge Graphs (KGs). Considering Wikidata as the background KG, there are still limited tools to link knowledge within the text to Wikidata. In this paper, we present Falcon 2.0, the first joint entity and relation linking tool over Wikidata. It receives a short natural language text in the English language and outputs a ranked list of entities and relations annotated with the proper candidates in Wikidata. The candidates are represented by their Internationalized Resource Identifier (IRI) in Wikidata. Falcon 2.0 resorts to the English language model for the recognition task (e.g., N-Gram tiling and N-Gram splitting), and then an optimization approach for the linking task. We have empirically studied the performance of Falcon 2.0 on Wikidata and concluded that it outperforms all the existing baselines. Falcon 2.0 is open source and can be reused by the community; all the required instructions of Falcon 2.0 are well-documented at our GitHub repository (https://github.com/SDM-TIB/falcon2.0). We also demonstrate an online API, which can be run without any technical expertise. Falcon 2.0 and its background knowledge bases are available as resources at https://labs.tib.eu/falcon/falcon2/.	https://doi.org/10.1145/3340531.3412777
688	Al Alam, S. M. Didar and Shahnewaz, S. M. and Pfahl, Dietmar and Ruhe, Guenther	Monitoring Bottlenecks in Achieving Release Readiness: A Retrospective Case Study across Ten OSS Projects	10.1145/2652524.2652549	2014	Context: Not releasing software on time can cause substantial loss in revenue. Continuous awareness of the product release status is required. Release readiness is a time-dependent attribute of the status of the product release, which aggregates the degree of satisfaction of a portfolio of release process and product measures.Goal: At different stages of a release cycle, the goal is to understand frequencies and pattern of occurrence of factors affecting project success by restricting the status of release readiness (called bottlenecks).Method: As a form of explorative case study research, we analyzed ten open source software (OSS) projects taken from the GitHub repository. As a retrospective study covering a period of 28 weeks, we monitored eight release readiness attributes and identified their impact on release readiness over time across the ten projects.Results: Feature completion rate, Bug fixing rate, and Features implemented were observed as the most frequent bottlenecks. The most frequent transition between bottlenecks is from Pull-request completion rate to Bug fixing rate. With the exception of Pull-request completion rate, no significant differences were found in occurrence of bottleneck factors between early and late stage of the release cycle.Conclusions: We received an initial understanding of the most frequent bottleneck factors for release readiness and their likelihood of subsequent occurrence. This is intended to guide the effort spent on improving release engineering.	https://doi.org/10.1145/2652524.2652549
689	Ahmed, Iftekhar and Brindescu, Caius and Mannan, Umme Ayda and Jensen, Carlos and Sarma, Anita	An Empirical Examination of the Relationship between Code Smells and Merge Conflicts	10.1109/ESEM.2017.12	2017	Background: Merge conflicts are a common occurrence in software development. Researchers have shown the negative impact of conflicts on the resulting code quality and the development workflow. Thus far, no one has investigated the effect of bad design (code smells) on merge conflicts. Aims: We posit that entities that exhibit certain types of code smells are more likely to be involved in a merge conflict. We also postulate that code elements that are both "smelly" and involved in a merge conflict are associated with other undesirable effects (more likely to be buggy). Method: We mined 143 repositories from GitHub and recreated 6,979 merge conflicts to obtain metrics about code changes and conflicts. We categorized conflicts into semantic or non-semantic, based on whether changes affected the Abstract Syntax Tree. For each conflicting change, we calculate the number of code smells and the number of future bug-fixes associated with the affected lines of code. Results: We found that entities that are smelly are three times more likely to be involved in merge conflicts. Method-level code smells (Blob Operation and Internal Duplication) are highly correlated with semantic conflicts. We also found that code that is smelly and experiences merge conflicts is more likely to be buggy. Conclusion: Bad code design not only impacts maintainability, it also impacts the day to day operations of a project, such as merging contributions, and negatively impacts the quality of the resulting code. Our findings indicate that research is needed to identify better ways to support merge conflict resolution to minimize its effect on code quality.	https://doi.org/10.1109/ESEM.2017.12
690	Jebnoun, Hadhemi and Ben Braiek, Houssem and Rahman, Mohammad Masudur and Khomh, Foutse	The Scent of Deep Learning Code: An Empirical Study	10.1145/3379597.3387479	2020	Deep learning practitioners are often interested in improving their model accuracy rather than the interpretability of their models. As a result, deep learning applications are inherently complex in their structures. They also need to continuously evolve in terms of code changes and model updates. Given these confounding factors, there is a great chance of violating the recommended programming practices by the developers in their deep learning applications. In particular, the code quality might be negatively affected due to their drive for the higher model performance. Unfortunately, the code quality of deep learning applications has rarely been studied to date. In this paper, we conduct an empirical study to investigate the distribution of code smells in deep learning applications. To this end, we perform a comparative analysis between deep learning and traditional open-source applications collected from GitHub. We have several major findings. First, long lambda expression, long ternary conditional expression, and complex container comprehension smells are frequently found in deep learning projects. That is, deep learning code involves more complex or longer expressions than the traditional code does. Second, the number of code smells increases across the releases of deep learning applications. Third, we found that there is a co-existence between code smells and software bugs in the studied deep learning code, which confirms our conjecture on the degraded code quality of deep learning applications.	https://doi.org/10.1145/3379597.3387479
691	Lu, Yafeng and Lou, Yiling and Cheng, Shiyang and Zhang, Lingming and Hao, Dan and Zhou, Yangfan and Zhang, Lu	How Does Regression Test Prioritization Perform in Real-World Software Evolution?	10.1145/2884781.2884874	2016	In recent years, researchers have intensively investigated various topics in test prioritization, which aims to re-order tests to increase the rate of fault detection during regression testing. While the main research focus in test prioritization is on proposing novel prioritization techniques and evaluating on more and larger subject systems, little effort has been put on investigating the threats to validity in existing work on test prioritization. One main threat to validity is that existing work mainly evaluates prioritization techniques based on simple artificial changes on the source code and tests. For example, the changes in the source code usually include only seeded program faults, whereas the test suite is usually not augmented at all. On the contrary, in real-world software development, software systems usually undergo various changes on the source code and test suite augmentation. Therefore, it is not clear whether the conclusions drawn by existing work in test prioritization from the artificial changes are still valid for real-world software evolution. In this paper, we present the first empirical study to investigate this important threat to validity in test prioritization. We reimplemented 24 variant techniques of both the traditional and time-aware test prioritization, and investigated the impacts of software evolution on those techniques based on the version history of 8 real-world Java programs from GitHub. The results show that for both traditional and time-aware test prioritization, test suite augmentation significantly hampers their effectiveness, whereas source code changes alone do not influence their effectiveness much.	https://doi.org/10.1145/2884781.2884874
692	De Bleser, Jonas and Di Nucci, Dario and De Roover, Coen	Assessing Diffusion and Perception of Test Smells in Scala Projects	10.1109/MSR.2019.00072	2019	Test smells are, analogously to code smells, defined as the characteristics exhibited by poorly designed unit tests. Their negative impact on test effectiveness, understanding, and maintenance has been demonstrated by several empirical studies.However, the scope of these studies has been limited mostly to JAVA in combination with the JUNIT testing framework. Results for other language and framework combinations are ---despite their prevalence in practice--- few and far between, which might skew our understanding of test smells. The combination of Scala and ScalaTest, for instance, offers more comprehensive means for defining and reusing test fixtures, thereby possibly reducing the diffusion and perception of fixture-related test smells.This paper therefore reports on two empirical studies conducted for this combination. In the first study, we analyse the tests of 164 open-source Scala projects hosted on GitHub for the diffusion of test smells. This required the transposition of their original definition to this new context, and the implementation of a tool (SoCRATES) for their automated detection. In the second study, we assess the perception and the ability of 14 Scala developers to identify test smells. For this context, our results show (i) that test smells have a low diffusion across test classes, (ii) that the most frequently occurring test smells are Lazy Test, Eager Test, and Assertion Roulette, and (iii) that many developers were able to perceive but not to identify the smells.	https://doi.org/10.1109/MSR.2019.00072
693	Watson, Cody and Tufano, Michele and Moran, Kevin and Bavota, Gabriele and Poshyvanyk, Denys	On Learning Meaningful Assert Statements for Unit Test Cases	10.1145/3377811.3380429	2020	Software testing is an essential part of the software lifecycle and requires a substantial amount of time and effort. It has been estimated that software developers spend close to 50% of their time on testing the code they write. For these reasons, a long standing goal within the research community is to (partially) automate software testing. While several techniques and tools have been proposed to automatically generate test methods, recent work has criticized the quality and usefulness of the assert statements they generate. Therefore, we employ a Neural Machine Translation (NMT) based approach called Atlas (<u>A</u>u<u>T</u>omatic <u>L</u>earning of <u>A</u>ssert <u>S</u>tatements) to automatically generate meaningful assert statements for test methods. Given a test method and a focal method (i.e., the main method under test), Atlas can predict a meaningful assert statement to assess the correctness of the focal method. We applied Atlas to thousands of test methods from GitHub projects and it was able to predict the exact assert statement manually written by developers in 31% of the cases when only considering the top-1 predicted assert. When considering the top-5 predicted assert statements, Atlas is able to predict exact matches in 50% of the cases. These promising results hint to the potential usefulness of our approach as (i) a complement to automatic test case generation techniques, and (ii) a code completion support for developers, who can benefit from the recommended assert statements while writing test code.	https://doi.org/10.1145/3377811.3380429
694	Chen, Junjie and Lou, Yiling and Zhang, Lingming and Zhou, Jianyi and Wang, Xiaoleng and Hao, Dan and Zhang, Lu	Optimizing Test Prioritization via Test Distribution Analysis	10.1145/3236024.3236053	2018	Test prioritization aims to detect regression faults faster via reordering test executions, and a large number of test prioritization techniques have been proposed accordingly. However, test prioritization effectiveness is usually measured in terms of the average percentage of faults detected concerned with the number of test executions, rather than the actual regression testing time, making it unclear which technique is optimal in actual regression testing time. To answer this question, this paper first conducts an empirical study to investigate the actual regression testing time of various prioritization techniques. The results reveal a number of practical guidelines. In particular, no prioritization technique can always perform optimal in practice.  To achieve the optimal prioritization effectiveness for any given project in practice, based on the findings of this study, we design learning-based Predictive Test Prioritization (PTP). PTP predicts the optimal prioritization technique for a given project based on the test distribution analysis (i.e., the distribution of test coverage, testing time, and coverage per unit time). The results show that PTP correctly predicts the optimal prioritization technique for 46 out of 50 open-source projects from GitHub, outperforming state-of-the-art techniques significantly in regression testing time, e.g., 43.16% to 94.92% improvement in detecting the first regression fault. Furthermore, PTP has been successfully integrated into the practical testing infrastructure of Baidu (a search service provider with over 600M monthly active users), and received positive feedbacks from the testing team of this company, e.g., saving beyond 2X testing costs with negligible overheads.	https://doi.org/10.1145/3236024.3236053
695	Nemec, Matus and Klinec, Dusan and Svenda, Petr and Sekan, Peter and Matyas, Vashek	Measuring Popularity of Cryptographic Libraries in Internet-Wide Scans	10.1145/3134600.3134612	2017	We measure the popularity of cryptographic libraries in large datasets of RSA public keys. We do so by improving a recently proposed method based on biases introduced by alternative implementations of prime selection in different cryptographic libraries. We extend the previous work by applying statistical inference to approximate a share of libraries matching an observed distribution of RSA keys in an inspected dataset (e.g., Internet-wide scan of TLS handshakes). The sensitivity of our method is sufficient to detect transient events such as a periodic insertion of keys from a specific library into Certificate Transparency logs and inconsistencies in archived datasets.We apply the method on keys from multiple Internet-wide scans collected in years 2010 through 2017, on Certificate Transparency logs and on separate datasets for PGP keys and SSH keys. The results quantify a strong dominance of OpenSSL with more than 84% TLS keys for Alexa 1M domains, steadily increasing since the first measurement. OpenSSL is even more popular for GitHub client-side SSH keys, with a share larger than 96%. Surprisingly, new certificates inserted in Certificate Transparency logs on certain days contain more than 20% keys most likely originating from Java libraries, while TLS scans contain less than 5% of such keys.Since the ground truth is not known, we compared our measurements with other estimates and simulated different scenarios to evaluate the accuracy of our method. To our best knowledge, this is the first accurate measurement of the popularity of cryptographic libraries not based on proxy information like web server fingerprinting, but directly on the number of observed unique keys.	https://doi.org/10.1145/3134600.3134612
696	Mirsaeedi, Ehsan and Rigby, Peter C.	Mitigating Turnover with Code Review Recommendation: Balancing Expertise, Workload, and Knowledge Distribution	10.1145/3377811.3380335	2020	Developer turnover is inevitable on software projects and leads to knowledge loss, a reduction in productivity, and an increase in defects. Mitigation strategies to deal with turnover tend to disrupt and increase workloads for developers. In this work, we suggest that through code review recommendation we can distribute knowledge and mitigate turnover with minimal impacton the development process. We evaluate review recommenders in the context of ensuring expertise during review, Expertise, reducing the review workload of the core team, CoreWorkload, and reducing the Files at Risk to turnover, FaR. We find that prior work that assigns reviewers based on file ownership concentrates knowledge on a small group of core developers increasing risk of knowledge loss from turnover by up to 65%. We propose learning and retention aware review recommenders that when combined are effective at reducing the risk of turnover by -29% but they unacceptably reduce the overall expertise during reviews by -26%. We develop the Sofia recommender that suggests experts when none of the files under review are hoarded by developers, but distributes knowledge when files are at risk. In this way, we are able to simultaneously increase expertise during review with a ΔExpertise of 6%, with a negligible impact on workload of ΔCoreWorkload of 0.09%, and reduce the files at risk by ΔFaR -28%. Sofia is integrated into GitHub pull requests allowing developers to select an appropriate expert or "learner" based on the context of the review. We release the Sofia bot as well as the code and data for replication purposes.	https://doi.org/10.1145/3377811.3380335
697	Khelladi, Djamel Eddine and Kretschmer, Roland and Egyed, Alexander	Detecting and Exploring Side Effects When Repairing Model Inconsistencies	10.1145/3357766.3359546	2019	When software models change, developers often fail in keeping them consistent. Automated support in repairing inconsistencies is widely addressed. Yet, merely enumerating repairs for developers is not enough. A repair can as a side effect cause new unexpected inconsistencies (negative) or even fix other inconsistencies as well (positive). To make matters worse, repairing negative side effects can in turn cause further side effects. Current approaches do not detect and track such side effects in depth, which can increase developers' effort and time spent in repairing inconsistencies. This paper presents an automated approach for detecting and tracking the consequences of repairs, i.e. side effects. It recursively explores in depth positive and negative side effects and identifies paths and cycles of repairs. This paper further ranks repairs based on side effect knowledge so that developers may quickly find the relevant ones. Our approach and its tool implementation have been empirically assessed on 14 case studies from industry, academia, and GitHub. Results show that both positive and negative side effects occur frequently. A comparison with three versioned models showed the usefulness of our ranking strategy based on side effects. It showed that our approach's top prioritized repairs are those that developers would indeed choose. A controlled experiment with 24 participants further highlights the significant influence of side effects and of our ranking of repairs on developers. Developers who received side effect knowledge chose far more repairs with positive side effects and far less with negative side effects, while being 12.3% faster, in contrast to developers who did not receive side effect knowledge.	https://doi.org/10.1145/3357766.3359546
698	Wang, Kaiyuan and Zhu, Chenguang and Celik, Ahmet and Kim, Jongwook and Batory, Don and Gligoric, Milos	Towards Refactoring-Aware Regression Test Selection	10.1145/3180155.3180254	2018	Regression testing checks that recent project changes do not break previously working functionality. Although important, regression testing is costly when changes are frequent. Regression test selection (RTS) optimizes regression testing by running only tests whose results might be affected by a change. Traditionally, RTS collects dependencies (e.g., on files) for each test and skips the tests, at a new project revision, whose dependencies did not change. Existing RTS techniques do not differentiate behavior-preserving transformations (i.e., refactorings) from other code changes. As a result, tests are run more frequently than necessary.We present the first step towards a refactoring-aware RTS technique, dubbed Reks, which skips tests affected only by behavior-preserving changes. Reks defines rules to update the test dependencies without running the tests. To ensure that Reks does not hide any bug introduced by the refactoring engines, we integrate Reks only in the pre-submit testing phase, which happens on the developers' machines. We evaluate Reks by measuring the savings in the testing effort. Specifically, we reproduce 100 refactoring tasks performed by developers of 37 projects on GitHub. Our results show that Reks would not run, on average, 33% of available tests (that would be run by a refactoring-unaware RTS technique). Additionally, we systematically run 27 refactoring types on ten projects. The results, based on 74,160 refactoring tasks, show that Reks would not run, on average, 16% of tests (max: 97% and SD: 24%). Finally, our results show that the Reks update rules are efficient.	https://doi.org/10.1145/3180155.3180254
699	Majumder, Anirban and Datta, Samik and Naidu, K.V.M.	Capacitated Team Formation Problem on Social Networks	10.1145/2339530.2339690	2012	In a team formation problem, one is required to find a group of users that can match the requirements of a collaborative task. Example of such collaborative tasks abound, ranging from software product development to various participatory sensing tasks in knowledge creation. Due to the nature of the task, team members are often required to work on a co-operative basis. Previous studies [1, 2] have indicated that co-operation becomes effective in presence of social connections. Therefore, effective team selection requires the team members to be socially close as well as a division of the task among team members so that no user is overloaded by the assignment. In this work, we investigate how such teams can be formed on a social network.Since our team formation problems are proven to be NP-hard, we design efficient approximate algorithms for finding near optimum teams with provable guarantees. As traditional data-sets from on-line social networks (e.g. Twitter, Facebook etc) typically do not contain instances of large scale collaboration, we have crawled millions of software repositories spanning a period of four years and hundreds of thousands of developers from GitHub, a popular open-source social coding network. We perform large scale experiments on this data-set to evaluate the accuracy and efficiency of our algorithms. Experimental results suggest that our algorithms achieve significant improvement in finding effective teams, as compared to naive strategies and scale well with the size of the data. Finally, we provide a validation of our techniques by comparing with existing software teams.	https://doi.org/10.1145/2339530.2339690
700	Sirres, Raphael and Bissyand\\'e, Tegawend\\'e F. and Kim, Dongsun and Lo, David and Klein, Jacques and Kim, Kisub and Traon, Yves Le	Augmenting and Structuring User Queries to Support Efficient Free-Form Code Search	10.1145/3180155.3182513	2018	Motivation: Code search is an important activity in software development since developers are regularly searching [6] for code examples dealing with diverse programming concepts, APIs, and specific platform peculiarities. To help developers search for source code, several Internet-scale code search engines, such as OpenHub [5] and Codota [1] have been proposed. Unfortunately, these Internet-scale code search engines have limited performance since they treat source code as natural language documents. To improve the performance of search engines, the construction of the search space index as well as the mapping process of querying must address the challenge that "no single word can be chosen to describe a programming concept in the best way" [2]. This is known in the literature as the vocabulary mismatch problem [3].Approach: We propose a novel approach to augmenting user queries in a free-form code search scenario. This approach aims at improving the quality of code examples returned by Internet-scale code search engines by building a Code voCaBulary (CoCaBu) [7]. The originality of CoCaBu is that it addresses the vocabulary mismatch problem, by expanding/enriching/re-targeting a user's free-form query, building on similar questions in Q&amp;A sites so that a code search engine can find highly relevant code in source code repositories. Figure 1 provides an overview of our approach.The search process begins with a free-form query from a user,i.e., a sentence written in a natural language:(a) For a given query, CoCaBu first searches for relevant posts in Q&amp;A forums. The role of the Search Proxy is then to forward developer free-form queries to web search engines that can collect and rank entries in Q&amp;A with the most relevant documents for the query.(b) CoCaBu then generates an augmented query based on the information in the relevant posts. It mainly leverages code snippets in the previously identified posts. The Code Query Generator then creates another query which includes not only the initial user query terms but also program elements. To accelerate this step in the search process, CoCaBu builds upfront a snippet index for Q&amp;A posts.(c) Once the augmented query is constructed, CoCaBu searches source files for code locations that match the query terms. For this step, we crawl a large number of repositories and build upfront a code index of program elements in the source code.Contributions:• CoCaBu approach to the vocabulary mismatch problem: We propose a technique for finding relevant code with freeform query terms that describe programming tasks, with no a-priori knowledge on the API keywords to search for.• GitSearch free-form search engine for GitHub: We instantiate the CoCaBu approach based on indices of Java files built from GitHub and Q&amp;A posts from Stack Overflow to find the most relevant code examples for developer queries.• Empirical user evaluation: Comparison with popular code search engines further shows that GitSearch is more effective in returning acceptable code search results. In addition, Comparison against web search engines indicates that GitSearch is a competitive alternative. Finally, via a live study, we show that users on Q&amp;A sites may find GitSearch's real code examples acceptable as answers to developer questions.Concluding remarks: As a follow-up work, we have also leveraged Stack Overflow data to build a practical, novel, and efficient code-to-code search engine [4].	https://doi.org/10.1145/3180155.3182513
701	Dey, Tapajit and Mockus, Audris	Effect of Technical and Social Factors on Pull Request Quality for the NPM Ecosystem	10.1145/3382494.3410685	2020	Background: Pull request (PR) based development, which is a norm for the social coding platforms, entails the challenge of evaluating the contributions of, often unfamiliar, developers from across the open source ecosystem and, conversely, submitting a contribution to a project with unfamiliar maintainers. Previous studies suggest that the decision of accepting or rejecting a PR may be influenced by a diverging set of technical and social factors, but often focus on relatively few projects, do not consider ecosystem-wide measures, or the possible non-monotonic relationships between the predictors and PR acceptance probability. Aim: We aim to shed light on this important decision making process by testing which measures significantly affect the probability of PR acceptance on a significant fraction of a large ecosystem, rank them by their relative importance in predicting PR acceptance, and determine the shape of the functions that map each predictor to PR acceptance. Method: We proposed seven hypotheses regarding which technical and social factors might affect PR acceptance and created 17 measures based on them. Our dataset consisted of 470,925 PRs from 3349 popular NPM packages and 79,128 GitHub users who created those. We tested which of the measures affect PR acceptance and ranked the significant measures by their importance in a predictive model. Results: Our predictive model had and AUC of 0.94, and 15 of the 17 measures were found to matter, including five novel ecosystem-wide measures. Measures describing the number of PRs submitted to a repository and what fraction of those get accepted, and signals about the PR review phase were most significant. We also discovered that only four predictors have a linear influence on the PR acceptance probability while others showed a more complicated response. Conclusion: Our findings should be helpful for PR creators, integrators, as well as tool designers to focus on the important factors affecting PR acceptance.	https://doi.org/10.1145/3382494.3410685
702	Braiek, Houssem Ben and Khomh, Foutse and Adams, Bram	The Open-Closed Principle of Modern Machine Learning Frameworks	10.1145/3196398.3196445	2018	Recent advances in computing technologies and the availability of huge volumes of data have sparked a new machine learning (ML) revolution, where almost every day a new headline touts the demise of human experts by ML models on some task. Open source software development is rumoured to play a significant role in this revolution, with both academics and large corporations such as Google and Microsoft releasing their ML frameworks under an open source license. This paper takes a step back to examine and understand the role of open source development in modern ML, by examining the growth of the open source ML ecosystem on GitHub, its actors, and the adoption of frameworks over time. By mining LinkedIn and Google Scholar profiles, we also examine driving factors behind this growth (paid vs. voluntary contributors), as well as the major players who promote its democratization (companies vs. communities), and the composition of ML development teams (engineers vs. scientists). According to the technology adoption lifecycle, we find that ML is in between the stages of early adoption and early majority. Furthermore, companies are the main drivers behind open source ML, while the majority of development teams are hybrid teams comprising both engineers and professional scientists. The latter correspond to scientists employed by a company, and by far represent the most active profiles in the development of ML applications, which reflects the importance of a scientific background for the development of ML frameworks to complement coding skills. The large influence of cloud computing companies on the development of open source ML frameworks raises the risk of vendor lock-in. These frameworks, while open source, could be optimized for specific commercial cloud offerings.	https://doi.org/10.1145/3196398.3196445
703	Hu, Xing and Liang, Ling and Li, Shuangchen and Deng, Lei and Zuo, Pengfei and Ji, Yu and Xie, Xinfeng and Ding, Yufei and Liu, Chang and Sherwood, Timothy and Xie, Yuan	DeepSniffer: A DNN Model Extraction Framework Based on Learning Architectural Hints	10.1145/3373376.3378460	2020	As deep neural networks (DNNs) continue their reach into a wide range of application domains, the neural network architecture of DNN models becomes an increasingly sensitive subject, due to either intellectual property protection or risks of adversarial attacks. Previous studies explore to leverage architecture-level events disposed in hardware platforms to extract the model architecture information. They pose the following limitations: requiring a priori knowledge of victim models, lacking in robustness and generality, or obtaining incomplete information of the victim model architecture.Our paper proposes DeepSniffer, a learning-based model extraction framework to obtain the complete model architecture information without any prior knowledge of the victim model. It is robust to architectural and system noises introduced by the complex memory hierarchy and diverse run-time system optimizations. The basic idea of DeepSniffer is to learn the relation between extracted architectural hints (e.g., volumes of memory reads/writes obtained by side-channel or bus snooping attacks) and model internal architectures. Taking GPU platforms as a show case, DeepSniffer conducts model extraction by learning both the architecture-level execution features of kernels and the inter-layer temporal association information introduced by the common practice of DNN design. We demonstrate that DeepSniffer works experimentally in the context of an off-the-shelf Nvidia GPU platform running a variety of DNN models. The extracted models are directly helpful to the attempting of crafting adversarial inputs. Our experimental results show that DeepSniffer achieves a high accuracy of model extraction and thus improves the adversarial attack success rate from 14.6%$sim$25.5% (without network architecture knowledge) to 75.9% (with extracted network architecture). The DeepSniffer project has been released in Github.	https://doi.org/10.1145/3373376.3378460
704	Fares, Ahmed and Zhong, Sheng-hua and Jiang, Jianmin	Brain-Media: A Dual Conditioned and Lateralization Supported GAN (DCLS-GAN) towards Visualization of Image-Evoked Brain Activities	10.1145/3394171.3413858	2020	Essentially, the current concept of multimedia is limited to presenting what people see in their eyes. What people think inside brains, however, remains a rich source of multimedia, such as imaginations of paradise and memories of good old days etc. In this paper, we propose a dual conditioned and lateralization supported GAN (DCLS-GAN) framework to learn and visualize the brain thoughts evoked by stimulating images and hence enable multimedia to reflect not only what people see but also what people think. To reveal such a new world of multimedia inside human brains, we coin such an attempt as "brain-media". By examining the relevance between the visualized image and the stimulation image, we are able to measure the efficiency of our proposed deep framework regarding the quality of such visualization and also the feasibility of exploring the concept of "brain-media". To ensure that such extracted multimedia elements remain meaningful, we introduce a dually conditioned learning technique in the proposed deep framework, where one condition is analyzing EEGs through deep learning to extract a class-dependent and more compact brain feature space utilizing the distinctive characteristics of hemispheric lateralization and brain stimulation, and the other is to extract expressive visual features assisting our automated analysis of brain activities as well as their visualizations aided by artificial intelligence. To support the proposed GAN framework, we create a combined-conditional space by merging the brain feature space with the visual feature space provoked by the stimuli. Extensive experiments are carried out and the results show that our proposed deep framework significantly outperforms the representative existing state-of-the-arts under several settings, especially in terms of both visualization and classification of brain responses to the evoked images. For the convenience of research dissemination, we make the source code openly accessible for downloading at GitHub.	https://doi.org/10.1145/3394171.3413858
705	Montalvillo, Leticia and D\\'\\iaz, Oscar and Fogdal, Thomas	Reducing Coordination Overhead in SPLs: Peering in on Peers	10.1145/3233027.3233041	2018	SPL product customers might not always wait for the next core asset release. When an organization aims to react to market events, quick bug fixes or urgent customer requests, strategies are needed to support fast adaptation, e.g. with product-specific extensions, which are later propagated into the SPL. This leads to the grow-and-prune model where quick reaction to changes often requires copying and specialization (grow) to be later cleaned up by merging and refactoring (prune). This paper focuses on the grow stage. Here, application engineers branch off the core-asset Master branch to account for their products' specifics within the times and priorities of their customers without having to wait for the next release of the core assets. However, this practice might end up in the so-called "integration hell". When long-living branches are merged back into the Master, the amount of code to be integrated might cause build failures or requires complex troubleshooting. On these premises, we advocate for making application engineers aware of potential coordination problems right during coding rather than deferring it until merge time. To this end, we introduce the notion of "peering bar" for Version Control Systems, i.e. visual bars that reflect whether your product's features are being upgraded in other product branches. In this way, engineers are aware of what their peers are doing on the other SPL's products. Being products from the same SPL, they are based on the very same core assets, and hence, bug ixes or functional enhancements undertaken for a product might well serve other products. This work introduces design principles for peering bars. These principles are fleshed out for GitHub as the Version Control System, and pure::variants as the SPL framework.	https://doi.org/10.1145/3233027.3233041
706	Aseeri, Samar and Muite, Benson K.	Benchmarking in the Datacenter (BID) 2020: Workshop Summary	10.1145/3380868.3398198	2020	The workshop in beautiful San Diego was composed of two submitted papers and two invited talks.The first paper presentation, "Power Modeling for Phytium FT-2000+ Multi-core Architecture" by Zhixin Ou a PhD student from the National University of Defense Technology was streamed from Hunan, China due to travel difficulties. Her talk describes the application of HPCC benchmarks on the first software-based power model for the new Phytium FT-2000+/64 ARM platform. The results of these benchmarks of the software were compared with real power measurements to prove how accurate this approach is.The first invited talk by Ammar Awan a PhD student at Ohio State University, "Benchmarking Deep Learning Workloads on Large-Scale HPC Systems" described machine learning and deep learning benchmarks. He described parallel communication in distributed deep learning for training image recognition networks and how it is different from typical high performance computing parallel communication. He identified reproducibility and benchmarks for new applications of deep learning as important future areas.The second invited presentation was given by the San Diego Supercomputer Center (SDSC) user support lead Mahidhar Tatineni and addressed the "Evolution of Benchmarking on SDSC systems". It was an interesting talk that gave an overview of platforms and benchmarks at the supercomputing center closest to the conference venue. The speaker succeeded in capturing all aspects in this regard during his 15-years of devoted work at the San Diego Supercomputing Center.The final paper presentation, "The ESIF-HPC-2 Benchmark Suite" was given by Christopher Chang who works at the National Renewable Energy Laboratory (NREL) in the HPC Application group in Denver. He described the benchmark suite he and his team developed for procurement of the most recent NREL supercomputer. He demonstrated a set of dimensions that are useful in classifying benchmarks and in systematically assessing their coverage of performance measures. This suite is released as open source software on GitHub.The program committee for the workshop was composed of:• David Bailey (Lawrence Berkely National Laboratory and University of California Davis)• Valeria Bartsch (Fraunhofer ITWM)• Ben Blamey (Uppsala University)• Rodrigo N. Calheiros (Western Sydney University)• Anando Chatterjee (Indian Institute of Technology Kanpur)• Juan Chen (National University of Defense Technology)• Pawe\\l Czarnul (Gdansk University of Technology)• Denis Demidov (Kazan Federal University and Russian Academy of Sciences)• Joel Guerrero (University of Genoa and Wolf Dynamics)• Khaled Ibrahim (Lawrence Berkeley National Laboratory)• Kate Isaacs (University of Arizona)• Beau Johnston (Australian National University and University of New England)• Mchael Lehn (University of Ulm)• Maged Korga• Guo Liang (Open Data Center Committee and China Academy of Information and Communications Technology)• Xioyi Lu (Ohio State University)• Amitava Majumdar (San Diego Supercomputing Center)• Jorji Nonaka (Riken)• Peter Pirkelbauer (Lawrence Livermore National Laboratory)• Harald Servat (Intel)• Ashwin Siddarth (University of Texas at Arlington)• Manodeep Sinha (Swinburne University of Technology)• Gabor Sz\\'arnyas (Budapest University of Technology and Economics)• Mahidhar Tatineni (San Diego Supercomputing Center)• Jianfeng Zhan (Chinese Academy of Sciences)We thank the program committee and the subreviewers for their careful review of the submitted papers, with each paper obtaining at least 4 reviews. We thank the authors for their patience with the publication process.	https://doi.org/10.1145/3380868.3398198
\.


--
-- Data for Name: acm_manual; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.acm_manual (id, author, title, doi, year, abstract, url) FROM stdin;
5	Acar, Yasemin and Stransky, Christian and Wermke, Dominik and Mazurek, Michelle L. and Fahl, Sascha	Security Developer Studies with Github Users: Exploring a Convenience Sample		2017	The usable security community is increasingly considering how to improve security decision-making not only for end users, but also for information technology professionals, including system administrators and software developers. Recruiting these professionals for user studies can prove challenging, as, relative to end users more generally, they are limited in numbers, geographically concentrated, and accustomed to higher compensation. One potential approach is to recruit active GitHub users, who are (in some ways) conveniently available for online studies. However, it is not well understood how GitHub users perform when working on security-related tasks. As a first step in addressing this question, we conducted an experiment in which we recruited 307 active GitHub users to each complete the same security-relevant programming tasks. We compared the results in terms of functional correctness as well as security, finding differences in performance for both security and functionality related to the participant's self-reported years of experience, but no statistically significant differences related to the participant's self-reported status as a student, status as a professional developer, or security background. These results provide initial evidence for how to think about validity when recruiting convenience samples as substitutes for professional developers in security developer studies.	
9	Badashian, Ali Sajedi and Esteki, Afsaneh and Gholipour, Ameneh and Hindle, Abram and Stroulia, Eleni	Involvement, Contribution and Influence in GitHub and Stack Overflow		2014	Software developers are increasingly adopting social-media platforms to contribute to software development, learn and develop a reputation for themselves. GitHub supports version-controlled code sharing and social-networking functionalities and Stack Overflow is a social forum for question answering on programming topics. Motivated by the features' overlap of the two networks, we set out to mine and analyze and correlate the members' core contributions, editorial activities and influence in the two networks. We aim to better understand the similarities and differences of the members' contributions in the two platforms and their evolution over time. In this context, while studying the activities of different user groups, we conducted a three-step investigation of GitHub activity, Stack Overflow activity and inter-network activity over a five-year period. We report our findings on interesting membership and activity patterns within each platform and some relations between the two.	
12	Gousios, Georgios and Spinellis, Diomidis	GHTorrent: GitHub's Data from a Firehose		2012	A common requirement of many empirical software engineering studies is the acquisition and curation of data from software repositories. During the last few years, GitHub has emerged as a popular project hosting, mirroring and collaboration platform. GitHub provides an extensive rest api, which enables researchers to retrieve both the commits to the projects' repositories and events generated through user actions on project resources. GHTorrent aims to create a scalable off line mirror of GitHub's event streams and persistent data, and offer it to the research community as a service. In this paper, we present the project's design and initial implementation and demonstrate how the provided datasets can be queried and processed.	
17	Coelho, Roberta and Almeida, Lucas and Gousios, Georgios and van Deursen, Arie	Unveiling Exception Handling Bug Hazards in Android Based on GitHub and Google Code Issues		2015	This paper reports on a study mining the exception stack traces included in 159,048 issues reported on Android projects hosted in GitHub (482 projects) and Google Code (157 projects). The goal of this study is to investigate whether stack trace information can reveal bug hazards related to exception handling code that may lead to a decrease in application robustness. Overall 6,005 exception stack traces were extracted, and subjected to source code and bytecode analysis. The outcomes of this study include the identification of the following bug hazards: (i) unexpected cross-type exception wrappings (for instance, trying to handle an instance of OutOfMemoryError "hidden" in a checked exception) which can make the exception-related code more complex and negatively impact the application robustness; (ii) undocumented runtime exceptions thrown by both the Android platform and third party libraries; and (iii) undocumented checked exceptions thrown by the Android Platform. Such undocumented exceptions make it difficult, and most of the times infeasible for the client code to protect against "unforeseen" situations that may happen while calling third-party code. This study provides further insights on such bug hazards and the robustness threats they impose to Android apps as well as to other systems based on the Java exception model.	
28	Liu, Gary and Siu, Joran and Dawson, Michael and Ho, Ivy and Yan, Yunliang	Introduction to Debugging and Monitoring Node.Js		2015	Node.js is a server-side JavaScript platform that has seen explosive growth in recent years. In its 6 years of existence, Node.js has leaped to being the third most-starred repository on GitHub, and is now one of the most popular frameworks for developing cloud, mobile and Internet-of-Things applications.	
29	Low, Andrew and Siu, Joran and Ho, Ivy and Liu, Gary	Introduction to Node.Js		2014	Node.js is a server-side JavaScript platform that has seen explosive growth in recent years. In its 5 years of existence, Node.js has leaped to being the third most-starred repository on GitHub, and is now one of the most popular frameworks for developing cloud, mobile and Internet-of-Things applications.	
22	Gousios, Georgios	The GHTorent Dataset and Tool Suite		2013	During the last few years, GitHub has emerged as a popular project hosting, mirroring and collaboration platform. GitHub provides an extensive REST API, which enables researchers to retrieve high-quality, interconnected data. The GHTorent project has been collecting data for all public projects available on Github for more than a year. In this paper, we present the dataset details and construction process and outline the challenges and research opportunities emerging from it. 	
23	Melo, Amanda Meincke	Acessibilidade e Inclus\\~ao Digital		2014	A promo\\cc\\~ao da acessibilidade est\\'a diretamente relacionada ao exerc\\'\\icio da cidadania. Efetiv\\'a-la no desenvolvimento de sistemas computacionais interativos para uso humano -- massivamente presentes em nosso dia a dia -- envolve ter um claro entendimento de seu significado nos dias de hoje, que deve estar alinhado \\`a defini\\cc\\~ao contempor\\^anea para defici\\^encia apresentada na Conven\\cc\\~ao Internacional sobre os Direitos das Pessoas com Defici\\^encia [2]:[...] a defici\\^encia resulta da intera\\cc\\~ao entre pessoas com defici\\^encia e as barreiras devidas \\`as atitudes e ao ambiente que impedem a plena e efetiva participa\\cc\\~ao dessas pessoas na sociedade em igual de oportunidades com as demais pessoas [...]\\'E no contexto do Desafio 4 da Sociedade Brasileira de Computa\\cc\\~ao (SBC) para o dec\\^enio 2006-2016 [1] -- "Acesso Participativo e Universal do Cidad\\~ao Brasileiro ao Conhecimento" -- e do desafio "Acessibilidade e Inclus\\~ao Digital", enunciado entre os Grandes Desafios de Pesquisa em Intera\\cc\\~ao Humano-Computador do Brasil [5], que este minicurso \\'e proposto.	
24	Zhao, Yangyang and Serebrenik, Alexander and Zhou, Yuming and Filkov, Vladimir and Vasilescu, Bogdan	The Impact of Continuous Integration on Other Software Development Practices: A Large-Scale Empirical Study		2017	Continuous Integration (CI) has become a disruptive innovation in software development: with proper tool support and adoption, positive effects have been demonstrated for pull request throughput and scaling up of project sizes. As any other innovation, adopting CI implies adapting existing practices in order to take full advantage of its potential, and "best practices" to that end have been proposed. Here we study the adaptation and evolution of code writing and submission, issue and pull request closing, and testing practices as Travis CI is adopted by hundreds of established projects on GitHub. To help essentialize the quantitative results, we also survey a sample of GitHub developers about their experiences with adopting Travis CI. Our findings suggest a more nuanced picture of how GitHub teams are adapting to, and benefiting from, continuous integration technology than suggested by prior work. 	
25	Packer, Heather S. and Chapman, Adriane and Carr, Leslie	GitHub2PROV: Provenance for Supporting Software Project Management		2019	Software project management is a complex task that requires accurate information and experience to inform the decision-making process. In the real world software project managers rarely have access to perfect information. In order to support them, we propose leveraging information from Version Control Systems and their repositories to support decision-making. In this paper, we propose a PROV model GitHub2PROV, which extends Git2PROV with details about GitHub commits and issues from GitHub repositories. We discuss how this model supports project management decisions in agile development, specifically in terms of Control Schedule Reviews and workload.	
32	Barboza, John and Mallick, Muntasir and Siu, Joran and Bajwa, Jaideep and Dawson, Michael	Hands-on: Microservices on NodeJS		2016	Node.js is a server-side JavaScript platform that has seen explosive growth in recent years. In its 5 years of existence, Node.js has leaped to being the third most-starred repository on GitHub, and is now one of the most popular frameworks for developing cloud, mobile and Internet-of-Things applications.	
34	Singh, Dhirendra and Padgham, Lin and Logan, Brian	Integrating BDI Agents with Agent-Based Simulation Platforms: (JAAMAS Extended Abstract)		2017	This paper describes an integration framework that allows development of simulations where the cognitive reasoning and decision making is programmed and executed within an existing BDI (Belief, Desire, Intention) system, and the simulation is played out in an existing ABM (Agent Based Modelling) system. The framework has a generic layer which manages communication and synchronisation, a system layer which integrates specific BDI and ABM systems, and the application layer which contains the program code for a particular application. The code is available on GitHub: https://github.com/agentsoz/bdi-abm-integration	
37	van der Veen, Erik and Gousios, Georgios and Zaidman, Andy	Automatically Prioritizing Pull Requests		2015	In previous work, we observed that in the pull-based development model integrators face challenges with regard to prioritizing work in the face of multiple concurrent pull requests. We present the design and initial implementation of a prototype pull request prioritisation tool called prioritizer. prioritizer works like a priority inbox for pull requests, recommending the top pull requests the project owner should focus on. A preliminary user study showed that prioritizer provides functionality that GitHub is currently lacking, even though users need more insight into how the priority ranking is established to make prioritizer really useful.	
39	Watanabe, Keisuke and Ubayashi, Naoyasu and Fukamachi, Takuya and Nakamura, Shunya and Muraoka, Hokuto and Kamei, Yasutaka	IArch-U: Interface-Centric Integrated Uncertainty-Aware Development Environment		2017	Uncertainty can appear in all aspects of software development: uncertainty in requirements analysis, design decisions, implementation and testing. If uncertainty can be dealt with modularly, we can add or delete uncertain concerns to/from models, code and tests whenever these concerns arise or are fixed to certain concerns. To deal with this problem, we developed iArch-U, an IDE (Integrated Development Environment) for managing uncertainty modularly in all phases in software development. In this paper, we introduce an overview of iArch-U. The iArch-U IDE is open source software and can be downloaded from GitHub.	
40	Faria, Daniel and Pesquita, Catia and Santos, Emanuel and Cruz, Isabel F. and Couto, Francisco M.	AgreementMakerLight 2.0: Towards Efficient Large-Scale Ontology Matching		2014	Ontology matching is a critical task to realize the Semantic Web vision, by enabling interoperability between ontologies. However, handling large ontologies efficiently is a challenge, given that ontology matching is a problem of quadratic complexity.AgreementMakerLight (AML) is a scalable automated ontology matching system developed to tackle large ontology matching problems, particularly for the life sciences domain. Its new 2.0 release includes several novel features, including an innovative algorithm for automatic selection of background knowledge sources, and an updated repair algorithm that is both more complete and more efficient.AML is an open source system, and is available through GitHub both for developers (as an Eclipse project) and end-users (as a runnable Jar with a graphical user interface).	
46	Hata, Hideaki and Todo, Taiki and Onoue, Saya and Matsumoto, Kenichi	Characteristics of Sustainable OSS Projects: A Theoretical and Empirical Study		2015	How can we attract developers? What can we do to incentivize developers to write code? We started the study by introducing the population pyramid visualization to software development communities, called software population pyramids, and found a typical pattern in shapes. This pattern comes from the differences in attracting coding contributors and discussion contributors. To understand the causes of the differences, we then build game-theoretical models of the contribution situation. Based on these results, we again analyzed the projects empirically to support the outcome of the models, and found empirical evidence. The answers to the initial questions are clear. To incentivize developers to code, the projects should prepare documents, or the projects or third parties should hire developers, and these are what sustainable projects in GitHub did in reality. In addition, making innovations to reduce the writing costs can also have an impact in attracting coding contributors.	
49	Oakes, Edward and Yang, Leon and Zhou, Dennis and Houck, Kevin and Harter, Tyler and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.	SOCK: Rapid Task Provisioning with Serverless-Optimized Containers		2018	Serverless computing promises to provide applications with cost savings and extreme elasticity. Unfortunately, slow application and container initialization can hurt common-case latency on serverless platforms. In this work, we analyze Linux container primitives, identifying scalability bottlenecks related to storage and network isolation. We also analyze Python applications from GitHub and show that importing many popular libraries adds about 100 ms to startup. Based on these findings, we implement SOCK, a container system optimized for serverless workloads. Careful avoidance of kernel scalability bottlenecks gives SOCK an 18\\texttimes speedup over Docker. A generalized-Zygote provisioning strategy yields an additional 3\\texttimes speedup. A more sophisticated three-tier caching strategy based on Zygotes provides a 45\\texttimes speedup over SOCK without Zygotes. Relative to AWS Lambda and OpenWhisk, OpenLambda with SOCK reduces platform overheads by 2.8\\texttimes and 5.3\\texttimes respectively in an image processing case study.	
51	Hashimoto, Tatsunori B. and Guu, Kelvin and Oren, Yonatan and Liang, Percy	A Retrieve-and-Edit Framework for Predicting Structured Outputs		2018	For the task of generating complex outputs such as source code, editing existing outputs can be easier than generating complex outputs from scratch. With this motivation, we propose an approach that first retrieves a training example based on the input (e.g., natural language description) and then edits it to the desired output (e.g., code). Our contribution is a computationally efficient method for learning a retrieval model that embeds the input in a task-dependent way without relying on a hand-crafted metric or incurring the expense of jointly training the retriever with the editor. Our retrieve-and-edit framework can be applied on top of any base model. We show that on a new autocomplete task for GitHub Python code and the Hearthstone cards benchmark, retrieve-and-edit significantly boosts the performance of a vanilla sequence-to-sequence model on both tasks.	
52	Zheng, Renjie and Chen, Junkun and Qiu, Xipeng	Same Representation, Different Attentions: Shareable Sentence Representation Learning from Multiple Tasks		2018	Distributed representation plays an important role in deep learning based natural language processing. However, the representation of a sentence often varies in different tasks, which is usually learned from scratch and suffers from the limited amounts of training data. In this paper, we claim that a good sentence representation should be invariant and can benefit the various subsequent tasks. To achieve this purpose, we propose a new scheme of information sharing for multi-task learning. More specifically, all tasks share the same sentence representation and each task can select the task-specific information from the shared sentence representation with attention mechanisms. The query vector of each task's attention could be either static parameters or generated dynamically. We conduct extensive experiments on 16 different text classification tasks, which demonstrate the benefits of our architecture. Source codes of this paper are available on Github.	
54	Bijlani, Ashish and Ramachandran, Umakishore	Extension Framework for File Systems in User Space		2019	User file systems offer numerous advantages over their in-kernel implementations, such as ease of development and better system reliability. However, they incur heavy performance penalty. We observe that existing user file system frameworks are highly general; they consist of a minimal interposition layer in the kernel that simply forwards all low-level requests to user space. While this design offers flexibility, it also severely degrades performance due to frequent kernel-user context switching.This work introduces EXTFUSE, a framework for developing extensible user file systems that also allows applications to register "thin" specialized request handlers in the kernel to meet their specific operative needs, while retaining the complex functionality in user space. Our evaluation with two FUSE file systems shows that EXTFUSE can improve the performance of user file systems with less than a few hundred lines on average. EXTFUSE is available on GitHub.	
55	Mehdi, Nabeel and Starly, Binil	A Simulator Testbed for MT-Connect Based Machines in a Scalable and Federated Multi-Enterprise Environment		2019	The emergence and steady adoption of machine communication protocols like the MTConnect are steering the manufacturing sector towards greater machine interoperability, higher operational productivity, substantial cost savings with advanced decision-making capabilities at the shop-floor level. MTConnect GitHub repository and NIST Smart Manufacturing Systems (SMS) Test Bed are two major resources for collecting data from CNC machines. However, these tools would be insufficient and protractive in Modeling &amp; Simulation (M&amp;S) scenarios where spawning hundreds of MTConnect agents and thousands of adapters with real-time virtual machining is necessary for advancing research in the digital supply chain. This paper introduces a flexible simulator testbed of multiple MTConnect agents and adapters for simulating Levels 0 &amp; 1 of the ISA-95 framework and help support R&amp;D activities in complex multi-enterprise supply chain scenarios. To the best knowledge of the authors, there is no publicly accessible multi-enterprise MTConnect testbed yet.	
56	Bass, Len and Holz, Ralph and Rimba, Paul and Tran, An Binh and Zhu, Liming	Securing a Deployment Pipeline		2015	At the RELENG 2014 Q&amp;A, the question was asked, "What is your greatest concern?" and the response was "someone subverting our deployment pipeline". That is the motivation for this paper. We explore what it means to subvert a pipeline and provide several different scenarios of subversion. We then focus on the issue of securing a pipeline. As a result, we provide an engineering process that is based on having trusted components mediate access to sensitive portions of the pipeline from other components, which can remain untrusted. Applying our process to a pipeline we constructed involving Chef, Jenkins, Docker, Github, and AWS, we find that some aspects of our process result in easy to make changes to the pipeline, whereas others are more difficult. Consequently, we have developed a design that hardens the pipeline, although it does not yet completely secure it.	
57	Xiao, Jun and Ye, Hao and He, Xiangnan and Zhang, Hanwang and Wu, Fei and Chua, Tat-Seng	Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks		2017	Factorization Machines  (FMs) are a supervised learning approach that enhances the linear regression model by incorporating the second-order feature interactions. Despite effectiveness, FM can be hindered by its modelling of all feature interactions with the same weight, as not all feature interactions are equally useful and predictive. For example, the interactions with useless features may even introduce noises and adversely degrade the performance. In this work, we improve FM by discriminating the importance of different feature interactions. We propose a novel model named  Attentional Factorization Machine  (AFM), which learns the importance of each feature interaction from data via a neural attention network. Extensive experiments on two real-world datasets demonstrate the effectiveness of AFM. Empirically, it is shown on regression task AFM betters FM with a 8.6% relative improvement, and consistently outperforms the state-of-the-art deep learning methods Wide&amp;Deep [Cheng  et al. , 2016] and Deep-Cross [Shan  et al. , 2016] with a much simpler structure and fewer model parameters. Our implementation of AFM is publicly available at: https://github. com/hexiangnan/attentional_factorization_machine	
68	He, Yang and Kang, Guoliang and Dong, Xuanyi and Fu, Yanwei and Yang, Yi	Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks		2018	This paper proposed a Soft Filter Pruning (SFP) method to accelerate the inference procedure of deep Convolutional Neural Networks (CNNs). Specifically, the proposed SFP enables the pruned filters to be updated when training the model after pruning. SFP has two advantages over previous works: (1) Larger model capacity. Updating previously pruned filters provides our approach with larger optimization space than fixing the filters to zero. Therefore, the network trained by our method has a larger model capacity to learn from the training data. (2) Less dependence on the pretrained model. Large capacity enables SFP to train from scratch and prune the model simultaneously. In contrast, previous filter pruning methods should be conducted on the basis of the pre-trained model to guarantee their performance. Empirically, SFP from scratch outperforms the previous filter pruning methods. Moreover, our approach has been demonstrated effective for many advanced CNN architectures. Notably, on ILSCRC-2012, SFP reduces more than 42% FLOPs on ResNet-101 with even 0.2% top-5 accuracy improvement, which has advanced the state-of-the-art. Code is publicly available on GitHub: https://github.com/he-y/soft-filter-pruning	
70	Kazemi, Seyed Mehran and Poole, David	SimplE Embedding for Link Prediction in Knowledge Graphs		2018	Knowledge graphs contain knowledge about the world and provide a structured representation of this knowledge. Current knowledge graphs contain only a small subset of what is true in the world. Link prediction approaches aim at predicting new links for a knowledge graph given the existing links among the entities. Tensor factorization approaches have proved promising for such link prediction problems. Proposed in 1927, Canonical Polyadic (CP) decomposition is among the first tensor factorization approaches. CP generally performs poorly for link prediction as it learns two independent embedding vectors for each entity, whereas they are really tied. We present a simple enhancement of CP (which we call SimplE) to allow the two embeddings of each entity to be learned dependently. The complexity of SimplE grows linearly with the size of embeddings. The embeddings learned through SimplE are interpretable, and certain types of background knowledge can be incorporated into these embeddings through weight tying. We prove SimplE is fully expressive and derive a bound on the size of its embeddings for full expressivity. We show empirically that, despite its simplicity, SimplE outperforms several state-of-the-art tensor factorization techniques. SimplE's code is available on GitHub at https://github.com/Mehran-k/SimplE.	
77	Fursin, Grigori and Lokhmotov, Anton and Plowman, Ed	Collective Knowledge: Towards R&amp;D Sustainability		2016	Research funding bodies strongly encourage research projects to disseminate discovered knowledge and transfer developed technology to industry. Unfortunately, capturing, sharing, reproducing and building upon experimental results has become close to impossible in computer systems' R&amp;D. The main challenges include the ever changing hardware and software technologies, lack of standard experimental methodology and lack of robust knowledge exchange mechanisms apart from publications where reproducibility is still rarely considered.Supported by the EU FP7 TETRACOM Coordination Action, we have developed Collective Knowledge (CK), an open-source framework and methodology that involves the R&amp;D community to solve the above problems collaboratively. CK helps researchers gradually convert their code and data into reusable components and share them via repositories such as GitHub, design and evolve over time experimental scenarios, replay experiments under the same or similar conditions, apply state-of-the-art statistical techniques, crowdsource experiments across different platforms, and enable interactive publications. Importantly, CK encourages the continuity and sustainability of R&amp;D efforts: researchers and engineers can build upon the work of others and make their own work available for others to build upon. We believe that R&amp;D sustainability will lead to better research and faster commercialization, thus increasing return-on-investment.	
78	Bernardo, Jo\\~ao Helis and da Costa, Daniel Alencar and Kulesza, Uir\\'a	Studying the Impact of Adopting Continuous Integration on the Delivery Time of Pull Requests		2018	Continuous Integration (CI) is a software development practice that leads developers to integrate their work more frequently. Software projects have broadly adopted CI to ship new releases more frequently and to improve code integration. The adoption of CI is motivated by the allure of delivering new functionalities more quickly. However, there is little empirical evidence to support such a claim. Through the analysis of 162,653 pull requests (PRs) of 87 GitHub projects that are implemented in 5 different programming languages, we empirically investigate the impact of adopting CI on the time to deliver merged PRs. Surprisingly, only 51.3% of the projects deliver merged PRs more quickly after adopting CI. We also observe that the large increase of PR submissions after CI is a key reason as to why projects deliver PRs more slowly after adopting CI. To investigate the factors that are related to the time-to-delivery of merged PRs, we train regression models that obtain sound median R-squares of 0.64-0.67. Finally, a deeper analysis of our models indicates that, before the adoption of CI, the integration-load of the development team, i.e., the number of submitted PRs competing for being merged, is the most impactful metric on the time to deliver merged PRs before CI. Our models also reveal that PRs that are merged more recently in a release cycle experience a slower delivery time.	https://doi.org/10.1145/3196398.3196421
92	Blincoe, Kelly and Harrison, Francis and Damian, Daniela	Ecosystems in GitHub and a Method for Ecosystem Identification Using Reference Coupling		2015	Software projects are not developed in isolation. Recent research has shifted to studying software ecosystems, communities of projects that depend on each other and are developed together. However, identifying technical dependencies at the ecosystem level can be challenging. In this paper, we propose a new method, known as reference coupling, for detecting technical dependencies between projects. The method establishes dependencies through user-specified cross-references between projects. We use our method to identify ecosystems in GitHub-hosted projects, and we identify several characteristics of the identified ecosystems. We find that most ecosystems are centered around one project and are interconnected with other ecosystems. The predominant type of ecosystems are those that develop tools to support software development. We also found that the project owners' social behaviour aligns well with the technical dependencies within the ecosystem, but project contributors' social behaviour does not align with these dependencies. We conclude with a discussion on future research that is enabled by our reference coupling method.	
80	Zhu, Jieming and He, Pinjia and Fu, Qiang and Zhang, Hongyu and Lyu, Michael R. and Zhang, Dongmei	Learning to Log: Helping Developers Make Informed Logging Decisions		2015	Logging is a common programming practice of practical importance to collect system runtime information for postmortem analysis. Strategic logging placement is desired to cover necessary runtime information without incurring unintended consequences (e.g., performance overhead, trivial logs). However, in current practice, there is a lack of rigorous specifications for developers to govern their logging behaviours. Logging has become an important yet tough decision which mostly depends on the domain knowledge of developers. To reduce the effort on making logging decisions, in this paper, we propose a "learning to log" framework, which aims to provide informative guidance on logging during development. As a proof of concept, we provide the design and implementation of a logging suggestion tool, LogAdvisor, which automatically learns the common logging practices on where to log from existing logging instances and further leverages them for actionable suggestions to developers. Specifically, we identify the important factors for determining where to log and extract them as structural features, textual features, and syntactic features. Then, by applying machine learning techniques (e.g., feature selection and classifier learning) and noise handling techniques, we achieve high accuracy of logging suggestions. We evaluate LogAdvisor on two industrial software systems from Microsoft and two open-source software systems from GitHub (totally 19.1M LOC and 100.6K logging statements). The encouraging experimental results, as well as a user study, demonstrate the feasibility and effectiveness of our logging suggestion tool. We believe our work can serve as an important first step towards the goal of "learning to log".	
88	Vendome, Christopher	A Large Scale Study of License Usage on GitHub		2015	The open source community relies upon licensing in order to govern the distribution, modification, and reuse of existing code. These licenses evolve to better suit the requirements of the development communities and to cope with unaddressed or new legal issues. In this paper, we report the results of a large empirical study conducted over the change history of 16,221 open source Java projects mined from GitHub. Our study investigates how licensing usage and adoption changes over a period of ten years. We consider both the distribution of license usage within projects of a rapidly growing forge and the extent that new versions of licenses are introduced in these projects.	
89	Casalnuovo, Casey and Devanbu, Prem and Oliveira, Abilio and Filkov, Vladimir and Ray, Baishakhi	Assert Use in GitHub Projects		2015	Asserts have long been a strongly recommended (if non-functional) adjunct to programs. They certainly don't add any user-evident feature value; and it can take quite some skill and effort to devise and add useful asserts. However, they are believed to add considerable value to the developer. Certainly, they can help with automated verification; but even in the absence of that, claimed advantages include improved understandability, maintainability, easier fault localization and diagnosis, all eventually leading to better software quality. We focus on this latter claim, and use a large dataset of asserts in C and C++ programs to explore the connection between asserts and defect occurrence. Our data suggests a connection: functions with asserts do have significantly fewer defects. This indicates that asserts do play an important role in software quality; we therefore explored further the factors that play a role in assertion placement: specifically, process factors (such as developer experience and ownership) and product factors, particularly interprocedural factors, exploring how the placement of assertions in functions are influenced by local and global network properties of the callgraph. Finally, we also conduct a differential analysis of assertion use across different application domains.	
90	Vendome, Christopher and Linares-V\\'asquez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and German, Daniel and Poshyvanyk, Denys	License Usage and Changes: A Large-Scale Study of Java Projects on GitHub		2015	Software licenses determine, from a legal point of view, under which conditions software can be integrated, used, and above all, redistributed. Licenses evolve over time to meet the needs of development communities and to cope with emerging legal issues and new development paradigms. Such evolution of licenses is likely to be accompanied by changes in the way how software uses such licenses, resulting in some licenses being adopted while others are abandoned. This paper reports a large empirical study aimed at quantitatively and qualitatively investigating when and why developer change software licenses. Specifically, we first identify licenses' changes in 1,731,828 commits, representing the entire history of 16,221 Java projects hosted on GitHub. Then, to understand the rationale of license changes, we perform a qualitative analysis---following a grounded theory approach---of commit notes and issue tracker discussions concerning licensing topics and, whenever possible, try to build traceability links between discussions and changes. Our results point out a lack of traceability of when and why licensing changes are made. This can be a major concern, because a change in the license of a system can negatively impact those that reuse it.	
91	Kalliamvakou, Eirini and Damian, Daniela and Blincoe, Kelly and Singer, Leif and German, Daniel M.	Open Source-Style Collaborative Development Practices in Commercial Projects Using GitHub		2015	Researchers are currently drawn to study projects hosted on GitHub due to its popularity, ease of obtaining data, and its distinctive built-in social features. GitHub has been found to create a transparent development environment, which together with a pull request-based workflow, provides a lightweight mechanism for committing, reviewing and managing code changes. These features impact how GitHub is used and the benefits it provides to teams' development and collaboration. While most of the evidence we have is from GitHub's use in open source software (oss) projects, GitHub is also used in an increasing number of commercial projects. It is unknown how GitHub supports these projects given that GitHub's workflow model does not intuitively fit the commercial development way of working. In this paper, we report findings from an online survey and interviews with GitHub users on how GitHub is used for collaboration in commercial projects. We found that many commercial projects adopted practices that are more typical of oss projects including reduced communication, more independent work, and self-organization. We discuss how GitHub's transparency and popular workflow can promote open collaboration, allowing organizations to increase code reuse and promote knowledge sharing across their teams.	
93	Wang, Weiliang and Poo-Caama\\~no, Germ\\'an and Wilde, Evan and German, Daniel M.	What is the Gist? Understanding the Use of Public Gists on GitHub		2015	GitHub is a popular source code hosting site which serves as a collaborative coding platform. The many features of GitHub have greatly facilitated developers' collaboration, communication, and coordination. Gists are one feature of GitHub, which defines them as "a simple way to share snippets and pastes with others." This three-part study explores how users are using Gists. The first part is a quantitative analysis of Gist metadata and contents. The second part investigates the information contained in a Gist: We sampled 750k users and their Gists (totalling 762k Gists), then manually categorized the contents of 398. The third part of the study investigates what users are saying Gists are for by reading the contents of web pages and twitter feeds. The results indicate that Gists are used by a small portion of GitHub users, and those that use them typically only have a few. We found that Gists are usually small and composed of a single file. However, Gists serve a wide variety of uses, from saving snippets of code, to creating reusable components for web pages.	
94	Sawant, Anand Ashok and Bacchelli, Alberto	A Dataset for API Usage		2015	An Application Programming Interface (API) provides a specific set of functionalities to a developer. The main aim of an API is to encourage the reuse of already existing functionality. There has been some work done into API popularity trends, API evolution and API usage. For all the aforementioned research avenues there has been a need to mine the usage of an API in order to perform any kind of analysis. Each one of the approaches that has been employed in the past involved a certain degree of inaccuracy as there was no type check that takes place. We introduce an approach that takes type information into account while mining API method invocations and annotation usages. This approach accurately makes a connection between a method invocation and the class of the API to which the method belongs to. We try collecting as many usages of an API as possible, this is achieved by targeting projects hosted on GitHub. Additionally, we look at the history of every project to collect the usage of an API from earliest version onwards. By making such a large and rich dataset public, we hope to stimulate some more research in the field of APIs with the aid of accurate API usage samples.	
95	Grichi, Manel and Abidi, Mouna and Gu\\'eh\\'eneuc, Yann-Ga\\"el and Khomh, Foutse	State of Practices of Java Native Interface		2019	The use of the Java Native Interface (JNI) allows taking advantage of the existing libraries written in different programming languages for code reuse, performance, and security. Despite the importance of JNI in development, practices on its usages are not well studied yet. In this paper, we investigated the usage of JNI in 100 open source systems collected from OpenHub and Github, around 8k of source code files combined between Java and C/C++, including the Java class libraries part of the JDK v9. We identified the state of the practice in JNI systems by semi-automatically and manually analyzing the source code.Our qualitative analysis shows eleven JNI practices where they are mainly related to loading libraries, implementing native methods, exception management, return types, and local/global references management. Basing on our findings, we provided some suggestions and recommendations to developers to facilitate the debugging tasks of JNI in multi-language systems, which can also help them to deal with the Java and C memory.	
96	Weicheng, Yang and Beijun, Shen and Ben, Xu	Mining GitHub: Why Commit Stops -- Exploring the Relationship between Developer's Commit Pattern and File Version Evolution		2013	Using the freeware in GitHub, we are often confused by a phenomenon: the new version of GitHub freeware usually was released in an indefinite frequency, and developers often committed nothing for a long time. This evolution phenomenon interferes with our own development plan and architecture design. Why do these updates happen at that time? Can we predict GitHub software version evolution by developers' activities? This paper aims to explore the developer commit patterns in GitHub, and try to mine the relationship between these patterns (if exists) and code evolution. First, we define four metrics to measure commit activity and code evolution: the changes in each commit, the time between two commits, the author of each changes, and the source code dependency. Then, we adopt visualization techniques to explore developers' commit activity and code evolution. Visual techniques are used to describe the progress of the given project and the authors' contributions. To analyze the commit logs in GitHub software repository automatically, Commits Analysis Tool (CAT) is designed and implemented. Finally, eight open source projects in GitHub are analyzed using CAT, and we find that: 1) the file changes in the previous versions may affect the file depend on it in the next version, 2) the average days around "huge commit" is 3 times of that around normal commit. Using these two patterns and developer's commit model, we can predict when his next commit comes and which file may be changed in that commit. Such information is valuable for project planning of both GitHub projects and other projects which use GitHub freeware to develop software.	
97	Badashian, Ali Sajedi and Shah, Vraj and Stroulia, Eleni	GitHub's Big Data Adaptor: An Eclipse Plugin		2015	The data of GitHub, the most popular code-sharing platform, fits the characteristics of "big data" (Volume, Variety and Velocity). To facilitate studies on this huge GitHub data volume, the GHTorrent web-site publishes a MYSQL dump of (some) GitHub data quarterly. Unfortunately, developers using these published data dumps face challenges with respect to the time required to parse and ingest the data, the space required to store it, and the latency of their queries. To help address these challenges, we developed a data adaptor as an Eclipse plugin, which efficiently handles this dump. The plugin offers an interactive interface through which users can explore and select any field in any table. After extracting the data selected by the user, the parser exports it in easy-to-use spreadsheets. We hope that using this plugin will facilitate further studies on the GitHub data as a whole.	
98	Hauff, Claudia and Gousios, Georgios	Matching GitHub Developer Profiles to Job Advertisements		2015	GitHub is a social coding platform that enables developers to efficiently work on projects, connect with other developers, collaborate and generally "be seen" by the community. This visibility also extends to prospective employers and HR personnel who may use GitHub to learn more about a developer's skills and interests. We propose a pipeline that automatizes this process and automatically suggests matching job advertisements to developers, based on signals extracting from their activities on GitHub.	
99	Onoue, Saya and Hata, Hideaki and Matsumoto, Ken-ichi	A Study of the Characteristics of Developers' Activities in GitHub		2013	What types of developers do active software projects have? This paper presents a study of the characteristics of developers' activities in open source software development. GitHub, a widely-used hosting service for software development projects, provides APIs for collecting various kinds of GitHub data. To clarify the characteristics of developers' activities, we used these APIs to investigate GitHub events generated by each developer. Using this information, we categorized developers based on measures such as whether they prefer communication by coding or comments, or whether they are specialists or generalists. Our study indicates that active software projects have various kinds of developers characterized by different types of development activities.	
100	Yu, Yue and Wang, Huaimin and Filkov, Vladimir and Devanbu, Premkumar and Vasilescu, Bogdan	Wait for It: Determinants of Pull Request Evaluation Latency on GitHub		2015	The pull-based development model, enabled by git and popularised by collaborative coding platforms like BitBucket, Gitorius, and GitHub, is widely used in distributed software teams. While this model lowers the barrier to entry for potential contributors (since anyone can submit pull requests to any repository), it also increases the burden on integrators (i.e., members of a project's core team, responsible for evaluating the proposed changes and integrating them into the main development line), who struggle to keep up with the volume of incoming pull requests. In this paper we report on a quantitative study that tries to resolve which factors affect pull request evaluation latency in GitHub. Using regression modeling on data extracted from a sample of GitHub projects using the Travis-CI continuous integration service, we find that latency is a complex issue, requiring many independent variables to explain adequately.	
101	Pham, Raphael and Singer, Leif and Liskin, Olga and Figueira Filho, Fernando and Schneider, Kurt	Creating a Shared Understanding of Testing Culture on a Social Coding Site		2013	Many software development projects struggle with creating and communicating a testing culture that is appropriate for the project's needs. This may degrade software quality by leaving defects undiscovered. Previous research suggests that social coding sites such as GitHub provide a collaborative environment with a high degree of social transparency. This makes developers' actions and interactions more visible and traceable. We conducted interviews with 33 active users of GitHub to investigate how the increased transparency found on GitHub influences developers' testing behaviors. Subsequently, we validated our findings with an online questionnaire that was answered by 569 members of GitHub. We found several strategies that software developers and managers can use to positively influence the testing behavior in their projects. However, project owners on GitHub may not be aware of them. We report on the challenges and risks caused by this and suggest guidelines for promoting a sustainable testing culture in software development projects. 	
102	Perrie, Jessica and Xie, Jing and Nayebi, Maleknaz and Fokaefs, Marios and Lyons, Kelly and Stroulia, Eleni	City on the River: Visualizing Temporal Collaboration		2019	Collaboration is an important component of most work activities. We are interested in understanding how configurations of people come together to create outputs over time. We propose an interactive visualization tool (City on the River) for visualizing collaborations over time. The City on the River (CotR) visualization shows the contributions and artifacts ("products") of a team on a timeline and the individuals on the team who contributed to each product. CotR enables interactive analyses of each of these components for answering questions such as, which people work together on the most products, which products involve the most people, what kinds of products were produced when and by whom, etc. CotR can be used for analyzing diverse domains such as research collaborations, conference participation, email conversations, and software development. In this paper, we present the results of an experiment to assess CotR for analyzing collaboration and outcomes in GitHub projects. We compared the quality of answers, time to answer, and approaches taken to analyze the project collaborations by two groups of people: one group used the GitHub data displayed in a spreadsheet; the other group used the GitHub data displayed using CotR.	
103	Vasilescu, Bogdan and Serebrenik, Alexander and Filkov, Vladimir	A Data Set for Social Diversity Studies of GitHub Teams		2015	Like any other team oriented activity, the software development process is effected by social diversity in the programmer teams. The effect of team diversity can be significant, but also complex, especially in decentralized teams. Discerning the precise contribution of diversity on teams' effectiveness requires quantitative studies of large data sets.Here we present for the first time a large data set of social diversity attributes of programmers in GitHub teams. Using alias resolution, location data, and gender inference techniques, we collected a team social diversity data set of 23,493 GitHub projects. We illustrate how the data set can be used in practice with a series of case studies, and we hope its availability will foster more interest in studying diversity issues in software teams.	
104	Vasilescu, Bogdan and Filkov, Vladimir and Serebrenik, Alexander	Perceptions of Diversity on GitHub: A User Survey		2015	Understanding one's work environment is important for one's success, especially when working in teams. In virtual collaborative environments this amounts to being aware of the technical and social attributes of one's team members. Focusing on Open Source Software teams, naturally very diverse both socially and technically, we report the results of a user survey that tries to resolve how teamwork and individual attributes are perceived by developers collaborating on GitHub, and how those perceptions influence their work. Our findings can be used as complementary data to quantitative studies of developers' behavior on GitHub.	
105	Chapman, Carl and Wang, Peipei and Stolee, Kathryn T.	Exploring Regular Expression Comprehension		2017	The regular expression (regex) is a powerful tool employed in a large variety of software engineering tasks. However, prior work has shown that regexes can be very complex and that it could be difficult for developers to compose and understand them. This work seeks to identify code smells that impact comprehension. We conduct an empirical study on 42 of pairs of behaviorally equivalent but syntactically different regexes using 180 participants and evaluated the understandability of various regex language features. We further analyzed regexes in GitHub to find the community standards or the common usages of various features. We found that some regex expression representations are more understandable than others. For example, using a range (e.g., [0-9]) is often more understandable than a default character class (e.g., [d]). We also found that the DFA size of a regex significantly affects comprehension for the regexes studied. The larger the DFA of a regex (up to size eight), the more understandable it was. Finally, we identify smelly and non-smelly regex representations based on a combination of community standards and understandability metrics. 	
106	Kavaler, David and Sirovica, Sasha and Hellendoorn, Vincent and Aranovich, Raul and Filkov, Vladimir	Perceived Language Complexity in GitHub Issue Discussions and Their Effect on Issue Resolution		2017	Modern software development is increasingly collaborative. Open Source Software (OSS) are the bellwether; they support dynamic teams, with tools for code sharing, communication, and issue tracking. The success of an OSS project is reliant on team communication. E.g., in issue discussions, individuals rely on rhetoric to argue their position, but also maintain technical relevancy. Rhetoric and technical language are on opposite ends of a language complexity spectrum: the former is stylistically natural; the latter is terse and concise. Issue discussions embody this duality, as developers use rhetoric to describe technical issues. The style mix in any discussion can define group culture and affect performance, e.g., issue resolution times may be longer if discussion is imprecise.  Using GitHub, we studied issue discussions to understand whether project-specific language differences exist, and to what extent users conform to a language norm. We built project-specific and overall GitHub language models to study the effect of perceived language complexity on multiple responses. We find that experienced users conform to project-specific language norms, popular individuals use overall GitHub language rather than project-specific language, and conformance to project-specific language norms reduces issue resolution times. We also provide a tool to calculate project-specific perceived language complexity. 	
107	Podolskiy, Vladimir and Patrou, Maria and Patros, Panos and Gerndt, Michael and Kent, Kenneth B.	The Weakest Link: Revealing and Modeling the Architectural Patterns of Microservice Applications		2020	Cloud microservice applications comprise interconnected services packed into containers. Such applications generate complex communication patterns among their microservices. Studying such patterns can support assuring various quality attributes, such as autoscaling for satisfying performance, availability and scalability, or targeted penetration testing for satisfying security and correctness. We study the structure of containerized microservice applications via providing the methodology and the results of a structural graph-based analysis of 103 Docker Compose deployment files from open-sourced Github repositories. Our findings indicate the dominance of a power-law distribution of microservice interconnections. Further analysis highlights the suitability of the Barab\\'asi-Albert model for generating large random graphs that model the architecture of real microservice applications. The exhibited structures and their usage for engineering microservice applications are discussed.	
108	Pham, Raphael and Singer, Leif and Schneider, Kurt	Building Test Suites in Social Coding Sites by Leveraging Drive-by Commits		2013	GitHub projects attract contributions from a community of users with varying coding and quality assurance skills. Developers on GitHub feel a need for automated tests and rely on test suites for regression testing and continuous integration. However, project owners report to often struggle with implementing an exhaustive test suite. Convincing contributors to provide automated test cases remains a challenge. The absence of an adequate test suite or using tests of low quality can degrade the quality of the software product. We present an approach for reducing the effort required by project owners for extending their test suites. We aim to utilize the phenomenon of drive-by commits: capable users quickly and easily solve problems in others' projects---even though they are not particularly involved in that project---and move on. By analyzing and directing the drive-by commit phenomenon, we hope to use crowdsourcing to improve projects' quality assurance efforts. Valuable test cases and maintenance tasks would be completed by capable users, giving core developers more resources to work on the more complicated issues. 	
109	Matteis, Luca and Verborgh, Ruben	Hosting Queryable and Highly Available Linked Data for Free		2014	SPARQL endpoints suffer from low availability, and require to buy and configure complex servers to host them. With the advent of Linked Data Fragments, and more specifically Triple Pattern Fragments (TPFs), we can now perform complex queries on low-cost servers. Online file repositories and cloud hosting services, such as GitHub, Google Code, Google App Engine or Dropbox can be exploited to host this type of linked data for free. For this purpose we have developed two different proof-of-concept tools that can be used to publish TPFs on GitHub and Google App Engine. A generic TPF client can then be used to perform SPARQL queries on the freely hosted TPF servers.	
110	Sinha, Vibha Singhal and Saha, Diptikalyan and Dhoolia, Pankaj and Padhye, Rohan and Mani, Senthil	Detecting and Mitigating Secret-Key Leaks in Source Code Repositories		2015	Several news articles in the past year highlighted incidents in which malicious users stole API keys embedded in files hosted on public source code repositories such as GitHub and BitBucket in order to drive their own work-loads for free. While some service providers such as Amazon have started taking steps to actively discover such developer carelessness by scouting public repositories and suspending leaked API keys, there is little support for tackling the problem from the code sharing platforms themselves.In this paper, we discuss practical solutions to detecting, preventing and fixing API key leaks. We first outline a handful of methods for detecting API keys embedded within source code, and evaluate their effectiveness using a sample set of projects from GitHub. Second, we enumerate the mechanisms which could be used by developers to prevent or fix key leaks in code repositories manually. Finally, we outline a possible solution that combines these techniques to provide tool support for protecting against key leaks in version control systems.	
111	Eckman, David J. and Henderson, Shane G. and Pasupathy, Raghu	Redesigning a Testbed of Simulation-Optimization Problems and Solvers for Experimental Comparisons		2019	We describe major improvements to the testing capabilities of SimOpt, a library of simulation-optimization problems and solvers. Foremost among these improvements is a transition to GitHub that makes SimOpt easier to use and maintain. We also design two new wrapper functions that facilitate empirical comparisons of solvers. The wrapper functions make extensive use of common random numbers (CRN) both within and across solvers for various purposes; e.g., identifying random initial solutions and running simulation replications. We examine some of the intricacies of using CRN to compare simulation-optimization solvers.	
112	Amir, Ofra and Grosz, Barbara J. and Gajos, Krzysztof Z.	MIP-Nets: Enabling Information Sharing in Loosely-Coupled Teamwork		2016	People collaborate in carrying out such complex activities as treating patients, co-authoring documents and developing software. While technologies such as Dropbox and Github enable groups to work in a distributed manner, coordinating team members' individual activities poses significant challenges. In this paper, we formalize the problem of "information sharing in loosely-coupled extended-duration teamwork". We develop a new representation, Mutual Influence Potential Networks (MIP-Nets), to model collaboration patterns and dependencies among activities, and an algorithm, MIP-DOI, that uses this representation to reason about information sharing.	
113	Bhattacharya, Parantapa and Ekanayake, Saliya and Kuhlman, Chris J. and Lebiere, Christian and Morrison, Don and Swarup, Samarth and Wilson, Mandy L. and Orr, Mark G.	The Matrix: An Agent-Based Modeling Framework for Data Intensive Simulations		2019	Human decision-making is influenced by social, psychological, neurological, emotional, normative, and learning factors, as well as individual traits like age and education level. Social/cognitive computational models that incorporate these factors are increasingly used to study how humans make decisions. A result is that agent models, within agent-based modeling (ABM), are becoming more heavyweight, i.e., are more computationally demanding, making scalability and at-scale simulations all the more difficult to achieve. To address these challenges, we have developed an ABM simulation framework that addresses data-intensive simulation at-scale. We describe system requirements and design, and demonstrate at-scale simulation by modeling 3 million users (each as an individual agent), 13 million repositories, and 239 million user-repository interactions on GitHub. Simulations predict user interactions with GitHub repositories, which, to our knowledge, are the first simulations of this kind. Our simulations demonstrate a three-order of magnitude increase in the number of cognitive agents simultaneously interacting.	
114	Vendome, Christopher and Rao, Dhananjai M. and Giabbanelli, Philippe J.	How Do Modelers Code Artificial Societies? Investigating Practices and Quality of Netlogo Codes from Large Repositories		2020	Many guidelines have been developed for simulations in general or for agent-based models which support artificial societies. When applying such guidelines to examine existing practices, assessment studies are limited by the artifacts released by modelers. Although code is the final product defining an artificial society, 90% of the code produced is not released hence previous assessments necessarily focused on higher-level items such as conceptual design or validation. We address this gap by collecting 338 artificial societies from two hosting platforms, CoMSES/OpenABM and GitHub. An innovation of our approach is the use of software engineering techniques to automatically examine the models with respect to items such as commenting the code, using libraries, or dividing code into functions. We found that developers of artificial societies code the decision-making of their agents from scratch in every model, despite the existence of several libraries that could be used as building blocks.	
115	Blythe, James and Ferrara, Emilio and Huang, Di and Lerman, Kristina and Muric, Goran and Sapienza, Anna and Tregubov, Alexey and Pacheco, Diogo and Bollenbacher, John and Flammini, Alessandro and Hui, Pik-Mai and Menczer, Filippo	The DARPA SocialSim Challenge: Massive Multi-Agent Simulations of the Github Ecosystem		2019	We model the evolution of GitHub, a large collaborative software-development ecosystem, using massive multi-agent simulations as a part of DARPA's SocialSim program. Our best performing models and our agent-based simulation framework are described here. Six different agent models were tested based on a variety of machine learning and statistical methods. The most successful models are based on sampling from a stationary probability distribution of actions and repositories for each agent.	
116	Leibzon, William	Social Network of Software Development at GitHub		2016	This paper looks at organization of software development teams and project communities at GitHub. Using social network analysis several open-source projects are analyzed and social networks of users with ties to a project are shown to have some scale-free properties. We further show how to find core development group and a network metric is introduced to measure collaboration among core members, corresponding to if a project is healthy and more likely to be successful.	
117	Yao, Shuochao and Hao, Yifan and Liu, Dongxin and Liu, Shengzhong and Shao, Huajie and Wu, Jiahao and Bamba, Mouna and Abdelzaher, Tarek and Flamino, James and Szymanski, Boleslaw	A Predictive Self-Configuring Simulator for Online Media		2018	This paper describes the design, implementation, and early experiences with a novel agent-based simulator of online media streams, developed under DARPA's SocialSim Program to extract and predict trends in information dissemination on online media. A hallmark of the simulator is its self-configuring property. Instead of requiring initial set-up, the input to the simulator constitutes data traces collected from the medium to be simulated. The simulator automatically learns from the data such elements as the number of agents involved, the number of objects involved, and the rate of introduction of new agents and objects. It also develops behavior models of simulated agents and objects, and their dependencies. These models are then used to run simulations allowing for future extrapolations and "what if" analyses. Results are presented on using this system to simulate GitHub transactions. They show good performance in terms of both simulation accuracy and overhead.	
118	Nakazawa, Shun and Tanaka, Tetsuo	Prototype of Kanban Tool and Preliminary Evaluation of Visualizing Method for Task Assignment		2015	Kanban is a method used in agile software development. It is a most important tool as it acts as a central communication hub among the members of an agile development team. In this research, the authors develop a prototype of a Kanban tool. The tool displays each developer's tasks across multiple horizontal rows. Therefore, users can assess the task assignment and workloads of team members in one glance. The board also links up with GitHub and has a feature of real time synchronization among clients for distributed development. An experiment showed that the proposed approach was effective.	
119	Loyola, Pablo and Ko, In-Young	Biological Mutualistic Models Applied to Study Open Source Software Development		2012	The evolution of the Web has allowed the generation of several platforms for collaborative work. One of the main contributors to these advances is the Open Source initiative, in which projects are boosted to a new level of interaction and cooperation that improves their software quality and reliability. In order to understand how the group of contributors interacts with the software under development, we propose a novel methodology that adapts Lotka-Volterra-based biological models used for host-parasite interaction. In that sense, we used the concept mutualism from social parasites. Preliminary results based on experiments on the Github collaborative platform showed that Open Source phenomena can be modeled as a mutualistic system, in terms of the evolution of the population of developers and repositories.	
120	Dantas, Carlos E. C. and de A. Maia, Marcelo	On the Actual Use of Inheritance and Interface in Java Projects: Evolution and Implications		2017	Background: Inheritance is one of the main features in the object-oriented paradigm (OOP). Nonetheless, previous work recommend carefully using it, suggesting alternatives such as the adoption of composition with implementation of interfaces. Despite of being a well-studied theme, there is still little knowledge if such recommendations have been widely adopted by developers in general. Aims: This work aims at evaluating how the inheritance and composition with interfaces have been used in Java, comparing new projects with older ones (transversal), and also the different releases of the same projects (longitudinal). Method: A total of 1, 656 open-source projects built between 1997 and 2013, hosted in the repositories GitHub and SourceForge, were analyzed. The likelihood of more recent projects using inheritance and interfaces differently from older ones was analyzed considering indicators, such as, the prevalence of corrective changes, instanceof operations, and code smells. Regression analysis, chi-squared test of proportions and descriptive statistics were used to analyze the data. In addition, a thematic analysis based method was used to verify how often and why inheritance and interface are added or removed from classes. Results: We observed that developers still use inheritance primarily for code reuse, motivated by the need to avoid duplicity of source code. In newer projects, classes in inheritance had fewer corrective changes and subclasses had fewer use of the instance of operator. However, as they evolve, classes in inheritance tend to become complex as changes occur. Classes implementing interfaces have shown little relation to the interfaces, and there is indication that interfaces are still underutilized. Conclusion: These results show there is still some lack of knowledge about the use of recommended object-oriented practices, suggesting the need of training developers on how to design better classes.	
121	Vasilescu, Bogdan and Serebrenik, Alexander and Mens, Tom	A Historical Dataset of Software Engineering Conferences		2013	The Mining Software Repositories community typically focuses on data from software configuration management tools, mailing lists, and bug tracking repositories to uncover interesting and actionable information about the evolution of software systems. However, the techniques employed and the challenges faced when mining are not restricted to these types of repositories. In this paper, we present an atypical dataset of software engineering conferences, containing historical data about the accepted papers and the composition of programme committees for eleven well-established conferences. The dataset (published on Github at https://github.com/tue-mdse/conferenceMetrics) can be used, e.g., by conference steering committees or programme committee chairs to assess their selection process and compare against other conferences in the field, or by prospective authors to decide in which conferences to publish. 	
122	Spinellis, Diomidis	A Repository with 44 Years of Unix Evolution		2015	The evolution of the Unix operating system is made available as a version-control repository, covering the period from its inception in 1972 as a five thousand line kernel, to 2015 as a widely-used 26 million line system. The repository contains 659 thousand commits and 2306 merges. The repository employs the commonly used Git system for its storage, and is hosted on the popular GitHub archive. It has been created by synthesizing with custom software 24 snapshots of systems developed at Bell Labs, Berkeley University, and the 386BSD team, two legacy repositories, and the modern repository of the open source FreeBSD system. In total, 850 individual contributors are identified, the early ones through primary research. The data set can be used for empirical research in software engineering, information systems, and software archaeology.	
123	Vassiliadis, Vangelis and Wielemaker, Jan and Mungall, Chris	Processing OWL2 Ontologies Using Thea: An Application of Logic Programming		2009	Traditional object-oriented programming languages can be difficult to use when working with ontologies, leading to the creation of domain-specific languages designed specifically for ontology processing. Prolog, with its logic-based, declarative semantics offers many advantages as a host programming language for querying and processing OWL2 ontologies. The SWI-Prolog semweb library provides some support for OWL but until now there has been a lack of any library providing direct and comprehensive support for OWL2.We have developed Thea, a library based directly on the OWL2 functional-style syntax, allowing storage and manipulation of axioms as a Prolog database. Thea can translate ontologies to Description Logic programs but the emphasis is on using Prolog as an application programming and processing language rather than a reasoning engine. Thea offers the ability to seamless connect to the java OWL API and OWLLink servers. Thea also includes support for SWRL.In this paper we provide examples of using Thea for processing ontologies, and compare the results to alternative methods. Thea is available from GitHub: http://github.com/vangelisv/thea.	
124	Menashe, Jacob and Stone, Peter	Escape Room: A Configurable Testbed for Hierarchical Reinforcement Learning		2019	Recent successes in Reinforcement Learning have encouraged a fast growing network of RL researchers and a number of breakthroughs in RL research. As the RL community and body of work grows, so does the need for widely applicable benchmarks that can fairly and effectively evaluate a variety of RL algorithms. In this paper we present the Escape Room Domain (ERD), a new flexible, scalable, and fully implemented testing domain for Hierarchical RL that bridges the "moderate complexity" gap left behind by existing alternatives. ERD is open-source and freely available through GitHub, and conforms to widely-used public testing interfaces for simple integration and testing with a variety of public RL agent implementations.	
125	Hosek, Petr and Cadar, Cristian	Safe Software Updates via Multi-Version Execution		2013	Software systems are constantly evolving, with new versions and patches being released on a continuous basis. Unfortunately, software updates present a high risk, with many releases introducing new bugs and security vulnerabilities.  We tackle this problem using a simple but effective multi-version based approach. Whenever a new update becomes available, instead of upgrading the software to the new version, we run the new version in parallel with the old one; by carefully coordinating their executions and selecting the behaviour of the more reliable version when they diverge, we create a more secure and dependable multi-version application.  We implemented this technique in Mx, a system targeting Linux applications running on multi-core processors, and show that it can be applied successfully to several real applications such as Coreutils, a set of user-level UNIX applications; Lighttpd, a popular web server used by several high-traffic websites such as Wikipedia and YouTube; and Redis, an advanced key-value data structure server used by many well-known services such as GitHub and Flickr. 	
126	Grigoriou, Marios-Stavros and Kontogiannis, Kostas and Giammaria, Alberto and Brealey, Chris	Report on Evaluation Experiments Using Different Machine Learning Techniques for Defect Prediction		2020	With the emergence of AI, it is of no surprise that the application of Machine Learning techniques has attracted the attention of numerous software maintenance groups around the world. For defect proneness classification in particular, the use of Machine Learning classifiers has been touted as a promising approach. As a consequence, a large volume of research works has been published in the related research literature, utilizing either proprietary data sets or the PROMISE data repository which, for the purposes of this study, focuses only on the use of source code metrics as defect prediction training features. It has been argued though by several researchers, that process metrics may provide a better option as training features than source code metrics. For this paper, we have conducted a detailed extraction of GitHub process metrics from 148 open source systems, and we report on the findings of experiments conducted by using different Machine Learning classification algorithms for defect proneness classification. The main purpose of the paper is not to propose yet another Machine Learning technique for defect proneness classification, but to present to the community a very large data set using process metrics as opposed to source code metrics, and draw some initial interesting conclusions from this statistically significant data set.	
127	Li, Yi	Managing Software Evolution through Semantic History Slicing		2017	Software change histories are results of incremental updates made by developers. As a side-effect of the software development process, version history is a surprisingly useful source of information for understanding, maintaining and reusing software. However, traditional commit-based sequential organization of version histories lacks semantic structure and thus are insufficient for many development tasks that require high-level, semantic understanding of program functionality, such as locating feature implementations and porting hot fixes. In this work, we propose to use well-organized unit tests as identifiers for corresponding software functionalities. We then present a family of automated techniques which analyze the semantics of historical changes and assist developers in many everyday practical settings. For validation, we evaluate our approaches on a benchmark of developer-annotated version history instances obtained from real-world open source software projects on GitHub. 	
128	Mirhosseini, Samim and Parnin, Chris	Can Automated Pull Requests Encourage Software Developers to Upgrade Out-of-Date Dependencies?		2017	Developers neglect to update legacy software dependencies, resulting in buggy and insecure software. One explanation for this neglect is the difficulty of constantly checking for the availability of new software updates, verifying their safety, and addressing any migration efforts needed when upgrading a dependency. Emerging tools attempt to address this problem by introducing automated pull requests and project badges to inform the developer of stale dependencies. To understand whether these tools actually help developers, we analyzed 7,470 GitHub projects that used these notification mechanisms to identify any change in upgrade behavior. Our results find that, on average, projects that use pull request notifications upgraded 1.6x as often as projects that did not use any tools. Badge notifications were slightly less effective: users upgraded 1.4x more frequently. Unfortunately, although pull request notifications are useful, developers are often overwhelmed by notifications: only a third of pull requests were actually merged. Through a survey, 62 developers indicated that their most significant concerns are breaking changes, understanding the implications of changes, and migration effort. The implications of our work suggests ways in which notifications can be improved to better align with developers' expectations and the need for new mechanisms to reduce notification fatigue and improve confidence in automated pull requests. 	
129	Wagstrom, Patrick and Jergensen, Corey and Sarma, Anita	A Network of Rails: A Graph Dataset of Ruby on Rails and Associated Projects		2013	Software projects, whether open source, proprietary, or a combination thereof, rarely exist in isolation. Rather, most projects build on a network of people and ideas from dozens, hundreds, or even thousands of other projects. Using the GitHub APIs it is possible to extract these relationships for millions of users and projects. In this paper we present a dataset of a large network of open source projects centered around Ruby on Rails. This dataset provides insight into the relationships between Ruby on Rails and an ecosystem involving 1116 projects. To facilitate understanding of this data in the context of relationships between projects, users, and their activities, it is provided as a graph database suitable for assessing network properties of the community and individuals within those communities and can be found at https://github.com/pridkett/gitminer-data-rails. 	
130	Nobel, Parth	Auto_diff: An Automatic Differentiation Package for Python		2020	We present auto_diff, a package that performs automatic differentiation of numerical Python code. auto_diff overrides Python's NumPy package's functions, augmenting them with seamless automatic differentiation capabilities. Notably, auto_diff is non-intrusive, i.e., the code to be differentiated does not require auto_diff-specific alterations. We illustrate auto_diff on electronic devices, a circuit simulation, and a mechanical system simulation. In our evaluations so far, we found that running simulations with auto_diff takes less than 4 times as long as simulations with hand-written differentiation code. We believe that auto_diff, which was written after attempts to use existing automatic differentiation packages on our applications ran into difficulties, caters to an important need within the numerical Python community. We have attempted to write this paper in a tutorial style to make it accessible to those without prior background in automatic differentiation techniques and packages. We have released auto_diff as open source on GitHub.	
131	Hellendoorn, Vincent J. and Devanbu, Premkumar T. and Bacchelli, Alberto	Will They like This? Evaluating Code Contributions with Language Models		2015	Popular open-source software projects receive and review contributions from a diverse array of developers, many of whom have little to no prior involvement with the project. A recent survey reported that reviewers consider conformance to the project's code style to be one of the top priorities when evaluating code contributions on Github. We propose to quantitatively evaluate the existence and effects of this phenomenon. To this aim we use language models, which were shown to accurately capture stylistic aspects of code. We find that rejected changesets do contain code significantly less similar to the project than accepted ones; furthermore, the less similar changesets are more likely to be subject to thorough review. Armed with these results we further investigate whether new contributors learn to conform to the project style and find that experience is positively correlated with conformance to the project's code style.	
132	Dyer, Robert and Nguyen, Hoan Anh and Rajan, Hridesh and Nguyen, Tien N.	Boa: A Language and Infrastructure for Analyzing Ultra-Large-Scale Software Repositories		2013	In today's software-centric world, ultra-large-scale software repositories, e.g. SourceForge (350,000+ projects), GitHub (250,000+ projects), and Google Code (250,000+ projects) are the new library of Alexandria. They contain an enormous corpus of software and information about software. Scientists and engineers alike are interested in analyzing this wealth of information both for curiosity as well as for testing important hypotheses. However, systematic extraction of relevant data from these repositories and analysis of such data for testing hypotheses is hard, and best left for mining software repository (MSR) experts! The goal of Boa, a domain-specific language and infrastructure described here, is to ease testing MSR-related hypotheses. We have implemented Boa and provide a web-based interface to Boa's infrastructure. Our evaluation demonstrates that Boa substantially reduces programming efforts, thus lowering the barrier to entry. We also see drastic improvements in scalability. Last but not least, reproducing an experiment conducted using Boa is just a matter of re-running small Boa programs provided by previous researchers. 	
133	Oliveira, Johnatan and Fernandes, Eduardo and Souza, Mauricio and Figueiredo, Eduardo	A Method Based on Naming Similarity to Identify Reuse Opportunities		2016	Software reuse is a development strategy in which existing software components, called reusable assets, are used in the development of new software systems. There are many advantages of reuse in software development, such as minimization of development efforts and improvement of software quality. New methods for reusable asset extraction are essential to achieve these advantages. Extraction methods may be used in different contexts including software product lines derivation. However, few methods have been proposed in literature for reusable asset extraction and recommendation of these reuse opportunities. In this paper, we propose a method for extraction of reuse opportunities based on naming similarity of two types of object-oriented entities: classes and methods. Our method, called JReuse, computes a similarity function to identify similarly named classes and methods from a set of software systems from a domain. These classes and methods compose a repository with reuse opportunities. We also present a prototype tool to support the extraction by applying our method. We evaluate the method with 38 e-commerce information systems mined from GitHub. As a result, we observe that our method is able to identify classes and methods that are relevant in the e-commerce domain.	
134	Unruh, Tommi and Shastry, Bhargava and Skoruppa, Malte and Maggi, Federico and Rieck, Konrad and Seifert, Jean-Pierre and Yamaguchi, Fabian	Leveraging Flawed Tutorials for Seeding Large-Scaleweb Vulnerability Discovery		2017	The Web is replete with tutorial-style content on how to accomplish programming tasks. Unfortunately, even topranked tutorials suffer from severe security vulnerabilities, such as cross-site scripting (XSS), and SQL injection (SQLi). Assuming that these tutorials influence real-world software development, we hypothesize that code snippets from popular tutorials can be used to bootstrap vulnerability discovery at scale. To validate our hypothesis, we propose a semi-automated approach to find recurring vulnerabilities starting from a handful of top-ranked tutorials that contain vulnerable code snippets. We evaluate our approach by performing an analysis of tens of thousands of open-source web applications to check if vulnerabilities originating in the selected tutorials recur. Our analysis framework has been running on a standard PC, analyzed 64,415 PHP codebases hosted on GitHub thus far, and found a total of 117 vulnerabilities that have a strong syntactic similarity to vulnerable code snippets present in popular tutorials. In addition to shedding light on the anecdotal belief that programmers reuse web tutorial code in an ad hoc manner, our study finds disconcerting evidence of insufficiently reviewed tutorials compromising the security of open-source projects. Moreover, our findings testify to the feasibility of large-scale vulnerability discovery using poorly written tutorials as a starting point.	
135	Jiang, Siyuan and Armaly, Ameer and McMillan, Collin	Automatically Generating Commit Messages from Diffs Using Neural Machine Translation		2017	Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, humans write messages that are short and summarize the high level rationale. In this paper, we adapt Neural Machine Translation (NMT) to automatically ``translate'' diffs into commit messages. We trained an NMT algorithm using a corpus of diffs and human-written commit messages from the top 1k Github projects. We designed a filter to help ensure that we only trained the algorithm on higher-quality commit messages. Our evaluation uncovered a pattern in which the messages we generate tend to be either very high or very low quality. Therefore, we created a quality-assurance filter to detect cases in which we are unable to produce good messages, and return a warning instead. 	
136	Rigby, Peter C. and Barr, Earl T. and Bird, Christian and Devanbu, Prem and German, Daniel M.	What Effect Does Distributed Version Control Have on OSS Project Organization?		2013	Many Open Source Software (OSS) projects are moving form Centralized Version Control (CVC) to Distributed Version Control (DVC). The effect of this shift on project organization and developer collaboration is not well understood. In this paper, we use a theoretical argument to evaluate the appropriateness of using DVC in the context of two very common organization forms in OSS: a dictatorship and a peer group. We find that DVC facilitates large hierarchical communities as well as smaller groups of developers, while CVC allows for consensus-building by a peer group. We also find that the flexibility of DVC systems allows for diverse styles of developer collaboration. With CVC, changes flow up and down (and publicly) via a central repository. In contrast, DVC facilitates collaboration in which work output can flow sideways (and privately) between collaborators, with no repository being inherently more important or central. These sideways flows are a relatively new concept. Developers on the Linux project, who tend to be experienced DVC users, cluster around "sandboxes:" repositories where developers can work together on a particular topic, isolating their changes from other developers. In this work, we focus on two large, mature OSS projects to illustrate these findings. However, we suggest that social media sites like GitHub may engender other original styles of collaboration that deserve further study.	
137	Burlet, Gregory and Hindle, Abram	An Empirical Study of End-User Programmers in the Computer Music Community		2015	Computer musicians are a community of end-user programmers who often use visual programming languages such as Max/MSP or Pure Data to realize their musical compositions. This research study conducts a multifaceted analysis of the software development practices of computer musicians when programming in these visual music-oriented languages. A statistical analysis of project metadata harvested from software repositories hosted on GitHub reveals that in comparison to the general population of software developers, computer musicians' repositories have less commits, less frequent commits, more commits on weekends, yet similar numbers of bug reports and similar numbers of contributing authors. Analysis of source code in these repositories reveals that the vast majority of code can be reconstructed from duplicate fragments. Finally, these results are corroborated by a survey of computer musicians and interviews with individuals in this end-user community. Based on this analysis and feedback from computer musicians we find that there are many avenues where software engineering can be applied to help aid this community of end-user programmers.	
138	Stevens, Marc and Shumow, Daniel	Speeding up Detection of SHA-1 Collision Attacks Using Unavoidable Attack Conditions		2017	Counter-cryptanalysis, the concept of using cryptanalytic techniques to detect cryptanalytic attacks, was introduced at CRYPTO 2013 [23] with a hash collision detection algorithm. That is, an algorithm that detects whether a given single message is part of a colliding message pair constructed using a cryptanalytic collision attack on MD5 or SHA-1.Unfortunately, the original collision detection algorithm is not a low-cost solution as it costs 15 to 224 times more than a single hash computation. In this paper we present a significant performance improvement for collision detection based on the new concept of unavoidable conditions. Unavoidable conditions are conditions that are necessary for all feasible attacks in a certain attack class. As such they can be used to quickly dismiss particular attack classes that may have been used in the construction of the message. To determine an unavoidable condition one must rule out any feasible variant attack where this condition might not be necessary, otherwise adversaries aware of counter-cryptanalysis could easily bypass this improved collision detection with a carefully chosen variant attack. Based on a conjecture solidly supported by the current state of the art, we show how we can determine such unavoidable conditions for SHA-1.We have implemented the improved SHA-1 collision detection using such unavoidable conditions and which is more than 20 times faster than without our unavoidable condition improvements. We have measured that overall our implemented SHA-1 with collision detection is only a factor 1.60 slower, on average, than SHA-1. With the demonstration of a SHA-1 collision, the algorithm presented here has been deployed by Git, GitHub, Google Drive, Gmail, Microsoft OneDrive and others, showing the effectiveness of this technique.	
139	Lyons, Kelly and Oh, Christie	SOA4DM: Applying an SOA Paradigm to Coordination in Humanitarian Disaster Response		2015	Despite efforts to achieve a sustainable state of control over the management of global crises, disasters are occurring with greater frequency, intensity, and affecting many more people than ever before while the resources to deal with them do not grow apace. As we enter 2015, with continued concerns that mega-crises may become the new normal, we need to develop novel methods to improve the efficiency and effectiveness of our management of disasters. Software engineering as a discipline has long had an impact on society beyond its role in the development of software systems. In fact, software engineers have been described as the developers of prototypes for future knowledge workers; tools such as Github and Stack Overflow have demonstrated applications beyond the domain of software engineering. In this paper, we take the potential influence of software engineering one-step further and propose using the software service engineering paradigm as a new approach to managing disasters. Specifically, we show how the underlying principles of service-oriented architectures (SOA) can be applied to the coordination of disaster response operations. We describe key challenges in coordinating disaster response and discuss how an SOA approach can address those challenges.	
140	Moura, Irineu and Pinto, Gustavo and Ebert, Felipe and Castor, Fernando	Mining Energy-Aware Commits		2015	Over the last years, energy consumption has become a first-class citizen in software development practice. While energy-efficient solutions on lower-level layers of the software stack are well-established, there is convincing evidence that even better results can be achieved by encouraging practitioners to participate in the process. For instance, previous work has shown that using a newer version of a concurrent data structure can yield a 2.19x energy savings when compared to the old associative implementation [75]. Nonetheless, little is known about how much software engineers are employing energy-efficient solutions in their applications and what solutions they employ for improving energy-efficiency. In this paper we present a qualitative study of "energy-aware commits". Using Github as our primary data source, we perform a thorough analysis on an initial sample of 2,189 commits and carefully curate a set of 371 energy-aware commits spread over 317 real-world non-trivial applications. Our study reveals that software developers heavily rely on low-level energy management approaches, such as frequency scaling and multiple levels of idleness. Also, our findings suggest that ill-chosen energy saving techniques can impact the correctness of an application. Yet, we found what we call "energy-aware interfaces", which are means for clients (e.g., developers or end-users) to save energy in their applications just by using a function, abstracting away the low-level implementation details.	
141	Lin, Jinfeng and Liu, Yalin and Guo, Jin and Cleland-Huang, Jane and Goss, William and Liu, Wenchuang and Lohar, Sugandha and Monaikul, Natawut and Rasin, Alexander	TiQi: A Natural Language Interface for Querying Software Project Data		2017	Abstract—Software projects produce large quantities of data such as feature requests, requirements, design artifacts, source code, tests, safety cases, release plans, and bug reports. If leveraged effectively, this data can be used to provide project intelligence that supports diverse software engineering activities such as release planning, impact analysis, and software analytics. However, project stakeholders often lack skills to formulate complex queries needed to retrieve, manipulate, and display the data in meaningful ways. To address these challenges we introduce TiQi, a natural language interface, which allows users to express software-related queries verbally or written in natural language. TiQi is a web-based tool. It visualizes available project data as a prompt to the user, accepts Natural Language (NL) queries, transforms those queries into SQL, and then executes the queries against a centralized or distributed database. Raw data is stored either directly in the database or retrieved dynamically at runtime from case tools and repositories such as Github and Jira. The transformed query is visualized back to the user as SQL and augmented UML, and raw data results are returned. Our tool demo can be found on YouTube at the following link:http://tinyurl.com/TIQIDemo. Keywords-Natural Language Interface, Project Data, Query 	
142	Muri\\'c, Goran and Tregubov, Alexey and Blythe, Jim and Abeliuk, Andr\\'es and Choudhary, Divya and Lerman, Kristina and Ferrara, Emilio	Massive Cross-Platform Simulations of Online Social Networks		2020	As part of the DARPA SocialSim challenge, we address the problem of predicting behavioral phenomena including information spread involving hundreds of thousands of users across three major linked social networks: Twitter, Reddit and GitHub. Our approach develops a framework for data-driven agent simulation that begins with a discrete-event simulation of the environment populated with generic, flexible agents, then optimizes the decision model of the agents by combining a number of machine learning classification problems. The ML problems predict when an agent will take a certain action in its world and are designed to combine aspects of the agents, gathered from historical data, with dynamic aspects of the environment including the resources, such as tweets, that agents interact with at a given point in time. In this way, each of the agents makes individualized decisions based on their environment, neighbors and history during the simulation, although global simulation data is used to learn accurate generalizations. This approach showed the best performance of all participants in the DARPA challenge across a broad range of metrics. We describe the performance of models both with and without machine learning on measures of cross-platform information spread defined both at the level of the whole population and at the community level. The best-performing model overall combines learned agent behaviors with explicit modeling of bursts in global activity. Because of the general nature of our approach, it is applicable to a range of prediction problems that require modeling individualized, situational agent behavior from trace data that combines many agents.	
\.


--
-- Data for Name: dblp; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.dblp (id, author, title, doi, year, abstract, url) FROM stdin;
1	Zhenhui Peng and	Exploring how software developers work with mention bot in GitHub	10.1007/s42486-019-00013-2	2019		https://doi.org/10.1007/s42486-019-00013-2
2	Cunyan Li and	Github\\unicode20013\\unicode24320\\unicode21457\\unicode20154\\unicode21592\\unicode30340\\unicode34892\\unicode20026\\unicode29305\\unicode24449\\unicode20998\\unicode26512	10.11896/j.issn.1002-137X.2019.02.024	2019		https://doi.org/10.11896/j.issn.1002-137X.2019.02.024
3	Chao Liu and	Recommending GitHub Projects for Developer Onboarding	10.1109/ACCESS.2018.2869207	2018		https://doi.org/10.1109/ACCESS.2018.2869207
4	Neil C. Borle and	Analyzing the effects of test driven development in GitHub	10.1007/s10664-017-9576-3	2018		https://doi.org/10.1007/s10664-017-9576-3
5	Yan Hu and	User influence analysis for Github developer social networks	10.1016/j.eswa.2018.05.002	2018		https://doi.org/10.1016/j.eswa.2018.05.002
6	Oskar Jarczyk and	Surgical teams on GitHub: Modeling performance of GitHub project development	10.1016/j.infsof.2018.03.010	2018		https://doi.org/10.1016/j.infsof.2018.03.010
7	Valerio Cosentino and	A Systematic Mapping Study of Software Development With GitHub	10.1109/ACCESS.2017.2682323	2017		https://doi.org/10.1109/ACCESS.2017.2682323
8	Yang Zhang and	Social media in GitHub: the role of @-mention in assisting software	10.1007/s11432-015-1024-6	2017		https://doi.org/10.1007/s11432-015-1024-6
9	Jing Jiang and	Why and how developers fork what from whom in GitHub	10.1007/s10664-016-9436-6	2017		https://doi.org/10.1007/s10664-016-9436-6
10	Yunxiang Xiong and	Developer Identity Linkage and Behavior Mining Across GitHub and StackOverflow	10.1142/S0218194017400034	2017		https://doi.org/10.1142/S0218194017400034
11	Ritu Arora and	Supporting collaborative software development over GitHub	10.1002/spe.2468	2017		https://doi.org/10.1002/spe.2468
12	Francisco Jurado and	Sentiment Analysis in monitoring software development processes: An	10.1016/j.jss.2015.02.055	2015		https://doi.org/10.1016/j.jss.2015.02.055
13	Andrew Begel and	Social Networking Meets Software Development: Perspectives from GitHub	10.1109/MS.2013.13	2013		https://doi.org/10.1109/MS.2013.13
14	Thomas S. Heinze and	Mining BPMN Processes on GitHub for Tool Validation and Development	10.1007/978-3-030-49418-6\\_13	2020		https://doi.org/10.1007/978-3-030-49418-6\\_13
15	Vikram N. Subramanian	An empirical study of the first contributions of developers to open	10.1145/3377812.3382165	2020		https://doi.org/10.1145/3377812.3382165
16	Ifraz Rehman and	Newcomer Candidate: Characterizing Contributions of a Novice Developer	10.1109/ICSME46990.2020.00110	2020		https://doi.org/10.1109/ICSME46990.2020.00110
17	Sri Lakshmi Vadlamani and	Studying Software Developer Expertise and Contributions in Stack Overflow	10.1109/ICSME46990.2020.00038	2020		https://doi.org/10.1109/ICSME46990.2020.00038
18	Hongbo Fang and	Need for Tweet: How Open Source Developers Talk About Their GitHub	10.1145/3379597.3387466	2020		https://doi.org/10.1145/3379597.3387466
19	Danielle Gonzalez and	The State of the ML-universe: 10 Years of Artificial Intelligence	10.1145/3379597.3387473	2020		https://doi.org/10.1145/3379597.3387473
20	Chris Brown and	Understanding the impact of GitHub suggested changes on recommendations	10.1145/3368089.3409722	2020		https://doi.org/10.1145/3368089.3409722
21	Syed Fatiul Huq and	Is Developer Sentiment Related to Software Bugs: An Exploratory Study	10.1109/SANER48275.2020.9054801	2020		https://doi.org/10.1109/SANER48275.2020.9054801
22	Syed Fatiul Huq and	Understanding the Effect of Developer Sentiment on Fix-Inducing Changes:	10.1109/APSEC48747.2019.00075	2019		https://doi.org/10.1109/APSEC48747.2019.00075
23	Simon Larsen and	RepoBee: Developing Tool Support for Courses using Git/GitHub	10.1145/3304221.3319784	2019		https://doi.org/10.1145/3304221.3319784
24	Saraj Singh Manes and	How often and what StackOverflow posts do developers reference in	10.1109/MSR.2019.00047	2019		https://doi.org/10.1109/MSR.2019.00047
25	Rijnard van Tonder and	A panel data set of cryptocurrency development activity on GitHub	10.1109/MSR.2019.00037	2019		https://doi.org/10.1109/MSR.2019.00037
26	Luis Silvestre and	Improving Continuous Software Development in Academic Scenarios using	10.1109/SCCC49216.2019.8966391	2019		https://doi.org/10.1109/SCCC49216.2019.8966391
27	Yutsuki Miyashita and	A Visualization System of the Contribution of Learners in Software	10.1109/APSEC.2018.00093	2018		https://doi.org/10.1109/APSEC.2018.00093
28	Zhenhui Peng and	Exploring How Software Developers Work with Mention Bot in GitHub	10.1145/3202667.3202694	2018		https://doi.org/10.1145/3202667.3202694
29	Ayushi Rastogi and	Relationship between geographical location and evaluation of developer	10.1145/3239235.3240504	2018		https://doi.org/10.1145/3239235.3240504
30	Riyu Bana and	Influence Indexing of Developers, Repositories, Technologies and Programming	10.1109/IC3.2018.8530644	2018		https://doi.org/10.1109/IC3.2018.8530644
31	Neil C. Borle and	Analyzing the effects of test driven development in GitHub	10.1145/3180155.3182535	2018		https://doi.org/10.1145/3180155.3182535
32	Naoyasu Ubayashi and	Exploring uncertainty in GitHub OSS projects: when and how do developers	10.1145/3183440.3194966	2018		https://doi.org/10.1145/3183440.3194966
33	Zhendong Wang and	Competence-confidence gap: a threat to female developers' contribution	10.1145/3183428.3183437	2018		https://doi.org/10.1145/3183428.3183437
34	Eldan Cohen and	Large-scale analysis of the co-commit patterns of the active developers	10.1145/3196398.3196436	2018		https://doi.org/10.1145/3196398.3196436
35	Justin Middleton and	Which contributions predict whether developers are accepted into github	10.1145/3196398.3196429	2018		https://doi.org/10.1145/3196398.3196429
36	Marco Ortu and	Mining Communication Patterns in Software Development: A GitHub	10.1145/3273934.3273943	2018		https://doi.org/10.1145/3273934.3273943
37	Can Cheng and	Automatic Detection of Public Development Projects in Large Open Source	10.18293/SEKE2018-085	2018		https://doi.org/10.18293/SEKE2018-085
38	Mateus F. Santos and	Analyzing The Impact Of Feedback In GitHub On The Software Developer's	10.18293/SEKE2018-153	2018		https://doi.org/10.18293/SEKE2018-153
39	Navdeep Singh and	How Do Code Refactoring Activities Impact Software Developers' Sentiments?	10.1109/APSEC.2017.79	2017		https://doi.org/10.1109/APSEC.2017.79
40	Christoph Matthies and	Prof. CI: Employing continuous integration services and Github workflows	10.1109/FIE.2017.8190589	2017		https://doi.org/10.1109/FIE.2017.8190589
41	Zhifang Liao and	DevRank: Mining Influential Developers in Github	10.1109/GLOCOM.2017.8255005	2017		https://doi.org/10.1109/GLOCOM.2017.8255005
42	Wanwangying Ma and	How do developers fix cross-project correlated bugs?: a case study	10.1109/ICSE.2017.42	2017		https://doi.org/10.1109/ICSE.2017.42
43	Francesca Arcelli Fontana and	Students' Feedback in Using GitHub in a Project Development for a	10.1145/3059009.3072984	2017		https://doi.org/10.1145/3059009.3072984
44	Yunxiang Xiong and	Mining Developer Behavior Across GitHub and StackOverflow	10.18293/SEKE2017-062	2017		https://doi.org/10.18293/SEKE2017-062
45	Roy Ka-Wei Lee and	GitHub and Stack Overflow: Analyzing Developer Interests Across Multiple	10.1007/978-3-319-67256-4\\_19	2017		https://doi.org/10.1007/978-3-319-67256-4\\_19
46	Roman Bartusiak and	Cooperation Prediction in GitHub Developers Network with Restricted	10.1007/978-3-662-49390-8\\_9	2016		https://doi.org/10.1007/978-3-662-49390-8\\_9
47	William Leibzon	Social network of software development at GitHub	10.1109/ASONAM.2016.7752419	2016		https://doi.org/10.1109/ASONAM.2016.7752419
48	Yusuke Saito and	How do GitHub Users Feel with Pull-Based Development?	10.1109/IWESEP.2016.19	2016		https://doi.org/10.1109/IWESEP.2016.19
49	Radoslaw Nielek and	Choose a Job You Love: Predicting Choices of GitHub Developers	10.1109/WI.2016.0037	2016		https://doi.org/10.1109/WI.2016.0037
50	Eirini Kalliamvakou and	Open Source-Style Collaborative Development Practices in Commercial	10.1109/ICSE.2015.74	2015		https://doi.org/10.1109/ICSE.2015.74
51	Yang Zhang and	Exploring the Use of @-mention to Assist Software Development in GitHub	10.1145/2875913.2875914	2015		https://doi.org/10.1145/2875913.2875914
52	Claudia Hauff and	Matching GitHub Developer Profiles to Job Advertisements	10.1109/MSR.2015.41	2015		https://doi.org/10.1109/MSR.2015.41
53	Casey Casalnuovo and	Developer onboarding in GitHub: the role of prior social links and	10.1145/2786805.2786854	2015		https://doi.org/10.1145/2786805.2786854
54	Leticia Montalvillo and	Tuning GitHub for SPL development: branching models \\& repository	10.1145/2791060.2791083	2015		https://doi.org/10.1145/2791060.2791083
55	David Rusk and	Location-Based Analysis of Developers and Technologies on GitHub	10.1109/WAINA.2014.110	2014		https://doi.org/10.1109/WAINA.2014.110
56	Yu Wu and	Exploring the ecosystem of software developers on GitHub and other	10.1145/2556420.2556483	2014		https://doi.org/10.1145/2556420.2556483
57	Liguo Yu and	An Empirical Study of the Dynamics of GitHub Repository and Its Impact	10.1007/978-3-662-45550-0\\_46	2014		https://doi.org/10.1007/978-3-662-45550-0\\_46
58	Saya Onoue and	A Study of the Characteristics of Developers' Activities in GitHub	10.1109/APSEC.2013.104	2013		https://doi.org/10.1109/APSEC.2013.104
59	Weicheng Yang and	Mining GitHub: Why Commit Stops - Exploring the Relationship between	10.1109/APSEC.2013.133	2013		https://doi.org/10.1109/APSEC.2013.133
60	Michael J. Lee and	GitHub developers use rockstars to overcome overflow of news	10.1145/2468356.2468381	2013		https://doi.org/10.1145/2468356.2468381
61	Bogdan Vasilescu and	StackOverflow and GitHub: Associations between Software Development	10.1109/SocialCom.2013.35	2013		https://doi.org/10.1109/SocialCom.2013.35
62	Sebastian Baltes and Stephan Diehl	Usage and attribution of Stack Overflow code snippets in GitHub projects	10.1007/s10664-018-9650-5	2019		https://doi.org/10.1007/s10664-018-9650-5
63	Christopher Vendome and Gabriele Bavota and Massimiliano Di Penta and Mario Linares Vasquez and Daniel M. German andDenys Poshyvanyk	License usage and changes: a large-scale study on gitHub	10.1007/s10664-016-9438-4	2017		https://doi.org/10.1007/s10664-016-9438-4
64	Muhammad Hilmi Asyrofi and	AUSearch: Accurate API Usage Search in GitHub Repositories with	10.1109/SANER48275.2020.9054809	2020		https://doi.org/10.1109/SANER48275.2020.9054809
65	David Kavaler and	Tool choice matters: JavaScript quality assurance tools and usage	10.1109/ICSE.2019.00060	2019		https://doi.org/10.1109/ICSE.2019.00060
66	Hudson Borges and	Beyond Textual Issues: Understanding the Usage and Impact of GitHub	10.1145/3350768.3350788	2019		https://doi.org/10.1145/3350768.3350788
67	Johannes H\\"artel and	EMF Patterns of Usage on GitHub	10.1007/978-3-319-92997-2\\_14	2018		https://doi.org/10.1007/978-3-319-92997-2\\_14
68	Anastasia Reinhardt and	Augmenting stack overflow with API usage patterns mined from GitHub	10.1145/3236024.3264585	2018		https://doi.org/10.1145/3236024.3264585
69	Casimiro Conde Marco Neto and	A structured survey on the usage of the issue tracking system provided	10.1145/3132498.3134110	2017		https://doi.org/10.1145/3132498.3134110
70	Christopher Vendome	A Large Scale Study of License Usage on GitHub	10.1109/ICSE.2015.245	2015		https://doi.org/10.1109/ICSE.2015.245
71	Christopher Vendome and	License usage and changes: a large-scale study of Java projects on	10.1109/ICPC.2015.32	2015		https://doi.org/10.1109/ICPC.2015.32
\.


--
-- Data for Name: dblp_manual; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.dblp_manual (id, author, title, doi, year, abstract, url) FROM stdin;
1	Nat\\'ercia A. Batista and	Tie Strength Metrics to Rank Pairs of Developers from GitHub		2018		https://periodicos.ufmg.br/index.php/jidm/article/view/417
2	Bogdan Negoita and	Code Forking and Software Development Project Sustainability: Evidence		2019		https://aisel.aisnet.org/icis2019/is\\_development/is\\_development/7
3	Yasemin Acar and	Security Developer Studies with GitHub Users: Exploring a Convenience		2017		https://www.usenix.org/conference/soups2017/technical-sessions/presentation/acar
4	Tianjie Deng and	Diversity in Software Development Routines are Attractive: A Preliminary		2015		http://aisel.aisnet.org/amcis2015/SystemsAnalysis/GeneralPresentations/7
5	Damien Legay and	On the Usage of Badges in Open Source Packages on GitHub		2019		http://ceur-ws.org/Vol-2605/9.pdf
\.


--
-- Data for Name: final; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.final (id, author, title, doi, year, abstract, url) FROM stdin;
1	Longo, Justin and Kelley, Tanya M.	Use of GitHub as a Platform for Open Collaboration on Text Documents	10.1145/2788993.2789838	2015	Recently, researchers are paying attention to the use of the software development and code-hosting web service GitHub for other collaborative purposes, including a class of activity referred to as document, text, or prose collaboration. These alternative uses of GitHub as a platform for sharing non-code artifacts represent an important modification in the practice of open collaboration. We survey cases where GitHub has been used to facilitate collaboration on non-code outputs, identify its strengths and weaknesses when used in this mode, and propose conditions for successful collaborations on co-created text documents.	https://doi.org/10.1145/2788993.2789838
2	Feliciano, Joseph and Storey, Margaret-Anne and Zagalsky, Alexey	Student Experiences Using GitHub in Software Engineering Courses: A Case Study	10.1145/2889160.2889195	2016	GitHub has been embraced by the software development community as an important social platform for managing software projects and to support collaborative development. More recently, educators have begun to adopt it for hosting course content and student assignments. From our previous research, we found that educators leverage GitHub's collaboration and transparency features to create, reuse and remix course materials, and to encourage student contributions and monitor student activity on assignments and projects. However, our previous research did not consider the student perspective.In this paper, we present a case study where GitHub is used as a learning platform for two software engineering courses. We gathered student perspectives on how the use of GitHub in their courses might benefit them and to identify the challenges they may face. The findings from our case study indicate that software engineering students do benefit from GitHub's transparent and open workflow. However, students were concerned that since GitHub is not inherently an educational tool, it lacks key features important for education and poses learning and privacy concerns. Our findings provide recommendations for designers on how tools such as GitHub can be used to improve software engineering education, and also point to recommendations for instructors on how to use it more effectively in their courses.	https://doi.org/10.1145/2889160.2889195
3	Neto, Casimiro Conde Marco and de O. Barros, M\\'arcio	A Structured Survey on the Usage of the Issue Tracking System Provided by the GitHub Platform	10.1145/3132498.3134110	2017	Issue tracking systems help software development teams in identifying problems to be solved and new features to be added to a software system. In this paper, we replicate and extend a study carried out in 2013 on the usage of the issue tracking system provided by the GitHub platform. The replication aims at determining whether the results observed four years ago are still valid. The extension seeks to analyze how often issues are terminated by commits to the version control system and understand whether this feature allows developers to relate an issue to the source code modules that were changed to resolve it. We conclude that the results of the previous study remain valid and that issues closed by commits are uncommon (about 4% of our sample) and often linked to technical aspects of the project.	https://doi.org/10.1145/3132498.3134110
4	Zhang, Yang and Wang, Huaimin and Yin, Gang and Wang, Tao and Yu, Yue	Exploring the Use of @-Mention to Assist Software Development in GitHub	10.1145/2875913.2875914	2015	Recently, many researches propose that social media tools can promote the collaboration among developers, which are beneficial to the software development. Nevertheless, there is little empirical evidence to confirm that using @-mention has indeed a beneficial impact on the issues in GitHub. In this paper, we analyze the data from GitHub and give some insights on how @-mention is used in the issues (general-issues and pull-requests). Our statistical results indicate that, @-mention attracts more participants and tends to be used in the difficult issues. @-mention favors the solving process of issues by enlarging the visibility of issues and facilitating the developers' collaboration. In addition to this global study, our study also build a @-network based on the @-mention database we extract. Through the @-network, we can mine the relationships and characteristics of developers in GitHub's issues.	https://doi.org/10.1145/2875913.2875914
5	Borges, Hudson and Brito, Rodrigo and Valente, Marco Tulio	Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions	10.1145/3350768.3350788	2019	Recently, GitHub introduced a new social feature, named reactions, which are "pictorial characters" similar to emoji symbols widely used nowadays in text-based communications. Particularly, GitHub users can use a pre-defined set of such symbols to react to issues and pull requests. However, little is known about the real usage and impact of GitHub reactions. In this paper, we analyze the reactions provided by developers to more than 2.5 million issues and 9.7 million issue comments, in order to answer an extensive list of nine research questions about the usage and adoption of reactions. We show that reactions are being increasingly used by open source developers. Moreover, we also found that issues with reactions usually take more time to be handled and have longer discussions.	https://doi.org/10.1145/3350768.3350788
6	Glassey, Richard	Managing Assignment Feedback via Issue Tracking	10.1145/3197091.3205819	2018	This poster provides insight into the use of an issue tracker for the management of assignment feedback within an introductory course in computer science (CS). Students have made use of Github for three successive years, and the issue tracker has become one of the key mechanisms for managing formative feedback. This approach has yielded three key benefits: increased student engagement in their own feedback; provided an early experience of an authentic and industry desirable communication skill; and created a means to oversee and learn from feedback discussions for the teaching team.	https://doi.org/10.1145/3197091.3205819
7	K\\"afer, Verena and Graziotin, Daniel and Bogicevic, Ivan and Wagner, Stefan and Ramadani, Jasmin	Communication in Open-Source Projects-End of the e-Mail Era?	10.1145/3183440.3194951	2018	Communication is essential in software engineering. Especially in distributed open-source teams, communication needs to be supported by channels including mailing lists, forums, issue trackers, and chat systems. Yet, we do not have a clear understanding of which communication channels stakeholders in open-source projects use. In this study, we fill the knowledge gap by investigating a statistically representative sample of 400 GitHub projects. We discover the used communication channels by regular expressions on project data. We show that (1) half of the GitHub projects use observable communication channels; (2) GitHub Issues, e-mail addresses, and the modern chat system Gitter are the most common channels; (3) mailing lists are only in place five and have a lower market share than all modern chat systems combined.	https://doi.org/10.1145/3183440.3194951
8	Rahman, Mohammad Masudur and Roy, Chanchal K.	An Insight into the Pull Requests of GitHub	10.1145/2597073.2597121	2014	Given the increasing number of unsuccessful pull requests in GitHub projects, insights into the success and failure of these requests are essential for the developers. In this paper, we provide a comparative study between successful and unsuccessful pull requests made to 78 GitHub base projects by 20,142 developers from 103,192 forked projects. In the study, we analyze pull request discussion texts, project specific information (e.g., domain, maturity), and developer specific information (e.g., experience) in order to report useful insights, and use them to contrast between successful and unsuccessful pull requests. We believe our study will help developers overcome the issues with pull requests in GitHub, and project administrators with informed decision making. 	https://doi.org/10.1145/2597073.2597121
9	Bentley, Carmen A. and Gehringer, Edward F.	Promoting Collaborative Skills with Github Project Boards	10.1145/3328778.3372646	2020	Teamwork skills are much in demand in the workplace, even more so with the growth of Agile methods. This calls for giving Computer Science students more practice in the kinds of team scenarios they will encounter on the job. Key for success are hands-on experience with planning methods, prioritization techniques, time management and organization. This poster shows how the cooperative tracking tool Github Project Boards helps teams strategize development, track progress, distribute work evenly, and facilitate collaboration. It also shows how instructors can use Github Project Boards to visualize and evaluate a team's development process.	https://doi.org/10.1145/3328778.3372646
10	Bhattacharjee, Avijit and Nath, Sristy Sumana and Zhou, Shurui and Chakroborti, Debasish and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin	An Exploratory Study to Find Motives Behind Cross-Platform Forks from Software Heritage Dataset	10.1145/3379597.3387512	2020	The fork-based development mechanism provides the flexibility and the unified processes for software teams to collaborate easily in a distributed setting without too much coordination overhead. Currently, multiple social coding platforms support fork-based development, such as GitHub, GitLab, and Bitbucket. Although these different platforms virtually share the same features, they have different emphasis. As GitHub is the most popular platform and the corresponding data is publicly available, most of the current studies are focusing on GitHub hosted projects. However, we observed anecdote evidences that people are confused about choosing among these platforms, and some projects are migrating from one platform to another, and the reasons behind these activities remain unknown. With the advances of Software Heritage Graph Dataset (SWHGD), we have the opportunity to investigate the forking activities across platforms. In this paper, we conduct an exploratory study on 10 popular open-source projects to identify cross-platform forks and investigate the motivation behind. Preliminary result shows that cross-platform forks do exist. For the 10 subject systems used in this study, we found 81,357 forks in total among which 179 forks are on GitLab. Based on our qualitative analysis, we found that most of the cross-platform forks that we identified are mirrors of the repositories on another platform, but we still find cases that were created due to preference of using certain functionalities (e.g. Continuous Integration (CI)) supported by different platforms. This study lays the foundation of future research directions, such as understanding the differences between platforms and supporting cross-platform collaboration.	https://doi.org/10.1145/3379597.3387512
11	Brown, Chris and Parnin, Chris	Understanding the Impact of GitHub Suggested Changes on Recommendations between Developers	10.1145/3368089.3409722	2020	Recommendations between colleagues are effective for encouraging developers to adopt better practices. Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks. However, in-person recommendations between developers in the workplace are declining. One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions. GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests. To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception. Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests. This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.	https://doi.org/10.1145/3368089.3409722
12	Kikas, Riivo and Dumas, Marlon and Pfahl, Dietmar	Issue Dynamics in Github Projects	10.1007/978-3-319-26844-6_22	2015	Issue repositories are used to keep of track of bugs, development tasks and feature requests in software development projects. In the case of open source projects, everyone can submit a new issue in the tracker. This practice can lead to situations where more issues are created than what can be effectively handled by the project members, raising the question of how issues are treated as the capacity of the project members is exceeded. In this paper, we study the temporal dynamics of issues in a popular open source development platform, namely Github, based on a sample of 4000 projects. We specifically analyze how the rate of issue creation, the amount of pending issues, and their average lifetime evolve over the course of time. The results show that more issues are opened shortly after the creation of a project repository and that the amount of pending issues increases inexorably due to forgotten unclosed issues. Yet, the average issue lifetime for issues that do get closed is relatively stable over time. These observations suggest that Github projects have implicit mechanisms for handling issues perceived to be important to the project, while neglecting those that exceed the project's capacity.	https://doi.org/10.1007/978-3-319-26844-6_22
13	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	What the Fork: A Study of Inefficient and Efficient Forking Practices in Social Coding	10.1145/3338906.3338918	2019	Forking and pull requests have been widely used in open-source communities as a uniform development and contribution mechanism, giving developers the flexibility to modify their own fork without affecting others before attempting to contribute back. However, not all projects use forks efficiently; many experience lost and duplicate contributions and fragmented communities. In this paper, we explore how open-source projects on GitHub differ with regard to forking inefficiencies. First, we observed that different communities experience these inefficiencies to widely different degrees and interviewed practitioners to understand why. Then, using multiple regression modeling, we analyzed which context factors correlate with fewer inefficiencies.We found that better modularity and centralized management are associated with more contributions and a higher fraction of accepted pull requests, suggesting specific best practices that project maintainers can adopt to reduce forking-related inefficiencies in their communities.	https://doi.org/10.1145/3338906.3338918
14	Stanciulescu, Stefan and Schulze, Sandro and Wasowski, Andrzej	Forked and Integrated Variants in an Open-Source Firmware Project	10.1109/ICSM.2015.7332461	2015	Code cloning has been reported both on small (code fragments) and large (entire projects) scale. Cloning-in-the-large, or forking, is gaining ground as a reuse mechanism thanks to availability of better tools for maintaining forked project variants, hereunder distributed version control systems and interactive source management platforms such as Github. We study advantages and disadvantages of forking using the case of Marlin, an open source firmware for 3D printers. We find that many problems and advantages of cloning do translate to forking. Interestingly, the Marlin community uses both forking and integrated variability management (conditional compilation) to create variants and features. Thus, studying it increases our understanding of the choice between integrated and clone-based variant management. It also allows us to observe mechanisms governing source code maturation, in particular when, why and how feature implementations are migrated from forks to the main integrated platform. We believe that this understanding will ultimately help development of tools mixing clone-based and integrated variant management, combining the advantages of both.	https://doi.org/10.1109/ICSM.2015.7332461
15	Pietri, Antoine and Rousseau, Guillaume and Zacchiroli, Stefano	Forking Without Clicking: On How to Identify Software Repository Forks	10.1145/3379597.3387450	2020	The notion of software "fork" has been shifting over time from the (negative) phenomenon of community disagreements that result in the creation of separate development lines and ultimately software products, to the (positive) practice of using distributed version control system (VCS) repositories to collaboratively improve a single product without stepping on each others toes. In both cases the VCS repositories participating in a fork share parts of a common development history.Studies of software forks generally rely on hosting platform metadata, such as GitHub, as the source of truth for what constitutes a fork. These "forge forks" however can only identify as forks repositories that have been created on the platform, e.g., by clicking a "fork" button on the platform user interface. The increased diversity in code hosting platforms (e.g., GitLab) and the habits of significant development communities (e.g., the Linux kernel, which is not primarily hosted on any single platform) call into question the reliability of trusting code hosting platforms to identify forks. Doing so might introduce selection and methodological biases in empirical studies.In this article we explore various definitions of "software forks", trying to capture forking workflows that exist in the real world. We quantify the differences in how many repositories would be identified as forks on GitHub according to the various definitions, confirming that a significant number could be overlooked by only considering forge forks. We study the structure and size of fork networks, observing how they are affected by the proposed definitions and discuss the potential impact on empirical research.	https://doi.org/10.1145/3379597.3387450
16	Ford, Denae and Behroozi, Mahnaz and Serebrenik, Alexander and Parnin, Chris	Beyond the Code Itself: How Programmers <i>Really</i> Look at Pull Requests	10.1109/ICSE-SEIS.2019.17	2019	Developers in open source projects must make decisions on contributions from other community members, such as whether or not to accept a pull request. However, secondary factors---beyond the code itself---can influence those decisions. For example, signals from GitHub profiles, such as a number of followers, activity, names, or gender can also be considered when developers make decisions. In this paper, we examine how developers use these signals (or not) when making decisions about code contributions. To evaluate this question, we evaluate how signals related to perceived gender identity and code quality influenced decisions on accepting pull requests. Unlike previous work, we analyze this decision process with data collected from an eye-tracker. We analyzed differences in what signals developers said are important for themselves versus what signals they actually used to make decisions about others. We found that after the code snippet (x = 57%), the second place programmers spent their time ixating is on supplemental technical signals (x = 32%), such as previous contributions and popular repositories. Diverging from what participants reported themselves, we also found that programmers ixated on social signals more than recalled.	https://doi.org/10.1109/ICSE-SEIS.2019.17
17	Jiang, J., Lo, D., He, J., Xia, X., Kochhar, P.S., Zhang, L.	Why and how developers fork what from whom in GitHub	10.1007/s10664-016-9436-6	2017		https://doi.org/10.1007/s10664-016-9436-6
18	Sheoran, Jyoti and Blincoe, Kelly and Kalliamvakou, Eirini and Damian, Daniela and Ell, Jordan	Understanding "Watchers" on GitHub	10.1145/2597073.2597114	2014	Users on GitHub can watch repositories to receive notifications about project activity. This introduces a new type of passive project membership. In this paper, we investigate the behavior of watchers and their contribution to the projects they watch. We find that a subset of project watchers begin contributing to the project and those contributors account for a significant percentage of contributors on the project. As contributors, watchers are more confident and contribute over a longer period of time in a more varied way than other contributors. This is likely attributable to the knowledge gained through project notifications. 	https://doi.org/10.1145/2597073.2597114
19	Destefanis, Giuseppe and Ortu, Marco and Bowes, David and Marchesi, Michele and Tonelli, Roberto	On Measuring Affects of Github Issues' Commenters	10.1145/3194932.3194936	2018	In this study, we analyzed issues and comments on GitHub projects and built collaboration networks dividing contributors into two categories: users and commenters. We identified as commenters those users who only post comments without posting any issues nor committing changes in the source code. Since previous studies showed that there is a link between a positive environment (regarding affectiveness) and productivity, our goal was to investigate commenters' contribution to the project concerning affectiveness.We analyzed more than 370K comments from 100K issues of 25K contributors from 3 open source projects. We then calculated and compared the affectiveness of the issues' comments written by users and commenters in terms of sentiment, politeness, and emotions. We provide empirical evidence that commenters are less polite, less positive and in general they express a lower level of emotions in their comments than users. Our results also confirm that GitHub's contributors consist of different groups which behave differently, and this provides useful information for future studies in the field.	https://doi.org/10.1145/3194932.3194936
20	Tan, Xin and Zhou, Minghui and Sun, Zeyu	A First Look at Good First Issues on GitHub	10.1145/3368089.3409746	2020	Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time. To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers. However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain. To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices. By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results. We find that more and more projects are applying this mechanism in the past decade, especially the popular projects. Compared to common issues, GFIs usually need more days to be solved. While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers. We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective. We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc. Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.	https://doi.org/10.1145/3368089.3409746
21	Tsay, Jason and Dabbish, Laura and Herbsleb, James	Let's Talk about It: Evaluating Contributions through Discussion in GitHub	10.1145/2635868.2635882	2014	Open source software projects often rely on code contributions from a wide variety of developers to extend the capabilities of their software. Project members evaluate these contributions and often engage in extended discussions to decide whether to integrate changes. These discussions have important implications for project management regarding new contributors and evolution of project requirements and direction. We present a study of how developers in open work environments evaluate and discuss pull requests, a primary method of contribution in GitHub, analyzing a sample of extended discussions around pull requests and interviews with GitHub developers. We found that developers raised issues around contributions over both the appropriateness of the problem that the submitter attempted to solve and the correctness of the implemented solution. Both core project members and third-party stakeholders discussed and sometimes implemented alternative solutions to address these issues. Different stakeholders also influenced the outcome of the evaluation by eliciting support from different communities such as dependent projects or even companies. We also found that evaluation outcomes may be more complex than simply acceptance or rejection. In some cases, although a submitter's contribution was rejected, the core team fulfilled the submitter's technical goals by implementing an alternative solution. We found that the level of a submitter's prior interaction on a project changed how politely developers discussed the contribution and the nature of proposed alternative solutions. 	https://doi.org/10.1145/2635868.2635882
22	Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	Investigating Social Media in GitHub's Pull-Requests: A Case Study on Ruby on Rails	10.1145/2666539.2666572	2014	In GitHub, pull-request mechanism is an outstanding social development method by integrating with many social media. Many studies have explored that social media has an important effect on software development. @-mention as a typical social media, is a useful tool in social platform. In this paper, we made a quantitative analysis of @-mention in pull-requests of the project Ruby on Rails. First, we make a convictive statistics of the popularity of pull-request mechanism in GitHub. Then we investigate the current situation of @-mention in the Ruby on Rails. Our empirical analysis results find some insights of @-mention. 	https://doi.org/10.1145/2666539.2666572
23	Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	A Exploratory Study of @-Mention in GitHub's Pull-Requests	10.1109/APSEC.2014.58	2014	Pull-request mechanism is an outstanding social development method in Git Hub. @-mention is a social media tool that deeply integrated with pull-request mechanism. Recently, many research results show that social media tools can promote the collaborative software development, but few work focuses on the impacts of @-mention. In this paper, we conduct an exploratory study of @-mention in pull-request based software development, including its current situation and benefits. We obtain some interesting findings which indicate that @-mention is beneficial to the processing of pull-request. Our work also proposes some possible research directions and problems of the @-mention. It helps the developers and researchers notice the significance of @-mention in the pull-request based software development.	https://doi.org/10.1109/APSEC.2014.58
24	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	How Has Forking Changed in the Last 20 Years? A Study of Hard Forks on GitHub	10.1145/3377811.3380412	2020	The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub. Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks. To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories. We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project.	https://doi.org/10.1145/3377811.3380412
25	Yang Zhang and	Social media in GitHub: the role of @-mention in assisting software	10.1007/s11432-015-1024-6	2017		https://doi.org/10.1007/s11432-015-1024-6
26	Jiang, J. and Wu, Q. and Cao, J. and Xia, X. and Zhang, L.	Recommending tags for pull requests in GitHub	10.1016/j.infsof.2020.106394	2021		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092068193&doi=10.1016%2fj.infsof.2020.106394&partnerID=40&md5=4ee8a71e5e67bc61a40e84464506400e
27	Utomo, P. and Falahah	Building Serverless Website on GitHub Pages	10.1088/1757-899X/879/1/012077	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091346359&doi=10.1088%2f1757-899X%2f879%2f1%2f012077&partnerID=40&md5=a42a4e51229c007d6a3f1d1c6a969772
28	Zhang, Y. and Wang, H. and Wu, Y. and Hu, D. and Wang, T.	GitHub's milestone tool: A mixed-methods analysis on its use	10.1002/smr.2229	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075388288&doi=10.1002%2fsmr.2229&partnerID=40&md5=491143dfea220852a144e812cc022ee9
29	Wang, W., Poo-Caamaño, G., Wilde, E., German, D.M.	What is the GIST? Understanding the use of public gists on GitHub	10.1109/MSR.2015.36	2015	GitHub is a popular source code hosting site which serves as a collaborative coding platform. The many features of GitHub have greatly facilitated developers' collaboration, communication, and coordination. Gists are one feature of GitHub, which defines them as 'a simple way to share snippets and pastes with others.' This three-part study explores how users are using Gists. The first part is a quantitative analysis of Gist metadata and contents. The second part investigates the information contained in a Gist: We sampled 750k users and their Gists (totalling 762k Gists), then manually categorized the contents of 398. The third part of the study investigates what users are saying Gists are for by reading the contents of web pages and twitter feeds. The results indicate that Gists are used by a small portion of GitHub users, and those that use them typically only have a few. We found that Gists are usually small and composed of a single file. However, Gists serve a wide variety of uses, from saving snippets of code, to creating reusable components for web pages. © 2015 IEEE.	https://ieeexplore.ieee.org/document/7180090
30	Alexey Zagalsky, Joseph Feliciano, Margaret-Anne Storey, Yiyun Zhao, Weiliang Wang	The Emergence of GitHub as a Collaborative Platform forEducation	10.1145/2675133.2675284	2015	The software development community has embraced GitHubas an essential platform for managing their software projects.GitHub has created efficiencies and helped improve the waysoftware professionals work. It not only provides a traceableproject  repository,  but  it  acts  as  a  social  meeting  place  forinterested parties,  supporting communities of practice.   Re-cently, educators have seen the potential in GitHub’s collab-orative features for managing and improving—perhaps eventransforming—the learning experience.In this study, we examine how GitHub is emerging as a col-laborative platform for education. We aim to understand howenvironments such as GitHub—environments that provide so-cial and collaborative features in conjunction with distributedversion control—may improve (or possibly hinder) the edu-cational  experience  for  students  and  teachers.   We  conducta  qualitative  study  focusing  on  how  GitHub  is  being  usedin education, and the motivations, benefits and challenges itbrings.	http://dx.doi.org/10.1145/2675133.2675284
31	T. F. Bissyandé, D. Lo, L. Jiang, L. Réveillère, J. Klein and Y. L. Traon	Got issues? Who cares about it? A large scale investigation of issue trackers from GitHub	10.1109/ISSRE.2013.6698918	2013	Feedback from software users constitutes a vital part in the evolution of software projects. By filing issue reports, users help identify and fix bugs, document software code, and enhance the software via feature requests. Many studies have explored issue reports, proposed approaches to enable the submission of higher-quality reports, and presented techniques to sort, categorize and leverage issues for software engineering needs. Who, however, cares about filing issues? What kind of issues are reported in issue trackers? What kind of correlation exist between issue reporting and the success of software projects? In this study, we address the need for answering such questions by performing an empirical study on a hundred thousands of open source projects. After filtering relevant trackers, the study used about 20,000 projects. We investigate and answer various research questions on the popularity and impact of issue trackers.	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6698918&isnumber=6698873
32	Miroslav Tushev, Grant Williams & Anas Mahmoud	Using GitHub in large software engineering classes. An exploratory case study	10.1080/08993408.2019.1696168	2020	Background and Context: GitHub has been recently used in Software Engineering (SE) classes to facilitate collaboration in student team projects as well as help teachers to evaluate the contributions of their students more objectively. Objective: We explore the benefits and drawbacks of using GitHub as a means for team collaboration and performance evaluation in large SE classes. Method: Our research method takes the form of a case study conducted in a senior level SE class with 91 students. Our study also includes entry and exit surveys, an exit interview, and a qualitative analysis of students’ commit behavior. Findings: Different teams adapt GitHub to their workflow differently. Furthermore, despite the steep learning curve, using GitHub should not affect the quality of students’ submissions. However, using GitHub metrics as a proxy for evaluating team performance can be risky. Implications: We provide several recommendations for integrating Web-based configuration management tools in SE classes. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.	https://doi.org/10.1080/08993408.2019.1696168
33	Jordi Cabot, Javier Luis C ́anovas Izquierdo, Valerio Cosentino, Bel ́en Rolandi	Exploring the use of labels to categorize issues in Open-Source Software projects	10.1109/SANER.2015.7081875	2015	Reporting bugs, asking for new features and in general giving any kind of feedback is a common way to contribute to an Open-Source Software (OSS) project. This feedback is generally reported in the form of new issues for the project, managed by the so-called issue-trackers. One of the features provided by most issue-trackers is the possibility to define a set of labels/tags to classify the issues and, at least in theory, facilitate their management. Nevertheless, there is little empirical evidence to confirm that taking the time to categorize new issues has indeed a beneficial impact on the project evolution. In this paper we analyze a population of more than three million of GitHub projects and give some insights on how labels are used in them. Our preliminary results reveal that, even if the label mechanism is scarcely used, using labels favors the resolution of issues. Our analysis also suggests that not all projects use labels in the same way (e.g., for some labels are only a way to prioritize the project while others use them to signal their temporal evolution as they move along in the development workflow). Further research is needed to precisely characterize these label families and learn more the ideal application scenarios for each of them. © 2015 IEEE.	https://ieeexplore.ieee.org/document/7081875
34	Gousios, Georgios and Pinzger, Martin and Deursen, Arie van	An exploratory study of the pull-based software development model	10.1145/2568225.2568260	2014	The advent of distributed version control systems has led to the development of a new paradigm for distributed software development; instead of pushing changes to a central repository, developers pull them from other repositories and merge them locally. Various code hosting sites, notably Github, have tapped on the opportunity to facilitate pull-based development by offering workflow support tools, such as code reviewing systems and integrated issue trackers. In this work, we explore how pull-based software development works, first on the GHTorrent corpus and then on a carefully selected sample of 291 projects. We find that the pull request model offers fast turnaround, increased opportunities for community engagement and decreased time to incorporate contributions. We show that a relatively small number of factors affect both the decision to merge a pull request and the time to process it. We also examine the reasons for pull request rejection and find that technical ones are only a small minority. © 2014 ACM.	https://doi.org/10.1145/2568225.2568260
35	 Kavaler, D., Devanbu, P., Filkov, V.	Whom are you going to call? determinants of @-mentions in Github discussions	10.1007/s10664-019-09728-3	2019	Open Source Software (OSS) project success relies on crowd contributions. When an issue arises in pull-request based systems, @-mentions are used to call on people to task; previous studies have shown that @-mentions in discussions are associated with faster issue resolution. In most projects there may be many developers who could technically handle a variety of tasks. But OSS supports dynamic teams distributed across a wide variety of social and geographic backgrounds, as well as levels of involvement. It is, then, important to know whom to call on, i.e., who can be relied or trusted with important task-related duties, and why. In this paper, we sought to understand which observable socio-technical attributes of developers can be used to build good models of them being future @-mentioned in GitHub issues and pull request discussions. We built overall and project-specific predictive models of future @-mentions, in order to capture the determinants of @-mentions in each of two hundred GitHub projects, and to understand if and how those determinants differ between projects. We found that visibility, expertise, and productivity are associated with an increase in @-mentions, while responsiveness is not, in the presence of a number of control variables. Also, we find that though project-specific differences exist, the overall model can be used for cross-project prediction, indicating its GitHub-wide utility. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.	https://link.springer.com/article/10.1007%2Fs10664-019-09728-3
36	Borges, H., Tulio Valente, M.	What's in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform	10.1016/j.jss.2018.09.016	2018	Besides a git-based version control system, GitHub integrates several social coding features. Particularly, GitHub users can star a repository, presumably to manifest interest or satisfaction with an open source project. However, the real and practical meaning of starring a project was never the subject of an in-depth and well-founded empirical investigation. Therefore, we provide in this paper a throughout study on the meaning, characteristics, and dynamic growth of GitHub stars. First, by surveying 791 developers, we report that three out of four developers consider the number of stars before using or contributing to a GitHub project. Then, we report a quantitative analysis on the characteristics of the top-5,000 most starred GitHub repositories. We propose four patterns to describe stars growth, which are derived after clustering the time series representing the number of stars of the studied repositories; we also reveal the perception of 115 developers about these growth patterns. To conclude, we provide a list of recommendations to open source project managers (e.g., on the importance of social media promotion) and to GitHub users and Software Engineering researchers (e.g., on the risks faced when selecting projects by GitHub stars). © 2018 Elsevier Inc.	https://www.sciencedirect.com/science/article/abs/pii/S0164121218301961?via%3Dihub
37	Robles, G., González-Barahona, J.M.	A comprehensive study of software forks: Dates, reasons and outcomes	10.1007/978-3-642-33442-9_1	2012	In general it is assumed that a software product evolves within the authoring company or group of developers that develop the project. However, in some cases different groups of developers make the software evolve in different directions, a situation which is commonly known as a fork. In the case of free software, although forking is a practice that is considered as a last resort, it is inherent to the four freedoms. This paper tries to shed some light on the practice of forking. Therefore, we have identified significant forks, several hundreds in total, and have studied them in depth. Among the issues that have been analyzed for each fork is the date when the forking occurred, the reason of the fork, and the outcome of the fork, i.e., if the original or the forking project are still developed. Our investigation shows, among other results, that forks occur in every software domain, that they have become more frequent in recent years, and that very few forks merge with the original project. © 2012 IFIP International Federation for Information Processing.	https://link.springer.com/chapter/10.1007%2F978-3-642-33442-9_1
38	Lisha Li; Zhilei Ren; Xiaochen Li; Weiqin Zou; He Jiang	How Are Issue Units Linked? Empirical Study on the Linking Behavior in GitHub	10.1109/APSEC.2018.00053	2018	Issue reports and Pull Requests (PRs) are two important kinds of artifacts of software projects in GitHub. It is common for developers to leave explicit links in issues/PRs that refer to the other issues/PRs during discussions. Existing studies have demonstrated the value of such links in identifying complex bugs and duplicate issue reports. However, there are no broad examinations of why developers leave links within issues/PRs and the potential impact of such links on software development. Without such knowledge, practitioners and researchers may miss various opportunities to develop practical techniques for better solving bug-fixing or feature implementation related tasks. To fill this gap, we conducted the first empirical study to explore the characteristics of a large number of links within 642,281 issues/PRs of 16,584 popular (>50 stars) Python projects in GitHub. Specifically, we first constructed an Issue Unit Network (IUN, we refer to issue reports or PRs as issue units) by making use of the links between issue units. Then, we manually checked a sample of 1,384 links in the IUN and concluded six major kinds of linking relationships between issue units. For each kind of linking relationships, we presented some common patterns that developers usually adopted while linking issue units. By further analyzing as many as 423,503 links that match these common patterns, we found several interesting findings which indicate potential research directions in the future, including detecting cross-project duplicate issue reports, using IUN to help better identify influential projects and core issue reports.	https://ieeexplore.ieee.org/document/8719531
\.


--
-- Data for Name: scopus; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.scopus (id, author, title, doi, year, abstract, url) FROM stdin;
1	Klymenko, M.V. and Vaitkus, J.A. and Smith, J.S. and Cole, J.H.	NanoNET: An extendable Python framework for semi-empirical tight-binding models	10.1016/j.cpc.2020.107676	2021		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093703421&doi=10.1016%2fj.cpc.2020.107676&partnerID=40&md5=64cae03ab9761ddb74469ce7662352ea
2	Jiang, J. and Wu, Q. and Cao, J. and Xia, X. and Zhang, L.	Recommending tags for pull requests in GitHub	10.1016/j.infsof.2020.106394	2021		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092068193&doi=10.1016%2fj.infsof.2020.106394&partnerID=40&md5=4ee8a71e5e67bc61a40e84464506400e
3	Vandenbon, A. and Diez, D.	A clustering-independent method for finding differentially expressed genes in single-cell transcriptome data	10.1038/s41467-020-17900-3	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089959492&doi=10.1038%2fs41467-020-17900-3&partnerID=40&md5=8689d80ad95d749b8647b6aa1702553e
4	Gousiya Begum and Huq, S.Z.U. and Kumar, A.P.S.	Sandbox security model for Hadoop file system	10.1186/s40537-020-00356-z	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091723500&doi=10.1186%2fs40537-020-00356-z&partnerID=40&md5=0544c228f4c502091d39e636cc731f2e
5	Dong, X. and Zhang, L. and Hao, X. and Wang, T. and Vijg, J.	SCCNV: A Software Tool for Identifying Copy Number Variation From Single-Cell Whole-Genome Sequencing	10.3389/fgene.2020.505441	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096911460&doi=10.3389%2ffgene.2020.505441&partnerID=40&md5=53744123682c18ef81098aaf05f6fd3f
6	Miyaki, R. and Yoshida, N. and Tsuzuki, N. and Yamamoto, R. and Takada, H.	Fuzz4B: A front-end to AFL not only for fuzzing experts	10.1145/3412452.3423572	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096991783&doi=10.1145%2f3412452.3423572&partnerID=40&md5=016f6557b31fc37fb2e5b5f5c3165ccc
7	Fischbach, A. and Strohschein, J. and Bunte, A. and Stork, J. and Faeskorn-Woyke, H. and Moriz, N. and Bartz-Beielstein, T.	CAAI—a cognitive architecture to introduce artificial intelligence in cyber-physical production systems	10.1007/s00170-020-06094-z	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091780685&doi=10.1007%2fs00170-020-06094-z&partnerID=40&md5=87c2e04e856f2d9703ee6164f64dd45f
8	Zhou, Q. and Wang, Y. and Fan, Y. and Wu, X. and Zhang, S. and Kang, B. and Latecki, L.J.	AGLNet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network	10.1016/j.asoc.2020.106682	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090219040&doi=10.1016%2fj.asoc.2020.106682&partnerID=40&md5=8db4eb8ecc0ee0bf2c360e70736f9e34
9	Fang, Z. and Zhou, H.	Identification of the conjugative and mobilizable plasmid fragments in the plasmidome using sequence signatures	10.1099/mgen.0.000459	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097002939&doi=10.1099%2fmgen.0.000459&partnerID=40&md5=156831ee64593ad9f8cbe414b208da9c
10	Du, R. and Turner, E. and Dzitsiuk, M. and Prasso, L. and Duarte, I. and Dourgarian, J. and Afonso, J. and Pascoal, J. and Gladstone, J. and Cruces, N. and Izadi, S. and Kowdle, A. and Tsotsos, K. and Kim, D.	DepthLab: Real-time 3D interaction with depth maps for mobile augmented reality	10.1145/3379337.3415881	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095609289&doi=10.1145%2f3379337.3415881&partnerID=40&md5=6e25b17d4c445bcc9d91639d54eecaac
11	Jančigová, I. and Kovalčíková, K. and Weeber, R. and Cimrák, I.	PyOIF: Computational tool for modelling of multi-cell flows in complex geometries	10.1371/journal.pcbi.1008249	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094677907&doi=10.1371%2fjournal.pcbi.1008249&partnerID=40&md5=2d68172d8b9e0f40bc87df4d5625691c
12	Scoccia, G.L. and Autili, M.	Web frameworks for desktop apps: An exploratory study	10.1145/3382494.3422171	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095841232&doi=10.1145%2f3382494.3422171&partnerID=40&md5=9fc34f2c245e192caa30de19a532d5ec
13	Jiang, J. and Chen, X. and Li, T. and Wang, C. and Shen, T. and Zhao, S. and Cui, H. and Wang, C.-L. and Zhang, F.	Uranus: Simple, Efficient SGX Programming and its Applications	10.1145/3320269.3384763	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090417085&doi=10.1145%2f3320269.3384763&partnerID=40&md5=774a4ad80ec09358941282046e889a8a
14	Schubert, R. and Andaleon, A. and Wheeler, H.E.	Comparing local ancestry inference models in populations of two- And three-way admixture	10.7717/peerj.10090	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093849582&doi=10.7717%2fpeerj.10090&partnerID=40&md5=1c50e36ec05321c6ddb4d134a58755c6
15	Qin, X. and Zhang, Z. and Huang, C. and Dehghan, M. and Zaiane, O.R. and Jagersand, M.	U2-Net: Going deeper with nested U-structure for salient object detection	10.1016/j.patcog.2020.107404	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084667067&doi=10.1016%2fj.patcog.2020.107404&partnerID=40&md5=3f69209b10cfcb2ad361d52df4bbcf2e
16	Lovelace, R. and Beecham, R. and Heinen, E. and Vidal Tortosa, E. and Yang, Y. and Slade, C. and Roberts, A.	Is the London Cycle Hire Scheme becoming more inclusive? An evaluation of the shifting spatial distribution of uptake based on 70 million trips	10.1016/j.tra.2020.07.017	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089236805&doi=10.1016%2fj.tra.2020.07.017&partnerID=40&md5=24f02fc14e8d9123d1bf94171a607517
17	Zhang, H. and Dimitrov, D. and Simpson, L. and Plaks, N. and Singh, B. and Penney, S. and Charles, J. and Sheehan, R. and Flammini, S. and Murphy, S. and Landman, A.	A web-based, mobile-responsive application to screen health care workers for COVID-19 symptoms: Rapid design, deployment, and usage	10.2196/19533	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096939020&doi=10.2196%2f19533&partnerID=40&md5=b8f674188494f3d142fadc8a0a8c82c3
18	Guebila, M.B.	VFFVA: Dynamic load balancing enables large-scale flux variability analysis	10.1186/s12859-020-03711-2	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092396672&doi=10.1186%2fs12859-020-03711-2&partnerID=40&md5=f83340abfbc487711f4451c1ad945a7c
19	Cuculovic, M. and Fondement, F. and Devanne, M. and Weber, J. and Hassenforder, M.	Change Detection on JATS Academic Articles: An XML Diff Comparison Study	10.1145/3395027.3419581	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093094261&doi=10.1145%2f3395027.3419581&partnerID=40&md5=688a09efda95ffabd75ca8aa8451aa27
20	Walsh, K. and Voineagu, M.A. and Vafaee, F. and Voineagu, I.	TDAview: an online visualization tool for topological data analysis	10.1093/bioinformatics/btaa600	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097003370&doi=10.1093%2fbioinformatics%2fbtaa600&partnerID=40&md5=28c1442821cb48ffc9b75fc75eac447f
21	Silverj, A. and Rota-Stabelli, O.	On the correct interpretation of similarity index in codon usage studies: Comparison with four other metrics and implications for Zika and West Nile virus	10.1016/j.virusres.2020.198097	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088387605&doi=10.1016%2fj.virusres.2020.198097&partnerID=40&md5=575da4ab4e27b75884501ce23f06ffe0
22	Lin, C. and Nadi, S. and Khazaei, H.	A Large-scale Data Set and an Empirical Study of Docker Images Hosted on Docker Hub	10.1109/ICSME46990.2020.00043	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096684066&doi=10.1109%2fICSME46990.2020.00043&partnerID=40&md5=56711d85175bab985a31ae44b97b8f9b
23	Salau, J. and Krieter, J.	Analysing the space-usage-pattern of a cow herd using video surveillance and automated motion detection	10.1016/j.biosystemseng.2020.06.015	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089190975&doi=10.1016%2fj.biosystemseng.2020.06.015&partnerID=40&md5=30bda1c9b475eca6f59e76b00ca60c29
24	Chen, G. and Pui, C.-W. and Li, H. and Young, E.F.Y.	Dr. CU: Detailed Routing by Sparse Grid Graph and Minimum-Area-Captured Path Search	10.1109/TCAD.2019.2927542	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077797669&doi=10.1109%2fTCAD.2019.2927542&partnerID=40&md5=59444f948f052fa3d2c03634697df2e5
25	Zheng, T. and Zhu, X. and Zhang, X. and Zhao, Z. and Yi, X. and Wang, J. and Li, H.	A machine learning framework for genotyping the structural variations with copy number variant	10.1186/s12920-020-00733-w	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090003441&doi=10.1186%2fs12920-020-00733-w&partnerID=40&md5=50c179373193c61151593a6b53d2c30a
26	Utomo, P. and Falahah	Building Serverless Website on GitHub Pages	10.1088/1757-899X/879/1/012077	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091346359&doi=10.1088%2f1757-899X%2f879%2f1%2f012077&partnerID=40&md5=a42a4e51229c007d6a3f1d1c6a969772
27	Farber, M.	Analyzing the github repositories of research papers	10.1145/3383583.3398578	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095119274&doi=10.1145%2f3383583.3398578&partnerID=40&md5=ba45665816ab7016bebc6a32f0429031
28	Ekholm, J. and Ohukainen, P. and Kangas, A.J. and Kettunen, J. and Wang, Q. and Karsikas, M. and Khan, A.A. and Kingwell, B.A. and Kähönen, M. and Lehtimäki, T. and Raitakari, O.T. and Järvelin, M.-R. and Meikle, P.J. and Ala-Korpela, M.	EpiMetal: an open-source graphical web browser tool for easy statistical analyses in epidemiology and metabolomics	10.1093/ije/dyz244	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096151779&doi=10.1093%2fije%2fdyz244&partnerID=40&md5=d80d6725a52b855f2dffa49c9499261f
29	Avigal, Y. and Gao, J. and Wong, W. and Li, K. and Pierroz, G. and Deng, F.S. and Theis, M. and Presten, M. and Goldberg, K.	Simulating Polyculture Farming to Tune Automation Policies for Plant Diversity and Precision Irrigation	10.1109/CASE48305.2020.9216984	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094116346&doi=10.1109%2fCASE48305.2020.9216984&partnerID=40&md5=72a82965ce03cb4fec3e52149000d832
30	Tong, Y. and Wang, J. and Zheng, T. and Zhang, X. and Xiao, X. and Zhu, X. and Lai, X. and Liu, X.	SETE: Sequence-based Ensemble learning approach for TCR Epitope binding prediction	10.1016/j.compbiolchem.2020.107281	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087106460&doi=10.1016%2fj.compbiolchem.2020.107281&partnerID=40&md5=e67e6d1c849c4e44dcac40277f6add90
31	Deng, Y. and Xu, X. and Qiu, Y. and Xia, J. and Zhang, W. and Liu, S.	A multimodal deep learning framework for predicting drug-drug interaction events	10.1093/bioinformatics/btaa501	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089401503&doi=10.1093%2fbioinformatics%2fbtaa501&partnerID=40&md5=5d156e3b9d2fac840aee85fcedd3ff80
32	Petit, R.A. and Read, T.D.	Bactopia: A flexible pipeline for complete analysis of bacterial genomes	10.1128/mSystems.00190-20	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089832943&doi=10.1128%2fmSystems.00190-20&partnerID=40&md5=5af0fcd140516e60f0f521565b7cedd4
33	Wu, Z. and Serie, D. and Xu, G. and Zou, J.	PB-Net: Automatic peak integration by sequential deep learning for multiple reaction monitoring	10.1016/j.jprot.2020.103820	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084579710&doi=10.1016%2fj.jprot.2020.103820&partnerID=40&md5=e79796465e7f5b4a831e27c17c02b655
34	Patrick, R. and Humphreys, D.T. and Janbandhu, V. and Oshlack, A. and Ho, J.W.K. and Harvey, R.P. and Lo, K.K.	Sierra: Discovery of differential transcript usage from polyA-captured single-cell RNA-seq data	10.1186/s13059-020-02071-7	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087727921&doi=10.1186%2fs13059-020-02071-7&partnerID=40&md5=516e4bd1fa7573fa12c21bf501de7096
35	Manikumar, D.V.V.S. and Maheswari, B.U.	Blockchain Based DDoS Mitigation Using Machine Learning Techniques	10.1109/ICIRCA48905.2020.9183092	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092045962&doi=10.1109%2fICIRCA48905.2020.9183092&partnerID=40&md5=816506c29ef45d1a082ccddaa8d8e028
36	Kronk, C.A. and Dexheimer, J.W.	Development of the Gender, Sex, and Sexual Orientation ontology: Evaluation and workflow	10.1093/jamia/ocaa061	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088491637&doi=10.1093%2fjamia%2focaa061&partnerID=40&md5=29d675f7c37d97d7c334016af01472a1
37	Ross, J.C. and Nardelli, P. and Onieva, J. and Gerard, S.E. and Harmouche, R. and Okajima, Y. and Diaz, A.A. and Washko, G. and San José Estépar, R.	An open-source framework for pulmonary fissure completeness assessment	10.1016/j.compmedimag.2020.101712	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080058487&doi=10.1016%2fj.compmedimag.2020.101712&partnerID=40&md5=6bb7de7f1be8e2c49a08424dd025d71d
38	Zheng, H. and Kingsford, C. and Marçais, G.	Improved design and analysis of practical minimizers	10.1093/bioinformatics/btaa472	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087867285&doi=10.1093%2fbioinformatics%2fbtaa472&partnerID=40&md5=0421716ebf213f88a656a998c7dc463d
39	Wickramarachchi, A. and Mallawaarachchi, V. and Rajan, V. and Lin, Y.	MetaBCC-LR: metagenomics binning by coverage and composition for long reads	10.1093/bioinformatics/btaa441	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087876955&doi=10.1093%2fbioinformatics%2fbtaa441&partnerID=40&md5=f2854a61f9f5b4b52e237987991f1653
40	Fang, H. and Klug, D. and Lamba, H. and Herbsleb, J. and Vasilescu, B.	Need for Tweet: How Open Source Developers Talk about Their GitHub Work on Twitter	10.1145/3379597.3387466	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093695561&doi=10.1145%2f3379597.3387466&partnerID=40&md5=6542a7b8519d23eb948394e4ccd487bc
41	Wang, P. and Brown, C. and Jennings, J.A. and Stolee, K.T.	An Empirical Study on Regular Expression Bugs	10.1145/3379597.3387464	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093687976&doi=10.1145%2f3379597.3387464&partnerID=40&md5=07c4cb7902e5d4c1146b552941809161
42	Romano, A. and Wang, W.	WasmView: Visual testing for webassembly applications	10.1145/3377812.3382155	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094113445&doi=10.1145%2f3377812.3382155&partnerID=40&md5=89f8e431dbf81cf722ded5255f4d704c
43	Ramanathan, M.K. and Clapp, L. and Barik, R. and Sridharan, M.	Piranha: Reducing feature flag debt at Uber	10.1145/3377813.3381350	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092548989&doi=10.1145%2f3377813.3381350&partnerID=40&md5=b484d75492bbe3ff8113c96dee58922c
44	Chen, B. and Jiang, Z.J.	Studying the use of java logging utilities in the wild	10.1145/3377811.3380408	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094325311&doi=10.1145%2f3377811.3380408&partnerID=40&md5=6925359b1718ffc865ae4bcab1443a5b
45	Xu, G. and Wang, Q. and Ma, J.	OPUS-Fold: An Open-Source Protein Folding Framework Based on Torsion-Angle Sampling	10.1021/acs.jctc.0c00186	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086286110&doi=10.1021%2facs.jctc.0c00186&partnerID=40&md5=f52cf35a50adeb1e8b6b89272e55d60f
46	Dai, X. and Boujut, J.F. and Pourroy, F. and Marin, P.	Correlation between process openness and collaboration tool usage in open source hardware design: an empirical study	10.1007/s12008-019-00632-0	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076222438&doi=10.1007%2fs12008-019-00632-0&partnerID=40&md5=f7bc3c846d0a7af4500655aca85e4195
47	Preechayasomboon, P. and Rombokas, E.	Negshell casting: 3D-printed structured and sacrificial cores for soft robot fabrication	10.1371/journal.pone.0234354	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086524529&doi=10.1371%2fjournal.pone.0234354&partnerID=40&md5=31d621367ce70c3b33407774a89eccca
48	Torniainen, J. and Afara, I.O. and Prakash, M. and Sarin, J.K. and Stenroth, L. and Töyräs, J.	Open-source python module for automated preprocessing of near infrared spectroscopic data	10.1016/j.aca.2020.02.030	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080036102&doi=10.1016%2fj.aca.2020.02.030&partnerID=40&md5=5d6aa44390e5095c9bcb6ee248b09eae
49	Eashaan Rao, A. and Chimalakonda, S.	An Exploratory Study towards Understanding Lambda Expressions in Python	10.1145/3383219.3383255	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090859602&doi=10.1145%2f3383219.3383255&partnerID=40&md5=7adc2870ee237564a7b2e201fd10082c
50	Wu, L. and Deng, Q. and Xu, Z. and Zhou, S. and Li, C. and Li, Y.-X.	A novel virtual barcode strategy for accurate panel-wide variant calling in circulating tumor DNA	10.1186/s12859-020-3412-2	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083003516&doi=10.1186%2fs12859-020-3412-2&partnerID=40&md5=4660a91bc4ef91b9fa0b009d26ef5003
51	Zhang, Y. and Wang, H. and Wu, Y. and Hu, D. and Wang, T.	GitHub's milestone tool: A mixed-methods analysis on its use	10.1002/smr.2229	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075388288&doi=10.1002%2fsmr.2229&partnerID=40&md5=491143dfea220852a144e812cc022ee9
52	Fu, J. and Ke, B. and Dong, S.	LCQS: An efficient lossless compression tool of quality scores with random access functionality	10.1186/s12859-020-3428-7	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081946500&doi=10.1186%2fs12859-020-3428-7&partnerID=40&md5=1768c5d240ee7408ed0029429d869fde
53	Bright, J.M. and Bai, X. and Zhang, Y. and Sun, X. and Acord, B. and Wang, P.	irradpy: Python package for MERRA-2 download, extraction and usage for clear-sky irradiance modelling	10.1016/j.solener.2020.02.061	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079861962&doi=10.1016%2fj.solener.2020.02.061&partnerID=40&md5=c2eda03f3cfb64c9e9f29e92617b7b25
54	Kobus, R. and Abuín, J.M. and Müller, A. and Hellmann, S.L. and Pichel, J.C. and Pena, T.F. and Hildebrandt, A. and Hankeln, T. and Schmidt, B.	A big data approach to metagenomics for all-food-sequencing	10.1186/s12859-020-3429-6	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081900147&doi=10.1186%2fs12859-020-3429-6&partnerID=40&md5=d0defae23d40ecb04a0d4d089f01252e
55	Lu, Z. and Gilchrist, M.A. and Emrich, S.	Analysis of mutation bias in shaping CODON usage bias and its association with gene expression across specie	10.29007/87r9	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085380619&doi=10.29007%2f87r9&partnerID=40&md5=faec1bfee0e518dd9d8235365f4fa52f
56	Agol, E. and Agol, E. and Luger, R. and Luger, R. and Foreman-Mackey, D.	Analytic Planetary Transit Light Curves and Derivatives for Stars with Polynomial Limb Darkening	10.3847/1538-3881/ab4fee	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086519933&doi=10.3847%2f1538-3881%2fab4fee&partnerID=40&md5=42f2e59b590c51e92e7fbaa73c3f5dea
57	Vassallo, C. and Panichella, S. and Palomba, F. and Proksch, S. and Gall, H.C. and Zaidman, A.	How developers engage with static analysis tools in different contexts	10.1007/s10664-019-09750-5	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076207019&doi=10.1007%2fs10664-019-09750-5&partnerID=40&md5=93c776c9292559058c77371ea7856e32
58	Wu, Y. and He, K.	Group Normalization	10.1007/s11263-019-01198-w	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069694688&doi=10.1007%2fs11263-019-01198-w&partnerID=40&md5=c6cfe24ef06716090dc30309edb838b2
59	Liu, L. and Dou, Q. and Chen, H. and Qin, J. and Heng, P.-A.	Multi-Task Deep Model with Margin Ranking Loss for Lung Nodule Analysis	10.1109/TMI.2019.2934577	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081671450&doi=10.1109%2fTMI.2019.2934577&partnerID=40&md5=76895bbd7ee993c6372cbc6a4f1acd4a
60	Dhasade, A.B. and Venigalla, A.S.M. and Chimalakonda, S.	Towards Prioritizing GitHub Issues	10.1145/3385032.3385052	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082666629&doi=10.1145%2f3385032.3385052&partnerID=40&md5=50aff18f28a8dbf386e0c146d1414f94
61	Chang, C.H. and Carpenter, I.L. and Jones, W.B.	The ESIF-HPC-2 benchmark suite	10.1145/3380868.3398200	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095594507&doi=10.1145%2f3380868.3398200&partnerID=40&md5=f1cd66f40efc0655073cd158522c7cf2
62	Benoit, G. and Mariadassou, M. and Robin, S. and Schbath, S. and Peterlongo, P. and Lemaitre, C.	SimkaMin: Fast and resource frugal de novo comparative metagenomics	10.1093/bioinformatics/btz685	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080842376&doi=10.1093%2fbioinformatics%2fbtz685&partnerID=40&md5=035569ffed6ee4dce503cd8cc07c06e3
63	Asyrofi, M.H. and Thung, F. and Lo, D. and Jiang, L.	AUSearch: Accurate API Usage Search in GitHub Repositories with Type Resolution	10.1109/SANER48275.2020.9054809	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083550934&doi=10.1109%2fSANER48275.2020.9054809&partnerID=40&md5=1f7f682d33fd5a9a6cfe657bf5c19cef
64	Farahmand, S. and Riley, T. and Zarringhalam, K.	ModEx: A text mining system for extracting mode of regulation of transcription factor-gene regulatory interaction	10.1016/j.jbi.2019.103353	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077029336&doi=10.1016%2fj.jbi.2019.103353&partnerID=40&md5=3a81acccae490fcb806f49e3b5399e43
65	Flegr, J. and Tureček, P.	New approach and new permutation tests with R programs for analyses of false-negative-contaminated data in medicine and biology	10.1242/BIO.045948	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089875568&doi=10.1242%2fBIO.045948&partnerID=40&md5=c6a78593422b7381e69757276107a635
66	Ergasheva, S. and Ivanov, V. and Kruglov, A. and Sadovykh, A. and Succi, G. and Zouev, E.	Analysis of development tool usage in software engineering classes	10.1007/978-3-030-57663-9_19	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089721050&doi=10.1007%2f978-3-030-57663-9_19&partnerID=40&md5=824b1360db49f472cb83796e7160574b
67	Perez-Jimenez, M. and Ramon-Soria, P. and Arrue, B.C. and Ollero, A.	Hecatonquiros: Open-source hardware for aerial manipulation applications	10.1177/1729881420921622	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084611037&doi=10.1177%2f1729881420921622&partnerID=40&md5=4314299cf7529a547f77a055253f2baa
68	Le, C.P. and Pham, A.Q. and La, H.M. and Feil-Seifer, D.	A Multi-Robotic System for Environmental Dirt Cleaning	10.1109/SII46433.2020.9026295	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082626697&doi=10.1109%2fSII46433.2020.9026295&partnerID=40&md5=26356419229313917f389e037e95242b
69	Gur, T.	Biobtree: A tool to search and map bioinformatics identifiers and special keywords	10.12688/f1000research.17927.1	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075964883&doi=10.12688%2ff1000research.17927.1&partnerID=40&md5=cd394940fe3e53245fc22bb98e2ced0f
71	Anwar, A. and Raychowdhury, A.	Autonomous Navigation via Deep Reinforcement Learning for Resource Constraint Edge Nodes Using Transfer Learning	10.1109/ACCESS.2020.2971172	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081097413&doi=10.1109%2fACCESS.2020.2971172&partnerID=40&md5=c9edfb7317ea58f07fa7e8332a2e7096
72	Imran, A. and Kosar, T.	The impact of auto-refactoring code smells on the resource utilization of cloud software	10.18293/SEKE2020-138	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090511559&doi=10.18293%2fSEKE2020-138&partnerID=40&md5=1c423914737262b17c8a5a3d5bd50732
73	Unnisa, Z. and Zia, S. and Butt, U.M. and Letchmunan, S. and Ilyas, S.	Ensemble Usage for Classification of EEG Signals A Review with Comparison	10.1007/978-3-030-50353-6_14	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089238420&doi=10.1007%2f978-3-030-50353-6_14&partnerID=40&md5=007fd5c3c3c14e9f2ef8bd9d103d6c2f
74	Zhu, Z. and Xu, Z. and You, A. and Bai, X.	Semantically multi-modal image synthesis	10.1109/CVPR42600.2020.00551	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094810175&doi=10.1109%2fCVPR42600.2020.00551&partnerID=40&md5=b23c854135a51da3fa6f02e6db0c6989
75	Maximov, M. and Elezi, I. and Leal-Taixe, L.	CIAGAN: Conditional identity anonymization generative adversarial networks	10.1109/CVPR42600.2020.00549	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094811356&doi=10.1109%2fCVPR42600.2020.00549&partnerID=40&md5=528b5f33b73d9814a27d68291fa48aa4
76	Pradel, C. and Sileo, D. and Rodrigo, Á. and Peñas, A. and Agirre, E.	Question Answering When Knowledge Bases are Incomplete	10.1007/978-3-030-58219-7_4	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092166275&doi=10.1007%2f978-3-030-58219-7_4&partnerID=40&md5=785dc7fc6c1c743d292949d30ed908b4
77	You, Y. and Chen, T. and Wang, Z. and Shen, Y.	L2-GCN: Layer-wise and learned efficient training of graph convolutional networks	10.1109/CVPR42600.2020.00220	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094822233&doi=10.1109%2fCVPR42600.2020.00220&partnerID=40&md5=aa11467ff581cb46bef0fcc08ee2120f
78	Kovaltsuk, A. and Raybould, M.I.J. and Wong, W.K. and Marks, C. and Kelm, S. and Snowden, J. and Trück, J. and Deane, C.M.	Structural diversity of B-cell receptor repertoires along the B-cell differentiation axis in humans and mice	10.1371/journal.pcbi.1007636	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081072062&doi=10.1371%2fjournal.pcbi.1007636&partnerID=40&md5=63eaf01712971c8e2e7bacb135e8fe88
79	Diamantopoulos, T. and Symeonidis, A.L.	Mining source code for component reuse	10.1007/978-3-030-30106-4_6	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083969504&doi=10.1007%2f978-3-030-30106-4_6&partnerID=40&md5=08742a34386a395666bea2be6dec1ef8
80	Debe, M. and Salah, K. and Rehman, M.H.U. and Svetinovic, D.	Blockchain-based decentralized reverse bidding in fog computing	10.1109/ACCESS.2020.2991261	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084949230&doi=10.1109%2fACCESS.2020.2991261&partnerID=40&md5=71307b2343bbd6087c72d281ac37d43d
82	Zhou, H. and Xu, X. and Lin, D. and Wang, X. and Liu, Z.	Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation	10.1007/978-3-030-58610-2_4	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093121743&doi=10.1007%2f978-3-030-58610-2_4&partnerID=40&md5=d122e72dccba7f9fc6bede63d68e2216
83	Ma, S.-P. and Hsu, M.-J. and Chen, H.-J. and Su, Y.-S.	API Prober – A Tool for Analyzing Web API Features and Clustering Web APIs	10.1007/978-3-030-34986-8_6	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083439887&doi=10.1007%2f978-3-030-34986-8_6&partnerID=40&md5=3f257e8065caab9d6111cd33c9900c84
84	Joppich, M. and Olenchuk, M. and Mayer, J.M. and Emslander, Q. and Jimenez-Soto, L.F. and Zimmer, R.	SEQU-INTO: Early detection of impurities, contamination and off-targets (ICOs) in long read/MinION sequencing	10.1016/j.csbj.2020.05.014	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086568936&doi=10.1016%2fj.csbj.2020.05.014&partnerID=40&md5=9d4d50c963b330be0b613b382d3aaf09
85	Dowling, A. and Swiatowicz, F. and Liu, Y. and Tolnai, A.J. and Engel, F.H.	COMBS: First Open-Source Based Benchmark Suite for Multi-physics Simulation Relevant HPC Research	10.1007/978-3-030-60245-1_1	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092677337&doi=10.1007%2f978-3-030-60245-1_1&partnerID=40&md5=faca6b4880c353f28188af80e226079e
86	Akatsu, S. and Masuda, A. and Shida, T. and Tsuda, K.	A study of quality indicator model of large-scale open source software projects for adoption decision-making	10.1016/j.procs.2020.09.020	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093365060&doi=10.1016%2fj.procs.2020.09.020&partnerID=40&md5=44c68dc4d7e58aa73b2936215b8cdaf6
87	Zhang, L. and Tanno, R. and Bronik, K. and Jin, C. and Nachev, P. and Barkhof, F. and Ciccarelli, O. and Alexander, D.C.	Learning to segment when experts disagree	10.1007/978-3-030-59710-8_18	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093116546&doi=10.1007%2f978-3-030-59710-8_18&partnerID=40&md5=fba2d3b1132d07ddccf468a3d64935a9
88	Huang, Y. and Chen, J. and Ouyang, W. and Wan, W. and Xue, Y.	Image Captioning with End-to-End Attribute Detection and Subsequent Attributes Prediction	10.1109/TIP.2020.2969330	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079506459&doi=10.1109%2fTIP.2020.2969330&partnerID=40&md5=624ea52ee7fa2479d7ea6675bacc9f21
89	Seifert, H. and Weber, M. and Glöckner, F.O. and Kostadinov, I.	An open-source GIS-enabled lookup service for Nagoya Protocol party information	10.1093/database/baaa014	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083366543&doi=10.1093%2fdatabase%2fbaaa014&partnerID=40&md5=68bd8c43777fd1f347041df576d1cfb6
90	An, L. and Yang, T. and Yang, J. and Nuebler, J. and Xiang, G. and Hardison, R.C. and Li, Q. and Zhang, Y.	OnTAD: Hierarchical domain structure reveals the divergence of activity among TADs and boundaries	10.1186/s13059-019-1893-y	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076860203&doi=10.1186%2fs13059-019-1893-y&partnerID=40&md5=1effa847ee8d4183cd1387dba344fce5
91	Usevich, K. and Markovsky, I.	Software package for mosaic-Hankel structured low-rank approximation	10.1109/CDC40024.2019.9028867	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082477622&doi=10.1109%2fCDC40024.2019.9028867&partnerID=40&md5=c9d568596110327c0811b1b6e374c407
92	Masoudi-Sobhanzadeh, Y. and Omidi, Y. and Amanlou, M. and Masoudi-Nejad, A.	Trader as a new optimization algorithm predicts drug-target interactions efficiently	10.1038/s41598-019-45814-8	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068039947&doi=10.1038%2fs41598-019-45814-8&partnerID=40&md5=3990b19e3b6f40138e48e65e02fad041
93	Lin, S. and Ji, R. and Chen, C. and Tao, D. and Luo, J.	Holistic CNN Compression via Low-Rank Decomposition with Knowledge Transfer	10.1109/TPAMI.2018.2873305	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054402256&doi=10.1109%2fTPAMI.2018.2873305&partnerID=40&md5=36f9680975dd44383f4b33ef91f67dc9
94	Wang, Z. and Mamun, A.-A. and Cai, X. and Ravishanker, N. and Rajasekaran, S.	Efficient sequential and parallel algorithms for estimating higher order spectra	10.1145/3357384.3358062	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075422530&doi=10.1145%2f3357384.3358062&partnerID=40&md5=66b6b59cfef3804ad6b28a08bc6e9161
95	Escobar-Velasquez, C. and Osorio-Riano, M. and Linares-Vasquez, M.	MutAPK: Source-codeless mutant generation for android apps	10.1109/ASE.2019.00109	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078925599&doi=10.1109%2fASE.2019.00109&partnerID=40&md5=d6a858661dbffa78d06a499588152c84
96	Peterson, T.J. and Fulton, S.	Joint Estimation of Gross Recharge, Groundwater Usage, and Hydraulic Properties within HydroSight	10.1111/gwat.12946	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074279030&doi=10.1111%2fgwat.12946&partnerID=40&md5=c864a3fab8e9916649259977668ffeb0
97	Li, D. and Wang, H. and Xu, C. and Zhang, R. and Cheung, S.-C. and Ma, X.	SGUARD: A feature-based clustering tool for effective spreadsheet defect detection	10.1109/ASE.2019.00122	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078947024&doi=10.1109%2fASE.2019.00122&partnerID=40&md5=313e083c5b4cd6af26f6197f91735b32
98	Athron, P. and Balázs, C. and Bardsley, M. and Fowlie, A. and Harries, D. and White, G.	Bubbleprofiler: Finding the field profile and action for cosmological phase transitions	10.1016/j.cpc.2019.05.017	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066957132&doi=10.1016%2fj.cpc.2019.05.017&partnerID=40&md5=0d2c5ebfbca43bfece17e30e0dd0c23f
99	Tegunov, D. and Cramer, P.	Real-time cryo-electron microscopy data preprocessing with Warp	10.1038/s41592-019-0580-y	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074279272&doi=10.1038%2fs41592-019-0580-y&partnerID=40&md5=978d973acb4c51c36cb0b726cd52a8b2
100	Si, D. and Cheng, S.C. and Xing, R. and Liu, C. and Wu, H.Y.	Scaling up prediction of psychosis by natural language processing	10.1109/ICTAI.2019.00055	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081080446&doi=10.1109%2fICTAI.2019.00055&partnerID=40&md5=e4f35e0ddbf13ca55df454dd9e320e1e
101	Li, C. and Zhou, M. and Gu, Z. and Gu, M. and Zhang, H.	Ares: Inferring error specifications through static analysis	10.1109/ASE.2019.00130	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078941395&doi=10.1109%2fASE.2019.00130&partnerID=40&md5=e13f9659a6f99a8476d6c33ae99e141f
102	An, S. and Che, G. and Zhou, F. and Liu, X. and Ma, X. and Chen, Y.	Fast and Incremental Loop Closure Detection Using Proximity Graphs	10.1109/IROS40897.2019.8968043	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081159056&doi=10.1109%2fIROS40897.2019.8968043&partnerID=40&md5=f1afcbc34a8eaf3d8a1e14c3c9ffe672
103	Khaled Saifullah, C.M. and Asaduzzaman, M. and Roy, C.K.	Learning from examples to find fully qualified names of API elements in code snippets	10.1109/ASE.2019.00032	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078903099&doi=10.1109%2fASE.2019.00032&partnerID=40&md5=c0b0d2da6a0e2699222a1f48593108df
104	Tripathi, A. and Domingue, B.	Curve fitting from probabilistic emissions and applications to dynamic item response theory	10.1109/ICDM.2019.00170	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078870971&doi=10.1109%2fICDM.2019.00170&partnerID=40&md5=44a508647a346143954448bd90432a03
105	Warren, R.L. and Coombe, L. and Mohamadi, H. and Zhang, J. and Jaquish, B. and Isabel, N. and Jones, S.J.M. and Bousquet, J. and Bohlmann, J.	ntEdit: scalable genome sequence polishing	10.1093/bioinformatics/btz400	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074306724&doi=10.1093%2fbioinformatics%2fbtz400&partnerID=40&md5=61976839122ab36abd940a3aa615ce0c
106	Seifer, P. and Härtel, J. and Leinberger, M. and Lämmel, R. and Staab, S.	Empirical study on the usage of graph query languages in open source Java projects	10.1145/3357766.3359541	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076766330&doi=10.1145%2f3357766.3359541&partnerID=40&md5=6765027b0204dbc000e2b28bf1152abf
107	Hoffmann, N. and Hartler, J. and Ahrends, R.	JmzTab-M: A Reference Parser, Writer, and Validator for the Proteomics Standards Initiative mzTab 2.0 Metabolomics Standard	10.1021/acs.analchem.9b01987	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072971699&doi=10.1021%2facs.analchem.9b01987&partnerID=40&md5=49a9fd48f466ac039cd35b0319df65f6
108	Yao, W. and Huang, F. and Zhang, X. and Tang, J.	ECOGEMS: Efficient compression and retrieve of SNP data of 2058 rice accessions with integer sparse matrices	10.1093/bioinformatics/btz186	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073176664&doi=10.1093%2fbioinformatics%2fbtz186&partnerID=40&md5=0b348a7613961ca1630bb8c335775419
109	Chen, Y.-A. and Tripathi, L.P. and Fujiwara, T. and Kameyama, T. and Itoh, M.N. and Mizuguchi, K.	The TargetMine Data Warehouse: Enhancement and Updates	10.3389/fgene.2019.00934	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074130327&doi=10.3389%2ffgene.2019.00934&partnerID=40&md5=838f1aa3d5adc015426def1966a75b42
110	Hu, X. and Friedberg, I.	SwiftOrtho: A fast, memory-efficient, multiple genome orthology classifier	10.1093/gigascience/giz118	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074089972&doi=10.1093%2fgigascience%2fgiz118&partnerID=40&md5=2edd399fa50a6217000c0f2cd45a8c81
111	Tang, Y. and Liu, X.	G2P: A Genome-Wide-Association-Study simulation tool for genotype simulation, phenotype simulation and power evaluation	10.1093/bioinformatics/btz126	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067889548&doi=10.1093%2fbioinformatics%2fbtz126&partnerID=40&md5=fc7b9b31752f6ca22fe16be6b224ef05
112	Mei, K. and Li, J. and Zhang, J. and Wu, H. and Li, J. and Huang, R.	HighEr-resolution network for image demosaicing and enhancing	10.1109/ICCVW.2019.00427	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082468300&doi=10.1109%2fICCVW.2019.00427&partnerID=40&md5=38a840e866d793c8b2cbc9ad2a18e0c6
113	Schorghuber, M. and Steininger, D. and Cabon, Y. and Humenberger, M. and Gelautz, M.	SLAMANTIC - Leveraging semantics to improve VSLAM in dynamic environments	10.1109/ICCVW.2019.00468	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082464315&doi=10.1109%2fICCVW.2019.00468&partnerID=40&md5=c4ebb1cc5b44b7e7301b995d779e1634
114	Hu, S.X. and Zagoruyko, S. and Komodakis, N.	Exploring weight symmetry in deep neural networks	10.1016/j.cviu.2019.07.006	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070393548&doi=10.1016%2fj.cviu.2019.07.006&partnerID=40&md5=9644659904218a4aa9452344332f6193
115	Aguilera, L.U. and Raymond, W. and Fox, Z.R. and May, M. and Djokic, E. and Morisaki, T. and Stasevich, T.J. and Munsky, B.	Computational design and interpretation of single-RNA translation experiments	10.1371/journal.pcbi.1007425	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074242850&doi=10.1371%2fjournal.pcbi.1007425&partnerID=40&md5=efad652c8921ed7c13b560ea30262fa3
116	Huang, Z. and Wang, X. and Huang, L. and Huang, C. and Wei, Y. and Liu, W.	CCNet: Criss-cross attention for semantic segmentation	10.1109/ICCV.2019.00069	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079745733&doi=10.1109%2fICCV.2019.00069&partnerID=40&md5=c9dc5eb6a489aec64a28b5a9e8694702
117	Wan, F. and Zhu, Y. and Hu, H. and Dai, A. and Cai, X. and Chen, L. and Gong, H. and Xia, T. and Yang, D. and Wang, M.-W. and Zeng, J.	DeepCPI: A Deep Learning-based Framework for Large-scale in silico Drug Screening	10.1016/j.gpb.2019.04.003	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079810153&doi=10.1016%2fj.gpb.2019.04.003&partnerID=40&md5=037432e53a20eb81d3c61d66cb1130fc
118	Hai, J. and Wang, C. and Chen, X. and Li, T.O. and Cui, H. and Wang, S.	Fulva: Efficient live migration for in-memory key-value stores with zero downtime	10.1109/SRDS47363.2019.00019	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084126416&doi=10.1109%2fSRDS47363.2019.00019&partnerID=40&md5=df57edba8f7f263d69ebb0100b2552fd
119	Borges, H. and Brito, R. and Tulio Valente, M.	Beyond textual issues: Understanding the usage and impact of GitHub reactions	10.1145/3350768.3350788	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073188315&doi=10.1145%2f3350768.3350788&partnerID=40&md5=b64a53e9da8ba76c99d708395efbed3d
120	Fazzolino, R. and Rodrigues, G.N.	Feature-trace: Generating operational profile and supporting testing prioritization from BDD features	10.1145/3350768.3350781	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073209112&doi=10.1145%2f3350768.3350781&partnerID=40&md5=43067642556626381dc7d258bb643e28
121	Tyryshkina, A. and Coraor, N. and Nekrutenko, A.	Predicting runtimes of bioinformatics tools based on historical data: Five years of Galaxy usage	10.1093/bioinformatics/btz054	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072508575&doi=10.1093%2fbioinformatics%2fbtz054&partnerID=40&md5=91a23e21ed94c04f1909f1ade57cd772
122	Mukherjee, K. and Alipanahi, B. and Kahveci, T. and Salmela, L. and Boucher, C.	Aligning optical maps to de Bruijn graphs	10.1093/bioinformatics/btz069	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072332120&doi=10.1093%2fbioinformatics%2fbtz069&partnerID=40&md5=37c3de3d6c8d1e12124dbd224fd60d7b
123	Pereira-Flores, E. and Glöckner, F.O. and Fernandez-Guerra, A.	Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data	10.1186/s12859-019-3031-y	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071767766&doi=10.1186%2fs12859-019-3031-y&partnerID=40&md5=9da4eabc4fbcf8d25ca829ebfaa2eb9d
124	Kallis, R. and Di Sorbo, A. and Canfora, G. and Panichella, S.	Ticket Tagger: Machine Learning Driven Issue Classification	10.1109/ICSME.2019.00070	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077205637&doi=10.1109%2fICSME.2019.00070&partnerID=40&md5=7a617f0a31e3b6be8984d97167e11370
125	Bradley, K. and Godfrey, M.	A study on the effects of exception usage in open-source C++ systems	10.1109/SCAM.2019.00010	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077812575&doi=10.1109%2fSCAM.2019.00010&partnerID=40&md5=a891cdbd21df4f81fe61a52e8798ea54
126	Uthayamoorthy, K. and Kanthasamy, K. and Senthaalan, T. and Sarveswaran, K. and Dias, G.	DDSpell - A Data Driven Spell Checker and Suggestion Generator for the Tamil Language	10.1109/ICTer48817.2019.9023698	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082302525&doi=10.1109%2fICTer48817.2019.9023698&partnerID=40&md5=eca7b16ee37b8adbaef086b1eab2ffb5
127	Avelino, G. and Constantinou, E. and Valente, M.T. and Serebrenik, A.	On the abandonment and survival of open source projects: An empirical investigation	10.1109/ESEM.2019.8870181	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072031326&doi=10.1109%2fESEM.2019.8870181&partnerID=40&md5=b3a793b07964f4d7b3ce3d2f6a7b515f
128	Georgeson, P. and Syme, A. and Sloggett, C. and Chung, J. and Dashnow, H. and Milton, M. and Lonsdale, A. and Powell, D. and Seemann, T. and Pope, B.	Bionitio: Demonstrating and facilitating best practices for bioinformatics command-line software	10.1093/gigascience/giz109	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072574632&doi=10.1093%2fgigascience%2fgiz109&partnerID=40&md5=3855835094bd0f75ba052e56a9a19573
129	Borg, M. and Svensson, O. and Berg, K. and Hansson, D.	SZZ unleashed: An open implementation of the SZZ algorithm-featuring example usage in a study of just-in-time bug prediction for the jenkins project	10.1145/3340482.3342742	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076393558&doi=10.1145%2f3340482.3342742&partnerID=40&md5=d52bd5d7284bb13a4dcfe42e503eceef
130	Steenwyk, J.L. and Rokas, A.	Treehouse: A user-friendly application to obtain subtrees from large phylogenies	10.1186/s13104-019-4577-5	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071577517&doi=10.1186%2fs13104-019-4577-5&partnerID=40&md5=62c66e48329971da8f3516dff603335a
131	Abid, S.	Recommending related functions from API usage-based function clone structures	10.1145/3338906.3342486	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071903250&doi=10.1145%2f3338906.3342486&partnerID=40&md5=12b29c2cf6fa6827474edc9ffa8e0719
132	Islam, M.J. and Nguyen, G. and Pan, R. and Rajan, H.	A comprehensive study on deep learning bug characteristics	10.1145/3338906.3338955	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071909185&doi=10.1145%2f3338906.3338955&partnerID=40&md5=5417703fdc2f3e7bbab976c1cfa80ea4
133	Chen, Z. and Cao, Y. and Lu, X. and Mei, Q. and Liu, X.	SEntiMoji: An emoji-powered learning approach for sentiment analysis in software engineering	10.1145/3338906.3338977	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071906723&doi=10.1145%2f3338906.3338977&partnerID=40&md5=1e967ded2d75e2d58c7afc55754eefc0
134	Sun, Y. and Venugopal, V. and Brandt, A.R.	Short-term solar power forecast with deep learning: Exploring optimal input and output configuration	10.1016/j.solener.2019.06.041	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067921025&doi=10.1016%2fj.solener.2019.06.041&partnerID=40&md5=a1a0f73ffd0db8dfecadd2120d671a3f
135	Torner, J. and Skouras, S. and Molinuevo, J.L. and Gispert, J.D. and Alpiste, F.	Multipurpose Virtual Reality Environment for Biomedical and Health Applications	10.1109/TNSRE.2019.2926786	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071348830&doi=10.1109%2fTNSRE.2019.2926786&partnerID=40&md5=5329da375e5f1c030800b2906fd911cb
136	Tian, M. and Guo, H. and Chen, H. and Wang, Q. and Long, C. and Ma, Y.	Automated pig counting using deep learning	10.1016/j.compag.2019.05.049	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067302123&doi=10.1016%2fj.compag.2019.05.049&partnerID=40&md5=c42aa19c9a7110c63af4996c90651a84
137	Ren, S. and Jia, M.	Scenario Oriented Program Slicing for Large-Scale Software Through Constraint Logic Programming and Program Transformation	10.1109/ACCESS.2018.2853153	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049770937&doi=10.1109%2fACCESS.2018.2853153&partnerID=40&md5=a68a76b5e162176fcd196c390614dc97
138	Zou, W. and Zhang, W. and Xia, X. and Holmes, R. and Chen, Z.	Branch Use in Practice: A Large-Scale Empirical Study of 2,923 Projects on GitHub	10.1109/QRS.2019.00047	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073782631&doi=10.1109%2fQRS.2019.00047&partnerID=40&md5=c4f5acf40f44203ca6fdf2e1d82564ec
139	Grinvald, M. and Furrer, F. and Novkovic, T. and Chung, J.J. and Cadena, C. and Siegwart, R. and Nieto, J.	Volumetric instance-aware semantic mapping and 3D object discovery	10.1109/LRA.2019.2923960	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068681307&doi=10.1109%2fLRA.2019.2923960&partnerID=40&md5=f18bd3cd788a49420bf21a7b4dc0a958
140	Lakhani, J. and Khunteta, A. and Choudhary, A. and Harwani, D.	MPSAGA: a matrix-based pair-wise sequence alignment algorithm for global alignment with position based sequence representation	10.1007/s12046-019-1141-x	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068172167&doi=10.1007%2fs12046-019-1141-x&partnerID=40&md5=d612fff71b1cbe91a93810bb47c305fe
141	Hayen, L. and Severijns, N.	Beta Spectrum Generator: High precision allowed β spectrum shapes	10.1016/j.cpc.2019.02.012	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062808184&doi=10.1016%2fj.cpc.2019.02.012&partnerID=40&md5=ed913caa0bad3c440ccdc55d73c007c7
142	Baltes, S. and Diehl, S.	Usage and attribution of Stack Overflow code snippets in GitHub projects	10.1007/s10664-018-9650-5	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054385016&doi=10.1007%2fs10664-018-9650-5&partnerID=40&md5=de4d56d866ca9ea5b4a38d350cfa9e83
143	Lapierre, N. and Mangul, S. and Alser, M. and Mandric, I. and Wu, N.C. and Koslicki, D. and Eskin, E.	MiCoP: Microbial community profiling method for detecting viral and fungal organisms in metagenomic samples	10.1186/s12864-019-5699-9	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066843320&doi=10.1186%2fs12864-019-5699-9&partnerID=40&md5=5ddc3867faf2619a46389a46a63491e2
144	Chu, C. and Li, X. and Wu, Y.	GAPPadder: A sensitive approach for closing gaps on draft genomes with short sequence reads	10.1186/s12864-019-5703-4	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066843780&doi=10.1186%2fs12864-019-5703-4&partnerID=40&md5=5ddf5e1106134f472393ce4879d6b6da
145	Gao, S. and Zhuang, X.	Multi-scale deep neural networks for real image super-resolution	10.1109/CVPRW.2019.00252	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078101629&doi=10.1109%2fCVPRW.2019.00252&partnerID=40&md5=8043341b70a3e3216897e18329a729fe
146	Cheng, G. and Matsune, A. and Li, Q. and Zhu, L. and Zang, H. and Zhan, S.	Encoder-decoder residual network for real super-resolution	10.1109/CVPRW.2019.00270	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082884126&doi=10.1109%2fCVPRW.2019.00270&partnerID=40&md5=80ad03b61778642728b3d5c73ffbb8ad
147	Qiao, S. and Lin, Z. and Zhang, J. and Yuille, A.L.	Neural rejuvenation: Improving deep network training by enhancing computational resource utilization	10.1109/CVPR.2019.00015	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078783923&doi=10.1109%2fCVPR.2019.00015&partnerID=40&md5=7f1aa8313e974b219ea2f84737990665
148	Muenchow, J. and Schäfer, S. and Krüger, E.	Reviewing qualitative GIS research—Toward a wider usage of open-source GIS and reproducible research practices	10.1111/gec3.12441	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067387953&doi=10.1111%2fgec3.12441&partnerID=40&md5=ebc8dbf49b298822aabf0b1e0405544f
149	Voicu, T.A. and Al-Ars, Z.	SparkJNI: A Toolchain for Hardware Accelerated Big Data Apache Spark	10.1109/ICBDA.2019.8713201	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066608307&doi=10.1109%2fICBDA.2019.8713201&partnerID=40&md5=87dbe3d34ef5e1832978953b747077a3
150	Pérez-Rubio, P. and Lottaz, C. and Engelmann, J.C.	FastqPuri: High-performance preprocessing of RNA-seq data	10.1186/s12859-019-2799-0	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065132299&doi=10.1186%2fs12859-019-2799-0&partnerID=40&md5=25632a3045b34d0ae258708864c1cc59
151	Tsubaki, M. and Mizoguchi, T.	Correction to: Fast and accurate molecular property prediction: Learning atomic interactions and potentials with neural networks (Journal of Physical Chemistry Letters (2018) 9:19 (5733-5741) DOI: 10.1021/acs.jpclett.8b01837)	10.1021/acs.jpclett.9b00301	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065308996&doi=10.1021%2facs.jpclett.9b00301&partnerID=40&md5=39cc33d2cad890c43ef55d120ce072b4
152	Nguyen, P.T. and Di Rocco, J. and Di Ruscio, D. and Ochoa, L. and Degueule, T. and Di Penta, M.	FOCUS: A Recommender System for Mining API Function Calls and Usage Patterns	10.1109/ICSE.2019.00109	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064745329&doi=10.1109%2fICSE.2019.00109&partnerID=40&md5=ae00b7042201692d4af3586752a891b7
153	Baltes, S. and Treude, C. and Diehl, S.	SOTorrent: Studying the origin, evolution, and usage of stack overflow code snippets	10.1109/MSR.2019.00038	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072322327&doi=10.1109%2fMSR.2019.00038&partnerID=40&md5=06eeacd48e5ade4f92c3f6d0ccf23eff
154	Biswas, S. and Islam, M.J. and Huang, Y. and Rajan, H.	Boa meets python: A boa dataset of data science software in python language	10.1109/MSR.2019.00086	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071933042&doi=10.1109%2fMSR.2019.00086&partnerID=40&md5=29dc9e0e59364610a6c434c555293775
155	Hanussek, M. and Bartusch, F. and Kruger, J. and Kohlbacher, O.	BOOTABLE: Bioinformatics benchmark tool suite	10.1109/CCGRID.2019.00027	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069536228&doi=10.1109%2fCCGRID.2019.00027&partnerID=40&md5=a3c6cebefffbbb62749cb6b895e5c555
157	Kavaler, D. and Trockman, A. and Vasilescu, B. and Filkov, V.	Tool Choice Matters: JavaScript Quality Assurance Tools and Usage Outcomes in GitHub Projects	10.1109/ICSE.2019.00060	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071947090&doi=10.1109%2fICSE.2019.00060&partnerID=40&md5=b0e63d9763d8e93ff3718ba7d8c93d3b
158	Lin, Y. and Cheng, S. and Shen, J. and Pantic, M.	MobiFace: A novel dataset for mobile face tracking in the wild	10.1109/FG.2019.8756581	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070461305&doi=10.1109%2fFG.2019.8756581&partnerID=40&md5=78bb3b253ace68850e0b89cf5f8d6999
159	Scoccia, G.L. and Peruma, A. and Pujols, V. and Christians, B. and Krutz, D.	An empirical history of permission requests and mistakes in open source android apps	10.1109/MSR.2019.00090	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072334068&doi=10.1109%2fMSR.2019.00090&partnerID=40&md5=bd7f8c960e9440d24b53d8b4c334b689
160	Xu, S. and Dong, Z. and Meng, N.	Meditor: Inference and application of API migration edits	10.1109/ICPC.2019.00052	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070651329&doi=10.1109%2fICPC.2019.00052&partnerID=40&md5=d611eb7ca3a6e88565560cc1ee0ae01b
161	Iacoangeli, A. and Al Khleifat, A. and Sproviero, W. and Shatunov, A. and Jones, A.R. and Morgan, S.L. and Pittman, A. and Dobson, R.J. and Newhouse, S.J. and Al-Chalabi, A.	DNAscan: Personal computer compatible NGS analysis, annotation and visualisation	10.1186/s12859-019-2791-8	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064860203&doi=10.1186%2fs12859-019-2791-8&partnerID=40&md5=af5fb841b8d1f724c7203ecd466c9c62
162	Seefried, F. and Schmidt, T. and Reinecke, M. and Heinzlmeir, S. and Kuster, B. and Wilhelm, M.	CiRCus: A Framework to Enable Classification of Complex High-Throughput Experiments	10.1021/acs.jproteome.8b00724	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063527988&doi=10.1021%2facs.jproteome.8b00724&partnerID=40&md5=8fea405ae664bf72b4929150569ee43a
163	Sun, Z. and Gao, S. and Liu, B. and Wang, Y. and Yang, T. and Cui, B.	Magic Cube Bloom Filter: Answering Membership Queries for Multiple Sets	10.1109/BIGCOMP.2019.8679119	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064651993&doi=10.1109%2fBIGCOMP.2019.8679119&partnerID=40&md5=78c268d929c31384649d9f6a3aa4b704
164	Ren, X. and Zheng, L. and Zhang, Z.	SSCC: A Novel Computational Framework for Rapid and Accurate Clustering Large-scale Single Cell RNA-seq Data	10.1016/j.gpb.2018.10.003	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067492639&doi=10.1016%2fj.gpb.2018.10.003&partnerID=40&md5=104dc2d80cec8094a84883a3194a4492
165	Tong, Y. and Yang, D. and Jiang, J. and Gao, S. and Cui, B. and Shi, L. and Li, X.	Coloring embedder: A memory efficient data structure for answering multi-set query	10.1109/ICDE.2019.00105	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067992865&doi=10.1109%2fICDE.2019.00105&partnerID=40&md5=b74b3b537134bd79225dadf9de44135a
166	da Silva Neto, A.M. and Silva, S.R. and Vendruscolo, M. and Camilloni, C. and Montalvão, R.W.	A superposition free method for protein conformational ensemble analyses and local clustering based on a differential geometry representation of backbone	10.1002/prot.25652	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061041270&doi=10.1002%2fprot.25652&partnerID=40&md5=fe2e25d93caa6f856ba3322f51604946
167	Wang, P. and Bai, G.R. and Stolee, K.T.	Exploring Regular Expression Evolution	10.1109/SANER.2019.8667972	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064174666&doi=10.1109%2fSANER.2019.8667972&partnerID=40&md5=4cec9cff3af89379065c46dceb56c0ad
168	Madeiral, F. and Urli, S. and Maia, M. and Monperrus, M.	BEARS: An Extensible Java Bug Benchmark for Automatic Program Repair Studies	10.1109/SANER.2019.8667991	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064151415&doi=10.1109%2fSANER.2019.8667991&partnerID=40&md5=664ffc6e21723bf279da626dc8662b6c
169	Otlu, B. and Can, T.	JOA: Joint Overlap Analysis of multiple genomic interval sets 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing 08 Information and Computing Sciences 0802 Computation Theory and Mathematics	10.1186/s12859-019-2698-4	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062613795&doi=10.1186%2fs12859-019-2698-4&partnerID=40&md5=35ec15e4970f1db0260c92ae80627a63
170	Chiu, H.-K. and Adeli, E. and Wang, B. and Huang, D.-A. and Niebles, J.C.	Action-agnostic human pose forecasting	10.1109/WACV.2019.00156	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063581024&doi=10.1109%2fWACV.2019.00156&partnerID=40&md5=7d96a08804e833bda296bfd18cbafbbc
171	Casey, E. and Barnum, S. and Griffith, R. and Snyder, J. and van Beek, H. and Nelson, A.	Corrigendum to ‘Advancing coordinated cyber-investigations and tool interoperability using a community developed specification language’ [Digital Investigation 22C (2017) 14–45](S1742287617301007)(10.1016/j.diin.2017.08.002)	10.1016/j.diin.2018.10.001	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057261321&doi=10.1016%2fj.diin.2018.10.001&partnerID=40&md5=d56964aaf71a1c9c69fb988e1c309fcc
172	Kobus, R. and Lamoth, A. and Müller, A. and Hundt, C. and Kramer, S. and Schmidt, B.	CuBool: Bit-Parallel Boolean Matrix Factorization on CUDA-Enabled Accelerators	10.1109/PADSW.2018.8644574	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063338298&doi=10.1109%2fPADSW.2018.8644574&partnerID=40&md5=7642dfffd8d3dc42019f354f7810664d
173	Xiao, A. and Wu, Z. and Dong, S.	Ads-hcspark: A scalable haplotypecaller leveraging adaptive data segmentation to accelerate variant calling on spark	10.1186/s12859-019-2665-0	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061580507&doi=10.1186%2fs12859-019-2665-0&partnerID=40&md5=5ac4d84837f1ffb8049192785a88c596
174	Uszkoreit, J. and Perez-Riverol, Y. and Eggers, B. and Marcus, K. and Eisenacher, M.	Protein Inference Using PIA Workflows and PSI Standard File Formats	10.1021/acs.jproteome.8b00723	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060918776&doi=10.1021%2facs.jproteome.8b00723&partnerID=40&md5=65a3399eedbd97aff2630ca4fca4178e
175	Sun, C. and Medvedev, P.	Toward fast and accurate SNP genotyping from whole genome sequencing data for bedside diagnostics	10.1093/bioinformatics/bty641	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061119596&doi=10.1093%2fbioinformatics%2fbty641&partnerID=40&md5=bc41e205b27b4d2f3f606dddd5d641d3
176	Zhernakov, A.I. and Afonin, A.M. and Gavriliuk, N.D. and Moiseeva, O.M. and Zhukov, V.A.	s-dePooler: Determination of polymorphism carriers from overlapping DNA pools	10.1186/s12859-019-2616-9	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060292432&doi=10.1186%2fs12859-019-2616-9&partnerID=40&md5=6402bf9af164c5707d0ad0906f3f1279
177	Chen, C.-Y. and Chuang, T.-J.	NCLcomparator: Systematically post-screening non-co-linear transcripts (circular, trans-spliced, or fusion RNAs) identified from various detectors	10.1186/s12859-018-2589-0	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059503343&doi=10.1186%2fs12859-018-2589-0&partnerID=40&md5=55af031257b41841bc83f5ba6cfcf957
178	Lemay, M.J.	Understanding java usability by mining GitHub repositories	10.4230/OASIcs.PLATEAU.2018.2	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067886618&doi=10.4230%2fOASIcs.PLATEAU.2018.2&partnerID=40&md5=bbb5fc693f341647d987f2b547f31f82
180	Petke, J. and Brownlee, A.E.I.	Software Improvement with Gin: A Case Study	10.1007/978-3-030-27455-9_14	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072863413&doi=10.1007%2f978-3-030-27455-9_14&partnerID=40&md5=affbdd02f327c3876dde5b143c42e2c7
182	Kubitza, D.O. and Böckmann, M. and Graux, D.	SemanGit: A Linked Dataset from git	10.1007/978-3-030-30796-7_14	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081082643&doi=10.1007%2f978-3-030-30796-7_14&partnerID=40&md5=e6aedb452a49c79cc28f1b33573c1a91
183	Mohan, V.S. and Vinayakumar, R. and Sowmya, V. and Soman, K.P.	Deep rectified system for high-speed tracking in images	10.3233/JIFS-169907	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063456639&doi=10.3233%2fJIFS-169907&partnerID=40&md5=f066b9f86b13d6267826a35253052940
184	Shiau, C.-K. and Huang, J.-H. and Tsai, H.-K.	Catana: A tool for generating comprehensive annotations of alternative transcript events	10.1093/bioinformatics/bty795	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068492251&doi=10.1093%2fbioinformatics%2fbty795&partnerID=40&md5=4d50c96384000b147a5dc2896d4ab2f6
185	Guidotti, R. and Soldani, J. and Neri, D. and Brogi, A. and Pedreschi, D.	Helping your docker images to spread based on explainable models	10.1007/978-3-030-10997-4_13	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061153581&doi=10.1007%2f978-3-030-10997-4_13&partnerID=40&md5=70fe9654269fdd75d3fed5fbda578f35
187	Fink, L. and Lee, S.C. and Wu, J.Y. and Liu, X. and Song, T. and Velikova, Y. and Stamminger, M. and Navab, N. and Unberath, M.	LumiPath – Towards Real-Time Physically-Based Rendering on Embedded Devices	10.1007/978-3-030-32254-0_75	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075667340&doi=10.1007%2f978-3-030-32254-0_75&partnerID=40&md5=d5292b3c86634d41124db5a2daa63efc
188	Sharif, S.M.A. and Mahbootf, M.	Deep HOG: A hybrid model to classify bangla isolated alpha-numerical symbols	10.14311/NNW.2019.29.009	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070239897&doi=10.14311%2fNNW.2019.29.009&partnerID=40&md5=ca74d2f3733d7cac306f72e505bd0a21
189	Anatskiy, E. and Ryan, D.P. and Grüning, B.A. and Arrigoni, L. and Manke, T. and Bönisch, U.	Parkour LiMs: High-quality sample preparation in next generation sequencing	10.1093/bioinformatics/bty820	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068582245&doi=10.1093%2fbioinformatics%2fbty820&partnerID=40&md5=fb25d53d31523264060b0186a44b294e
190	Goncharenko, A. and Denisov, A. and Alyamkin, S. and Terentev, E.	Trainable Thresholds for Neural Network Quantization	10.1007/978-3-030-20518-8_26	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067573043&doi=10.1007%2f978-3-030-20518-8_26&partnerID=40&md5=671b47c82dc642d31fd6199403a04988
193	Liu, Q. and Liu, F. and He, J. and Zhou, M. and Hou, T. and Liu, Y.	VFM: Identification of Bacteriophages from Metagenomic Bins and Contigs Based on Features Related to Gene and Genome Composition	10.1109/ACCESS.2019.2957833	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077239485&doi=10.1109%2fACCESS.2019.2957833&partnerID=40&md5=0301932b5c898e5587db0d0764daebe6
194	Fadishei, H. and Doustian, S. and Saadati, P.	The Merits of Bitset Compression Techniques for Mining Association Rules from Big Data	10.1007/978-3-030-33495-6_10	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075823324&doi=10.1007%2f978-3-030-33495-6_10&partnerID=40&md5=b1cb51565360a5c80b524ff031d961ee
197	Wang, A. and Shi, Y. and Yi, X. and Yan, Y. and Liao, C. and de Supinski, B.R.	Ompparser: A standalone and unified openmp parser	10.1007/978-3-030-28596-8_10	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072855794&doi=10.1007%2f978-3-030-28596-8_10&partnerID=40&md5=326987f6455e85a12df3746eb05d6800
198	Raborn, R.T. and Brendel, V.P.	Using RAMPAGE to identify and annotate promoters in insect genomes	10.1007/978-1-4939-8775-7_9	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056393633&doi=10.1007%2f978-1-4939-8775-7_9&partnerID=40&md5=fe687e204c9738dd27757e8be536c4e5
199	Hosseini, M. and Pratas, D. and Pinho, A.J.	Cryfa: A secure encryption tool for genomic data	10.1093/bioinformatics/bty645	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058744156&doi=10.1093%2fbioinformatics%2fbty645&partnerID=40&md5=41772737cf6b084637d2f679f8a92a97
202	Florea, A.G. and Buiu, C.	Using a web-based framework to build and experiment with virtual reality worlds	10.12753/2066-026X-19-037	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085200368&doi=10.12753%2f2066-026X-19-037&partnerID=40&md5=4e303327c6127bdb86da73854ae6f6db
203	Naeem, M.R. and Lin, T. and Naeem, H. and Ullah, F. and Saeed, S.	Scalable Mutation Testing Using Predictive Analysis of Deep Learning Model	10.1109/ACCESS.2019.2950171	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077961490&doi=10.1109%2fACCESS.2019.2950171&partnerID=40&md5=27b2b35bb352c07c7001b81e2adf5036
205	Garnier, R.	Dual vibration configuration interaction (DVCI). An efficient factorization of molecular Hamiltonian for high performance infrared spectrum computation	10.1016/j.cpc.2018.07.008	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050756499&doi=10.1016%2fj.cpc.2018.07.008&partnerID=40&md5=6e272a47db8526585e8c79e4cfbe472f
206	Wei, Z.-G. and Zhang, S.-W.	DMSC: A dynamic multi-seeds method for clustering 16S rRNA sequences into OTUs	10.3389/fmicb.2019.00428	2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066503067&doi=10.3389%2ffmicb.2019.00428&partnerID=40&md5=d9f525f0808d0f7a5fda680818768221
207	Siam, M. and Eikerdawy, S. and Gamal, M. and Abdel-Razek, M. and Jagersand, M. and Zhang, H.	Real-Time Segmentation with Appearance, Motion and Geometry	10.1109/IROS.2018.8594088	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063000902&doi=10.1109%2fIROS.2018.8594088&partnerID=40&md5=34ea6c1b00f415c5a3f40b56db7fbb34
208	Marcos, D. and Tuia, D. and Kellenberger, B. and Zhang, L. and Bai, M. and Liao, R. and Urtasun, R.	Learning Deep Structured Active Contours End-to-End	10.1109/CVPR.2018.00925	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057620146&doi=10.1109%2fCVPR.2018.00925&partnerID=40&md5=56d081f365989fcf85345d81139b5fb2
209	Carlson, J. and Li, J.Z. and Zöllner, S.	Helmsman: Fast and efficient mutation signature analysis for massive sequencing datasets	10.1186/s12864-018-5264-y	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057527291&doi=10.1186%2fs12864-018-5264-y&partnerID=40&md5=2f37f0628dcc3910226a3b0c7c592d28
210	Yu, T. and Wang, T.	A Study of Regression Test Selection in Continuous Integration Environments	10.1109/ISSRE.2018.00024	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059631520&doi=10.1109%2fISSRE.2018.00024&partnerID=40&md5=2f27a47720aac43fc231613f61ca6e54
211	Jiarpakdee, J. and Tantithamthavorn, C. and Treude, C.	Artefact: An r implementation of the autospearman function	10.1109/ICSME.2018.00083	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058314837&doi=10.1109%2fICSME.2018.00083&partnerID=40&md5=bbfb7192701c5e999da7be8c1694a932
212	Kochhar, P.S. and Swierc, S. and Carnahan, T. and Sajnani, H. and Nagappan, M.	Understanding the role of reporting in work item tracking systems for software development: An industrial case study	10.1109/ICSME.2018.00070	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058291545&doi=10.1109%2fICSME.2018.00070&partnerID=40&md5=ffc200d3d2fbc0766314f2b1772fb7d9
213	Thorve, S. and Sreshtha, C. and Meng, N.	An empirical study of flaky tests in android apps	10.1109/ICSME.2018.00062	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058316108&doi=10.1109%2fICSME.2018.00062&partnerID=40&md5=fca6e18e7bb39ef9614f1b1eca187013
214	Saied, M.A. and Ouni, A. and Sahraoui, H. and Kula, R.G. and Inoue, K. and Lo, D.	Improving reusability of software libraries through usage pattern mining	10.1016/j.jss.2018.08.032	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052331660&doi=10.1016%2fj.jss.2018.08.032&partnerID=40&md5=7c0289c5437875dae5fce4b41e59df2a
215	Jadoul, Y. and Thompson, B. and de Boer, B.	Introducing Parselmouth: A Python interface to Praat	10.1016/j.wocn.2018.07.001	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050463066&doi=10.1016%2fj.wocn.2018.07.001&partnerID=40&md5=03eb1002bb7f4b3979c9e2c2c8658c92
216	Wessel, M. and De Souza, B.M. and Steinmacher, I. and Wiese, I.S. and Polato, I. and Chaves, A.P. and Gerosa, M.A.	The power of bots: Understanding bots in OSS projects	10.1145/3274451	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064157845&doi=10.1145%2f3274451&partnerID=40&md5=9b136fc43db8f92bbd51f215980b01ba
217	Shelenkov, A.A. and Slavokhotova, A.A. and Odintsova, T.I.	Cysmotif Searcher Pipeline for Antimicrobial Peptide Identification in Plant Transcriptomes	10.1134/S0006297918110135	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056605620&doi=10.1134%2fS0006297918110135&partnerID=40&md5=07792323d67216973fab744cbf2d32c7
218	Reinhardt, A. and Zhang, T. and Mathur, M. and Kim, M.	Augmenting stack overflow with api usage patterns mined from GitHub	10.1145/3236024.3264585	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058345090&doi=10.1145%2f3236024.3264585&partnerID=40&md5=e8397a485a95e724c3d27c0d7ea978f2
219	Basios, M. and Li, L. and Wu, F. and Kanthan, L. and Barr, E.T.	Darwinian data structure selection	10.1145/3236024.3236043	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058345723&doi=10.1145%2f3236024.3236043&partnerID=40&md5=5ef469be25b68e9331a23f8b1f799281
220	Lipčák, J. and Rossi, B.	A large-scale study on source code reviewer recommendation	10.1109/SEAA.2018.00068	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057204726&doi=10.1109%2fSEAA.2018.00068&partnerID=40&md5=525ca30e887f1c7fac89306318ee8e08
221	Kómár, P. and Kural, D.	Geck: Trio-based comparative benchmarking of variant calls	10.1093/bioinformatics/bty415	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054889812&doi=10.1093%2fbioinformatics%2fbty415&partnerID=40&md5=507b60687c8cad2c25a289fe254afdfd
223	Rácz, A. and Bajusz, D. and Héberger, K.	Life beyond the Tanimoto coefficient: Similarity measures for interaction fingerprints	10.1186/s13321-018-0302-y	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054537670&doi=10.1186%2fs13321-018-0302-y&partnerID=40&md5=a7a9a49e18b5c6f0441baac5069016ac
224	Wang, H. and Marcišauskas, S. and Sánchez, B.J. and Domenzain, I. and Hermansson, D. and Agren, R. and Nielsen, J. and Kerkhoven, E.J.	RAVEN 2.0: A versatile toolbox for metabolic network reconstruction and a case study on Streptomyces coelicolor	10.1371/journal.pcbi.1006541	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055635316&doi=10.1371%2fjournal.pcbi.1006541&partnerID=40&md5=8e34d8ac36ffec399a40f59cbd2b622d
225	Saborido, R. and Morales, R. and Khomh, F. and Guéhéneuc, Y.-G. and Antoniol, G.	Getting the most from map data structures in Android	10.1007/s10664-018-9607-8	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045030669&doi=10.1007%2fs10664-018-9607-8&partnerID=40&md5=5f54b44ea67e32903abf4b76bf2ec290
226	Moore, F.C. and Rising, J. and Lollo, N. and Springer, C. and Vasquez, V. and Dolginow, A. and Hope, C. and Anthoff, D.	Mimi-PAGE, an open-source implementation of the PAGE09 integrated assessment model	10.1038/sdata.2018.187	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054070490&doi=10.1038%2fsdata.2018.187&partnerID=40&md5=0814b96e4538cc1c69fe57deced69bd9
227	Ahmar, Y.E. and Pallec, X.L. and Gérard, S.	The visual variables in UML: How are they used by women?	10.1145/3241403.3241422	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055689848&doi=10.1145%2f3241403.3241422&partnerID=40&md5=01113c866ec9636a87b7f378d24abf4b
228	Rosenfeld, A.M. and Meng, W. and Luning Prak, E.T. and Hershberg, U.	ImmuneDB, a novel tool for the analysis, storage, and dissemination of immune repertoire sequencing data	10.3389/fimmu.2018.02107	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054779808&doi=10.3389%2ffimmu.2018.02107&partnerID=40&md5=fa6a1c028dde9cd542ec559fcdf5d7eb
229	Janes, A. and Mairegger, M. and Russo, B.	Code_Call_lens: Raising the developer awareness of critical code	10.1145/3238147.3240488	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056520236&doi=10.1145%2f3238147.3240488&partnerID=40&md5=5bf69491015f1e6896e7ffb68bc4a1f2
230	Pereira, R. and Cunha, J. and Simão, P. and Saraiva, J.	JStanley: Placing a green thumb on Java collections	10.1145/3238147.3240473	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054401366&doi=10.1145%2f3238147.3240473&partnerID=40&md5=0051344416edf38f1aac15d8b6af79c0
231	Ankenbrand, M.J. and Hohlfeld, S.C.Y. and Weber, L. and Förster, F. and Keller, A.	Functional exploration of natural networks and ecological communities	10.1111/2041-210X.13060	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052824894&doi=10.1111%2f2041-210X.13060&partnerID=40&md5=7e00e124ca08f173cfbe92d5db40b63d
232	Yang, D.	SolarData: An R package for easy access of publicly available solar datasets	10.1016/j.solener.2018.06.107	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052434812&doi=10.1016%2fj.solener.2018.06.107&partnerID=40&md5=ebca0e528fc16b539bd612e5648ddddb
233	Jain, C. and Koren, S. and Dilthey, A. and Phillippy, A.M. and Aluru, S.	A fast adaptive algorithm for computing whole-genome homology maps	10.1093/bioinformatics/bty597	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054146576&doi=10.1093%2fbioinformatics%2fbty597&partnerID=40&md5=67c62cff95e80cebc214a79014e00a86
234	Behera, S. and Gayen, S. and Deogun, J.S. and Vinodchandran, N.V.	KmerEstimate: A Streaming Algorithm for Estimating k-mer Counts with Optimal Space Usage	10.1145/3233547.3233587	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056109624&doi=10.1145%2f3233547.3233587&partnerID=40&md5=51a14ae8ffe7a46048ae942c44dbf6af
235	Borle, N.C. and Feghhi, M. and Stroulia, E. and Greiner, R. and Hindle, A.	Analyzing the effects of test driven development in GitHub	10.1007/s10664-017-9576-3	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034827767&doi=10.1007%2fs10664-017-9576-3&partnerID=40&md5=694f065a257ee7566d89600b6d2db3a7
236	Sawant, A.A. and Robbes, R. and Bacchelli, A.	On the reaction to deprecation of clients of 4 + 1 popular Java APIs and the JDK	10.1007/s10664-017-9554-9	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031416657&doi=10.1007%2fs10664-017-9554-9&partnerID=40&md5=00e478fbaaf19937c9e60b62e5bd0d5d
237	Echegaray, S. and Bakr, S. and Rubin, D.L. and Napel, S.	Quantitative Image Feature Engine (QIFE): an Open-Source, Modular Engine for 3D Quantitative Feature Extraction from Volumetric Medical Images	10.1007/s10278-017-0019-x	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030866982&doi=10.1007%2fs10278-017-0019-x&partnerID=40&md5=43a61493b60214673086ca2e440a145b
238	Tian, Y. and Wang, X. and Sun, H. and Zhao, Y. and Guo, C. and Liu, X.	Automatically Generating API Usage Patterns from Natural Language Queries	10.1109/APSEC.2018.00020	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066793048&doi=10.1109%2fAPSEC.2018.00020&partnerID=40&md5=0623756ba3dd5369cd7480225b72a40d
239	Nguyen, T. and Chen, S.W. and Shivakumar, S.S. and Taylor, C.J. and Kumar, V.	Unsupervised Deep Homography: A Fast and Robust Homography Estimation Model	10.1109/LRA.2018.2809549	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052248455&doi=10.1109%2fLRA.2018.2809549&partnerID=40&md5=f656755a68b252433ed58e7643541144
240	Dube, R. and Gollub, M.G. and Sommer, H. and Gilitschenski, I. and Siegwart, R. and Cadena, C. and Nieto, J.	Incremental-segment-based localization in 3-d point clouds	10.1109/LRA.2018.2803213	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053825306&doi=10.1109%2fLRA.2018.2803213&partnerID=40&md5=84ae30043a7de46d002bb818eba51185
241	Mak, L. and Li, M. and Cao, C. and Gordon, P. and Tarailo-Graovac, M. and Bousman, C. and Wang, P. and Long, Q.	SimPEL: Simulation-based power estimation for sequencing studies of low-prevalence conditions	10.1002/gepi.22129	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049050190&doi=10.1002%2fgepi.22129&partnerID=40&md5=0beb355dccad65c5d4eed055ae59feac
242	Król, M. and Reñé, S. and Ascigil, O. and Psaras, I.	ChainSoft: Collaborative software development using smart contracts	10.1145/3211933.3211934	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051677658&doi=10.1145%2f3211933.3211934&partnerID=40&md5=828ea74bb8f6e6b411ab0842f37dd8bc
243	Sun, X. and Fu, Y. and Dong, Y. and Liu, Z. and Zhang, Y.	Improving Fitness Function for Language Fuzzing with PCFG Model	10.1109/COMPSAC.2018.00098	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055429872&doi=10.1109%2fCOMPSAC.2018.00098&partnerID=40&md5=04693d144f3e126836ccc3998ae9811a
244	Barletta, A. and de Magistris, P.S.	Analyzing the risks embedded in option prices with rndfittool	10.3390/risks6020028	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056743634&doi=10.3390%2frisks6020028&partnerID=40&md5=51b2c4bdd8a5c709ac11087c5b3595dc
245	Laurin-Lemay, S. and Philippe, H. and Rodrigue, N.	Multiple factors confounding phylogenetic detection of selection on codon usage	10.1093/molbev/msy047	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059961771&doi=10.1093%2fmolbev%2fmsy047&partnerID=40&md5=66ecba6335f0448b2a789e0c132e70c8
246	Sun, W. and Duan, T. and Ye, P. and Chen, K. and Zhang, G. and Lai, M. and Zhang, H.	TSVdb: A web-tool for TCGA splicing variants analysis	10.1186/s12864-018-4775-x	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047824127&doi=10.1186%2fs12864-018-4775-x&partnerID=40&md5=d61a3fc555c265b7114a28f8e59eead7
247	Porkoláb, Z. and Brunner, T. and Krupp, D. and Csordás, M.	Codecompass: An open software comprehension framework for industrial usage	10.1145/3196321.3197546	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051672172&doi=10.1145%2f3196321.3197546&partnerID=40&md5=73c6d2642b37cd747c16c9dcc269d663
249	Porkoláb, Z. and Brunner, T.	The codecompass comprehension framework	10.1145/3196321.3196352	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051663783&doi=10.1145%2f3196321.3196352&partnerID=40&md5=bc1df16b024d36c28838384a22de85dc
250	Zhang, T. and Upadhyaya, G. and Reinhardt, A. and Rajan, H. and Kim, M.	Are code examples on an online Q&amp;A forum reliable?: A study of API misuse on stack overflow	10.1145/3180155.3180260	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046979029&doi=10.1145%2f3180155.3180260&partnerID=40&md5=c6a58327c8bd3e25e13ca2b8a213878e
251	Kochhar, P.S. and Swierc, S. and Carnahan, T. and Sajnani, H. and Nagappan, M.	Poster: Understanding the role of reporting in work item tracking systems for software development: An industrial case study	10.1145/3183440.3195071	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049697318&doi=10.1145%2f3183440.3195071&partnerID=40&md5=2a79c5fd1372850135457b0f56e05a35
252	Banerjee, A. and Chong, L.K. and Ballabriga, C. and Roychoudhury, A.	EnergyPatch: Repairing Resource Leaks to Improve Energy-Efficiency of Android Apps	10.1109/TSE.2017.2689012	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047012040&doi=10.1109%2fTSE.2017.2689012&partnerID=40&md5=90975c442961d54a3871d02bc1433323
253	Hamouda, E. and Sara, E.-M. and Tarek, M.	Ant lion optimization algorithm for kidney exchanges	10.1371/journal.pone.0196707	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046684400&doi=10.1371%2fjournal.pone.0196707&partnerID=40&md5=a8d4be9994b998b5e4425756ad3ad451
254	Kolomiiets, B. and Popov, A.	System for registration and analysis of human stabilograms	10.1109/TCSET.2018.8336288	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047462467&doi=10.1109%2fTCSET.2018.8336288&partnerID=40&md5=ebefd9e8903f82cfb80a066cb2c2dba1
255	Yang, S. and Wang, J. and Ng, R.T.	Inferring RNA sequence preferences for poorly studied RNA-binding proteins based on co-evolution	10.1186/s12859-018-2091-8	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043479956&doi=10.1186%2fs12859-018-2091-8&partnerID=40&md5=9b6c603696039e7d46ca46ef0e6319ee
256	Pikelner, A.	FMFT: fully massive four-loop tadpoles	10.1016/j.cpc.2017.11.017	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039705695&doi=10.1016%2fj.cpc.2017.11.017&partnerID=40&md5=a773ddff82eb65a0cd8cc7662be6caf5
257	Sweeney, P.W. and Starly, B. and Morris, P.J. and Xu, Y. and Jones, A. and Radhakrishnan, S. and Grassa, C.J. and Davis, C.C.	Large-scale digitization of herbarium specimens: Development and usage of an automated, high-throughput conveyor system	10.12705/671.9	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043323449&doi=10.12705%2f671.9&partnerID=40&md5=6d1c3d1a07a13e0a37dc5f5dc034ea1f
258	Madanecki, P. and Bałut, M. and Buckley, P.G. and Renata Ochocka, J. and Bartoszewski, R. and Crossman, D.K. and Messiaen, L.M. and Piotrowski, A.	High-Throughput Tabular Data Processor – Platform independent graphical tool for processing large data sets	10.1371/journal.pone.0192858	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042121876&doi=10.1371%2fjournal.pone.0192858&partnerID=40&md5=97797d98be9811ba45bc4e026a6c3d98
259	Zampieri, G. and Tran, D.V. and Donini, M. and Navarin, N. and Aiolli, F. and Sperduti, A. and Valle, G.	Scuba: Scalable kernel-based gene prioritization	10.1186/s12859-018-2025-5	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041449628&doi=10.1186%2fs12859-018-2025-5&partnerID=40&md5=01edcf5d46e4535cb773534048284e60
260	Probst, D. and Reymond, J.-L.	SmilesDrawer: Parsing and Drawing SMILES-Encoded Molecular Structures Using Client-Side JavaScript	10.1021/acs.jcim.7b00425	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040905901&doi=10.1021%2facs.jcim.7b00425&partnerID=40&md5=4717030ff906eb388bffacef5db14f11
261	Diaz-del-Pino, S. and Trelles, O. and Falgueras, J.	mORCA: Ubiquitous access to life science web services	10.1186/s12864-018-4439-x	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040740007&doi=10.1186%2fs12864-018-4439-x&partnerID=40&md5=76f83b9ae8787584fc14bd69337ce090
262	Rao, D. and Dubey, S. and Mohan Kumar, J. and Rao, D. and Balaji, B.	Descriptive and distribution analysis of GitHub repository data	10.14419/ijet.v7i3.12489	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077664193&doi=10.14419%2fijet.v7i3.12489&partnerID=40&md5=6b7a1840e3ef8dbe38969a031b8d8c9b
263	Härtel, J. and Heinz, M. and Lämmel, R.	EMF patterns of usage on github	10.1007/978-3-319-92997-2_14	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048775242&doi=10.1007%2f978-3-319-92997-2_14&partnerID=40&md5=ee3d49a87e988ab0c914ad0c07fb6859
264	Laurin-Lemay, S. and Rodrigue, N. and Lartillot, N. and Philippe, H.	Conditional approximate Bayesian computation: A new approach for across-site dependency in high-dimensional mutation-selection models	10.1093/molbev/msy173	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056310223&doi=10.1093%2fmolbev%2fmsy173&partnerID=40&md5=3a96d6e48c7c744e6d755de4e73a3952
265	Kohl, T.A. and Utpatel, C. and Schleusener, V. and De Filippo, M.R. and Beckert, P. and Cirillo, D.M. and Niemann, S.	MTBseq: A comprehensive pipeline for whole genome sequence analysis of Mycobacterium tuberculosis complex isolates	10.7717/peerj.5895	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054851920&doi=10.7717%2fpeerj.5895&partnerID=40&md5=67f6e2f61b0f0be1d76ba9a4908dda00
266	Chaudhary, H.A.A. and Hassan, S.-U. and Aljohani, N.R. and Daud, A.	Quality classification of scientific publications using hybrid summarization model	10.1007/978-3-030-04257-8_6	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057262907&doi=10.1007%2f978-3-030-04257-8_6&partnerID=40&md5=9ab2c4aa9f76475bd2d23c4473c268bb
267	Oliveira, J. and Viggiato, M. and Santos, M. and Figueiredo, E. and Marques-Neto, H.	An empirical study on the impact of android code smells on resource usage	10.18293/SEKE2018-157	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056839301&doi=10.18293%2fSEKE2018-157&partnerID=40&md5=8822f5556d206c977080599d910c09a5
270	Raja, M.A. and Ryan, C.	GELAB - A Matlab toolbox for grammatical evolution	10.1007/978-3-030-03496-2_22	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057089290&doi=10.1007%2f978-3-030-03496-2_22&partnerID=40&md5=5cf886665a07789453b78c5803363235
271	Li, Y. and Ouyang, W. and Zhou, B. and Shi, J. and Zhang, C. and Wang, X.	Factorizable Net: An Efficient Subgraph-Based Framework for Scene Graph Generation	10.1007/978-3-030-01246-5_21	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055105093&doi=10.1007%2f978-3-030-01246-5_21&partnerID=40&md5=82cb20743c257f2f2af0dd3329566ded
272	Barido-Sottani, J. and Bošková, V. and Plessis, L.D. and Kühnert, D. and Magnus, C. and Mitov, V. and Müller, N.F. and Pečerska, J. and Rasmussen, D.A. and Zhang, C. and Drummond, A.J. and Heath, T.A. and Pybus, O.G. and Vaughan, T.G. and Stadler, T.	Taming the BEAST - A Community Teaching Material Resource for BEAST 2	10.1093/sysbio/syx060	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040108507&doi=10.1093%2fsysbio%2fsyx060&partnerID=40&md5=44ab357256d08be7626ffbdb7da30fd9
273	Sethi, T. and Maheshwari, S. and Nagori, A. and Lodha, R.	Stewarding antibiotic stewardship in intensive care units with bayesian artificial intelligence [version 1; peer review: 2 approved with reservations]	10.12688/wellcomeopenres.14629.1	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078336824&doi=10.12688%2fwellcomeopenres.14629.1&partnerID=40&md5=df738b35c6342dc93955adf281e1687a
274	Endara, L. and Thessen, A.E. and Cole, H.A. and Walls, R. and Gkoutos, G. and Cao, Y. and Chong, S.S. and Cui, H.	Modifier Ontologies for frequency, certainty, degree, and coverage phenotype modifier	10.3897/BDJ.6.E29232	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082880742&doi=10.3897%2fBDJ.6.E29232&partnerID=40&md5=fe451943a15591a55547c7ca23c0c143
275	Borowka, S. and Heinrich, G. and Jahn, S. and Jones, S.P. and Kerner, M. and Schlenk, J. and Zirke, T.	pySecDec: A toolbox for the numerical evaluation of multi-scale integrals	10.1016/j.cpc.2017.09.015	2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031431867&doi=10.1016%2fj.cpc.2017.09.015&partnerID=40&md5=2805a13dcd12f1980f7a7aa9487bf3b5
276	Hou, S. and Feng, Y. and Wang, Z.	VegFru: A Domain-Specific Dataset for Fine-Grained Visual Categorization	10.1109/ICCV.2017.66	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041895074&doi=10.1109%2fICCV.2017.66&partnerID=40&md5=16516f9dc358a4b8cd0dd4b16d6e3c8c
277	Kafkas, Ş. and Sarntivijai, S. and Hoehndorf, R.	Usage of cell nomenclature in biomedical literature	10.1186/s12859-017-1978-0	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038955885&doi=10.1186%2fs12859-017-1978-0&partnerID=40&md5=9b68bd9d36bf5a42c09bc7900af8fd53
278	Costin, A.	Lua Code: Security overview and practical approaches to static analysis	10.1109/SPW.2017.38	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048319697&doi=10.1109%2fSPW.2017.38&partnerID=40&md5=c6a34231af4721b9c24605fe4ae8c15b
279	Poehlman, W.L. and Rynge, M. and Balamurugan, D. and Mills, N. and Feltus, F.A.	OSG-KINC: High-throughput gene co-expression network construction using the open science grid	10.1109/BIBM.2017.8217938	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046091228&doi=10.1109%2fBIBM.2017.8217938&partnerID=40&md5=beb2f916034fcaad283d377cf699193c
280	Chapman, C. and Wang, P. and Stolee, K.T.	Exploring regular expression comprehension	10.1109/ASE.2017.8115653	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041430882&doi=10.1109%2fASE.2017.8115653&partnerID=40&md5=0c8a512b78ca4c961eb8c540762d12f1
281	Alimoglu, A. and Ozturan, C.	Design of a smart contract based autonomous organization for sustainable software	10.1109/eScience.2017.76	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043760581&doi=10.1109%2feScience.2017.76&partnerID=40&md5=b76e002bff8bb638602886737835f3e3
282	Xu, W. and Sun, X. and Hu, J. and Li, B.	REPERSP: Recommending personalized software projects on GitHub	10.1109/ICSME.2017.20	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032496394&doi=10.1109%2fICSME.2017.20&partnerID=40&md5=72ddb256bacfb19352d83e4dab953357
283	Herz, C. and Fillion-Robin, J.-C. and Onken, M. and Riesmeier, J. and Lasso, A. and Pinter, C. and Fichtinger, G. and Pieper, S. and Clunie, D. and Kikinis, R. and Fedorov, A.	dcmqi: An open source library for standardized communication of quantitative image analysis results using DICOM	10.1158/0008-5472.CAN-17-0336	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033433885&doi=10.1158%2f0008-5472.CAN-17-0336&partnerID=40&md5=bf0635dc9fe3c75ac5aab22569514e56
284	Sayagh, M. and Dong, Z. and Andrzejak, A. and Adams, B.	Does the Choice of Configuration Framework Matter for Developers? Empirical Study on 11 Java Configuration Frameworks	10.1109/SCAM.2017.25	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047197551&doi=10.1109%2fSCAM.2017.25&partnerID=40&md5=dfd9358cd85fb3cfb66ee6bbd6678f22
285	Duan, R. and Bijlani, A. and Xu, M. and Kim, T. and Lee, W.	Identifying open-source license violation and 1-day security risk at large scale	10.1145/3133956.3134048	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041441238&doi=10.1145%2f3133956.3134048&partnerID=40&md5=495b5e41caa6c4796f021dcf554a9ecf
286	Stacey, R.G. and Skinnider, M.A. and Scott, N.E. and Foster, L.J.	A rapid and accurate approach for prediction of interactomes from co-elution data (PrInCE)	10.1186/s12859-017-1865-8	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031900758&doi=10.1186%2fs12859-017-1865-8&partnerID=40&md5=673cb14e9f6fa15a77ecee9f0e9005d8
287	Hosseinabady, M. and Nunez-Yanez, J.L.	A systematic approach to design and optimise streaming applications on FPGA using high-level synthesis	10.23919/FPL.2017.8056758	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034445484&doi=10.23919%2fFPL.2017.8056758&partnerID=40&md5=9ab4f54a0b6f8eb12d01877a154b339d
288	Verdegem, D. and Moseley, H.N.B. and Vermaelen, W. and Sanchez, A.A. and Ghesquière, B.	MAIMS: a software tool for sensitive metabolic tracer analysis through the deconvolution of 13C mass isotopologue profiles of large composite metabolites	10.1007/s11306-017-1250-7	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029167235&doi=10.1007%2fs11306-017-1250-7&partnerID=40&md5=81430f39c1aae5a491233232e73145c3
291	Limasset, A. and Rizk, G. and Chikhi, R. and Peterlongo, P.	Fast and scalable minimal perfect hashing for massive key sets	10.4230/LIPIcs.SEA.2017.25	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028774755&doi=10.4230%2fLIPIcs.SEA.2017.25&partnerID=40&md5=94a707c55201e871d0968c7a877b7dd0
292	Silva, L.H. and Valente, M.T. and Bergel, A. and Anquetil, N. and Etien, A.	Identifying Classes in Legacy JavaScript Code	10.1002/smr.1864	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026836053&doi=10.1002%2fsmr.1864&partnerID=40&md5=e3ca1bd5a022845d4038e4dd9fa7474e
293	Almodaresi, F. and Pandey, P. and Patro, R.	Rainbowfish: A succinct colored de Bruijn graph representation	10.4230/LIPIcs.WABI.2017.18	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028766603&doi=10.4230%2fLIPIcs.WABI.2017.18&partnerID=40&md5=875e4b2c4f555353948db4252094bd3f
294	Yang, D. and Tian, D. and Gong, J. and Gao, S. and Yang, T. and Li, X.	Difference Bloom Filter: A probabilistic structure for multi-set membership query	10.1109/ICC.2017.7996678	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028305891&doi=10.1109%2fICC.2017.7996678&partnerID=40&md5=69043350670573ce88e28c1865bff34e
295	Wei, Z.-G. and Zhang, S.-W.	DBH: A de Bruijn graph-based heuristic method for clustering large-scale 16S rRNA sequences into OTUs	10.1016/j.jtbi.2017.04.019	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019417482&doi=10.1016%2fj.jtbi.2017.04.019&partnerID=40&md5=f7d17cb21ee1767941e4f460de24e7d9
296	Schröder, J. and Wirawan, A. and Schmidt, B. and Papenfuss, A.T.	CLOVE: Classification of genomic fusions into structural variation events	10.1186/s12859-017-1760-3	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025113789&doi=10.1186%2fs12859-017-1760-3&partnerID=40&md5=f93c82f6be3cf66b51779292d851b01c
297	Khatchadourian, R. and Masuhara, H.	Automated Refactoring of Legacy Java Software to Default Methods	10.1109/ICSE.2017.16	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027716666&doi=10.1109%2fICSE.2017.16&partnerID=40&md5=1e70ebaaf5b72fe1b6621011225a9fcb
298	Khelik, K. and Lagesen, K. and Sandve, G.K. and Rognes, T. and Nederbragt, A.J.	NucDiff: In-depth characterization and annotation of differences between two sets of DNA sequences	10.1186/s12859-017-1748-z	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023207388&doi=10.1186%2fs12859-017-1748-z&partnerID=40&md5=d5aaababc8605f99cee76099bc2a4dc4
299	Walsh, T.A. and Kapfhammer, G.M. and McMinn, P.	ReDeCheck: An automatic layout failure checking tool for responsively designed web pages	10.1145/3092703.3098221	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026667206&doi=10.1145%2f3092703.3098221&partnerID=40&md5=dbc20af7124e7187a303b6992df11ff2
300	Dennis, C. and Krutz, D.E. and Wiem Mkaouer, M.	P-Lint: A Permission Smell Detector for Android Applications	10.1109/MOBILESoft.2017.24	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027037638&doi=10.1109%2fMOBILESoft.2017.24&partnerID=40&md5=d36faf195f044547d79802a4c659f3ef
301	Teleman, J. and Hauri, S. and Malmström, J.	Improvements in Mass Spectrometry Assay Library Generation for Targeted Proteomics	10.1021/acs.jproteome.6b00928	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023172993&doi=10.1021%2facs.jproteome.6b00928&partnerID=40&md5=feba444e0c4f33b35a3eafd928397b58
302	Zhou, Y. and Liu, P. and Jin, H. and Yang, T. and Dang, S. and Li, X.	One Memory Access Sketch: A More Accurate and Faster Sketch for Per-Flow Measurement	10.1109/GLOCOM.2017.8254741	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046397838&doi=10.1109%2fGLOCOM.2017.8254741&partnerID=40&md5=10209a7a9eb1a6aa338692386deced4d
303	Yang, T. and Yin, B. and Li, H. and Shahzad, M. and Uhlig, S. and Cm, B. and Li, X.	Rectangular hash table: Bloom filter and bitmap assisted hash table with high speed	10.1109/BigData.2017.8257999	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047736321&doi=10.1109%2fBigData.2017.8257999&partnerID=40&md5=f90176a81889548fe771fc1e845f27ec
304	Baltes, S. and Kiefer, R. and Diehl, S.	Attribution required: Stack overflow code snippets in GitHub projects	10.1109/ICSE-C.2017.99	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730072&doi=10.1109%2fICSE-C.2017.99&partnerID=40&md5=f150a26c7ace22743bfe213b6992e49e
305	Zampetti, F. and Scalabrino, S. and Oliveto, R. and Canfora, G. and Di Penta, M.	How Open Source Projects Use Static Code Analysis Tools in Continuous Integration Pipelines	10.1109/MSR.2017.2	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026532196&doi=10.1109%2fMSR.2017.2&partnerID=40&md5=faeb88b4c5b6ea11a5a7438cdbd37396
306	Malaquias, R. and Ribeiro, M. and Bonifacio, R. and Monteiro, E. and Medeiros, F. and Garcia, A. and Gheyi, R.	The Discipline of Preprocessor-Based Annotations - Does #ifdef TAG n't #endif Matter	10.1109/ICPC.2017.41	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025173309&doi=10.1109%2fICPC.2017.41&partnerID=40&md5=a9777caa317869cded2555dbcf790122
308	Chen, X. and Wang, C. and Tang, S. and Yu, C. and Zou, Q.	CMSA: A heterogeneous CPU/GPU computing system for multiple similar RNA/DNA sequence alignment	10.1186/s12859-017-1725-6	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021212447&doi=10.1186%2fs12859-017-1725-6&partnerID=40&md5=2af6ffd652936e4b554aa0a5b7ed3a0e
309	Kochhar, P.S. and Lo, D.	Revisiting assert use in GitHub projects	10.1145/3084226.3084259	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025455377&doi=10.1145%2f3084226.3084259&partnerID=40&md5=189313fa545da7d77ed93ef6231410dc
310	Sawant, A.A. and Bacchelli, A.	fine-GRAPE: fine-grained APi usage extractor – an approach and dataset to investigate API usage	10.1007/s10664-016-9444-6	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982947678&doi=10.1007%2fs10664-016-9444-6&partnerID=40&md5=8f44f4b75d284872cdcf6a7d8ad72b83
311	Vendome, C. and Bavota, G. and Penta, M.D. and Linares-Vásquez, M. and German, D. and Poshyvanyk, D.	License usage and changes: a large-scale study on gitHub	10.1007/s10664-016-9438-4	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020033576&doi=10.1007%2fs10664-016-9438-4&partnerID=40&md5=8854e37b29ad157bd8c1251cb52edb99
312	Cardall, C.Y. and Budiardja, R.D.	GENASIS   Basics: Object-oriented utilitarian functionality for large-scale physics simulations (Version 2)	10.1016/j.cpc.2016.12.019	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011898489&doi=10.1016%2fj.cpc.2016.12.019&partnerID=40&md5=79804a4975e39e2c6ef3fe81bfd064fa
313	Beshero-Bondar, E.E. and Parker, R.J.	A GitHub garage for a digital humanities course	10.1007/978-3-319-54226-3_15	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033979673&doi=10.1007%2f978-3-319-54226-3_15&partnerID=40&md5=b998a0c04dd71e6e844e40438dbe142a
314	Leitner, P. and Bezemer, C.-P.	An exploratory study of the state of practice of performance testing in Java-based open source projects	10.1145/3030207.3030213	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019046338&doi=10.1145%2f3030207.3030213&partnerID=40&md5=014e9d6263420a8166cf42cbaa28c2ff
315	Edmands, W.M.B. and Petrick, L. and Barupal, D.K. and Scalbert, A. and Wilson, M.J. and Wickliffe, J.K. and Rappaport, S.M.	CompMS2Miner: An Automatable Metabolite Identification, Visualization, and Data-Sharing R Package for High-Resolution LC-MS Data Sets	10.1021/acs.analchem.6b02394	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019765844&doi=10.1021%2facs.analchem.6b02394&partnerID=40&md5=b1c4f0a196637eadeff88fbe89dc6928
317	Zhang, Y. and Lo, D. and Kochhar, P.S. and Xia, X. and Li, Q. and Sun, J.	Detecting similar repositories on GitHub	10.1109/SANER.2017.7884605	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018437178&doi=10.1109%2fSANER.2017.7884605&partnerID=40&md5=f997ac4638de3de022c5a14bd3b52d2e
318	Zerouali, A. and Mens, T.	Analyzing the evolution of testing library usage in open source Java projects	10.1109/SANER.2017.7884645	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018411983&doi=10.1109%2fSANER.2017.7884645&partnerID=40&md5=2087e3cb3f3941d46fb4331c158e8d6a
319	Ouni, A. and Kula, R.G. and Kessentini, M. and Ishio, T. and German, D.M. and Inoue, K.	Search-based software library recommendation using multi-objective optimization	10.1016/j.infsof.2016.11.007	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006282719&doi=10.1016%2fj.infsof.2016.11.007&partnerID=40&md5=92b41cc2c123052c8bbf93cd91b59a6a
320	Sandi, S. and Krstajic, B. and Popovic, T.	PyPMU - Open source python package for synchrophasor data transfer	10.1109/TELFOR.2016.7818916	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013665825&doi=10.1109%2fTELFOR.2016.7818916&partnerID=40&md5=3b262e34a23874997c4149d9869469b8
321	Sliwko, L. and Getov, V.	AGOCS - Accurate Google Cloud Simulator Framework	10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0095	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013219936&doi=10.1109%2fUIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0095&partnerID=40&md5=184496035a674337e22edcb0da751920
322	Gaye, A.	Extending the R Library PROPER to enable power calculations for isoform-level analysis with EBSeq	10.3389/fgene.2016.00225	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012202199&doi=10.3389%2ffgene.2016.00225&partnerID=40&md5=d64c6f12fca7588333124e35170075cf
323	Audain, E. and Uszkoreit, J. and Sachsenberg, T. and Pfeuffer, J. and Liang, X. and Hermjakob, H. and Sanchez, A. and Eisenacher, M. and Reinert, K. and Tabb, D.L. and Kohlbacher, O. and Perez-Riverol, Y.	In-depth analysis of protein inference algorithms using multiple search engines and well-defined metrics	10.1016/j.jprot.2016.08.002	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988843652&doi=10.1016%2fj.jprot.2016.08.002&partnerID=40&md5=4d4b37efcc310c115168539d2dd38469
324	Roveda, R. and Fontana, F.A. and Raibulet, C. and Zanoni, M. and Rampazzo, F.	Does the migration to GitHub relate to internal software quality?	10.5220/0006367402930300	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025468384&doi=10.5220%2f0006367402930300&partnerID=40&md5=8bc66fdfbec847b1b7b48970028b8129
325	Orlov, S.	C++ playground for numerical integration method developers	10.1007/978-3-319-71255-0_34	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035098847&doi=10.1007%2f978-3-319-71255-0_34&partnerID=40&md5=d0d1685f20bb8c60ad8a2d5c089d899c
326	Lu, H. and Zhou, Y. and Zhang, Z.-K.	Calculate deep convolution NeurAl network on cell unit	10.1007/978-981-10-4154-9_61	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016119646&doi=10.1007%2f978-981-10-4154-9_61&partnerID=40&md5=8d6f45d34a83f96eafec8664106fcceb
329	Bond, S.R. and Keat, K.E. and Barreira, S.N. and Baxevanis, A.D.	BuddySuite: Command-line toolkits for manipulating sequences, alignments, and phylogenetic trees	10.1093/molbev/msx089	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027411555&doi=10.1093%2fmolbev%2fmsx089&partnerID=40&md5=ccf3f18cba3e7affdf75f6afd373e8dd
330	Santos, M.R. and de Sá, T.Q.V. and da Silva, F.E. and dos Santos Junior, M.R. and Maia, T.A. and Reis, Z.S.N.	Health information exchange for continuity of maternal and neonatal care supporting: A proof-of-concept based on ISO standard	10.4338/ACI-2017-06-RA-0106	2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034568205&doi=10.4338%2fACI-2017-06-RA-0106&partnerID=40&md5=2fff9fb8b35315185d9f93f7e35be1c1
331	Feist, M.D. and Santos, E.A. and Watts, I. and Hindle, A.	Visualizing Project Evolution through Abstract Syntax Tree Analysis	10.1109/VISSOFT.2016.6	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010424321&doi=10.1109%2fVISSOFT.2016.6&partnerID=40&md5=c8e471fc733147a53b49a2f5b195474d
332	Kim, D. and Hahn, A.S. and Hanson, N.W. and Konwar, K.M. and Hallam, S.J.	FAST: Fast annotation with synchronized threads	10.1109/CIBCB.2016.7758120	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011392004&doi=10.1109%2fCIBCB.2016.7758120&partnerID=40&md5=d889a8bd6b390ecff7a28f67f715cfc2
333	Fowkes, J. and Sutton, C.	Parameter-Free Probabilistic API Mining across GitHub	10.1145/2950290.2950319	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997219095&doi=10.1145%2f2950290.2950319&partnerID=40&md5=1e53b808fa56f7c08d3bd67cc57990af
334	Gu, X. and Zhang, H. and Zhang, D. and Kim, S.	Deep API Learning	10.1145/2950290.2950334	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997108965&doi=10.1145%2f2950290.2950334&partnerID=40&md5=ae730cb574590851b20d956bb285b909
335	Toal, R. and Rivera, R. and Schneider, A. and Choe, E.	Programming Language Explorations	10.1201/b21848	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042370650&doi=10.1201%2fb21848&partnerID=40&md5=c1e51c41e3ebffc4ceda1a810326c892
336	Shen, W. and Le, S. and Li, Y. and Hu, F.	SeqKit: A cross-platform and ultrafast toolkit for FASTA/Q file manipulation	10.1371/journal.pone.0163962	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992166172&doi=10.1371%2fjournal.pone.0163962&partnerID=40&md5=150eafb99a3677230d571a0e7ca5dc3d
360	Eck, B.J.	EpanetReader: A Package for Reading EPANET Files into R	10.1061/9780784479865.051	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976520090&doi=10.1061%2f9780784479865.051&partnerID=40&md5=52dd339e6306125e82d0ecaaf017cf5f
337	Viitanen, M. and Koivula, A. and Lemmetti, A. and Ylä-Outinen, A. and Vanne, J. and Hämäläinen, T.D.	Kvazaar: Open-source HEVC/H.265 encoder	10.1145/2964284.2973796	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994682412&doi=10.1145%2f2964284.2973796&partnerID=40&md5=a2785ab8b43ac911b25242dd24be28af
338	Tsuji, J. and Weng, Z.	DNApi: A de novo adapter prediction algorithm for small RNA sequencing data	10.1371/journal.pone.0164228	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991396410&doi=10.1371%2fjournal.pone.0164228&partnerID=40&md5=9d531f6a1e8acd4f8a4096334bd0492c
339	Hilton, M. and Tunnell, T. and Huang, K. and Marinov, D. and Dig, D.	Usage, costs, and benefits of continuous integration in open-source projects	10.1145/2970276.2970358	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989159511&doi=10.1145%2f2970276.2970358&partnerID=40&md5=7e96113dc1efb43fb7b51e2d6ed14763
340	Jeanquartier, F. and Jean-Quartier, C. and Cemernek, D. and Holzinger, A.	In silico modeling for tumor growth visualization	10.1186/s12918-016-0318-8	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984823845&doi=10.1186%2fs12918-016-0318-8&partnerID=40&md5=e702a59e0a2820987c79768921a8c28c
341	Cao, Y. and Wang, Y. and Zheng, X. and Li, F. and Bo, X.	RevEcoR: An R package for the reverse ecology analysis of microbiomes	10.1186/s12859-016-1088-4	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984653407&doi=10.1186%2fs12859-016-1088-4&partnerID=40&md5=6edac424aeb4f6fd297f84fec3bcfa5e
342	Irawan, H. and Prihatmanto, A.S.	Implementation of graph database for OpenCog artificial general intelligence framework using Neo4j	10.1109/IDM.2015.7516355	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983424321&doi=10.1109%2fIDM.2015.7516355&partnerID=40&md5=2fc001d89b1609b05cff4356607b6fea
343	Chapman, C. and Stolee, K.T.	Exploring regular expression usage and context in python	10.1145/2931037.2931073	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984870747&doi=10.1145%2f2931037.2931073&partnerID=40&md5=138862ce9980e3c48f4949bb9a2802d5
344	Liu, H. and Hou, T.	CaFE: A tool for binding affinity prediction using end-point free energy methods	10.1093/bioinformatics/btw215	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992346072&doi=10.1093%2fbioinformatics%2fbtw215&partnerID=40&md5=21d14d31b04eb690aa4a343898cf4e35
345	Liu, S. and Bai, G. and Sun, J. and Dong, J.S.	Towards Using Concurrent Java API Correctly	10.1109/ICECCS.2016.038	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012098118&doi=10.1109%2fICECCS.2016.038&partnerID=40&md5=b11f347897f08bafbf4b0cffcc50328c
346	Brankovics, B. and Zhang, H. and van Diepeningen, A.D. and van der Lee, T.A.J. and Waalwijk, C. and de Hoog, G.S.	GRAbB: Selective Assembly of Genomic Regions, a New Niche for Genomic Research	10.1371/journal.pcbi.1004753	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978828490&doi=10.1371%2fjournal.pcbi.1004753&partnerID=40&md5=8eb073a943810f7b63f2c416666264ba
347	Li, D. and Luo, R. and Liu, C.-M. and Leung, C.-M. and Ting, H.-F. and Sadakane, K. and Yamashita, H. and Lam, T.-W.	MEGAHIT v1.0: A fast and scalable metagenome assembler driven by advanced methodologies and community practices	10.1016/j.ymeth.2016.02.020	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962227778&doi=10.1016%2fj.ymeth.2016.02.020&partnerID=40&md5=d27fc1f11afce0603dfc0af769b9c303
348	Chavarrías, C. and García-Vázquez, V. and Alemán-Gómez, Y. and Montesinos, P. and Pascau, J. and Desco, M.	fMRat: an extension of SPM for a fully automatic analysis of rodent brain functional magnetic resonance series	10.1007/s11517-015-1365-9	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939479475&doi=10.1007%2fs11517-015-1365-9&partnerID=40&md5=ad0e61652d6f3d4d0fc739edb68f0c15
349	Cui, R. and Schumer, M. and Rosenthal, G.G.	Admix'em: A flexible framework for forward-time simulations of hybrid populations with selection and mate choice	10.1093/bioinformatics/btv700	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964413487&doi=10.1093%2fbioinformatics%2fbtv700&partnerID=40&md5=afa9e2a98a720fa27c2e362e08db4621
350	Hu, H. and Wang, W. and Zhu, Z. and Zhu, J. and Tan, D. and Zhou, Z. and Mao, C. and Chen, X.	GIPS: A software guide to sequencing-based direct gene cloning in forward genetics studies	10.1104/pp.15.01327	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962109512&doi=10.1104%2fpp.15.01327&partnerID=40&md5=2e80b8ed84361b97f98fcf9a9c907504
351	Basso, F. and Levorato, R. and Munaro, M. and Menegatti, E.	A distributed calibration algorithm for color and range camera networks	10.1007/978-3-319-26054-9_16	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958581753&doi=10.1007%2f978-3-319-26054-9_16&partnerID=40&md5=1ad5bcba2616dec740eec236bfb6302b
352	Melo, A.T.O. and Bartaula, R. and Hale, I.	GBS-SNP-CROP: A reference-optional pipeline for SNP discovery and plant germplasm characterization using variable length, paired-end genotyping-by-sequencing data	10.1186/s12859-016-0879-y	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953923814&doi=10.1186%2fs12859-016-0879-y&partnerID=40&md5=e7c81c8f469f3359475481f3b31271f4
354	Gilpin, W.	PyPDB: A Python API for the Protein Data Bank	10.1093/bioinformatics/btv543	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959906715&doi=10.1093%2fbioinformatics%2fbtv543&partnerID=40&md5=7de012dd3ee8401ed67c9d9989534ec6
355	Busby, B. and Lesko, M. and Federer, L.	Closing gaps between open software and public data in a hackathon setting: User-centered software prototyping	10.12688/f1000research.8382.1	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969640914&doi=10.12688%2ff1000research.8382.1&partnerID=40&md5=9dc49cba3aa5fdbb90ccb36fc84dd76f
357	Roe, K. and Smith, S.	Coqpie: An IDE aimed at improving proof development productivity	10.1007/978-3-319-43144-4_32	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984815254&doi=10.1007%2f978-3-319-43144-4_32&partnerID=40&md5=b79e92dc29a5fa8a776e423e5096f798
358	Ambati, B.R. and Reddy, S. and Steedman, M.	Assessing relative sentence complexity using an incremental CCG parser	10.18653/v1/n16-1120	2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994104623&doi=10.18653%2fv1%2fn16-1120&partnerID=40&md5=26475f1ec73ca1551895b3c3b1c1c3ea
362	Cui, X. and Wei, Z. and Zhang, L. and Liu, H. and Sun, L. and Zhang, S.-W. and Huang, Y. and Meng, J.	Sketching the distribution of transcriptomic features on RNA transcripts with Travis coordinates	10.1109/BIBM.2015.7359904	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962427488&doi=10.1109%2fBIBM.2015.7359904&partnerID=40&md5=a102c11efa170fd77f2f4f4d62eebfd3
363	Nazarov, V.I. and Pogorelyy, M.V. and Komech, E.A. and Zvyagin, I.V. and Bolotin, D.A. and Shugay, M. and Chudakov, D.M. and Lebedev, Y.B. and Mamedov, I.Z.	tcR: An R package for T cell receptor repertoire advanced data analysis	10.1186/s12859-015-0613-1	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939258340&doi=10.1186%2fs12859-015-0613-1&partnerID=40&md5=28f21836830cb6ba41f3c49af665f46e
364	Goeminne, M. and Mens, T.	Towards a survival analysis of database framework usage in Java projects	10.1109/ICSM.2015.7332512	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961576026&doi=10.1109%2fICSM.2015.7332512&partnerID=40&md5=ad0d9afed762aac9df38356c3c88835a
365	Hoobin, C. and Kind, T. and Boucher, C. and Puglisi, S.J.	Fast and efficient compression of high-throughput sequencing reads	10.1145/2808719.2808753	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963502761&doi=10.1145%2f2808719.2808753&partnerID=40&md5=4327d6eb60b44f35af988029f60c07d1
366	Vendome, C.	A Large Scale Study of License Usage on GitHub	10.1109/ICSE.2015.245	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951802256&doi=10.1109%2fICSE.2015.245&partnerID=40&md5=56cc0cf822fd5c5a2737eec5f7cf7ffa
367	Vendome, C. and Linares-Vásquez, M. and Bavota, G. and Di Penta, M. and German, D. and Poshyvanyk, D.	License Usage and Changes: A Large-Scale Study of Java Projects on GitHub	10.1109/ICPC.2015.32	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988267541&doi=10.1109%2fICPC.2015.32&partnerID=40&md5=c9a21d3e27caf9ead671b39820c29367
368	Sawant, A.A. and Bacchelli, A.	A dataset for API usage	10.1109/MSR.2015.75	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957054673&doi=10.1109%2fMSR.2015.75&partnerID=40&md5=4985e472a4e2237225e39a700cf5865f
369	Forer, L. and Afgan, E. and Weißensteiner, H. and Davidović, D. and Specht, G. and Kronenberg, F. and Schönherr, S.	Cloudflow - A framework for MapReduce pipeline development in Biomedical Research	10.1109/MIPRO.2015.7160259	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946119273&doi=10.1109%2fMIPRO.2015.7160259&partnerID=40&md5=531af452d43bf709a51218c0a0573798
370	Bickhart, D.M. and Hutchison, J.L. and Xu, L. and Schnabel, R.D. and Taylor, J.F. and Reecy, J.M. and Schroeder, S. and Van Tassell, C.P. and Sonstegard, T.S. and Liu, G.E.	RAPTR-SV: A hybrid method for the detection of structural variants	10.1093/bioinformatics/btv086	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936760378&doi=10.1093%2fbioinformatics%2fbtv086&partnerID=40&md5=86cf8a447c4b858b6f37b03c9bc216af
371	De Klerk, E. and Fokkema, I.F.A.C. and Thiadens, K.A.M.H. and Goeman, J.J. and Palmblad, M. and Den Dunnen, J.T. and Von Lindern, M. and T'Hoen, P.A.C.	Assessing the translational landscape of myogenic differentiation by ribosome profiling	10.1093/nar/gkv281	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936806742&doi=10.1093%2fnar%2fgkv281&partnerID=40&md5=869c2fedda5f34ffac38926154ed80b6
372	Bovy, J.	Galpy: A python library for galactic dynamics	10.1088/0067-0049/216/2/29	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923246438&doi=10.1088%2f0067-0049%2f216%2f2%2f29&partnerID=40&md5=65aead4123f0657c19deee6cb32bb43d
373	Gnimpieba, E.Z. and Thavappiragasam, M. and Chango, A. and Conn, B. and Lushbough, C.M.	SBMLDock: Docker driven systems biology tool development and usage	10.1007/978-3-319-23401-4_24	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945976513&doi=10.1007%2f978-3-319-23401-4_24&partnerID=40&md5=78f34c04aeec4a9f5354eba79305b6ca
374	Siranosian, B. and Perera, S. and Williams, E. and Ye, C. and de Graffenried, C. and Shank, P.	Tetranucleotide usage highlights genomic heterogeneity among mycobacteriophages	10.12688/f1000research.6077.2	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969706679&doi=10.12688%2ff1000research.6077.2&partnerID=40&md5=9db859bbeccd0fb518cb90b5dd9d88e6
375	Silva, L.H. and Ramos, M. and Valente, M.T. and Bergel, A. and Anquetil, N.	Does JavaScript software embrace classes?	10.1109/SANER.2015.7081817	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928666921&doi=10.1109%2fSANER.2015.7081817&partnerID=40&md5=ed9e27c2269b7ab9d3b17c21c413867d
376	Lawrence, T.J. and Kauffman, K.T. and Amrine, K.C.H. and Carper, D.L. and Lee, R.S. and Becich, P.J. and Canales, C.J. and Ardell, D.H.	FAST: FAST Analysis of Sequences Toolbox	10.3389/fgene.2015.00172	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940103176&doi=10.3389%2ffgene.2015.00172&partnerID=40&md5=43fe4fe0cf4c7028be925d017e117ad7
377	Venev, S.V. and Zeldovich, K.B.	Massively parallel sampling of lattice proteins reveals foundations of thermal adaptation	10.1063/1.4927565	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938798021&doi=10.1063%2f1.4927565&partnerID=40&md5=65045d1214bc544ac66adf3c8c9c167b
378	Almeida-E-Silva, D.C. and Vêncio, R.Z.N.	Sifter-T: A scalable and optimized framework for the SIFTER phylogenomic method of probabilistic protein domain annotation	10.2144/000114266	2015		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924421750&doi=10.2144%2f000114266&partnerID=40&md5=8e1bcbbd919dc53a726e4efb747400b0
379	Zhang, Q. and Pell, J. and Canino-Koning, R. and Howe, A.C. and Brown, C.T.	These are not the K-mers you are looking for: Efficient online K-mer counting using a probabilistic data structure	10.1371/journal.pone.0101271	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904876565&doi=10.1371%2fjournal.pone.0101271&partnerID=40&md5=432e9e27fa984b14e51c1660f51d9e1b
380	Rosenberg, M.S.	Contextual cross-referencing of species names for fiddler crabs (genus Uca): An experiment in cyber-taxonomy	10.1371/journal.pone.0101704	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903888707&doi=10.1371%2fjournal.pone.0101704&partnerID=40&md5=4ec0029f1e5e1250d74057efeded7848
381	Billinger, M. and Brunner, C. and Müller-Putz, G.R.	SCoT: A python toolbox for EEG source connectivity	10.3389/fninf.2014.00022	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896924088&doi=10.3389%2ffninf.2014.00022&partnerID=40&md5=ca4fd24e321c184ba4562c5b60a0dcab
382	Bacci, G. and Bazzicalupo, M. and Benedetti, A. and Mengoni, A.	StreamingTrim 1.0: A Java software for dynamic trimming of 16S rRNA sequence data from metagenetic studies	10.1111/1755-0998.12187	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894243154&doi=10.1111%2f1755-0998.12187&partnerID=40&md5=296c000f43c62ef60c1366e6a0a2a38a
383	Rusk, D. and Coady, Y.	Location-based analysis of developers and technologies on GitHub	10.1109/WAINA.2014.110	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904480400&doi=10.1109%2fWAINA.2014.110&partnerID=40&md5=e976cddcd5b449f7fadf917c72e5d6f2
385	Bailey, D.H. and Borwein, J.M. and Kaiser, A.D.	Automated simplification of large symbolic expressions	10.1016/j.jsc.2013.09.001	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888197616&doi=10.1016%2fj.jsc.2013.09.001&partnerID=40&md5=db61f608d1e32bf86136cf0c75856d0b
386	Mostafa, S. and Wang, X.	An empirical study on the usage of mocking frameworks in software testing	10.1109/QSIC.2014.19	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912109692&doi=10.1109%2fQSIC.2014.19&partnerID=40&md5=7aa16634d3e1b305994c6a96e99d05c5
387	Padhye, R. and Mukherjee, D. and Sinha, V.S.	API as a social glue	10.1145/2591062.2591115	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903647935&doi=10.1145%2f2591062.2591115&partnerID=40&md5=6e78b05b3270e5948ff0b8c3086eae52
388	Turro, E. and Astle, W.J. and Tavaré, S.	Flexible analysis of RNA-seq data using mixed effects models	10.1093/bioinformatics/btt624	2014		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892702660&doi=10.1093%2fbioinformatics%2fbtt624&partnerID=40&md5=d634563c63a5096766662673cac4163c
389	Krell, M.M. and Straube, S. and Seeland, A. and Wöhrle, H. and Teiwes, J. and Metzen, J.H. and Kirchner, E.A. and Kirchner, F.	PySPACE - A signal processing and classification environment in python	10.3389/fninf.2013.00040	2013		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891553924&doi=10.3389%2ffninf.2013.00040&partnerID=40&md5=e1d801ea9c9c1ae1446def10bf897723
390	Teyton, C. and Falleri, J.-R. and Morandat, F. and Blanc, X.	Find your library experts	10.1109/WCRE.2013.6671295	2013		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893360702&doi=10.1109%2fWCRE.2013.6671295&partnerID=40&md5=8e36ea130fa9089de62385d47ffadae4
391	McDonnell, T. and Ray, B. and Kim, M.	An empirical study of API stability and adoption in the android ecosystem	10.1109/ICSM.2013.18	2013		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891682835&doi=10.1109%2fICSM.2013.18&partnerID=40&md5=230ac52147f4b89010f3c2bd8c417e4d
392	Itaya, H. and Oshita, K. and Arakawa, K. and Tomita, M.	GEMBASSY: An EMBOSS associated software package for comprehensive genome analyses	10.1186/1751-0473-8-17	2013		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883514925&doi=10.1186%2f1751-0473-8-17&partnerID=40&md5=4fd33cdb4cc4df18893ca086bf8f9ada
393	Collet, P. and Lahire, P.	Feature modeling and separation of concerns with FAMILIAR	10.1109/CMA-RE.2013.6664179	2013		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892583365&doi=10.1109%2fCMA-RE.2013.6664179&partnerID=40&md5=546241a7c36bd4fecff0f834ace7491c
394	Regedor, M. and da Cruz, D. and Henriques, P.	The role of best practices to Appraise open source software	10.14279/tuj.eceasst.48.799.817	2012		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043292355&doi=10.14279%2ftuj.eceasst.48.799.817&partnerID=40&md5=8e1e0efeaaf5bdb320f626d9188aae7c
\.


--
-- Data for Name: scopus_manual; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.scopus_manual (id, author, title, doi, year, abstract, url) FROM stdin;
2	Grichi, M. and Guéhéneuc, Y.-G. and Abidi, M. and Khomh, F.	State of practices of java native interface		2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087419066&partnerID=40&md5=37069b0f3a4ae4e70ebf87c386514467
3	Abdelaziz, I. and Srinivas, K. and Dolby, J. and McCusker, J.P.	A demonstration of codebreaker: A machine interpretable knowledge graph for code		2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096233087&partnerID=40&md5=216847069b28a16550f0d40c42e37979
5	Legay, D. and Decan, A. and Mens, T.	On the usage of badges in open source packages on GitHub		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089901592&partnerID=40&md5=592cfca20a6900752cfa70a92371d02e
7	Liu, H. and Han, Z. and Liu, Y.-S. and Gu, M.	Fast low-rank metric learning for large-scale and high-dimensional data		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090173303&partnerID=40&md5=29650e18c731b80e20f565a63d7e6490
8	Kim, Y.W. and Consens, M.P. and Hartig, O.	An empirical analysis of GraphQL API schemas in open code repositories and package registries		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066978177&partnerID=40&md5=93a82b208b3137e56012703227cafa3f
9	Luo, P. and Ren, J. and Peng, Z. and Zhang, R. and Li, J.	Differentiable learning-to-normalize via switchable normalization		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954533&partnerID=40&md5=52cdc018a15f0103e2162d3a18a5ebeb
11	Fan, Q. and Chen, C.-F. and Kuehne, H. and Pistoia, M. and Cox, D.	More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088876874&partnerID=40&md5=bfa70d0301052548ba334208dac815f7
12	Khashabi, D. and Sammons, M. and Zhou, B. and Redman, T. and Christodoulopoulos, C. and Srikumar, V. and Rizzolo, N. and Luo, L.R.G. and Do, Q. and Tsai, C.-T. and Roy, S. and Mayhew, S. and Feng, Z. and Wieting, J. and Yu, X. and Song, Y. and Gupta, S. and Upadhyay, S. and Arivazhagan, N. and Ning, Q. and Ling, S. and Roth, D.	CogcompnLP: Your Swiss army knife for NLP		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059881208&partnerID=40&md5=3f0eb4e7000f15d47ceb7069509f21bb
13	Wu, C. and Miller, J. and Chang, Y. and Sznaier, M. and Dy, J.	Solving interpretable kernel dimension reduction		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090175310&partnerID=40&md5=182e2e3fbd09f7c03f1342d0a754dc3f
14	Li, H. and Szum, C. and Lisauskas, S. and Bekhit, A. and Nesler, C. and Snyder, S.C.	Targeting building energy efficiency opportunities: An Open-source Analytical &amp; Benchmarking Tool		2019		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071939979&partnerID=40&md5=c15331ebd8c38a5fb0976030571eb521
17	Pedersoli, F. and Tzanetakis, G. and Tagliasacchi, A.	Espresso: Efficient forward propagation for binary deep neural networks		2018		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951336&partnerID=40&md5=a4ab7aa506219d7d3fe8074c6e663bea
20	Wilkerson, S.A. and Forsyth, J. and Korpela, C.M.	Project based learning using the robotic Operating System (ROS) for undergraduate research applications		2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030551439&partnerID=40&md5=75b64d5b362084bb54a580901aa00d00
22	Lemaître, G. and Nogueira, F. and Aridas, C.K.	Imbalanced-learn: A python toolbox to tackle the curse of imbalanced datasets in machine learning		2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016274615&partnerID=40&md5=dd32549cc0b9c2cd01c342fff0468b7b
23	Defferrard, M. and Benzi, K. and Vandergheynst, P. and Bresson, X.	FMA: A dataset for music analysis		2017		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068955365&partnerID=40&md5=52ec35cfef56f2b0a0851dd8d52c1502
25	Wang, S.-M. and Ku, L.-W.	ANTUSD: A large Chinese sentiment dictionary		2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027864979&partnerID=40&md5=d301422d69fcda6729833e0780272e0a
26	Pajkossy, K. and Zseder, A.	The hunvec framework for NN-CRF-based sequential tagging		2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037172480&partnerID=40&md5=b9f9a014d86dff83ec8bc4c270d56f1c
27	Blfgeh, A. and Warrender, J.D. and Hilkens, C.M.U. and Lord, P.	A document-centric approach for developing the tolAPC Ontology		2016		https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992323947&partnerID=40&md5=ed03bed2969be7406895b8f8958805b0
\.


--
-- Data for Name: selection_1; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.selection_1 (id, author, title, doi, year, abstract, url) FROM stdin;
1	Longo, Justin and Kelley, Tanya M.	Use of GitHub as a Platform for Open Collaboration on Text Documents	10.1145/2788993.2789838	2015	Recently, researchers are paying attention to the use of the software development and code-hosting web service GitHub for other collaborative purposes, including a class of activity referred to as document, text, or prose collaboration. These alternative uses of GitHub as a platform for sharing non-code artifacts represent an important modification in the practice of open collaboration. We survey cases where GitHub has been used to facilitate collaboration on non-code outputs, identify its strengths and weaknesses when used in this mode, and propose conditions for successful collaborations on co-created text documents.	https://doi.org/10.1145/2788993.2789838
2	Feliciano, Joseph and Storey, Margaret-Anne and Zagalsky, Alexey	Student Experiences Using GitHub in Software Engineering Courses: A Case Study	10.1145/2889160.2889195	2016	GitHub has been embraced by the software development community as an important social platform for managing software projects and to support collaborative development. More recently, educators have begun to adopt it for hosting course content and student assignments. From our previous research, we found that educators leverage GitHub's collaboration and transparency features to create, reuse and remix course materials, and to encourage student contributions and monitor student activity on assignments and projects. However, our previous research did not consider the student perspective.In this paper, we present a case study where GitHub is used as a learning platform for two software engineering courses. We gathered student perspectives on how the use of GitHub in their courses might benefit them and to identify the challenges they may face. The findings from our case study indicate that software engineering students do benefit from GitHub's transparent and open workflow. However, students were concerned that since GitHub is not inherently an educational tool, it lacks key features important for education and poses learning and privacy concerns. Our findings provide recommendations for designers on how tools such as GitHub can be used to improve software engineering education, and also point to recommendations for instructors on how to use it more effectively in their courses.	https://doi.org/10.1145/2889160.2889195
3	Neto, Casimiro Conde Marco and de O. Barros, M\\'arcio	A Structured Survey on the Usage of the Issue Tracking System Provided by the GitHub Platform	10.1145/3132498.3134110	2017	Issue tracking systems help software development teams in identifying problems to be solved and new features to be added to a software system. In this paper, we replicate and extend a study carried out in 2013 on the usage of the issue tracking system provided by the GitHub platform. The replication aims at determining whether the results observed four years ago are still valid. The extension seeks to analyze how often issues are terminated by commits to the version control system and understand whether this feature allows developers to relate an issue to the source code modules that were changed to resolve it. We conclude that the results of the previous study remain valid and that issues closed by commits are uncommon (about 4% of our sample) and often linked to technical aspects of the project.	https://doi.org/10.1145/3132498.3134110
4	Zhang, Yang and Wang, Huaimin and Yin, Gang and Wang, Tao and Yu, Yue	Exploring the Use of @-Mention to Assist Software Development in GitHub	10.1145/2875913.2875914	2015	Recently, many researches propose that social media tools can promote the collaboration among developers, which are beneficial to the software development. Nevertheless, there is little empirical evidence to confirm that using @-mention has indeed a beneficial impact on the issues in GitHub. In this paper, we analyze the data from GitHub and give some insights on how @-mention is used in the issues (general-issues and pull-requests). Our statistical results indicate that, @-mention attracts more participants and tends to be used in the difficult issues. @-mention favors the solving process of issues by enlarging the visibility of issues and facilitating the developers' collaboration. In addition to this global study, our study also build a @-network based on the @-mention database we extract. Through the @-network, we can mine the relationships and characteristics of developers in GitHub's issues.	https://doi.org/10.1145/2875913.2875914
10	Borges, Hudson and Brito, Rodrigo and Valente, Marco Tulio	Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions	10.1145/3350768.3350788	2019	Recently, GitHub introduced a new social feature, named reactions, which are "pictorial characters" similar to emoji symbols widely used nowadays in text-based communications. Particularly, GitHub users can use a pre-defined set of such symbols to react to issues and pull requests. However, little is known about the real usage and impact of GitHub reactions. In this paper, we analyze the reactions provided by developers to more than 2.5 million issues and 9.7 million issue comments, in order to answer an extensive list of nine research questions about the usage and adoption of reactions. We show that reactions are being increasingly used by open source developers. Moreover, we also found that issues with reactions usually take more time to be handled and have longer discussions.	https://doi.org/10.1145/3350768.3350788
11	Glassey, Richard	Managing Assignment Feedback via Issue Tracking	10.1145/3197091.3205819	2018	This poster provides insight into the use of an issue tracker for the management of assignment feedback within an introductory course in computer science (CS). Students have made use of Github for three successive years, and the issue tracker has become one of the key mechanisms for managing formative feedback. This approach has yielded three key benefits: increased student engagement in their own feedback; provided an early experience of an authentic and industry desirable communication skill; and created a means to oversee and learn from feedback discussions for the teaching team.	https://doi.org/10.1145/3197091.3205819
12	K\\"afer, Verena and Graziotin, Daniel and Bogicevic, Ivan and Wagner, Stefan and Ramadani, Jasmin	Communication in Open-Source Projects-End of the e-Mail Era?	10.1145/3183440.3194951	2018	Communication is essential in software engineering. Especially in distributed open-source teams, communication needs to be supported by channels including mailing lists, forums, issue trackers, and chat systems. Yet, we do not have a clear understanding of which communication channels stakeholders in open-source projects use. In this study, we fill the knowledge gap by investigating a statistically representative sample of 400 GitHub projects. We discover the used communication channels by regular expressions on project data. We show that (1) half of the GitHub projects use observable communication channels; (2) GitHub Issues, e-mail addresses, and the modern chat system Gitter are the most common channels; (3) mailing lists are only in place five and have a lower market share than all modern chat systems combined.	https://doi.org/10.1145/3183440.3194951
13	Rahman, Mohammad Masudur and Roy, Chanchal K.	An Insight into the Pull Requests of GitHub	10.1145/2597073.2597121	2014	Given the increasing number of unsuccessful pull requests in GitHub projects, insights into the success and failure of these requests are essential for the developers. In this paper, we provide a comparative study between successful and unsuccessful pull requests made to 78 GitHub base projects by 20,142 developers from 103,192 forked projects. In the study, we analyze pull request discussion texts, project specific information (e.g., domain, maturity), and developer specific information (e.g., experience) in order to report useful insights, and use them to contrast between successful and unsuccessful pull requests. We believe our study will help developers overcome the issues with pull requests in GitHub, and project administrators with informed decision making. 	https://doi.org/10.1145/2597073.2597121
15	Bentley, Carmen A. and Gehringer, Edward F.	Promoting Collaborative Skills with Github Project Boards	10.1145/3328778.3372646	2020	Teamwork skills are much in demand in the workplace, even more so with the growth of Agile methods. This calls for giving Computer Science students more practice in the kinds of team scenarios they will encounter on the job. Key for success are hands-on experience with planning methods, prioritization techniques, time management and organization. This poster shows how the cooperative tracking tool Github Project Boards helps teams strategize development, track progress, distribute work evenly, and facilitate collaboration. It also shows how instructors can use Github Project Boards to visualize and evaluate a team's development process.	https://doi.org/10.1145/3328778.3372646
22	Bhattacharjee, Avijit and Nath, Sristy Sumana and Zhou, Shurui and Chakroborti, Debasish and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin	An Exploratory Study to Find Motives Behind Cross-Platform Forks from Software Heritage Dataset	10.1145/3379597.3387512	2020	The fork-based development mechanism provides the flexibility and the unified processes for software teams to collaborate easily in a distributed setting without too much coordination overhead. Currently, multiple social coding platforms support fork-based development, such as GitHub, GitLab, and Bitbucket. Although these different platforms virtually share the same features, they have different emphasis. As GitHub is the most popular platform and the corresponding data is publicly available, most of the current studies are focusing on GitHub hosted projects. However, we observed anecdote evidences that people are confused about choosing among these platforms, and some projects are migrating from one platform to another, and the reasons behind these activities remain unknown. With the advances of Software Heritage Graph Dataset (SWHGD), we have the opportunity to investigate the forking activities across platforms. In this paper, we conduct an exploratory study on 10 popular open-source projects to identify cross-platform forks and investigate the motivation behind. Preliminary result shows that cross-platform forks do exist. For the 10 subject systems used in this study, we found 81,357 forks in total among which 179 forks are on GitLab. Based on our qualitative analysis, we found that most of the cross-platform forks that we identified are mirrors of the repositories on another platform, but we still find cases that were created due to preference of using certain functionalities (e.g. Continuous Integration (CI)) supported by different platforms. This study lays the foundation of future research directions, such as understanding the differences between platforms and supporting cross-platform collaboration.	https://doi.org/10.1145/3379597.3387512
23	Brown, Chris and Parnin, Chris	Understanding the Impact of GitHub Suggested Changes on Recommendations between Developers	10.1145/3368089.3409722	2020	Recommendations between colleagues are effective for encouraging developers to adopt better practices. Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks. However, in-person recommendations between developers in the workplace are declining. One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions. GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests. To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception. Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests. This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.	https://doi.org/10.1145/3368089.3409722
25	Kikas, Riivo and Dumas, Marlon and Pfahl, Dietmar	Issue Dynamics in Github Projects	10.1007/978-3-319-26844-6_22	2015	Issue repositories are used to keep of track of bugs, development tasks and feature requests in software development projects. In the case of open source projects, everyone can submit a new issue in the tracker. This practice can lead to situations where more issues are created than what can be effectively handled by the project members, raising the question of how issues are treated as the capacity of the project members is exceeded. In this paper, we study the temporal dynamics of issues in a popular open source development platform, namely Github, based on a sample of 4000 projects. We specifically analyze how the rate of issue creation, the amount of pending issues, and their average lifetime evolve over the course of time. The results show that more issues are opened shortly after the creation of a project repository and that the amount of pending issues increases inexorably due to forgotten unclosed issues. Yet, the average issue lifetime for issues that do get closed is relatively stable over time. These observations suggest that Github projects have implicit mechanisms for handling issues perceived to be important to the project, while neglecting those that exceed the project's capacity.	https://doi.org/10.1007/978-3-319-26844-6_22
26	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	What the Fork: A Study of Inefficient and Efficient Forking Practices in Social Coding	10.1145/3338906.3338918	2019	Forking and pull requests have been widely used in open-source communities as a uniform development and contribution mechanism, giving developers the flexibility to modify their own fork without affecting others before attempting to contribute back. However, not all projects use forks efficiently; many experience lost and duplicate contributions and fragmented communities. In this paper, we explore how open-source projects on GitHub differ with regard to forking inefficiencies. First, we observed that different communities experience these inefficiencies to widely different degrees and interviewed practitioners to understand why. Then, using multiple regression modeling, we analyzed which context factors correlate with fewer inefficiencies.We found that better modularity and centralized management are associated with more contributions and a higher fraction of accepted pull requests, suggesting specific best practices that project maintainers can adopt to reduce forking-related inefficiencies in their communities.	https://doi.org/10.1145/3338906.3338918
28	Stanciulescu, Stefan and Schulze, Sandro and Wasowski, Andrzej	Forked and Integrated Variants in an Open-Source Firmware Project	10.1109/ICSM.2015.7332461	2015	Code cloning has been reported both on small (code fragments) and large (entire projects) scale. Cloning-in-the-large, or forking, is gaining ground as a reuse mechanism thanks to availability of better tools for maintaining forked project variants, hereunder distributed version control systems and interactive source management platforms such as Github. We study advantages and disadvantages of forking using the case of Marlin, an open source firmware for 3D printers. We find that many problems and advantages of cloning do translate to forking. Interestingly, the Marlin community uses both forking and integrated variability management (conditional compilation) to create variants and features. Thus, studying it increases our understanding of the choice between integrated and clone-based variant management. It also allows us to observe mechanisms governing source code maturation, in particular when, why and how feature implementations are migrated from forks to the main integrated platform. We believe that this understanding will ultimately help development of tools mixing clone-based and integrated variant management, combining the advantages of both.	https://doi.org/10.1109/ICSM.2015.7332461
32	Pietri, Antoine and Rousseau, Guillaume and Zacchiroli, Stefano	Forking Without Clicking: On How to Identify Software Repository Forks	10.1145/3379597.3387450	2020	The notion of software "fork" has been shifting over time from the (negative) phenomenon of community disagreements that result in the creation of separate development lines and ultimately software products, to the (positive) practice of using distributed version control system (VCS) repositories to collaboratively improve a single product without stepping on each others toes. In both cases the VCS repositories participating in a fork share parts of a common development history.Studies of software forks generally rely on hosting platform metadata, such as GitHub, as the source of truth for what constitutes a fork. These "forge forks" however can only identify as forks repositories that have been created on the platform, e.g., by clicking a "fork" button on the platform user interface. The increased diversity in code hosting platforms (e.g., GitLab) and the habits of significant development communities (e.g., the Linux kernel, which is not primarily hosted on any single platform) call into question the reliability of trusting code hosting platforms to identify forks. Doing so might introduce selection and methodological biases in empirical studies.In this article we explore various definitions of "software forks", trying to capture forking workflows that exist in the real world. We quantify the differences in how many repositories would be identified as forks on GitHub according to the various definitions, confirming that a significant number could be overlooked by only considering forge forks. We study the structure and size of fork networks, observing how they are affected by the proposed definitions and discuss the potential impact on empirical research.	https://doi.org/10.1145/3379597.3387450
33	Ford, Denae and Behroozi, Mahnaz and Serebrenik, Alexander and Parnin, Chris	Beyond the Code Itself: How Programmers <i>Really</i> Look at Pull Requests	10.1109/ICSE-SEIS.2019.17	2019	Developers in open source projects must make decisions on contributions from other community members, such as whether or not to accept a pull request. However, secondary factors---beyond the code itself---can influence those decisions. For example, signals from GitHub profiles, such as a number of followers, activity, names, or gender can also be considered when developers make decisions. In this paper, we examine how developers use these signals (or not) when making decisions about code contributions. To evaluate this question, we evaluate how signals related to perceived gender identity and code quality influenced decisions on accepting pull requests. Unlike previous work, we analyze this decision process with data collected from an eye-tracker. We analyzed differences in what signals developers said are important for themselves versus what signals they actually used to make decisions about others. We found that after the code snippet (x = 57%), the second place programmers spent their time ixating is on supplemental technical signals (x = 32%), such as previous contributions and popular repositories. Diverging from what participants reported themselves, we also found that programmers ixated on social signals more than recalled.	https://doi.org/10.1109/ICSE-SEIS.2019.17
67	Jiang, J., Lo, D., He, J., Xia, X., Kochhar, P.S., Zhang, L.	Why and how developers fork what from whom in GitHub	10.1007/s10664-016-9436-6	2017		https://doi.org/10.1007/s10664-016-9436-6
43	Sheoran, Jyoti and Blincoe, Kelly and Kalliamvakou, Eirini and Damian, Daniela and Ell, Jordan	Understanding "Watchers" on GitHub	10.1145/2597073.2597114	2014	Users on GitHub can watch repositories to receive notifications about project activity. This introduces a new type of passive project membership. In this paper, we investigate the behavior of watchers and their contribution to the projects they watch. We find that a subset of project watchers begin contributing to the project and those contributors account for a significant percentage of contributors on the project. As contributors, watchers are more confident and contribute over a longer period of time in a more varied way than other contributors. This is likely attributable to the knowledge gained through project notifications. 	https://doi.org/10.1145/2597073.2597114
44	Destefanis, Giuseppe and Ortu, Marco and Bowes, David and Marchesi, Michele and Tonelli, Roberto	On Measuring Affects of Github Issues' Commenters	10.1145/3194932.3194936	2018	In this study, we analyzed issues and comments on GitHub projects and built collaboration networks dividing contributors into two categories: users and commenters. We identified as commenters those users who only post comments without posting any issues nor committing changes in the source code. Since previous studies showed that there is a link between a positive environment (regarding affectiveness) and productivity, our goal was to investigate commenters' contribution to the project concerning affectiveness.We analyzed more than 370K comments from 100K issues of 25K contributors from 3 open source projects. We then calculated and compared the affectiveness of the issues' comments written by users and commenters in terms of sentiment, politeness, and emotions. We provide empirical evidence that commenters are less polite, less positive and in general they express a lower level of emotions in their comments than users. Our results also confirm that GitHub's contributors consist of different groups which behave differently, and this provides useful information for future studies in the field.	https://doi.org/10.1145/3194932.3194936
46	Tan, Xin and Zhou, Minghui and Sun, Zeyu	A First Look at Good First Issues on GitHub	10.1145/3368089.3409746	2020	Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time. To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers. However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain. To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices. By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results. We find that more and more projects are applying this mechanism in the past decade, especially the popular projects. Compared to common issues, GFIs usually need more days to be solved. While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers. We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective. We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc. Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.	https://doi.org/10.1145/3368089.3409746
51	Tsay, Jason and Dabbish, Laura and Herbsleb, James	Let's Talk about It: Evaluating Contributions through Discussion in GitHub	10.1145/2635868.2635882	2014	Open source software projects often rely on code contributions from a wide variety of developers to extend the capabilities of their software. Project members evaluate these contributions and often engage in extended discussions to decide whether to integrate changes. These discussions have important implications for project management regarding new contributors and evolution of project requirements and direction. We present a study of how developers in open work environments evaluate and discuss pull requests, a primary method of contribution in GitHub, analyzing a sample of extended discussions around pull requests and interviews with GitHub developers. We found that developers raised issues around contributions over both the appropriateness of the problem that the submitter attempted to solve and the correctness of the implemented solution. Both core project members and third-party stakeholders discussed and sometimes implemented alternative solutions to address these issues. Different stakeholders also influenced the outcome of the evaluation by eliciting support from different communities such as dependent projects or even companies. We also found that evaluation outcomes may be more complex than simply acceptance or rejection. In some cases, although a submitter's contribution was rejected, the core team fulfilled the submitter's technical goals by implementing an alternative solution. We found that the level of a submitter's prior interaction on a project changed how politely developers discussed the contribution and the nature of proposed alternative solutions. 	https://doi.org/10.1145/2635868.2635882
53	Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	Investigating Social Media in GitHub's Pull-Requests: A Case Study on Ruby on Rails	10.1145/2666539.2666572	2014	In GitHub, pull-request mechanism is an outstanding social development method by integrating with many social media. Many studies have explored that social media has an important effect on software development. @-mention as a typical social media, is a useful tool in social platform. In this paper, we made a quantitative analysis of @-mention in pull-requests of the project Ruby on Rails. First, we make a convictive statistics of the popularity of pull-request mechanism in GitHub. Then we investigate the current situation of @-mention in the Ruby on Rails. Our empirical analysis results find some insights of @-mention. 	https://doi.org/10.1145/2666539.2666572
55	Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin	A Exploratory Study of @-Mention in GitHub's Pull-Requests	10.1109/APSEC.2014.58	2014	Pull-request mechanism is an outstanding social development method in Git Hub. @-mention is a social media tool that deeply integrated with pull-request mechanism. Recently, many research results show that social media tools can promote the collaborative software development, but few work focuses on the impacts of @-mention. In this paper, we conduct an exploratory study of @-mention in pull-request based software development, including its current situation and benefits. We obtain some interesting findings which indicate that @-mention is beneficial to the processing of pull-request. Our work also proposes some possible research directions and problems of the @-mention. It helps the developers and researchers notice the significance of @-mention in the pull-request based software development.	https://doi.org/10.1109/APSEC.2014.58
59	Zhou, Shurui and Vasilescu, Bogdan and K\\"astner, Christian	How Has Forking Changed in the Last 20 Years? A Study of Hard Forks on GitHub	10.1145/3377811.3380412	2020	The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub. Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks. To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories. We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project.	https://doi.org/10.1145/3377811.3380412
66	Yang Zhang and	Social media in GitHub: the role of @-mention in assisting software	10.1007/s11432-015-1024-6	2017		https://doi.org/10.1007/s11432-015-1024-6
69	Jiang, J. and Wu, Q. and Cao, J. and Xia, X. and Zhang, L.	Recommending tags for pull requests in GitHub	10.1016/j.infsof.2020.106394	2021		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092068193&doi=10.1016%2fj.infsof.2020.106394&partnerID=40&md5=4ee8a71e5e67bc61a40e84464506400e
70	Utomo, P. and Falahah	Building Serverless Website on GitHub Pages	10.1088/1757-899X/879/1/012077	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091346359&doi=10.1088%2f1757-899X%2f879%2f1%2f012077&partnerID=40&md5=a42a4e51229c007d6a3f1d1c6a969772
71	Zhang, Y. and Wang, H. and Wu, Y. and Hu, D. and Wang, T.	GitHub's milestone tool: A mixed-methods analysis on its use	10.1002/smr.2229	2020		https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075388288&doi=10.1002%2fsmr.2229&partnerID=40&md5=491143dfea220852a144e812cc022ee9
84	Wang, W., Poo-Caamaño, G., Wilde, E., German, D.M.	What is the GIST? Understanding the use of public gists on GitHub	10.1109/MSR.2015.36	2015	GitHub is a popular source code hosting site which serves as a collaborative coding platform. The many features of GitHub have greatly facilitated developers' collaboration, communication, and coordination. Gists are one feature of GitHub, which defines them as 'a simple way to share snippets and pastes with others.' This three-part study explores how users are using Gists. The first part is a quantitative analysis of Gist metadata and contents. The second part investigates the information contained in a Gist: We sampled 750k users and their Gists (totalling 762k Gists), then manually categorized the contents of 398. The third part of the study investigates what users are saying Gists are for by reading the contents of web pages and twitter feeds. The results indicate that Gists are used by a small portion of GitHub users, and those that use them typically only have a few. We found that Gists are usually small and composed of a single file. However, Gists serve a wide variety of uses, from saving snippets of code, to creating reusable components for web pages. © 2015 IEEE.	https://ieeexplore.ieee.org/document/7180090
\.


--
-- Data for Name: snowballing; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.snowballing (id, author, title, doi, year, abstract, url) FROM stdin;
1	Alexey Zagalsky, Joseph Feliciano, Margaret-Anne Storey, Yiyun Zhao, Weiliang Wang	The Emergence of GitHub as a Collaborative Platform forEducation	10.1145/2675133.2675284	2015	The software development community has embraced GitHubas an essential platform for managing their software projects.GitHub has created efficiencies and helped improve the waysoftware professionals work. It not only provides a traceableproject  repository,  but  it  acts  as  a  social  meeting  place  forinterested parties,  supporting communities of practice.   Re-cently, educators have seen the potential in GitHub’s collab-orative features for managing and improving—perhaps eventransforming—the learning experience.In this study, we examine how GitHub is emerging as a col-laborative platform for education. We aim to understand howenvironments such as GitHub—environments that provide so-cial and collaborative features in conjunction with distributedversion control—may improve (or possibly hinder) the edu-cational  experience  for  students  and  teachers.   We  conducta  qualitative  study  focusing  on  how  GitHub  is  being  usedin education, and the motivations, benefits and challenges itbrings.	http://dx.doi.org/10.1145/2675133.2675284
2	T. F. Bissyandé, D. Lo, L. Jiang, L. Réveillère, J. Klein and Y. L. Traon	Got issues? Who cares about it? A large scale investigation of issue trackers from GitHub	10.1109/ISSRE.2013.6698918	2013	Feedback from software users constitutes a vital part in the evolution of software projects. By filing issue reports, users help identify and fix bugs, document software code, and enhance the software via feature requests. Many studies have explored issue reports, proposed approaches to enable the submission of higher-quality reports, and presented techniques to sort, categorize and leverage issues for software engineering needs. Who, however, cares about filing issues? What kind of issues are reported in issue trackers? What kind of correlation exist between issue reporting and the success of software projects? In this study, we address the need for answering such questions by performing an empirical study on a hundred thousands of open source projects. After filtering relevant trackers, the study used about 20,000 projects. We investigate and answer various research questions on the popularity and impact of issue trackers.	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6698918&isnumber=6698873
3	Miroslav Tushev, Grant Williams & Anas Mahmoud	Using GitHub in large software engineering classes. An exploratory case study	10.1080/08993408.2019.1696168	2020	Background and Context: GitHub has been recently used in Software Engineering (SE) classes to facilitate collaboration in student team projects as well as help teachers to evaluate the contributions of their students more objectively. Objective: We explore the benefits and drawbacks of using GitHub as a means for team collaboration and performance evaluation in large SE classes. Method: Our research method takes the form of a case study conducted in a senior level SE class with 91 students. Our study also includes entry and exit surveys, an exit interview, and a qualitative analysis of students’ commit behavior. Findings: Different teams adapt GitHub to their workflow differently. Furthermore, despite the steep learning curve, using GitHub should not affect the quality of students’ submissions. However, using GitHub metrics as a proxy for evaluating team performance can be risky. Implications: We provide several recommendations for integrating Web-based configuration management tools in SE classes. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.	https://doi.org/10.1080/08993408.2019.1696168
4	Jordi Cabot, Javier Luis C ́anovas Izquierdo, Valerio Cosentino, Bel ́en Rolandi	Exploring the use of labels to categorize issues in Open-Source Software projects	10.1109/SANER.2015.7081875	2015	Reporting bugs, asking for new features and in general giving any kind of feedback is a common way to contribute to an Open-Source Software (OSS) project. This feedback is generally reported in the form of new issues for the project, managed by the so-called issue-trackers. One of the features provided by most issue-trackers is the possibility to define a set of labels/tags to classify the issues and, at least in theory, facilitate their management. Nevertheless, there is little empirical evidence to confirm that taking the time to categorize new issues has indeed a beneficial impact on the project evolution. In this paper we analyze a population of more than three million of GitHub projects and give some insights on how labels are used in them. Our preliminary results reveal that, even if the label mechanism is scarcely used, using labels favors the resolution of issues. Our analysis also suggests that not all projects use labels in the same way (e.g., for some labels are only a way to prioritize the project while others use them to signal their temporal evolution as they move along in the development workflow). Further research is needed to precisely characterize these label families and learn more the ideal application scenarios for each of them. © 2015 IEEE.	https://ieeexplore.ieee.org/document/7081875
6	Gousios, Georgios and Pinzger, Martin and Deursen, Arie van	An exploratory study of the pull-based software development model	10.1145/2568225.2568260	2014	The advent of distributed version control systems has led to the development of a new paradigm for distributed software development; instead of pushing changes to a central repository, developers pull them from other repositories and merge them locally. Various code hosting sites, notably Github, have tapped on the opportunity to facilitate pull-based development by offering workflow support tools, such as code reviewing systems and integrated issue trackers. In this work, we explore how pull-based software development works, first on the GHTorrent corpus and then on a carefully selected sample of 291 projects. We find that the pull request model offers fast turnaround, increased opportunities for community engagement and decreased time to incorporate contributions. We show that a relatively small number of factors affect both the decision to merge a pull request and the time to process it. We also examine the reasons for pull request rejection and find that technical ones are only a small minority. © 2014 ACM.	https://doi.org/10.1145/2568225.2568260
10	 Kavaler, D., Devanbu, P., Filkov, V.	Whom are you going to call? determinants of @-mentions in Github discussions	10.1007/s10664-019-09728-3	2019	Open Source Software (OSS) project success relies on crowd contributions. When an issue arises in pull-request based systems, @-mentions are used to call on people to task; previous studies have shown that @-mentions in discussions are associated with faster issue resolution. In most projects there may be many developers who could technically handle a variety of tasks. But OSS supports dynamic teams distributed across a wide variety of social and geographic backgrounds, as well as levels of involvement. It is, then, important to know whom to call on, i.e., who can be relied or trusted with important task-related duties, and why. In this paper, we sought to understand which observable socio-technical attributes of developers can be used to build good models of them being future @-mentioned in GitHub issues and pull request discussions. We built overall and project-specific predictive models of future @-mentions, in order to capture the determinants of @-mentions in each of two hundred GitHub projects, and to understand if and how those determinants differ between projects. We found that visibility, expertise, and productivity are associated with an increase in @-mentions, while responsiveness is not, in the presence of a number of control variables. Also, we find that though project-specific differences exist, the overall model can be used for cross-project prediction, indicating its GitHub-wide utility. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.	https://link.springer.com/article/10.1007%2Fs10664-019-09728-3
13	Borges, H., Tulio Valente, M.	What's in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform	10.1016/j.jss.2018.09.016	2018	Besides a git-based version control system, GitHub integrates several social coding features. Particularly, GitHub users can star a repository, presumably to manifest interest or satisfaction with an open source project. However, the real and practical meaning of starring a project was never the subject of an in-depth and well-founded empirical investigation. Therefore, we provide in this paper a throughout study on the meaning, characteristics, and dynamic growth of GitHub stars. First, by surveying 791 developers, we report that three out of four developers consider the number of stars before using or contributing to a GitHub project. Then, we report a quantitative analysis on the characteristics of the top-5,000 most starred GitHub repositories. We propose four patterns to describe stars growth, which are derived after clustering the time series representing the number of stars of the studied repositories; we also reveal the perception of 115 developers about these growth patterns. To conclude, we provide a list of recommendations to open source project managers (e.g., on the importance of social media promotion) and to GitHub users and Software Engineering researchers (e.g., on the risks faced when selecting projects by GitHub stars). © 2018 Elsevier Inc.	https://www.sciencedirect.com/science/article/abs/pii/S0164121218301961?via%3Dihub
14	Robles, G., González-Barahona, J.M.	A comprehensive study of software forks: Dates, reasons and outcomes	10.1007/978-3-642-33442-9_1	2012	In general it is assumed that a software product evolves within the authoring company or group of developers that develop the project. However, in some cases different groups of developers make the software evolve in different directions, a situation which is commonly known as a fork. In the case of free software, although forking is a practice that is considered as a last resort, it is inherent to the four freedoms. This paper tries to shed some light on the practice of forking. Therefore, we have identified significant forks, several hundreds in total, and have studied them in depth. Among the issues that have been analyzed for each fork is the date when the forking occurred, the reason of the fork, and the outcome of the fork, i.e., if the original or the forking project are still developed. Our investigation shows, among other results, that forks occur in every software domain, that they have become more frequent in recent years, and that very few forks merge with the original project. © 2012 IFIP International Federation for Information Processing.	https://link.springer.com/chapter/10.1007%2F978-3-642-33442-9_1
17	Lisha Li; Zhilei Ren; Xiaochen Li; Weiqin Zou; He Jiang	How Are Issue Units Linked? Empirical Study on the Linking Behavior in GitHub	10.1109/APSEC.2018.00053	2018	Issue reports and Pull Requests (PRs) are two important kinds of artifacts of software projects in GitHub. It is common for developers to leave explicit links in issues/PRs that refer to the other issues/PRs during discussions. Existing studies have demonstrated the value of such links in identifying complex bugs and duplicate issue reports. However, there are no broad examinations of why developers leave links within issues/PRs and the potential impact of such links on software development. Without such knowledge, practitioners and researchers may miss various opportunities to develop practical techniques for better solving bug-fixing or feature implementation related tasks. To fill this gap, we conducted the first empirical study to explore the characteristics of a large number of links within 642,281 issues/PRs of 16,584 popular (>50 stars) Python projects in GitHub. Specifically, we first constructed an Issue Unit Network (IUN, we refer to issue reports or PRs as issue units) by making use of the links between issue units. Then, we manually checked a sample of 1,384 links in the IUN and concluded six major kinds of linking relationships between issue units. For each kind of linking relationships, we presented some common patterns that developers usually adopted while linking issue units. By further analyzing as many as 423,503 links that match these common patterns, we found several interesting findings which indicate potential research directions in the future, including detecting cross-project duplicate issue reports, using IUN to help better identify influential projects and core issue reports.	https://ieeexplore.ieee.org/document/8719531
\.


--
-- Data for Name: snowballing_org; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.snowballing_org (id, author, title, doi, year, abstract, url) FROM stdin;
1	Alexey Zagalsky, Joseph Feliciano, Margaret-Anne Storey, Yiyun Zhao, Weiliang Wang	The Emergence of GitHub as a Collaborative Platform forEducation	10.1145/2675133.2675284	2015	The software development community has embraced GitHubas an essential platform for managing their software projects.GitHub has created efficiencies and helped improve the waysoftware professionals work. It not only provides a traceableproject  repository,  but  it  acts  as  a  social  meeting  place  forinterested parties,  supporting communities of practice.   Re-cently, educators have seen the potential in GitHub’s collab-orative features for managing and improving—perhaps eventransforming—the learning experience.In this study, we examine how GitHub is emerging as a col-laborative platform for education. We aim to understand howenvironments such as GitHub—environments that provide so-cial and collaborative features in conjunction with distributedversion control—may improve (or possibly hinder) the edu-cational  experience  for  students  and  teachers.   We  conducta  qualitative  study  focusing  on  how  GitHub  is  being  usedin education, and the motivations, benefits and challenges itbrings.	http://dx.doi.org/10.1145/2675133.2675284
2	T. F. Bissyandé, D. Lo, L. Jiang, L. Réveillère, J. Klein and Y. L. Traon	Got issues? Who cares about it? A large scale investigation of issue trackers from GitHub	10.1109/ISSRE.2013.6698918	2013	Feedback from software users constitutes a vital part in the evolution of software projects. By filing issue reports, users help identify and fix bugs, document software code, and enhance the software via feature requests. Many studies have explored issue reports, proposed approaches to enable the submission of higher-quality reports, and presented techniques to sort, categorize and leverage issues for software engineering needs. Who, however, cares about filing issues? What kind of issues are reported in issue trackers? What kind of correlation exist between issue reporting and the success of software projects? In this study, we address the need for answering such questions by performing an empirical study on a hundred thousands of open source projects. After filtering relevant trackers, the study used about 20,000 projects. We investigate and answer various research questions on the popularity and impact of issue trackers.	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6698918&isnumber=6698873
3	Miroslav Tushev, Grant Williams & Anas Mahmoud	Using GitHub in large software engineering classes. An exploratory case study	10.1080/08993408.2019.1696168	2020	Background and Context: GitHub has been recently used in Software Engineering (SE) classes to facilitate collaboration in student team projects as well as help teachers to evaluate the contributions of their students more objectively. Objective: We explore the benefits and drawbacks of using GitHub as a means for team collaboration and performance evaluation in large SE classes. Method: Our research method takes the form of a case study conducted in a senior level SE class with 91 students. Our study also includes entry and exit surveys, an exit interview, and a qualitative analysis of students’ commit behavior. Findings: Different teams adapt GitHub to their workflow differently. Furthermore, despite the steep learning curve, using GitHub should not affect the quality of students’ submissions. However, using GitHub metrics as a proxy for evaluating team performance can be risky. Implications: We provide several recommendations for integrating Web-based configuration management tools in SE classes. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.	https://doi.org/10.1080/08993408.2019.1696168
4	Jordi Cabot, Javier Luis C ́anovas Izquierdo, Valerio Cosentino, Bel ́en Rolandi	Exploring the use of labels to categorize issues in Open-Source Software projects	10.1109/SANER.2015.7081875	2015	Reporting bugs, asking for new features and in general giving any kind of feedback is a common way to contribute to an Open-Source Software (OSS) project. This feedback is generally reported in the form of new issues for the project, managed by the so-called issue-trackers. One of the features provided by most issue-trackers is the possibility to define a set of labels/tags to classify the issues and, at least in theory, facilitate their management. Nevertheless, there is little empirical evidence to confirm that taking the time to categorize new issues has indeed a beneficial impact on the project evolution. In this paper we analyze a population of more than three million of GitHub projects and give some insights on how labels are used in them. Our preliminary results reveal that, even if the label mechanism is scarcely used, using labels favors the resolution of issues. Our analysis also suggests that not all projects use labels in the same way (e.g., for some labels are only a way to prioritize the project while others use them to signal their temporal evolution as they move along in the development workflow). Further research is needed to precisely characterize these label families and learn more the ideal application scenarios for each of them. © 2015 IEEE.	https://ieeexplore.ieee.org/document/7081875
5	Lee, Michael J. and Ferwerda, Bruce and Choi, Junghong and Hahn, Jungpil and Moon, Jae Yun and Kim, Jinwoo	GitHub Developers Use Rockstars to Overcome Overflow of News	10.1145/2468356.2468381	2013	Keeping track of a constantly updating stream of news items on social networking enabled software development sites may be difficult. We analyzed the actions of 544 GitHub.com developers working across 5,657 projects to examine how the network of developers and projects influence where developers choose to contribute. Our analyses revealed the existence of a group of extremely well connected developers, or rockstars. We found that these rockstars': 1) actions have a greater influence on their followers compared to regular developers, 2) type of action affect their followers differently, 3) influence on followers may depend on a project's age, 4) increased activity on a project increases activity by followers, and 5) followers use as guides to projects to work on. We discuss the implications of these findings to the design of software development environments.	https://doi.org/10.1145/2468356.2468381
6	Gousios, Georgios and Pinzger, Martin and Deursen, Arie van	An exploratory study of the pull-based software development model	10.1145/2568225.2568260	2014	The advent of distributed version control systems has led to the development of a new paradigm for distributed software development; instead of pushing changes to a central repository, developers pull them from other repositories and merge them locally. Various code hosting sites, notably Github, have tapped on the opportunity to facilitate pull-based development by offering workflow support tools, such as code reviewing systems and integrated issue trackers. In this work, we explore how pull-based software development works, first on the GHTorrent corpus and then on a carefully selected sample of 291 projects. We find that the pull request model offers fast turnaround, increased opportunities for community engagement and decreased time to incorporate contributions. We show that a relatively small number of factors affect both the decision to merge a pull request and the time to process it. We also examine the reasons for pull request rejection and find that technical ones are only a small minority. © 2014 ACM.	https://doi.org/10.1145/2568225.2568260
7	Yang Zhang; Gang Yin; Yue Yu; Huaimin Wang	A Exploratory Study of @-Mention in GitHubs Pull-Requests	 10.1109/APSEC.2014.58	2014	Pull-request mechanism is an outstanding social development method in Git Hub. @-mention is a social media tool that deeply integrated with pull-request mechanism. Recently, many research results show that social media tools can promote the collaborative software development, but few work focuses on the impacts of @-mention. In this paper, we conduct an exploratory study of @-mention in pull-request based software development, including its current situation and benefits. We obtain some interesting findings which indicate that @-mention is beneficial to the processing of pull-request. Our work also proposes some possible research directions and problems of the @-mention. It helps the developers and researchers notice the significance of @-mention in the pull-request based software development.	https://ieeexplore.ieee.org/document/7091329
8	Yang Zhang , Gang Yin , Yue Yu , Huaimin Wang	Investigating social media in GitHubs pull-requests: a case study on Ruby on Rails	10.1145/2666539.2666572	2014	In GitHub, pull-request mechanism is an outstanding social development method by integrating with many social media. Many studies have explored that social media has an important effect on software development. @-mention as a typical social media, is a useful tool in social platform. In this paper, we made a quantitative analysis of @-mention in pull-requests of the project Ruby on Rails. First, we make a convictive statistics of the popularity of pull-request mechanism in GitHub. Then we investigate the current situation of @-mention in the Ruby on Rails. Our empirical analysis results find some insights of @-mention. 	https://doi.org/10.1145/2666539.2666572
9	Yang Zhang, Huaimin Wang, Yiwen Wu, Dongyang Hu, Tao Wang	GitHubs milestone tool: A mixed-methods analysis on its use	10.1002/smr.2229	2020	Social coding site GitHub provides developers with many management tools to facilitate project maintenance and developer collaboration. Milestone tool, in particular, plays an important role in organizing and tracking progress on groups of issues or pull requests in a project. However, few research has analyzed the milestone tool, even though it has been used in practice for a long time. In this paper, we want to address this literature gap and present an ongoing work aimed at investigating the use of the milestone tool in GitHub open-source projects. We conduct a mixed-methods analysis in a large-scale dataset of GitHub projects, to help developers gain some insights into the milestone tool, including its usage, benefits, and limitations. We quantitatively investigate the basic adoption of milestone tool and its correlation with project properties. We also survey developers to understand the reasons for using milestone tool or not and their perceptions of the milestone tool. We find that certain types of projects use milestone tool more than others. Adopting the milestone tool is associated with more commits, more releases, and more project popularity, but the current milestone tool also has some limitations. These observations can then be forwarded to the GitHub community for follow-up and can result in them potentially making a better milestone tool. © 2019 John Wiley & Sons, Ltd.	https://doi.org/10.1002/smr.2229
10	 Kavaler, D., Devanbu, P., Filkov, V.	Whom are you going to call? determinants of @-mentions in Github discussions	10.1007/s10664-019-09728-3	2019	Open Source Software (OSS) project success relies on crowd contributions. When an issue arises in pull-request based systems, @-mentions are used to call on people to task; previous studies have shown that @-mentions in discussions are associated with faster issue resolution. In most projects there may be many developers who could technically handle a variety of tasks. But OSS supports dynamic teams distributed across a wide variety of social and geographic backgrounds, as well as levels of involvement. It is, then, important to know whom to call on, i.e., who can be relied or trusted with important task-related duties, and why. In this paper, we sought to understand which observable socio-technical attributes of developers can be used to build good models of them being future @-mentioned in GitHub issues and pull request discussions. We built overall and project-specific predictive models of future @-mentions, in order to capture the determinants of @-mentions in each of two hundred GitHub projects, and to understand if and how those determinants differ between projects. We found that visibility, expertise, and productivity are associated with an increase in @-mentions, while responsiveness is not, in the presence of a number of control variables. Also, we find that though project-specific differences exist, the overall model can be used for cross-project prediction, indicating its GitHub-wide utility. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.	https://link.springer.com/article/10.1007%2Fs10664-019-09728-3
11	Neto, C.C.M., De Barros, M.O.	A structured survey on the usage of the issue tracking system provided by the GitHub platform	10.1145/3132498.3134110	2017	Issue tracking systems help software development teams in identifying problems to be solved and new features to be added to a software system. In this paper, we replicate and extend a study carried out in 2013 on the usage of the issue tracking system provided by the GitHub platform. The replication aims at determining whether the results observed four years ago are still valid. The extension seeks to analyze how often issues are terminated by commits to the version control system and understand whether this feature allows developers to relate an issue to the source code modules that were changed to resolve it. We conclude that the results of the previous study remain valid and that issues closed by commits are uncommon (about 4% of our sample) and often linked to technical aspects of the project.	https://doi.org/10.1145/3132498.3134110
12	Jiang, J., Lo, D., He, J., Xia, X., Kochhar, P.S., Zhang, L.	Why and how developers fork what from whom in GitHub	10.1007/s10664-016-9436-6	2017		https://doi.org/10.1007/s10664-016-9436-6
13	Borges, H., Tulio Valente, M.	What's in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform	10.1016/j.jss.2018.09.016	2018	Besides a git-based version control system, GitHub integrates several social coding features. Particularly, GitHub users can star a repository, presumably to manifest interest or satisfaction with an open source project. However, the real and practical meaning of starring a project was never the subject of an in-depth and well-founded empirical investigation. Therefore, we provide in this paper a throughout study on the meaning, characteristics, and dynamic growth of GitHub stars. First, by surveying 791 developers, we report that three out of four developers consider the number of stars before using or contributing to a GitHub project. Then, we report a quantitative analysis on the characteristics of the top-5,000 most starred GitHub repositories. We propose four patterns to describe stars growth, which are derived after clustering the time series representing the number of stars of the studied repositories; we also reveal the perception of 115 developers about these growth patterns. To conclude, we provide a list of recommendations to open source project managers (e.g., on the importance of social media promotion) and to GitHub users and Software Engineering researchers (e.g., on the risks faced when selecting projects by GitHub stars). © 2018 Elsevier Inc.	https://www.sciencedirect.com/science/article/abs/pii/S0164121218301961?via%3Dihub
14	Robles, G., González-Barahona, J.M.	A comprehensive study of software forks: Dates, reasons and outcomes	10.1007/978-3-642-33442-9_1	2012	In general it is assumed that a software product evolves within the authoring company or group of developers that develop the project. However, in some cases different groups of developers make the software evolve in different directions, a situation which is commonly known as a fork. In the case of free software, although forking is a practice that is considered as a last resort, it is inherent to the four freedoms. This paper tries to shed some light on the practice of forking. Therefore, we have identified significant forks, several hundreds in total, and have studied them in depth. Among the issues that have been analyzed for each fork is the date when the forking occurred, the reason of the fork, and the outcome of the fork, i.e., if the original or the forking project are still developed. Our investigation shows, among other results, that forks occur in every software domain, that they have become more frequent in recent years, and that very few forks merge with the original project. © 2012 IFIP International Federation for Information Processing.	https://link.springer.com/chapter/10.1007%2F978-3-642-33442-9_1
15	Zhou, S., Vasilescu, B., Kästner, C. 	How has forking changed in the last 20 years? a study of hard forks on github	10.1145/3377812.3390911	2020	The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub.Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks,conducted mostly in pre-GitHub days showed that hard forks wereoften seen critical as they may fragment a community. Today, in social coding environments, open-source developers are encouragedto fork a project in order to contribute to the community (whichwe call social forks), which may have also influenced perceptionsand practices around hard forks. To revisit hard forks, we identify,study, and classify 15,306 hard forks on GitHub and interview 18owners of hard forks or forked repositories. We find that, amongothers, hard forks often evolve out of social forks rather than beingplanned deliberately and that perception about hard forks haveindeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project. © 2020 Copyright held by the owner/author(s).	https://dl.acm.org/doi/10.1145/3377812.3390911
16	Zhou, S., Vasilescu, B., Kästner, C. 	What the fork: A study of inefficient and efficient forking practices in social coding	10.1145/3338906.3338918	2019	Forking and pull requests have been widely used in open-source communities as a uniform development and contribution mechanism, giving developers the flexibility to modify their own fork without affecting others before attempting to contribute back. However, not all projects use forks efficiently; many experience lost and duplicate contributions and fragmented communities. In this paper, we explore how open-source projects on GitHub differ with regard to forking inefficiencies. First, we observed that different communities experience these inefficiencies to widely different degrees and interviewed practitioners to understand why. Then, using multiple regression modeling, we analyzed which context factors correlate with fewer inefficiencies.We found that better modularity and centralized management are associated with more contributions and a higher fraction of accepted pull requests, suggesting specific best practices that project maintainers can adopt to reduce forking-related inefficiencies in their communities. © 2019 ACM.	https://dl.acm.org/doi/10.1145/3338906.3338918
17	Lisha Li; Zhilei Ren; Xiaochen Li; Weiqin Zou; He Jiang	How Are Issue Units Linked? Empirical Study on the Linking Behavior in GitHub	10.1109/APSEC.2018.00053	2018	Issue reports and Pull Requests (PRs) are two important kinds of artifacts of software projects in GitHub. It is common for developers to leave explicit links in issues/PRs that refer to the other issues/PRs during discussions. Existing studies have demonstrated the value of such links in identifying complex bugs and duplicate issue reports. However, there are no broad examinations of why developers leave links within issues/PRs and the potential impact of such links on software development. Without such knowledge, practitioners and researchers may miss various opportunities to develop practical techniques for better solving bug-fixing or feature implementation related tasks. To fill this gap, we conducted the first empirical study to explore the characteristics of a large number of links within 642,281 issues/PRs of 16,584 popular (>50 stars) Python projects in GitHub. Specifically, we first constructed an Issue Unit Network (IUN, we refer to issue reports or PRs as issue units) by making use of the links between issue units. Then, we manually checked a sample of 1,384 links in the IUN and concluded six major kinds of linking relationships between issue units. For each kind of linking relationships, we presented some common patterns that developers usually adopted while linking issue units. By further analyzing as many as 423,503 links that match these common patterns, we found several interesting findings which indicate potential research directions in the future, including detecting cross-project duplicate issue reports, using IUN to help better identify influential projects and core issue reports.	https://ieeexplore.ieee.org/document/8719531
18	Pietri, A., Rousseau, G., Zacchiroli, S.	Forking without Clicking: On How to Identify Software Repository Forks	10.1145/3379597.3387450	2020	The notion of software "fork" has been shifting over time from the (negative) phenomenon of community disagreements that result in the creation of separate development lines and ultimately software products, to the (positive) practice of using distributed version control system (VCS) repositories to collaboratively improve a single product without stepping on each others toes. In both cases the VCS repositories participating in a fork share parts of a common development history.  Studies of software forks generally rely on hosting platform metadata, such as GitHub, as the source of truth for what constitutes a fork. These "forge forks" however can only identify as forks repositories that have been created on the platform, e.g., by clicking a "fork" button on the platform user interface. The increased diversity in code hosting platforms (e.g., GitLab) and the habits of significant development communities (e.g., the Linux kernel, which is not primarily hosted on any single platform) call into question the reliability of trusting code hosting platforms to identify forks. Doing so might introduce selection and methodological biases in empirical studies.  In this article we explore various definitions of "software forks", trying to capture forking workflows that exist in the real world. We quantify the differences in how many repositories would be identified as forks on GitHub according to the various definitions, confirming that a significant number could be overlooked by only considering forge forks. We study the structure and size of fork networks, observing how they are affected by the proposed definitions and discuss the potential impact on empirical research.	https://dl.acm.org/doi/10.1145/3379597.3387450
19	Zhang, Y., Wang, H., Yin, G., Wang, T., Yu, Y. 	Social media in GitHub: the role of @-mention in assisting software development	10.1007/s11432-015-1024-6	2016\r\n	Recently, many researches propose that social media tools can promote the collaboration among developers, which are beneficial to the software development. Nevertheless, there is little empirical evidence to confirm that using @-mention has indeed a beneficial impact on the issues in GitHub. In order to begin investigating such claim, we examine data from two large and successful projects hosted on GitHub, the Ruby on Rails and the AngularJS. By using qualitative and quantitative analysis, we give an in-depth understanding on how @-mention is used in the issues and the role of @-mention in assisting software development. Our statistical results indicate that, @-mention attracts more participants and tends to be used in the difficult issues. @-mention favors the solving process of issues by enlarging the visibility of issues and facilitating the developers’ collaboration. Our study also build an @-network based on the @-mention database we extracted. Through the @-network, we investigate its evolution over time and prove that we certainly have the potential to mine the relationships and characteristics of developers by exploiting the knowledge from the @-network. © 2016, Science China Press and Springer-Verlag Berlin Heidelberg.	https://link.springer.com/article/10.10072/s11432-015-1024-6
20	Zhang, Yang and Wang, Huaimin and Yin, Gang and Wang, Tao and Yu, Yue	Exploring the Use of @-Mention to Assist Software Development in GitHub	10.1145/2875913.2875914	2015	Recently, many researches propose that social media tools can promote the collaboration among developers, which are beneficial to the software development. Nevertheless, there is little empirical evidence to confirm that using @-mention has indeed a beneficial impact on the issues in GitHub. In this paper, we analyze the data from GitHub and give some insights on how @-mention is used in the issues (general-issues and pull-requests). Our statistical results indicate that, @-mention attracts more participants and tends to be used in the difficult issues. @-mention favors the solving process of issues by enlarging the visibility of issues and facilitating the developers' collaboration. In addition to this global study, our study also build a @-network based on the @-mention database we extract. Through the @-network, we can mine the relationships and characteristics of developers in GitHub's issues.	https://doi.org/10.1145/2875913.2875914
21	Wang, W., Poo-Caamaño, G., Wilde, E., German, D.M.	What is the GIST? Understanding the use of public gists on GitHub	10.1109/MSR.2015.36	2015	GitHub is a popular source code hosting site which serves as a collaborative coding platform. The many features of GitHub have greatly facilitated developers' collaboration, communication, and coordination. Gists are one feature of GitHub, which defines them as 'a simple way to share snippets and pastes with others.' This three-part study explores how users are using Gists. The first part is a quantitative analysis of Gist metadata and contents. The second part investigates the information contained in a Gist: We sampled 750k users and their Gists (totalling 762k Gists), then manually categorized the contents of 398. The third part of the study investigates what users are saying Gists are for by reading the contents of web pages and twitter feeds. The results indicate that Gists are used by a small portion of GitHub users, and those that use them typically only have a few. We found that Gists are usually small and composed of a single file. However, Gists serve a wide variety of uses, from saving snippets of code, to creating reusable components for web pages. © 2015 IEEE.	https://ieeexplore.ieee.org/document/7180090
\.


--
-- Name: acm_manual_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.acm_manual_id_seq', 144, true);


--
-- Name: dblp_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.dblp_id_seq', 71, true);


--
-- Name: dblp_manual_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.dblp_manual_id_seq', 5, true);


--
-- Name: final_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.final_id_seq', 38, true);


--
-- Name: scopus_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.scopus_id_seq', 394, true);


--
-- Name: scopus_manual_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.scopus_manual_id_seq', 28, true);


--
-- Name: selection_1_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.selection_1_id_seq', 84, true);


--
-- Name: snowballing_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.snowballing_id_seq', 21, true);


--
-- Name: snowballing_id_seq1; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.snowballing_id_seq1', 21, true);


--
-- Name: tablename_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
--

SELECT pg_catalog.setval('public.tablename_id_seq', 706, true);


--
-- Name: acm_manual acm_manual_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.acm_manual
    ADD CONSTRAINT acm_manual_pkey PRIMARY KEY (id);


--
-- Name: dblp_manual dblp_manual_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.dblp_manual
    ADD CONSTRAINT dblp_manual_pkey PRIMARY KEY (id);


--
-- Name: dblp dblp_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.dblp
    ADD CONSTRAINT dblp_pkey PRIMARY KEY (id);


--
-- Name: final final_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.final
    ADD CONSTRAINT final_pkey PRIMARY KEY (id);


--
-- Name: scopus_manual scopus_manual_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.scopus_manual
    ADD CONSTRAINT scopus_manual_pkey PRIMARY KEY (id);


--
-- Name: scopus scopus_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.scopus
    ADD CONSTRAINT scopus_pkey PRIMARY KEY (id);


--
-- Name: selection_1 selection_1_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.selection_1
    ADD CONSTRAINT selection_1_pkey PRIMARY KEY (id);


--
-- Name: snowballing_org snowballing_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.snowballing_org
    ADD CONSTRAINT snowballing_pkey PRIMARY KEY (id);


--
-- Name: snowballing snowballing_pkey1; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.snowballing
    ADD CONSTRAINT snowballing_pkey1 PRIMARY KEY (id);


--
-- Name: acm tablename_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.acm
    ADD CONSTRAINT tablename_pkey PRIMARY KEY (id);


--
-- PostgreSQL database dump complete
--

