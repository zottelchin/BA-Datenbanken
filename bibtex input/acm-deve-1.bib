@inproceedings{10.1145/3084226.3084287,
author = {Sharma, Abhishek and Thung, Ferdian and Kochhar, Pavneet Singh and Sulistya, Agus and Lo, David},
title = {Cataloging GitHub Repositories},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084287},
doi = {10.1145/3084226.3084287},
abstract = {GitHub is one of the largest and most popular repository hosting service today, having about 14 million users and more than 54 million repositories as of March 2017. This makes it an excellent platform to find projects that developers are interested in exploring. GitHub showcases its most popular projects by cataloging them manually into categories such as DevOps tools, web application frameworks, and game engines. We propose that such cataloging should not be limited only to popular projects. We explore the possibility of developing such cataloging system by automatically extracting functionality descriptive text segments from readme files of GitHub repositories. These descriptions are then input to LDA-GA, a state-of-the-art topic modeling algorithm, to identify categories. Our preliminary experiments demonstrate that additional meaningful categories which complement existing GitHub categories can be inferred. Moreover, for inferred categories that match GitHub categories, our approach can identify additional projects belonging to them. Our experimental results establish a promising direction in realizing automatic cataloging system for GitHub.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {314–319},
numpages = {6},
keywords = {Latent Dirichlet Allocation, Genetic Algorithm, GitHub},
location = {Karlskrona, Sweden},
series = {EASE'17}
}

@inproceedings{10.1145/2597073.2597114,
author = {Sheoran, Jyoti and Blincoe, Kelly and Kalliamvakou, Eirini and Damian, Daniela and Ell, Jordan},
title = {Understanding "Watchers" on GitHub},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597114},
doi = {10.1145/2597073.2597114},
abstract = { Users on GitHub can watch repositories to receive notifications about project activity. This introduces a new type of passive project membership. In this paper, we investigate the behavior of watchers and their contribution to the projects they watch. We find that a subset of project watchers begin contributing to the project and those contributors account for a significant percentage of contributors on the project. As contributors, watchers are more confident and contribute over a longer period of time in a more varied way than other contributors. This is likely attributable to the knowledge gained through project notifications. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {336–339},
numpages = {4},
keywords = {Watchers, Repositories, GitHub, Software Teams},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/2901739.2901776,
author = {Cosentino, Valerio and Luis, Javier and Cabot, Jordi},
title = {Findings from GitHub: Methods, Datasets and Limitations},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2901776},
doi = {10.1145/2901739.2901776},
abstract = {GitHub, one of the most popular social coding platforms, is the platform of reference when mining Open Source repositories to learn from past experiences. In the last years, a number of research papers have been published reporting findings based on data mined from GitHub. As the community continues to deepen in its understanding of software engineering thanks to the analysis performed on this platform, we believe it is worthwhile to reflect how research papers have addressed the task of mining GitHub repositories over the last years. In this regard, we present a meta-analysis of 93 research papers which addresses three main dimensions of those papers: i) the empirical methods employed, ii) the datasets they used and iii) the limitations reported. Results of our meta-analysis show some concerns regarding the dataset collection process and size, the low level of replicability, poor sampling techniques, lack of longitudinal studies and scarce variety of methodologies.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {137–141},
numpages = {5},
keywords = {systematic review, GitHub, meta-analysis},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1145/3385032.3385052,
author = {Dhasade, Akash Balasaheb and Venigalla, Akhila Sri Manasa and Chimalakonda, Sridhar},
title = {Towards Prioritizing GitHub Issues},
year = {2020},
isbn = {9781450375948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385032.3385052},
doi = {10.1145/3385032.3385052},
abstract = {The vast growth in usage of GitHub by developers to host their projects has led to extensive forking and open source contributions. These contributions occur in the form of issues that report bugs or pull requests to either fix bugs or add new features to the project. On the other hand, massive increase in the number of issues reported by developers and users is a major challenge for integrators, as the number of concurrent issues to be handled is much higher than the number of core contributors. While there exists prior work on prioritizing pull requests, in this paper we make an attempt towards prioritizing issues using machine learning techniques. We present the Issue Prioritizer, a tool to prioritize issues based on three criteria: issue lifetime, issue hotness and category of the issue. We see this work as an initial step towards supporting developers to handle large volumes of issues in projects.},
booktitle = {Proceedings of the 13th Innovations in Software Engineering Conference on Formerly Known as India Software Engineering Conference},
articleno = {18},
numpages = {5},
keywords = {GitHub Issues, Dynamic Tracking, Automatic Issue Prioritisation, Multiple Concurrent Issues, Priority Ranking},
location = {Jabalpur, India},
series = {ISEC 2020}
}

@inproceedings{10.1145/2597073.2597126,
author = {Gousios, Georgios and Vasilescu, Bogdan and Serebrenik, Alexander and Zaidman, Andy},
title = {Lean GHTorrent: GitHub Data on Demand},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597126},
doi = {10.1145/2597073.2597126},
abstract = { In recent years, GitHub has become the largest code host in the world, with more than 5M developers collaborating across 10M repositories. Numerous popular open source projects (such as Ruby on Rails, Homebrew, Bootstrap, Django or jQuery) have chosen GitHub as their host and have migrated their code base to it. GitHub offers a tremendous research potential. For instance, it is a flagship for current open source development, a place for developers to showcase their expertise to peers or potential recruiters, and the platform where social coding features or pull requests emerged. However, GitHub data is, to date, largely underexplored. To facilitate studies of GitHub, we have created GHTorrent, a scalable, queriable, offline mirror of the data offered through the GitHub REST API. In this paper we present a novel feature of GHTorrent designed to offer customisable data dumps on demand. The new GHTorrent data-on-demand service offers users the possibility to request via a web form up-to-date GHTorrent data dumps for any collection of GitHub repositories. We hope that by offering customisable GHTorrent data dumps we will not only lower the "barrier for entry" even further for researchers interested in mining GitHub data (thus encourage researchers to intensify their mining efforts), but also enhance the replicability of GitHub studies (since a snapshot of the data on which the results were obtained can now easily accompany each study). },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {384–387},
numpages = {4},
keywords = {GitHub, dataset, data on demand},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3239235.3240501,
author = {Coelho, Jailton and Valente, Marco Tulio and Silva, Luciana L. and Shihab, Emad},
title = {Identifying Unmaintained Projects in Github},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3240501},
doi = {10.1145/3239235.3240501},
abstract = {Background: Open source software has an increasing importance in modern software development. However, there is also a growing concern on the sustainability of such projects, which are usually managed by a small number of developers, frequently working as volunteers. Aims: In this paper, we propose an approach to identify GitHub projects that are not actively maintained. Our goal is to alert users about the risks of using these projects and possibly motivate other developers to assume the maintenance of the projects. Method: We train machine learning models to identify unmaintained or sparsely maintained projects, based on a set of features about project activity (commits, forks, issues, etc). We empirically validate the model with the best performance with the principal developers of 129 GitHub projects. Results: The proposed machine learning approach has a precision of 80%, based on the feedback of real open source developers; and a recall of 96%. We also show that our approach can be used to assess the risks of projects becoming unmaintained. Conclusions: The model proposed in this paper can be used by open source users and developers to identify GitHub projects that are not actively maintained anymore.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {15},
numpages = {10},
keywords = {unmaintained projects, open source software, github},
location = {Oulu, Finland},
series = {ESEM '18}
}

@inproceedings{10.1109/ICSE-C.2017.164,
author = {Gousios, Georgios and Spinellis, Diomidis},
title = {Mining Software Engineering Data from GitHub},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.164},
doi = {10.1109/ICSE-C.2017.164},
abstract = {GitHub is the largest collaborative source code hosting site built on top of the Git version control system. The availability of a comprehensive API has made GitHub a target for many software engineering and online collaboration research efforts. In our work, we have discovered that a) obtaining data from GitHub is not trivial, b) the data may not be suitable for all types of research, and c) improper use can lead to biased results. In this tutorial, we analyze how data from GitHub can be used for large-scale, quantitative research, while avoiding common pitfalls. We use the GHTorrent dataset, a queryable offline mirror of the GitHub API data, to draw examples from and present pitfall avoidance strategies.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {501–502},
numpages = {2},
keywords = {git, empirical software engineering, GitHub, GHTorrent},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1109/SocialCom.2013.35,
author = {Vasilescu, Bogdan and Filkov, Vladimir and Serebrenik, Alexander},
title = {StackOverflow and GitHub: Associations between Software Development and Crowdsourced Knowledge},
year = {2013},
isbn = {9780769551371},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SocialCom.2013.35},
doi = {10.1109/SocialCom.2013.35},
abstract = {Stack Overflow is a popular on-line programming question and answer community providing its participants with rapid access to knowledge and expertise of their peers, especially benefitting coders. Despite the popularity of Stack Overflow, its role in the work cycle of open-source developers is yet to be understood: on the one hand, participation in it has the potential to increase the knowledge of individual developers thus improving and speeding up the development process. On the other hand, participation in Stack Overflow may interrupt the regular working rhythm of the developer, hence also possibly slow down the development process. In this paper we investigate the interplay between Stack Overflow activities and the development process, reflected by code changes committed to the largest social coding repository, GitHub. Our study shows that active GitHub committers ask fewer questions and provide more answers than others. Moreover, we observe that active Stack Overflow askers distribute their work in a less uniform way than developers that do not ask questions. Finally, we show that despite the interruptions incurred, the Stack Overflow activity rate correlates with the code changing activity in GitHub.},
booktitle = {Proceedings of the 2013 International Conference on Social Computing},
pages = {188–195},
numpages = {8},
keywords = {software development, social media, crowdsourced knowledge},
series = {SOCIALCOM '13}
}

@inproceedings{10.5555/2886444.2886490,
author = {Badashian, Ali Sajedi and Shah, Vraj and Stroulia, Eleni},
title = {GitHub's Big Data Adaptor: An Eclipse Plugin},
year = {2015},
publisher = {IBM Corp.},
address = {USA},
abstract = {The data of GitHub, the most popular code-sharing platform, fits the characteristics of "big data" (Volume, Variety and Velocity). To facilitate studies on this huge GitHub data volume, the GHTorrent web-site publishes a MYSQL dump of (some) GitHub data quarterly. Unfortunately, developers using these published data dumps face challenges with respect to the time required to parse and ingest the data, the space required to store it, and the latency of their queries. To help address these challenges, we developed a data adaptor as an Eclipse plugin, which efficiently handles this dump. The plugin offers an interactive interface through which users can explore and select any field in any table. After extracting the data selected by the user, the parser exports it in easy-to-use spreadsheets. We hope that using this plugin will facilitate further studies on the GitHub data as a whole.},
booktitle = {Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering},
pages = {265–268},
numpages = {4},
keywords = {big data, software tools, mining software repositories, GitHub, eclipse plugin},
location = {Markham, Canada},
series = {CASCON '15}
}

@inproceedings{10.5555/2623201.2623203,
author = {Weicheng, Yang and Beijun, Shen and Ben, Xu},
title = {Mining GitHub: Why Commit Stops -- Exploring the Relationship between Developer's Commit Pattern and File Version Evolution},
year = {2013},
isbn = {9781479921447},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Using the freeware in GitHub, we are often confused by a phenomenon: the new version of GitHub freeware usually was released in an indefinite frequency, and developers often committed nothing for a long time. This evolution phenomenon interferes with our own development plan and architecture design. Why do these updates happen at that time? Can we predict GitHub software version evolution by developers' activities? This paper aims to explore the developer commit patterns in GitHub, and try to mine the relationship between these patterns (if exists) and code evolution. First, we define four metrics to measure commit activity and code evolution: the changes in each commit, the time between two commits, the author of each changes, and the source code dependency. Then, we adopt visualization techniques to explore developers' commit activity and code evolution. Visual techniques are used to describe the progress of the given project and the authors' contributions. To analyze the commit logs in GitHub software repository automatically, Commits Analysis Tool (CAT) is designed and implemented. Finally, eight open source projects in GitHub are analyzed using CAT, and we find that: 1) the file changes in the previous versions may affect the file depend on it in the next version, 2) the average days around "huge commit" is 3 times of that around normal commit. Using these two patterns and developer's commit model, we can predict when his next commit comes and which file may be changed in that commit. Such information is valuable for project planning of both GitHub projects and other projects which use GitHub freeware to develop software.},
booktitle = {Proceedings of the 2013 20th Asia-Pacific Software Engineering Conference (APSEC) - Volume 02},
pages = {165–169},
numpages = {5},
keywords = {visualization technology, version evolution, repository mining, GitHub, commit pattern},
series = {APSEC '13}
}

@inproceedings{10.1109/MSR.2017.13,
author = {Yang, Di and Martins, Pedro and Saini, Vaibhav and Lopes, Cristina},
title = {Stack Overflow in Github: Any Snippets There?},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.13},
doi = {10.1109/MSR.2017.13},
abstract = {When programmers look for how to achieve certain programming tasks, Stack Overflow is a popular destination in search engine results. Over the years, Stack Overflow has accumulated an impressive knowledge base of snippets of code that are amply documented. We are interested in studying how programmers use these snippets of code in their projects. Can we find Stack Overflow snippets in real projects? When snippets are used, is this copy literal or does it suffer adaptations? And are these adaptations specializations required by the idiosyncrasies of the target artifact, or are they motivated by specific requirements of the programmer? The large-scale study presented on this paper analyzes 909k non-fork Python projects hosted on Github, which contain 290M function definitions, and 1.9M Python snippets captured in Stack Overflow. Results are presented as quantitative analysis of block-level code cloning intra and inter Stack Overflow and GitHub, and as an analysis of programming behaviors through the qualitative analysis of our findings.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {280–290},
numpages = {11},
keywords = {code clone, code reuse, large-scale analysis},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1007/978-3-319-26844-6_22,
author = {Kikas, Riivo and Dumas, Marlon and Pfahl, Dietmar},
title = {Issue Dynamics in Github Projects},
year = {2015},
isbn = {9783319268439},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-26844-6_22},
doi = {10.1007/978-3-319-26844-6_22},
abstract = {Issue repositories are used to keep of track of bugs, development tasks and feature requests in software development projects. In the case of open source projects, everyone can submit a new issue in the tracker. This practice can lead to situations where more issues are created than what can be effectively handled by the project members, raising the question of how issues are treated as the capacity of the project members is exceeded. In this paper, we study the temporal dynamics of issues in a popular open source development platform, namely Github, based on a sample of 4000 projects. We specifically analyze how the rate of issue creation, the amount of pending issues, and their average lifetime evolve over the course of time. The results show that more issues are opened shortly after the creation of a project repository and that the amount of pending issues increases inexorably due to forgotten unclosed issues. Yet, the average issue lifetime for issues that do get closed is relatively stable over time. These observations suggest that Github projects have implicit mechanisms for handling issues perceived to be important to the project, while neglecting those that exceed the project's capacity.},
booktitle = {Proceedings of the 16th International Conference on Product-Focused Software Process Improvement - Volume 9459},
pages = {295–310},
numpages = {16},
location = {Bolzano, Italy},
series = {PROFES 2015}
}

@inproceedings{10.1145/2972958.2972966,
author = {Borges, Hudson and Hora, Andre and Valente, Marco Tulio},
title = {Predicting the Popularity of GitHub Repositories},
year = {2016},
isbn = {9781450347723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2972958.2972966},
doi = {10.1145/2972958.2972966},
abstract = {GitHub is the largest source code repository in the world. It provides a git-based source code management platform and also many features inspired by social networks. For example, GitHub users can show appreciation to projects by adding stars to them. Therefore, the number of stars of a repository is a direct measure of its popularity. In this paper, we use multiple linear regressions to predict the number of stars of GitHub repositories. These predictions are useful both to repository owners and clients, who usually want to know how their projects are performing in a competitive open source development market. In a large-scale analysis, we show that the proposed models start to provide accurate predictions after being trained with the number of stars received in the last six months. Furthermore, specific models---generated using data from repositories that share the same growth trends---are recommended for repositories with slow growth and/or for repositories with less stars. Finally, we evaluate the ability to predict not the number of stars of a repository but its rank among the GitHub repositories. We found a very strong correlation between predicted and real rankings (Spearman's rho greater than 0.95).},
booktitle = {Proceedings of the The 12th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {9},
numpages = {10},
keywords = {Prediction Models, Social Coding, Popularity, GitHub, Open Source Development},
location = {Ciudad Real, Spain},
series = {PROMISE 2016}
}

@inproceedings{10.5555/2819321.2819330,
author = {Vasilescu, Bogdan and Filkov, Vladimir and Serebrenik, Alexander},
title = {Perceptions of Diversity on GitHub: A User Survey},
year = {2015},
publisher = {IEEE Press},
abstract = {Understanding one's work environment is important for one's success, especially when working in teams. In virtual collaborative environments this amounts to being aware of the technical and social attributes of one's team members. Focusing on Open Source Software teams, naturally very diverse both socially and technically, we report the results of a user survey that tries to resolve how teamwork and individual attributes are perceived by developers collaborating on GitHub, and how those perceptions influence their work. Our findings can be used as complementary data to quantitative studies of developers' behavior on GitHub.},
booktitle = {Proceedings of the Eighth International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {50–56},
numpages = {7},
location = {Florence, Italy},
series = {CHASE '15}
}

@inproceedings{10.1145/3272973.3274083,
author = {Pe-Than, Ei Pa Pa and Dabbish, Laura and Herbsleb, James D.},
title = {Collaborative Writing on GitHub: A Case Study of a Book Project},
year = {2018},
isbn = {9781450360180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3272973.3274083},
doi = {10.1145/3272973.3274083},
abstract = {Social coding platforms such as GitHub are increasingly becoming a digital workspace for the production of non-software digital artifacts. Since GitHub offers unique features that are different from traditional ways of collaborative writing, it is interesting to investigate how GitHub features are used for writing. In this paper, we present the preliminary findings of a mixed-methods, case study of collaboration practices in a GitHub book project. We found that the use of GitHub depended on task interdependence and audience participation. GitHub's direct push method was used to coordinate both loosely- and tightly-coupled work, with the latter requiring collaborators to follow socially-accepted conventions. The pull-based method was adopted once the project was released to the public. While face-to-face and online meetings were prominent in the early phases, GitHub's issues became instrumental for communication and project management in later phases. Our findings have implications for the design of collaborative writing tools.},
booktitle = {Companion of the 2018 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {305–308},
numpages = {4},
keywords = {collaborative writing, mixed methods research, collaboration, social computing, coordination, co-creation},
location = {Jersey City, NJ, USA},
series = {CSCW '18}
}

@inproceedings{10.1145/3300115.3309518,
author = {Glassey, Richard},
title = {Adopting Git/Github within Teaching: A Survey of Tool Support},
year = {2019},
isbn = {9781450362597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3300115.3309518},
doi = {10.1145/3300115.3309518},
abstract = {The adoption and use of Git and Github within computer science education is growing in popularity. The motivation for this shift is strong: it combines a robust system for managing student coursework, sophisticated collaboration and communication tools for students and teaching staff, and an authentic experience of an important software engineering skill. Whilst previous literature has reported upon experience and benefits, there still exists a technical barrier to overcome in adopting Git and Github within an educational context. In response, both the community of teachers using Git/Github and the Github organisation itself have developed tool support to help solve the challenge of adoption, however these efforts are somewhat isolated and relatively unstudied. This work aims to provide an overview of these tools, identify the commonalities and differences, and develop a framework for comparison to assist teachers when looking for solutions for their own courses.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education},
pages = {143–149},
numpages = {7},
keywords = {Git/Github, version control system, computing education},
location = {Chengdu,Sichuan, China},
series = {CompEd '19}
}

@inproceedings{10.1145/2597073.2597074,
author = {Kalliamvakou, Eirini and Gousios, Georgios and Blincoe, Kelly and Singer, Leif and German, Daniel M. and Damian, Daniela},
title = {The Promises and Perils of Mining GitHub},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597074},
doi = {10.1145/2597073.2597074},
abstract = { With over 10 million git repositories, GitHub is becoming one of the most important source of software artifacts on the Internet. Researchers are starting to mine the information stored in GitHub's event logs, trying to understand how its users employ the site to collaborate on software. However, so far there have been no studies describing the quality and properties of the data available from GitHub. We document the results of an empirical study aimed at understanding the characteristics of the repositories in GitHub and how users take advantage of GitHub's main features---namely commits, pull requests, and issues. Our results indicate that, while GitHub is a rich source of data on software development, mining GitHub for research purposes should take various potential perils into consideration. We show, for example, that the majority of the projects are personal and inactive; that GitHub is also being used for free storage and as a Web hosting service; and that almost 40% of all pull requests do not appear as merged, even though they were. We provide a set of recommendations for software engineering researchers on how to approach the data in GitHub. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {92–101},
numpages = {10},
keywords = {Mining software repositories, git, bias, github, code reviews},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3379597.3387496,
author = {Spinellis, Diomidis and Kotti, Zoe and Mockus, Audris},
title = {A Dataset for GitHub Repository Deduplication},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387496},
doi = {10.1145/3379597.3387496},
abstract = {GitHub projects can be easily replicated through the site's fork process or through a Git clone-push sequence. This is a problem for empirical software engineering, because it can lead to skewed results or mistrained machine learning models. We provide a dataset of 10.6 million GitHub projects that are copies of others, and link each record with the project's ultimate parent. The ultimate parents were derived from a ranking along six metrics. The related projects were calculated as the connected components of an 18.2 million node and 12 million edge denoised graph created by directing edges to ultimate parents. The graph was created by filtering out more than 30 hand-picked and 2.3 million pattern-matched clumping projects. Projects that introduced unwanted clumping were identified by repeatedly visualizing shortest path distances between unrelated important projects. Our dataset identified 30 thousand duplicate projects in an existing popular reference dataset of 1.8 million projects. An evaluation of our dataset against another created independently with different methods found a significant overlap, but also differences attributed to the operational definition of what projects are considered as related.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {523–527},
numpages = {5},
keywords = {project clone, Deduplication, dataset, GitHub, fork},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3131704.3131706,
author = {Xu, Wenyuan and Sun, Xiaobing and Xia, Xin and Chen, Xiang},
title = {Scalable Relevant Project Recommendation on GitHub},
year = {2017},
isbn = {9781450353137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131704.3131706},
doi = {10.1145/3131704.3131706},
abstract = {GitHub, one of the largest social coding platforms, fosters a flexible and collaborative development process. In practice, developers in the open source software platform need to find projects relevant to their development work to reuse their function, explore ideas of possible features, or analyze the requirements for their projects. Recommending relevant projects to a developer is a difficult problem considering that there are millions of projects hosted on GitHub, and different developers may have different requirements on relevant projects. In this paper, we propose a scalable and personalized approach to recommend projects by leveraging both developers' behaviors and project features. Based on the features of projects created by developers and their behaviors to other projects, our approach automatically recommends top N most relevant software projects to developers. Moreover, to improve the scalability of our approach, we implement our approach in a parallel processing frame (i.e., Apache Spark) to analyze large-scale data on GitHub for efficient recommendation. We perform an empirical study on the data crawled from GitHub, and the results show that our approach can efficiently recommend relevant software projects with a relatively high precision fit for developers' interests.},
booktitle = {Proceedings of the 9th Asia-Pacific Symposium on Internetware},
articleno = {9},
numpages = {10},
keywords = {GitHub, Software recommendation, parallel processing frame},
location = {Shanghai, China},
series = {Internetware'17}
}

@inproceedings{10.1145/3131704.3131725,
author = {Li, Zhixing and Yin, Gang and Yu, Yue and Wang, Tao and Wang, Huaimin},
title = {Detecting Duplicate Pull-Requests in GitHub},
year = {2017},
isbn = {9781450353137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131704.3131725},
doi = {10.1145/3131704.3131725},
abstract = {The widespread use of pull-requests boosts the development and evolution for many open source software projects. However, due to the parallel and uncoordinated nature of development process in GitHub, duplicate pull-requests may be submitted by different contributors to solve the same problem. Duplicate pull-requests increase the maintenance cost of GitHub, result in the waste of time spent on the redundant effort of code review, and even frustrate developers' willing to offer continuous contribution. In this paper, we investigate using text information to automatically detect duplicate pull-requests in GitHub. For a new-arriving pull-request, we compare the textual similarity between it and other existing pull-requests, and then return a candidate list of the most similar ones. We evaluate our approach on three popular projects hosted in GitHub, namely Rails, Elasticsearch and Angular.JS. The evaluation shows that about 55.3% -- 71.0% of the duplicates can be found when we use the combination of title similarity and description similarity.},
booktitle = {Proceedings of the 9th Asia-Pacific Symposium on Internetware},
articleno = {20},
numpages = {6},
keywords = {code review, Pull-request, textual similarity, duplicate detection},
location = {Shanghai, China},
series = {Internetware'17}
}

@inproceedings{10.1145/3243082.3243101,
author = {Oliveira, Gabriel P. and Batista, Nat\'{e}rcia A. and Brand\~{a}o, Michele A. and Moro, Mirella M.},
title = {Tie Strength in GitHub Heterogeneous Networks},
year = {2018},
isbn = {9781450358675},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243082.3243101},
doi = {10.1145/3243082.3243101},
abstract = {In social networks, the relationship between individuals is defined by many forms of interaction. Here, our goal is to measure the strength of the relationship between GitHub users by considering social and technical features. Thus, we model GitHub's heterogeneous collaboration network with different types of interaction and propose new metrics to the strength of relationships. The results show the new metrics are not correlated, bringing new information to the table. Finally, these metrics may become important tools to determine users' influence and popularity.},
booktitle = {Proceedings of the 24th Brazilian Symposium on Multimedia and the Web},
pages = {363–370},
numpages = {8},
keywords = {Semantics, Heterogeneous Social Networks, Tie Strength},
location = {Salvador, BA, Brazil},
series = {WebMedia '18}
}

@inproceedings{10.1145/2145204.2145396,
author = {Dabbish, Laura and Stuart, Colleen and Tsay, Jason and Herbsleb, Jim},
title = {Social Coding in GitHub: Transparency and Collaboration in an Open Software Repository},
year = {2012},
isbn = {9781450310864},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2145204.2145396},
doi = {10.1145/2145204.2145396},
abstract = {Social applications on the web let users track and follow the activities of a large number of others regardless of location or affiliation. There is a potential for this transparency to radically improve collaboration and learning in complex knowledge-based activities. Based on a series of in-depth interviews with central and peripheral GitHub users, we examined the value of transparency for large-scale distributed collaborations and communities of practice. We find that people make a surprisingly rich set of social inferences from the networked activity information in GitHub, such as inferring someone else's technical goals and vision when they edit code, or guessing which of several similar projects has the best chance of thriving in the long term. Users combine these inferences into effective strategies for coordinating work, advancing technical skills and managing their reputation.},
booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
pages = {1277–1286},
numpages = {10},
keywords = {open source software development, awareness, social computing, collaboration, transparency, coordination},
location = {Seattle, Washington, USA},
series = {CSCW '12}
}

@inproceedings{10.5555/2820518.2820563,
author = {Hauff, Claudia and Gousios, Georgios},
title = {Matching GitHub Developer Profiles to Job Advertisements},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {GitHub is a social coding platform that enables developers to efficiently work on projects, connect with other developers, collaborate and generally "be seen" by the community. This visibility also extends to prospective employers and HR personnel who may use GitHub to learn more about a developer's skills and interests. We propose a pipeline that automatizes this process and automatically suggests matching job advertisements to developers, based on signals extracting from their activities on GitHub.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {362–366},
numpages = {5},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3383583.3398578,
author = {F\"{a}rber, Michael},
title = {Analyzing the GitHub Repositories of Research Papers},
year = {2020},
isbn = {9781450375856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383583.3398578},
doi = {10.1145/3383583.3398578},
abstract = {Linking to code repositories, such as on GitHub, in scientific papers becomes increasingly common in the field of computer science. The actual quality and usage of these repositories are, however, to a large degree unknown so far. In this paper, we present for the first time a thorough analysis of all GitHub code repositories linked in scientific papers using the Microsoft Academic Graph as a data source. We analyze the repositories and their associated papers with respect to various dimensions. We observe that the number of stars and forks, respectively, over all repositories follows a power-law distribution. In the majority of cases, only one person from the authors is contributing to the repository. The GitHub manuals are mostly kept rather short with few sentences. The source code is mostly provided in Python. The papers containing the repository URLs as well as the papers' authors are typically from the AI field.},
booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020},
pages = {491–492},
numpages = {2},
keywords = {GitHub, bibliometrics, scholarly data, code repositories, papers},
location = {Virtual Event, China},
series = {JCDL '20}
}

@inproceedings{10.1109/CSMR.2013.41,
author = {Thung, Ferdian and Bissyande, Tegawende F. and Lo, David and Jiang, Lingxiao},
title = {Network Structure of Social Coding in GitHub},
year = {2013},
isbn = {9780769549484},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CSMR.2013.41},
doi = {10.1109/CSMR.2013.41},
abstract = {Social coding enables a different experience of software development as the activities and interests of one developer are easily advertised to other developers. Developers can thus track the activities relevant to various projects in one umbrella site. Such a major change in collaborative software development makes an investigation of networkings on social coding sites valuable. Furthermore, project hosting platforms promoting this development paradigm have been thriving, among which GitHub has arguably gained the most momentum. In this paper, we contribute to the body of knowledge on social coding by investigating the network structure of social coding in GitHub. We collect 100,000 projects and 30,000 developers from GitHub, construct developer-developer and project-project relationship graphs, and compute various characteristics of the graphs. We then identify influential developers and projects on this sub network of GitHub by using PageRank. Understanding how developers and projects are actually related to each other on a social coding site is the first step towards building tool supports to aid social programmers in performing their tasks more efficiently.},
booktitle = {Proceedings of the 2013 17th European Conference on Software Maintenance and Reengineering},
pages = {323–326},
numpages = {4},
keywords = {Social coding, developer-developer network, GitHub, project-project network},
series = {CSMR '13}
}

@inproceedings{10.1145/3106426.3106480,
author = {Batista, Nat\'{e}rcia A. and Brand\~{a}o, Michele A. and Alves, Gabriela B. and da Silva, Ana Paula Couto and Moro, Mirella M.},
title = {Collaboration Strength Metrics and Analyses on GitHub},
year = {2017},
isbn = {9781450349512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106426.3106480},
doi = {10.1145/3106426.3106480},
abstract = {We perform social analyses over an important community: the open code collaboration network. Specifically, we study the correlation among features that measure the strength of social coding collaboration on GitHub - a Web-based source code repository that can be modeled as a social coding network. We also make publicly available a curated dataset called GitSED, GitHub Socially Enhanced Dataset. Our results have many practical applications such as to improve the recommendation of developers, the evaluation of team formation and existing analysis algorithms.},
booktitle = {Proceedings of the International Conference on Web Intelligence},
pages = {170–178},
numpages = {9},
keywords = {tie strength, social network analysis, online cooperative work},
location = {Leipzig, Germany},
series = {WI '17}
}

@inproceedings{10.1145/3328778.3372646,
author = {Bentley, Carmen A. and Gehringer, Edward F.},
title = {Promoting Collaborative Skills with Github Project Boards},
year = {2020},
isbn = {9781450367936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328778.3372646},
doi = {10.1145/3328778.3372646},
abstract = {Teamwork skills are much in demand in the workplace, even more so with the growth of Agile methods. This calls for giving Computer Science students more practice in the kinds of team scenarios they will encounter on the job. Key for success are hands-on experience with planning methods, prioritization techniques, time management and organization. This poster shows how the cooperative tracking tool Github Project Boards helps teams strategize development, track progress, distribute work evenly, and facilitate collaboration. It also shows how instructors can use Github Project Boards to visualize and evaluate a team's development process.},
booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},
pages = {1332},
numpages = {1},
keywords = {github project boards, collaboration, cooperative tools, tracking systems, teaming skills},
location = {Portland, OR, USA},
series = {SIGCSE '20}
}

@inproceedings{10.1145/2666539.2666571,
author = {Yu, Yue and Yin, Gang and Wang, Huaimin and Wang, Tao},
title = {Exploring the Patterns of Social Behavior in GitHub},
year = {2014},
isbn = {9781450332248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666539.2666571},
doi = {10.1145/2666539.2666571},
abstract = { Social coding paradigm is reshaping the distributed software development with a surprising speed in recent years. Github, a remarkable social coding community, attracts a huge number of developers in a short time. Various kinds of social networks are formed based on social activities among developers. Why this new paradigm can achieve such a great success in attracting external developers, and how they are connected in such a massive community, are interesting questions for revealing power of social coding paradigm. In this paper, we firstly compare the growth curves of project and user in GitHub with three traditional open source software communities to explore differences of their growth modes. We find an explosive growth of the users in GitHub and introduce the Diffusion of Innovation theory to illustrate intrinsic sociological basis of this phenomenon. Secondly, we construct follow-networks according to the follow behaviors among developers in GitHub. Finally, we present four typical social behavior patterns by mining follow-networks containing independence-pattern, group-pattern, star-pattern and hub-pattern. This study can provide several instructions of crowd collaboration to newcomers. According to the typical behavior patterns, the community manager could design corresponding assistive tools for developers. },
booktitle = {Proceedings of the 1st International Workshop on Crowd-Based Software Development Methods and Technologies},
pages = {31–36},
numpages = {6},
keywords = {Social network, Behavior pattern, Social coding, Distributed software development},
location = {Hong Kong, China},
series = {CrowdSoft 2014}
}

@inproceedings{10.1145/2702123.2702549,
author = {Vasilescu, Bogdan and Posnett, Daryl and Ray, Baishakhi and van den Brand, Mark G.J. and Serebrenik, Alexander and Devanbu, Premkumar and Filkov, Vladimir},
title = {Gender and Tenure Diversity in GitHub Teams},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702549},
doi = {10.1145/2702123.2702549},
abstract = {Software development is usually a collaborative venture. Open Source Software (OSS) projects are no exception; indeed, by design, the OSS approach can accommodate teams that are more open, geographically distributed, and dynamic than commercial teams. This, we find, leads to OSS teams that are quite diverse. Team diversity, predominantly in offline groups, is known to correlate with team output, mostly with positive effects. How about in OSS? Using GitHub, the largest publicly available collection of OSS projects, we studied how gender and tenure diversity relate to team productivity and turnover. Using regression modeling of GitHub data and the results of a survey, we show that both gender and tenure diversity are positive and significant predictors of productivity, together explaining a sizable fraction of the data variability. These results can inform decision making on all levels, leading to better outcomes in recruiting and performance.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3789–3798},
numpages = {10},
keywords = {github, diversity, productivity, gender, open source},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3194932.3194936,
author = {Destefanis, Giuseppe and Ortu, Marco and Bowes, David and Marchesi, Michele and Tonelli, Roberto},
title = {On Measuring Affects of Github Issues' Commenters},
year = {2018},
isbn = {9781450357517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194932.3194936},
doi = {10.1145/3194932.3194936},
abstract = {In this study, we analyzed issues and comments on GitHub projects and built collaboration networks dividing contributors into two categories: users and commenters. We identified as commenters those users who only post comments without posting any issues nor committing changes in the source code. Since previous studies showed that there is a link between a positive environment (regarding affectiveness) and productivity, our goal was to investigate commenters' contribution to the project concerning affectiveness.We analyzed more than 370K comments from 100K issues of 25K contributors from 3 open source projects. We then calculated and compared the affectiveness of the issues' comments written by users and commenters in terms of sentiment, politeness, and emotions. We provide empirical evidence that commenters are less polite, less positive and in general they express a lower level of emotions in their comments than users. Our results also confirm that GitHub's contributors consist of different groups which behave differently, and this provides useful information for future studies in the field.},
booktitle = {Proceedings of the 3rd International Workshop on Emotion Awareness in Software Engineering},
pages = {14–19},
numpages = {6},
keywords = {human factors, mining software repositories, software engineering},
location = {Gothenburg, Sweden},
series = {SEmotion '18}
}

@inproceedings{10.1145/3366423.3380145,
author = {Shao, Huajie and Sun, Dachun and Wu, Jiahao and Zhang, Zecheng and Zhang, Aston and Yao, Shuochao and Liu, Shengzhong and Wang, Tianshi and Zhang, Chao and Abdelzaher, Tarek},
title = {Paper2repo: GitHub Repository Recommendation for Academic Papers},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380145},
doi = {10.1145/3366423.3380145},
abstract = {GitHub has become a popular social application platform, where a large number of users post their open source projects. In particular, an increasing number of researchers release repositories of source code related to their research papers in order to attract more people to follow their work. Motivated by this trend, we describe a novel item-item cross-platform recommender system, paper2repo, that recommends relevant repositories on GitHub that match a given paper in an academic search system such as Microsoft Academic. The key challenge is to identify the similarity between an input paper and its related repositories across the two platforms, without the benefit of human labeling. Towards that end, paper2repo integrates text encoding and constrained graph convolutional networks (GCN) to automatically learn and map the embeddings of papers and repositories into the same space, where proximity offers the basis for recommendation. To make our method more practical in real life systems, labels used for model training are computed automatically from features of user actions on GitHub. In machine learning, such automatic labeling is often called distant supervision. To the authors’ knowledge, this is the first distant-supervised cross-platform (paper to repository) matching system. We evaluate the performance of paper2repo on real-world data sets collected from GitHub and Microsoft Academic. Results demonstrate that it outperforms other state of the art recommendation methods.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {629–639},
numpages = {11},
keywords = {cross-platform recommendation, Recommender system, constrained graph convolutional networks, text encoding},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1109/ICSME.2014.107,
author = {Yu, Yue and Wang, Huaimin and Yin, Gang and Ling, Charles X.},
title = {Reviewer Recommender of Pull-Requests in GitHub},
year = {2014},
isbn = {9781479961467},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSME.2014.107},
doi = {10.1109/ICSME.2014.107},
abstract = {Pull-Request (PR) is the primary method for code contributions from thousands of developers in GitHub. To maintain the quality of software projects, PR review is an essential part of distributed software development. Assigning new PRs to appropriate reviewers will make the review process more effective which can reduce the time between the submission of a PR and the actual review of it. However, reviewer assignment is now organized manually in GitHub. To reduce this cost, we propose a reviewer recommender to predict highly relevant reviewers of incoming PRs. Combining information retrieval with social network analyzing, our approach takes full advantage of the textual semantic of PRs and the social relations of developers. We implement an online system to show how the reviewer recommender helps project managers to find potential reviewers from crowds. Our approach can reach a precision of 74% for top-1 recommendation, and a recall of 71% for top-10 recommendation.},
booktitle = {Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution},
pages = {609–612},
numpages = {4},
keywords = {Reviewer Recommendation, Distributed Software Development, Social Network Analysis, Pull-request},
series = {ICSME '14}
}

@inproceedings{10.1145/3084226.3084259,
author = {Kochhar, Pavneet Singh and Lo, David},
title = {Revisiting Assert Use in GitHub Projects},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084259},
doi = {10.1145/3084226.3084259},
abstract = {Assertions are often used to test the assumptions that developers have about a program. An assertion contains a boolean expression which developers believe to be true at a particular program point. It throws an error if the expression is not satisfied, which helps developers to detect and correct bugs. Since assertions make developer assumptions explicit, assertions are also believed to improve under-standability of code. Recently, Casalnuovo et al. analyse C and C++ programs to understand the relationship between assertion usage and defect occurrence. Their results show that asserts have a small effect on reducing the density of bugs and developers often add asserts to methods they have prior knowledge of and larger ownership. In this study, we perform a partial replication of the above study on a large dataset of Java projects from GitHub (185 projects, 20 million LOC, 4 million commits, 0.2 million files and 1 million methods). We collect metrics such as number of asserts, number of defects, number of developers and number of lines changed to a method, and examine the relationship between asserts and defect occurrence. We also analyse relationship between developer experience and ownership and the number of asserts. Furthermore, we perform a study of what are different types of asserts added and why they are added by developers. We find that asserts have a small yet significant relationship with defect occurrence and developers who have added asserts to methods often have higher ownership of and experience with the methods than developers who did not add asserts.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {298–307},
numpages = {10},
keywords = {Replication Study, GitHub, Assertions},
location = {Karlskrona, Sweden},
series = {EASE'17}
}

@inproceedings{10.1109/SE4Science.2019.00014,
author = {Lin, Xuanyi and Simon, Michelle and Niu, Nan},
title = {Releasing Scientific Software in GitHub: A Case Study on SWMM2PEST},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SE4Science.2019.00014},
doi = {10.1109/SE4Science.2019.00014},
abstract = {Release engineering involves code development, integration, testing, and software delivery. It has been widely applied to deliver high-quality software to users. While release engineering is a widespread practice in the software industry, there have been very few studies on the release engineering pipeline of scientific software. To shorten this gap, we present a case study in this paper to show a GitHub-driven release workflow on SWMM2PEST, a software system automating parameter calibration for the U.S. EPA's Storm Water Management Model (SWMM). Moreover, we analyze software version updates and requirements changes to develop strategies for improving the ongoing releases. The feasibility of improvement strategies is demonstrated by our consecutively released versions of SWMM2PEST. The results offered insights into the continuous release of scientific software.},
booktitle = {Proceedings of the 14th International Workshop on Software Engineering for Science},
pages = {47–50},
numpages = {4},
keywords = {GitHub, release scientific software, release engineering, software engineering, SWMM2PEST, SWMM},
location = {Montreal, Quebec, Canada},
series = {SE4Science '19}
}

@inproceedings{10.1145/2897659.2897663,
author = {Badashian, Ali Sajedi and Stroulia, Eleni},
title = {Measuring User Influence in GitHub: The Million Follower Fallacy},
year = {2016},
isbn = {9781450341585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897659.2897663},
doi = {10.1145/2897659.2897663},
abstract = {Influence in social networks has been extensively studied for collaborative-filtering recommendations and marketing purposes. We are interested in the notion of influence in Software Social Networks (SSNs); more specifically, we want to answer the following questions: 1) What does "influence" mean in SSNs? Given the variety of types of interactions supported in these networks and the abundance of centrality-type metrics, what is the nature of the influence captured by these matrics? 2) Are there silos of influence in these platforms or does influence span across thematic boundaries?To investigate these two questions, we first conducted an in-depth comparison of three influence metrics, number of followers, number of forked projects, and number of project watchers in GitHub1 (the largest code-sharing and version-control system). Next, we examined how the influence of the most influential software-engineering people in GitHub is spread over different programming languages.Our results indicate (a) that the three influence metrics capture two major characteristics: popularity and content value (code reusability) and (b) that the influence of influentials is spread over more than one programming language, but there is no specific trend toward any two programming languages.},
booktitle = {Proceedings of the 3rd International Workshop on CrowdSourcing in Software Engineering},
pages = {15–21},
numpages = {7},
keywords = {social influence, mining software repositories, programming languages, GitHub, software social networks},
location = {Austin, Texas},
series = {CSI-SE '16}
}

@inproceedings{10.5555/3235924.3235932,
author = {Acar, Yasemin and Stransky, Christian and Wermke, Dominik and Mazurek, Michelle L. and Fahl, Sascha},
title = {Security Developer Studies with Github Users: Exploring a Convenience Sample},
year = {2017},
isbn = {9781931971393},
publisher = {USENIX Association},
address = {USA},
abstract = {The usable security community is increasingly considering how to improve security decision-making not only for end users, but also for information technology professionals, including system administrators and software developers. Recruiting these professionals for user studies can prove challenging, as, relative to end users more generally, they are limited in numbers, geographically concentrated, and accustomed to higher compensation. One potential approach is to recruit active GitHub users, who are (in some ways) conveniently available for online studies. However, it is not well understood how GitHub users perform when working on security-related tasks. As a first step in addressing this question, we conducted an experiment in which we recruited 307 active GitHub users to each complete the same security-relevant programming tasks. We compared the results in terms of functional correctness as well as security, finding differences in performance for both security and functionality related to the participant's self-reported years of experience, but no statistically significant differences related to the participant's self-reported status as a student, status as a professional developer, or security background. These results provide initial evidence for how to think about validity when recruiting convenience samples as substitutes for professional developers in security developer studies.},
booktitle = {Proceedings of the Thirteenth USENIX Conference on Usable Privacy and Security},
pages = {81–95},
numpages = {15},
location = {Santa Clara, CA, USA},
series = {SOUPS '17}
}

@inproceedings{10.1145/2950290.2950305,
author = {Silva, Danilo and Tsantalis, Nikolaos and Valente, Marco Tulio},
title = {Why We Refactor? Confessions of GitHub Contributors},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950305},
doi = {10.1145/2950290.2950305},
abstract = { Refactoring is a widespread practice that helps developers to improve the maintainability and readability of their code. However, there is a limited number of studies empirically investigating the actual motivations behind specific refactoring operations applied by developers. To fill this gap, we monitored Java projects hosted on GitHub to detect recently applied refactorings, and asked the developers to explain the reasons behind their decision to refactor the code. By applying thematic analysis on the collected responses, we compiled a catalogue of 44 distinct motivations for 12 well-known refactoring types. We found that refactoring activity is mainly driven by changes in the requirements and much less by code smells. Extract Method is the most versatile refactoring operation serving 11 different purposes. Finally, we found evidence that the IDE used by the developers affects the adoption of automated refactoring tools. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {858–870},
numpages = {13},
keywords = {GitHub, software evolution, Refactoring, code smells},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.5555/2818754.2818846,
author = {Casalnuovo, Casey and Devanbu, Prem and Oliveira, Abilio and Filkov, Vladimir and Ray, Baishakhi},
title = {Assert Use in GitHub Projects},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Asserts have long been a strongly recommended (if non-functional) adjunct to programs. They certainly don't add any user-evident feature value; and it can take quite some skill and effort to devise and add useful asserts. However, they are believed to add considerable value to the developer. Certainly, they can help with automated verification; but even in the absence of that, claimed advantages include improved understandability, maintainability, easier fault localization and diagnosis, all eventually leading to better software quality. We focus on this latter claim, and use a large dataset of asserts in C and C++ programs to explore the connection between asserts and defect occurrence. Our data suggests a connection: functions with asserts do have significantly fewer defects. This indicates that asserts do play an important role in software quality; we therefore explored further the factors that play a role in assertion placement: specifically, process factors (such as developer experience and ownership) and product factors, particularly interprocedural factors, exploring how the placement of assertions in functions are influenced by local and global network properties of the callgraph. Finally, we also conduct a differential analysis of assertion use across different application domains.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {755–766},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/3192424.3192679,
author = {Leibzon, William},
title = {Social Network of Software Development at GitHub},
year = {2016},
isbn = {9781509028467},
publisher = {IEEE Press},
abstract = {This paper looks at organization of software development teams and project communities at GitHub. Using social network analysis several open-source projects are analyzed and social networks of users with ties to a project are shown to have some scale-free properties. We further show how to find core development group and a network metric is introduced to measure collaboration among core members, corresponding to if a project is healthy and more likely to be successful.},
booktitle = {Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1374–1376},
numpages = {3},
keywords = {collaboration, social network analysis, open-source, scale-free network, github},
location = {Davis, California},
series = {ASONAM '16}
}

@inproceedings{10.1145/3287324.3293787,
author = {Hu, Zhewei and Gehringer, Edward},
title = {Use Bots to Improve GitHub Pull-Request Feedback},
year = {2019},
isbn = {9781450358903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287324.3293787},
doi = {10.1145/3287324.3293787},
abstract = {Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student's work. In our software engineering course, we have 50-120 students each semester. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check code style and functionality. However, these tools cannot enforce system-specific customized guidelines and do not explicitly display detailed information. In this study, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. The Expertiza Bot can help detect violations of more than 35 system-specific guidelines. The Travis CI Bot can explicitly display instant test execution results on the GitHub pull-request page. The Code Climate Bot can insert pull-request comments to remind students to fix issues detected by the static code analyzer. These bots are either open source or free for OSS projects, and can be easily integrated with GitHub repositories. Our survey results show that more than 70% of students think the advice given by the bots is useful. We tallied the amount of feedback given by the bots and the teaching staff for each GitHub pull request. Results show that bots can provide significantly more feedback (six times more on average) than teaching staff. Bots can also offer more timely feedback than teaching staff and help student contributions avoid more than 33% system-specific guideline violations.},
booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
pages = {1262–1263},
numpages = {2},
keywords = {software engineering, open-source curriculum, open-source software, internet bots, expertiza},
location = {Minneapolis, MN, USA},
series = {SIGCSE '19}
}

@inproceedings{10.1145/2950290.2950319,
author = {Fowkes, Jaroslav and Sutton, Charles},
title = {Parameter-Free Probabilistic API Mining across GitHub},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950319},
doi = {10.1145/2950290.2950319},
abstract = {Existing API mining algorithms can be difficult to use as they require expensive parameter tuning and the returned set of API calls can be large, highly redundant and difficult to understand. To address this, we present PAM (Probabilistic API Miner), a near parameter-free probabilistic algorithm for mining the most interesting API call patterns. We show that PAM significantly outperforms both MAPO and UPMiner, achieving 69% test-set precision, at retrieving relevant API call sequences from GitHub. Moreover, we focus on libraries for which the developers have explicitly provided code examples, yielding over 300,000 LOC of hand-written API example code from the 967 client projects in the data set. This evaluation suggests that the hand-written examples actually have limited coverage of real API usages.},
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {254–265},
numpages = {12},
keywords = {sequential pattern mining, API mining},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/2597073.2597121,
author = {Rahman, Mohammad Masudur and Roy, Chanchal K.},
title = {An Insight into the Pull Requests of GitHub},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597121},
doi = {10.1145/2597073.2597121},
abstract = { Given the increasing number of unsuccessful pull requests in GitHub projects, insights into the success and failure of these requests are essential for the developers. In this paper, we provide a comparative study between successful and unsuccessful pull requests made to 78 GitHub base projects by 20,142 developers from 103,192 forked projects. In the study, we analyze pull request discussion texts, project specific information (e.g., domain, maturity), and developer specific information (e.g., experience) in order to report useful insights, and use them to contrast between successful and unsuccessful pull requests. We believe our study will help developers overcome the issues with pull requests in GitHub, and project administrators with informed decision making. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {364–367},
numpages = {4},
keywords = {Commit comments, topic model, pull request},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/2889160.2889195,
author = {Feliciano, Joseph and Storey, Margaret-Anne and Zagalsky, Alexey},
title = {Student Experiences Using GitHub in Software Engineering Courses: A Case Study},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889195},
doi = {10.1145/2889160.2889195},
abstract = {GitHub has been embraced by the software development community as an important social platform for managing software projects and to support collaborative development. More recently, educators have begun to adopt it for hosting course content and student assignments. From our previous research, we found that educators leverage GitHub's collaboration and transparency features to create, reuse and remix course materials, and to encourage student contributions and monitor student activity on assignments and projects. However, our previous research did not consider the student perspective.In this paper, we present a case study where GitHub is used as a learning platform for two software engineering courses. We gathered student perspectives on how the use of GitHub in their courses might benefit them and to identify the challenges they may face. The findings from our case study indicate that software engineering students do benefit from GitHub's transparent and open workflow. However, students were concerned that since GitHub is not inherently an educational tool, it lacks key features important for education and poses learning and privacy concerns. Our findings provide recommendations for designers on how tools such as GitHub can be used to improve software engineering education, and also point to recommendations for instructors on how to use it more effectively in their courses.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {422–431},
numpages = {10},
keywords = {learning, collaboration, education, software engineering, GitHub},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1109/MSR.2017.48,
author = {Robles, Gregorio and Ho-Quang, Truong and Hebig, Regina and Chaudron, Michel R. V. and Fernandez, Miguel Angel},
title = {An Extensive Dataset of UML Models in GitHub},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.48},
doi = {10.1109/MSR.2017.48},
abstract = {The Unified Modeling Language (UML) is widely taught in academia and has good acceptance in industry. However, there is not an ample dataset of UML diagrams publicly available. Our aim is to offer a dataset of UML files, together with meta-data of the software projects where the UML files belong to. Therefore, we have systematically mined over 12 million GitHub projects to find UML files in them. We present a semi-automated approach to collect UML stored in images, .xmi, and .uml files. We offer a dataset with over 93,000 UML diagrams from over 24,000 projects in GitHub.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {519–522},
numpages = {4},
keywords = {dataset, modeling, UML, GitHub, mining software repositories},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1109/FCST.2015.45,
author = {Luo, Zizhan and Mao, Xiaoguang and Li, Ang},
title = {An Exploratory Research of GitHub Based on Graph Model},
year = {2015},
isbn = {9781467392952},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/FCST.2015.45},
doi = {10.1109/FCST.2015.45},
abstract = {GitHub has accumulated a great number of developers and open source projects. In this research, we utilize property graph model to explore complex relationships and entities of GitHub. We attempt to answer three questions associated with GitHub using the dataset from MSR2014 data challenge. Firstly, we propose a graph based method to find out the cross technology background developers on GitHub. Secondly we define interesting metrics based on discrete entropy to analyze the project imbalance induced by commit action within a software family. The results show that the imbalance of development size induced by root projects is greater than that of development speed. Finally, we sort out the relatively important root projects with two link analysis methods and the experiment result demonstrates that our method is effective.},
booktitle = {Proceedings of the 2015 Ninth International Conference on Frontier of Computer Science and Technology},
pages = {96–103},
numpages = {8},
keywords = {Graph Model, Empirical Studies, Imbalance, Link Analysis, GitHub, Graph Database, Mining Software Repositories, Software Metric},
series = {FCST '15}
}

@inproceedings{10.1109/ICSE.2019.00079,
author = {Imtiaz, Nasif and Middleton, Justin and Chakraborty, Joymallya and Robson, Neill and Bai, Gina and Murphy-Hill, Emerson},
title = {Investigating the Effects of Gender Bias on GitHub},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00079},
doi = {10.1109/ICSE.2019.00079},
abstract = {Diversity, including gender diversity, is valued by many software development organizations, yet the field remains dominated by men. One reason for this lack of diversity is gender bias. In this paper, we study the effects of that bias by using an existing framework derived from the gender studies literature. We adapt the four main effects proposed in the framework by posing hypotheses about how they might manifest on GitHub, then evaluate those hypotheses quantitatively. While our results show that effects of gender bias are largely invisible on the GitHub platform itself, there are still signals of women concentrating their work in fewer places and being more restrained in communication than men.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {700–711},
numpages = {12},
keywords = {GitHub, gender, open source},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3196398.3196455,
author = {Yu, Yue and Li, Zhixing and Yin, Gang and Wang, Tao and Wang, Huaimin},
title = {A Dataset of Duplicate Pull-Requests in Github},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196455},
doi = {10.1145/3196398.3196455},
abstract = {In GitHub, the pull-based development model enables community contributors to collaborate in a more efficient way. However, the distributed and parallel characteristics of this model pose a potential risk for developers to submit duplicate pull-requests (PRs), which increase the extra cost of project maintenance. To facilitate the further studies to better understand and solve the issues introduced by duplicate PRs, we construct a large dataset of historical duplicate PRs extracted from 26 popular open source projects in GitHub by using a semi-automatic approach. Furthermore, we present some preliminary applications to illustrate how further researches can be conducted based on this dataset.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {22–25},
numpages = {4},
keywords = {distributed software development, duplicate pull-request, github},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1109/FIE43999.2019.9028685,
author = {Hu, Zhewei and Gehringer, Edward F.},
title = {Improving Feedback on GitHub Pull Requests: A Bots Approach},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FIE43999.2019.9028685},
doi = {10.1109/FIE43999.2019.9028685},
abstract = {Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student’s work. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check different aspects of the code. However, these tools have some limitations. In this paper, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. These bots are either open source or free for OSS projects and can be easily integrated with any GitHub repositories. One-hundred one Computer Science and Computer Engineering masters students participated in our study. The survey results showed that more than 84% of students thought bots can help them to contribute code with better quality. We analyzed 396 pull requests. Results revealed that bots can provide more timely feedback than teaching staff. The Danger Bot is associated with a significant reduction system-specific guideline violations (by 39%), and the Code Climate Bot is associated with a significant 60% decrease of code smells in student contributions. However, we found that the Travis CI Bot did not help student contributions pass automated tests.},
booktitle = {2019 IEEE Frontiers in Education Conference (FIE)},
pages = {1–9},
numpages = {9},
location = {Covington, KY, USA}
}

@inproceedings{10.1145/3183440.3194966,
author = {Ubayashi, Naoyasu and Muraoka, Hokuto and Muramoto, Daiki and Kamei, Yasutaka and Sato, Ryosuke},
title = {Exploring Uncertainty in GitHub OSS Projects: When and How Do Developers Face Uncertainty?},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194966},
doi = {10.1145/3183440.3194966},
abstract = {Recently, many developers begin to notice that uncertainty is a crucial problem in software development. Unfortunately, no one knows how often uncertainty appears or what kinds of uncertainty exist in actual projects, because there are no empirical studies on uncertainty. To deal with this problem, we conduct a large-scale empirical study analyzing commit messages and revision histories of 1,444 OSS projects selected from the GitHub repositories.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {272–273},
numpages = {2},
keywords = {OSS, commit message analysis, uncertainty, empirical study},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/2791060.2791083,
author = {Montalvillo, Leticia and D\'{\i}az, Oscar},
title = {Tuning GitHub for SPL Development: Branching Models &amp; Repository Operations for Product Engineers},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791083},
doi = {10.1145/2791060.2791083},
abstract = {SPLs distinguish between domain engineering (DE) and application engineering (AE). Though each realm has its own lifecycle, they might need to be regularly synchronized to avoid SPL erosion during evolution. This introduces two sync paths: update propagation (from DE to AE) and feedback propagation (from AE to DE). This work looks at how to support sync paths in Version Control Systems (VCSs) using traditional VCS constructs (i.e. merge, branch, fork and pull). In this way, synchronization mismatches can be resolved \`{a} la VCS, i.e. highlighting difference between distinct versions of the same artifact. However, this results in a conceptual gap between how propagations are conceived (i.e. update, feedback) and how propagation are realized (i.e. merge, branch, etc). To close this gap, we propose to enhance existing VCSs with SPL sync paths as first-class operations. As a proof-of-concept, we use Web Augmentation techniques to extend GitHub's Web pages with this extra functionality. Through a single click, product engineers can now (1) generate product repositories, (2) update propagating newer feature versions, or (3), feedback propagating product customizations amenable to be upgraded as core assets.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {111–120},
numpages = {10},
keywords = {change propagation, VCS, SPL evolution, branching model},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2468356.2468382,
author = {McDonald, Nora and Goggins, Sean},
title = {Performance and Participation in Open Source Software on GitHub},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468382},
doi = {10.1145/2468356.2468382},
abstract = {A few studies have attempted to provide metrics of success in open source software (OSS) projects but the role a code hosting workspace plays in how performance is viewed and measured is little examined. We conducted qualitative, exploratory research with lead and core developers on three successful projects on GitHub to understand how OSS communities on GitHub measure success. These results were obtained in connection with a larger project that is designed to understand the structure of code hosting platforms in relation to participation and performance. We report two main findings. First, lead and core members of the projects we interviewed display a nuanced understanding of community participation in their assessment of success. Second, they attribute increased participation on their projects to the features and usability provided by GitHub.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {139–144},
numpages = {6},
keywords = {social computing, open source software, performance},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.5555/2623201.2623216,
author = {Onoue, Saya and Hata, Hideaki and Matsumoto, Ken-ichi},
title = {A Study of the Characteristics of Developers' Activities in GitHub},
year = {2013},
isbn = {9781479921447},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {What types of developers do active software projects have? This paper presents a study of the characteristics of developers' activities in open source software development. GitHub, a widely-used hosting service for software development projects, provides APIs for collecting various kinds of GitHub data. To clarify the characteristics of developers' activities, we used these APIs to investigate GitHub events generated by each developer. Using this information, we categorized developers based on measures such as whether they prefer communication by coding or comments, or whether they are specialists or generalists. Our study indicates that active software projects have various kinds of developers characterized by different types of development activities.},
booktitle = {Proceedings of the 2013 20th Asia-Pacific Software Engineering Conference (APSEC) - Volume 02},
pages = {7–12},
numpages = {6},
series = {APSEC '13}
}

@inproceedings{10.1145/3350546.3352519,
author = {Horawalavithana, Sameera and Bhattacharjee, Abhishek and Liu, Renhao and Choudhury, Nazim and O. Hall, Lawrence and Iamnitchi, Adriana},
title = {Mentions of Security Vulnerabilities on Reddit, Twitter and GitHub},
year = {2019},
isbn = {9781450369343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350546.3352519},
doi = {10.1145/3350546.3352519},
abstract = {Activity on social media is seen as a relevant sensor for different aspects of the society. In a heavily digitized society, security vulnerabilities pose a significant threat that is publicly discussed on social media. This study presents a comparison of user-generated content related to security vulnerabilities on three digital platforms: two social media conversation channels (Reddit and Twitter) and a collaborative software development platform (GitHub). Our data analysis shows that while more security vulnerabilities are discussed on Twitter, relevant conversations go viral earlier on Reddit. We show that the two social media platforms can be used to accurately predict activity on GitHub. },
booktitle = {IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {200–207},
numpages = {8},
location = {Thessaloniki, Greece},
series = {WI '19}
}

@inproceedings{10.1145/2675133.2675284,
author = {Zagalsky, Alexey and Feliciano, Joseph and Storey, Margaret-Anne and Zhao, Yiyun and Wang, Weiliang},
title = {The Emergence of GitHub as a Collaborative Platform for Education},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675284},
doi = {10.1145/2675133.2675284},
abstract = {The software development community has embraced GitHub as an essential platform for managing their software projects. GitHub has created efficiencies and helped improve the way software professionals work. It not only provides a traceable project repository, but it acts as a social meeting place for interested parties, supporting communities of practice. Recently, educators have seen the potential in GitHub's collaborative features for managing and improving---perhaps even transforming---the learning experience. In this study, we examine how GitHub is emerging as a collaborative platform for education. We aim to understand how environments such as GitHub---environments that provide social and collaborative features in conjunction with distributed version control---may improve (or possibly hinder) the educational experience for students and teachers. We conduct a qualitative study focusing on how GitHub is being used in education, and the motivations, benefits and challenges it brings.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1906–1917},
numpages = {12},
keywords = {github, education, cscl, learning, qualitative methodology, distributed version control, social media, cscw},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{10.5220/0006367402930300,
author = {Roveda, Riccardo and Arcelli Fontana, Francesca and Raibulet, Claudia and Zanoni, Marco and Rampazzo, Federico},
title = {Does the Migration to GitHub Relate to Internal Software Quality?},
year = {2017},
isbn = {9789897582509},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0006367402930300},
doi = {10.5220/0006367402930300},
abstract = {Software development is more and more influenced by the usage of FLOSS (Free, Libre and Open Source Software) projects. These software projects are developed in web collaborative environments hosted on web platforms, called code forges. Many code forges exist, with different capabilities. Github is perhaps the largest code forge available, and many projects have been migrated from different code forges to Github. Given its success, we want to understand if its adoption has effect on the projects' internal quality. To consider objective measures of internal quality, we apply four known tools performing static analysis to extract metrics and code anomalies. These data is extracted on six versions of six FLOSS projects, and compared to understand if the migration to Github had any consistent effect over any of the considered measures.},
booktitle = {Proceedings of the 12th International Conference on Evaluation of Novel Approaches to Software Engineering},
pages = {293–300},
numpages = {8},
keywords = {Trend Analysis., Migration To GitHub, Quality Metrics, Code Smells},
location = {Porto, Portugal},
series = {ENASE 2017}
}

@inproceedings{10.1145/3034950.3034957,
author = {Maqsood, Junaid and Eshraghi, Iman and Ali, Syed Sarmad},
title = {Success or Failure Identification for GitHub's Open Source Projects},
year = {2017},
isbn = {9781450348348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034950.3034957},
doi = {10.1145/3034950.3034957},
abstract = {In this research we have tried to identify successful and unsuccessful projects on GitHub from a sample of 5000 randomly picked projects in a number of randomly selected languages (Java, PHP, JavaScript, C#/C++, HTML). We have selected 1000 projects for each of these languages through the publicly available GitHub API, refined our dataset, and applied different machine learning algorithms to achieve our aim. We initially implemented numerous queries against the dataset and found meaningful relationships and correlations between some of the fetched attributes which have an effect on the popularity of these projects. Later we could develop an application that will determine the success or failure of a specific open source project.},
booktitle = {Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {145–150},
numpages = {6},
keywords = {GitHub, Git, GHTorrent, Data Mining, Open Source, Machine Learning, Truck-Factor, MSR, Source Forge, WEKA},
location = {Wuhan, China},
series = {ICMSS '17}
}

@inproceedings{10.1109/MSR.2017.52,
author = {Noten, Jeroen and Mengerink, Josh G. M. and Serebrenik, Alexander},
title = {A Data Set of OCL Expressions on GitHub},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.52},
doi = {10.1109/MSR.2017.52},
abstract = {In model driven engineering (MDE), meta-models are the central artifacts. As a complement, the Object Constraint Language (OCL) is a language used to express constraints and operations on meta-models. The Eclipse Modeling Framework (EMF) provides an implementation of OCL, enabling OCL annotated meta-models.Existing empirical studies of the OCL have been conducted on small collections of data. To facilitate empirical research into the OCL on a larger scale, we present the first publicly-available data set of OCL expressions. The data set contains 9188 OCL expressions originating from 504 EMF meta-models in 245 systematically selected GitHub repositories. Both the original meta-models and the generated abstract syntax trees are included, allowing for a variety of empirical studies of the OCL. To illustrate the applicability of this data set in practice, we performed three case studies.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {531–534},
numpages = {4},
keywords = {GitHub, OCL, data set},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/2601248.2601269,
author = {Tomassetti, Federico and Torchiano, Marco},
title = {An Empirical Assessment of Polyglot-Ism in GitHub},
year = {2014},
isbn = {9781450324762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2601248.2601269},
doi = {10.1145/2601248.2601269},
abstract = {In this paper we study how the language cocktails are composed. How many languages are used in each software projects, which language types are used and which languages are typically used together. Our study was done on a sample of over 15,000 projects from the largest software forge, GitHub. The results show that many languages are used in each project: 96% projects employ at least 2 languages, over 50% employ at least two programming languages. Finally, there are strong relations between different languages: hence sets of languages tend to be adopted together.},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {17},
numpages = {4},
keywords = {polyglot development},
location = {London, England, United Kingdom},
series = {EASE '14}
}

@inproceedings{10.1109/MSR.2019.00054,
author = {Montandon, Jo\~{a}o Eduardo and Silva, Luciana Lourdes and Valente, Marco Tulio},
title = {Identifying Experts in Software Libraries and Frameworks among GitHub Users},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00054},
doi = {10.1109/MSR.2019.00054},
abstract = {Software development increasingly depends on libraries and frameworks to increase productivity and reduce time-to-market. Despite this fact, we still lack techniques to assess developers expertise in widely popular libraries and frameworks. In this paper, we evaluate the performance of unsupervised (based on clustering) and supervised machine learning classifiers (Random Forest and SVM) to identify experts in three popular JavaScript libraries: facebook/react, mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 features about developers activity on GitHub projects, including commits on source code files that depend on these libraries. We also build a ground truth including the expertise of 575 developers on the studied libraries, as self-reported by them in a survey. Based on our findings, we document the challenges of using machine learning classifiers to predict expertise in software libraries, using features extracted from GitHub. Then, we propose a method to identify library experts based on clustering feature data from GitHub; by triangulating the results of this method with information available on Linkedin profiles, we show that it is able to recommend dozens of GitHub users with evidences of being experts in the studied JavaScript libraries. We also provide a public dataset with the expertise of 575 developers on the studied libraries.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {276–287},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.5555/2735522.2735527,
author = {Badashian, Ali Sajedi and Esteki, Afsaneh and Gholipour, Ameneh and Hindle, Abram and Stroulia, Eleni},
title = {Involvement, Contribution and Influence in GitHub and Stack Overflow},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software developers are increasingly adopting social-media platforms to contribute to software development, learn and develop a reputation for themselves. GitHub supports version-controlled code sharing and social-networking functionalities and Stack Overflow is a social forum for question answering on programming topics. Motivated by the features' overlap of the two networks, we set out to mine and analyze and correlate the members' core contributions, editorial activities and influence in the two networks. We aim to better understand the similarities and differences of the members' contributions in the two platforms and their evolution over time. In this context, while studying the activities of different user groups, we conducted a three-step investigation of GitHub activity, Stack Overflow activity and inter-network activity over a five-year period. We report our findings on interesting membership and activity patterns within each platform and some relations between the two.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {19–33},
numpages = {15},
keywords = {time series analysis, GitHub, StackOverflow, mining software repositories, cross-network analysis},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/2970276.2970283,
author = {Rahman, Mohammad Masudur and Roy, Chanchal K. and Redl, Jesse and Collins, Jason A.},
title = {CORRECT: Code Reviewer Recommendation at GitHub for Vendasta Technologies},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970283},
doi = {10.1145/2970276.2970283},
abstract = { Peer code review locates common coding standard violations and simple logical errors in the early phases of software development, and thus, reduces overall cost. Unfortunately, at GitHub, identifying an appropriate code reviewer for a pull request is challenging given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation tool-CORRECT-that considers not only the relevant cross-project work experience (e.g., external library experience) of a developer but also her experience in certain specialized technologies (e.g., Google App Engine) associated with a pull request for determining her expertise as a potential code reviewer. We design our tool using client-server architecture, and then package the solution as a Google Chrome plug-in. Once the developer initiates a new pull request at GitHub, our tool automatically analyzes the request, mines two relevant histories, and then returns a ranked list of appropriate code reviewers for the request within the browser's context. Demo: https://www.youtube.com/watch?v=rXU1wTD6QQ0 },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {792–797},
numpages = {6},
keywords = {cross-project experience, specialized technology experience, pull request, Code reviewer recommendation, GitHub},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.1145/3180155.3182535,
author = {Borle, Neil C. and Feghhi, Meysam and Stroulia, Eleni and Greiner, Russell and Hindle, Abram},
title = {Analyzing the Effects of Test Driven Development in GitHub},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3182535},
doi = {10.1145/3180155.3182535},
abstract = {Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. Previous work by Fucci et al. [2, 3] engaged in laboratory studies of developers actively engaged in test-driven development practices. Fucci et al. found little difference between test-first behaviour of TDD and test-later behaviour. To that end, we opted to conduct a study about TDD behaviours in the "wild" rather than in the laboratory. Thus we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and that contained at least one test file. We compared how the TDD sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. We found that Java TDD projects were relatively rare. In addition, there were very few significant differences in any of the metrics we used to compare TDD-like and non-TDD projects; therefore, our results do not reveal any observable benefits from using TDD.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1062},
numpages = {1},
keywords = {continuous integration, GitHub repositories, human factors in software development, test driven development},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3092703.3098230,
author = {Casalnuovo, Casey and Suchak, Yagnik and Ray, Baishakhi and Rubio-Gonz\'{a}lez, Cindy},
title = {GitcProc: A Tool for Processing and Classifying GitHub Commits},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092703.3098230},
doi = {10.1145/3092703.3098230},
abstract = { Sites such as GitHub have created a vast collection of software artifacts that researchers interested in understanding and improving software systems can use. Current tools for processing such GitHub data tend to target project metadata and avoid source code processing, or process source code in a manner that requires significant effort for each language supported. This paper presents GitcProc, a lightweight tool based on regular expressions and source code blocks, which downloads projects and extracts their project history, including fine-grained source code information and development time bug fixes. GitcProc can track changes to both single-line and block source code structures and associate these changes to the surrounding function context with minimal set up required from users. We demonstrate GitcProc's ability to capture changes in multiple languages by evaluating it on C, C++, Java, and Python projects, and show it finds bug fixes and the context of source code changes effectively with few false positives. },
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {396–399},
numpages = {4},
keywords = {Information Extraction, Git Mining Tool, Language Independence},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.1145/3368089.3409746,
author = {Tan, Xin and Zhou, Minghui and Sun, Zeyu},
title = {A First Look at Good First Issues on GitHub},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409746},
doi = {10.1145/3368089.3409746},
abstract = {Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time. To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers. However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain. To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices. By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results. We find that more and more projects are applying this mechanism in the past decade, especially the popular projects. Compared to common issues, GFIs usually need more days to be solved. While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers. We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective. We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc. Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {398–409},
numpages = {12},
keywords = {Onborading, Open Source software, Good first issues, Newcomers},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/2597073.2597117,
author = {Pletea, Daniel and Vasilescu, Bogdan and Serebrenik, Alexander},
title = {Security and Emotion: Sentiment Analysis of Security Discussions on GitHub},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597117},
doi = {10.1145/2597073.2597117},
abstract = { Application security is becoming increasingly prevalent during software and especially web application development. Consequently, countermeasures are continuously being discussed and built into applications, with the goal of reducing the risk that unauthorized code will be able to access, steal, modify, or delete sensitive data. In this paper we gauged the presence and atmosphere surrounding security-related discussions on GitHub, as mined from discussions around commits and pull requests. First, we found that security related discussions account for approximately 10% of all discussions on GitHub. Second, we found that more negative emotions are expressed in security-related discussions than in other discussions. These findings confirm the importance of properly training developers to address security concerns in their applications as well as the need to test applications thoroughly for security vulnerabilities in order to reduce frustration and improve overall project atmosphere. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {348–351},
numpages = {4},
keywords = {Security, mining challenge, GitHub, sentiment analysis},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.5555/2820518.2820601,
author = {Vasilescu, Bogdan and Serebrenik, Alexander and Filkov, Vladimir},
title = {A Data Set for Social Diversity Studies of GitHub Teams},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {Like any other team oriented activity, the software development process is effected by social diversity in the programmer teams. The effect of team diversity can be significant, but also complex, especially in decentralized teams. Discerning the precise contribution of diversity on teams' effectiveness requires quantitative studies of large data sets.Here we present for the first time a large data set of social diversity attributes of programmers in GitHub teams. Using alias resolution, location data, and gender inference techniques, we collected a team social diversity data set of 23,493 GitHub projects. We illustrate how the data set can be used in practice with a series of case studies, and we hope its availability will foster more interest in studying diversity issues in software teams.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {514–517},
numpages = {4},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.5555/2819009.2819163,
author = {Vendome, Christopher},
title = {A Large Scale Study of License Usage on GitHub},
year = {2015},
publisher = {IEEE Press},
abstract = {The open source community relies upon licensing in order to govern the distribution, modification, and reuse of existing code. These licenses evolve to better suit the requirements of the development communities and to cope with unaddressed or new legal issues. In this paper, we report the results of a large empirical study conducted over the change history of 16,221 open source Java projects mined from GitHub. Our study investigates how licensing usage and adoption changes over a period of ten years. We consider both the distribution of license usage within projects of a rapidly growing forge and the extent that new versions of licenses are introduced in these projects.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {772–774},
numpages = {3},
keywords = {software licenses, mining software repositories, empirical studies},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3236024.3264585,
author = {Reinhardt, Anastasia and Zhang, Tianyi and Mathur, Mihir and Kim, Miryung},
title = {Augmenting Stack Overflow with API Usage Patterns Mined from GitHub},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3264585},
doi = {10.1145/3236024.3264585},
abstract = {Programmers often consult Q&amp;A websites such as Stack Overflow (SO) to learn new APIs. However, online code snippets are not always complete or reliable in terms of API usage. To assess online code snippets, we build a Chrome extension, ExampleCheck that detects API usage violations in SO posts using API usage patterns mined from 380K GitHub projects. It quantifies how many GitHub examples follow common API usage and illustrates how to remedy the detected violation in a given SO snippet. With ExampleCheck, programmers can easily identify the pitfalls of a given SO snippet and learn how much it deviates from common API usage patterns in GitHub. The demo video is at https://youtu.be/WOnN-wQZsH0.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {880–883},
numpages = {4},
keywords = {code assessment, online Q&amp;A forum, API usage pattern},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1109/WAINA.2014.110,
author = {Rusk, David and Coady, Yvonne},
title = {Location-Based Analysis of Developers and Technologies on GitHub},
year = {2014},
isbn = {9781479926534},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WAINA.2014.110},
doi = {10.1109/WAINA.2014.110},
abstract = {GitHub is a popular platform for collaboration on open source projects. It also provides a rich API to query various aspects of the public activity. This combination of a popular social coding website with a rich API presents an opportunity for researchers to gather empirical data about software development practices. There are an overwhelmingly large number of competing platforms to choose from in software development. Knowing which are gaining widespread adoption is valuable both for individual developers trying to increase their employability, as well as software engineers deciding which technology to use in their next big project. In terms of a developer's employability and an employer's ability to find available developers in their economic region, it is important to identify the most common technologies by geographic location. In this paper, analyses are done on GitHub data taking into account the developers' location and their technology usage. A web-based tool has been developed to interact with and visualize this data. In its current state of development, the tool summarizes the amount of code developers have in their public repositories broken down by programming language, and summarizes data about programmers using specific programming languages. This allows website visitors to get an immediate picture of the programming language usage in their region of interest. Future research could expand this work to technologies beyond programming languages such as frameworks and libraries.},
booktitle = {Proceedings of the 2014 28th International Conference on Advanced Information Networking and Applications Workshops},
pages = {681–685},
numpages = {5},
keywords = {GitHub, REST API, software repository, programming languages, open source},
series = {WAINA '14}
}

@inproceedings{10.1145/2556420.2556483,
author = {Wu, Yu and Kropczynski, Jessica and Shih, Patrick C. and Carroll, John M.},
title = {Exploring the Ecosystem of Software Developers on GitHub and Other Platforms},
year = {2014},
isbn = {9781450325417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556420.2556483},
doi = {10.1145/2556420.2556483},
abstract = {GitHub provides various social features for developers to collaborate with others. Those features are important for developers to coordinate their work (Dabbish et al., 2012; Marlow et al., 2013). We hypothesized that the social system of GitHub users was bound by system interactions such that contributing to similar code repositories would lead to users following one another on GitHub or vice versa. Using a quadratic assignment procedure (QAP) correlation, however, only a weak correlation among followship and production activities (code, issue, and wiki contributions) was found. Survey with GitHub users revealed an ecosystem on the Internet for software developers, which includes many platforms, such as Forrst, Twitter, and Hacker News, among others. Developers make social introductions and other interactions on these platforms and engage with one anther on GitHub. Due to these preliminary findings, we describe GitHub as a part of a larger ecosystem of developer interactions.},
booktitle = {Proceedings of the Companion Publication of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {265–268},
numpages = {4},
keywords = {ecosystem, follow, social connection, GitHub},
location = {Baltimore, Maryland, USA},
series = {CSCW Companion '14}
}

@inproceedings{10.1145/3196398.3196456,
author = {Schermann, Gerald and Zumberi, Sali and Cito, J\"{u}rgen},
title = {Structured Information on State and Evolution of Dockerfiles on Github},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196456},
doi = {10.1145/3196398.3196456},
abstract = {Docker containers are standardized, self-contained units of applications, packaged with their dependencies and execution environment. The environment is defined in a Dockerfile that specifies the steps to reach a certain system state as infrastructure code, with the aim of enabling reproducible builds of the container. To lay the groundwork for research on infrastructure code, we collected structured information about the state and the evolution of Dockerfiles on GitHub and release it as a PostgreSQL database archive (over 100,000 unique Dockerfiles in over 15,000 GitHub projects). Our dataset enables answering a multitude of interesting research questions related to different kinds of software evolution behavior in the Docker ecosystem.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {26–29},
numpages = {4},
keywords = {docker, github, mining software repositories, containers},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/2786805.2786850,
author = {Vasilescu, Bogdan and Yu, Yue and Wang, Huaimin and Devanbu, Premkumar and Filkov, Vladimir},
title = {Quality and Productivity Outcomes Relating to Continuous Integration in GitHub},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786850},
doi = {10.1145/2786805.2786850},
abstract = { Software processes comprise many steps; coding is followed by building, integration testing, system testing, deployment, operations, among others. Software process integration and automation have been areas of key concern in software engineering, ever since the pioneering work of Osterweil; market pressures for Agility, and open, decentralized, software development have provided additional pressures for progress in this area. But do these innovations actually help projects? Given the numerous confounding factors that can influence project performance, it can be a challenge to discern the effects of process integration and automation. Software project ecosystems such as GitHub provide a new opportunity in this regard: one can readily find large numbers of projects in various stages of process integration and automation, and gather data on various influencing factors as well as productivity and quality outcomes. In this paper we use large, historical data on process metrics and outcomes in GitHub projects to discern the effects of one specific innovation in process automation: continuous integration. Our main finding is that continuous integration improves the productivity of project teams, who can integrate more outside contributions, without an observable diminishment in code quality. },
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {805–816},
numpages = {12},
keywords = {pull requests, Continuous integration, GitHub},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/2597073.2597120,
author = {Aggarwal, Karan and Hindle, Abram and Stroulia, Eleni},
title = {Co-Evolution of Project Documentation and Popularity within Github},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597120},
doi = {10.1145/2597073.2597120},
abstract = { Github is a very popular collaborative software-development platform that provides typical source-code management and issue tracking features augmented by strong social-networking features such as following developers and watching projects. These features help ``spread the word'' about individuals and projects, building the reputation of the former and increasing the popularity of the latter. In this paper, we investigate the relation between project popularity and regular, consistent documentation updates. We found strong indicators that consistently popular projects exhibited consistent documentation effort and that this effort tended to attract more documentation collaborators. We also found that frameworks required more documentation effort than libraries to achieve similar adoption success, especially in the initial phase. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {360–363},
numpages = {4},
keywords = {Cross Correlation, Popularity, Documentation Change},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3301326.3301380,
author = {Pooput, Panthip and Muenchaisri, Pornsiri},
title = {Finding Impact Factors for Rejection of Pull Requests on GitHub},
year = {2018},
isbn = {9781450365536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301326.3301380},
doi = {10.1145/3301326.3301380},
abstract = {A pull request is an important method for code contributions in GitHub that will be submitted when the developers would like to merge their code changes from their local machine to the main repository on which all source code in the project are stored. Before merging the code changes into the main repository, the developers have to request for a permission. If their source code is allowed to merge, the pull request status is accepted. On the other hand, if their source code is not allowed to merge, the pull request status is rejected. The pull request status may be rejected due to several factors, such as code complexity, code quality, the number of changed files, etc. Fixing the rejected pull requests will take some extra effort and time which may affect the project cost and timeline. This paper aims at finding the impact factors that are associated with the rejection of pull requests on GitHub and also discovering the relationships among impact factors by using the association rules in data mining.},
booktitle = {Proceedings of the 2018 VII International Conference on Network, Communication and Computing},
pages = {70–76},
numpages = {7},
keywords = {Association rules, Data mining, GitHub, Ansible, Pull Request},
location = {Taipei City, Taiwan},
series = {ICNCC 2018}
}

@inproceedings{10.1145/3397537.3397551,
author = {Mattis, Toni and Rein, Patrick and Hirschfeld, Robert},
title = {Three Trillion Lines: Infrastructure for Mining GitHub in the Classroom},
year = {2020},
isbn = {9781450375078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397537.3397551},
doi = {10.1145/3397537.3397551},
abstract = {The increasing interest in collaborative software development on platforms like GitHub has led to the availability of large amounts of data about development activities. The GHTorrent project has recorded a significant proportion of GitHub’s public event stream and hosts the currently largest public dataset of meta-data about open-source development. We describe our infrastructure that makes this data locally available to researchers and students, examples for research activities carried out on this infrastructure, and what we learned from building the system. We identify a need for domain-specific tools, especially databases, that can deal with large-scale code repositories and associated meta-data and outline open challenges to use them more effectively for research and machine learning settings.},
booktitle = {Conference Companion of the 4th International Conference on Art, Science, and Engineering of Programming},
pages = {1–6},
numpages = {6},
keywords = {Repository Mining, Big Code, Teaching, TravisCI, GitHub},
location = {Porto, Portugal},
series = {20}
}

@inproceedings{10.1145/2597073.2597119,
author = {Matragkas, Nicholas and Williams, James R. and Kolovos, Dimitris S. and Paige, Richard F.},
title = {Analysing the 'biodiversity' of Open Source Ecosystems: The GitHub Case},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597119},
doi = {10.1145/2597073.2597119},
abstract = { In nature the diversity of species and genes in ecological communities affects the functioning of these communities. Biologists have found out that more diverse communities appear to be more productive than less diverse communities. Moreover such communities appear to be more stable in the face of perturbations. In this paper, we draw the analogy between ecological communities and Open Source Software (OSS) ecosystems, and we investigate the diversity and structure of OSS communities. To address this question we use the MSR 2014 challenge dataset, which includes data from the top-10 software projects for the top programming languages on GitHub. Our findings show that OSS communities on GitHub consist of 3 types of users (core developers, active users, passive users). Moreover, we show that the percentage of core developers and active users does not change as the project grows and that the majority of members of large projects are passive users. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {356–359},
numpages = {4},
keywords = {Data mining, Data and knowledge visualization},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.5555/2818754.2818825,
author = {Kalliamvakou, Eirini and Damian, Daniela and Blincoe, Kelly and Singer, Leif and German, Daniel M.},
title = {Open Source-Style Collaborative Development Practices in Commercial Projects Using GitHub},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Researchers are currently drawn to study projects hosted on GitHub due to its popularity, ease of obtaining data, and its distinctive built-in social features. GitHub has been found to create a transparent development environment, which together with a pull request-based workflow, provides a lightweight mechanism for committing, reviewing and managing code changes. These features impact how GitHub is used and the benefits it provides to teams' development and collaboration. While most of the evidence we have is from GitHub's use in open source software (oss) projects, GitHub is also used in an increasing number of commercial projects. It is unknown how GitHub supports these projects given that GitHub's workflow model does not intuitively fit the commercial development way of working. In this paper, we report findings from an online survey and interviews with GitHub users on how GitHub is used for collaboration in commercial projects. We found that many commercial projects adopted practices that are more typical of oss projects including reduced communication, more independent work, and self-organization. We discuss how GitHub's transparency and popular workflow can promote open collaboration, allowing organizations to increase code reuse and promote knowledge sharing across their teams.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {574–585},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3328778.3367027,
author = {Malan, David J. and Sharp, Chad and van Assema, Jelle and Yu, Brian and Zidane, Kareem},
title = {CS50's GitHub-Based Tools for Teaching and Learning},
year = {2020},
isbn = {9781450367936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328778.3367027},
doi = {10.1145/3328778.3367027},
abstract = {For CS50 at Harvard, we have developed a suite of free, open-source tools to help students with writing, testing, and submitting programming assignments; and to help teachers grade those assignments and check them for plagiarism. help50, a program that parses error messages and provides beginner-friendly advice to interpreting them, helps students understand and resolve often-cryptic compiler errors. check50 runs a set of automated tests on students' code, providing feedback and hints about where students have made errors. style50 lints students' code, highlighting places where it doesn't meet the course's style guide. submit50 allows students to submit assignments to a GitHub repository, without students needing to have knowledge of git or version control themselves. And compare50, an open-source and customizable alternative to Moss, allows teachers to analyze submissions for similarity, looking for pairs or clusters of submissions that might be the result of improper collaboration. The grading and submission tools require only a GitHub account to use, and can serve as free, extensible alternatives to tools like Codio, Gradescope, and Vocareum. In this workshop, we'll introduce each of the tools, and discuss how to use them for your own classroom. To date, each tool has been deployed to hundreds of students on campus and thousands online. Along the way, we'll discuss how to use the tools effectively, compare and contrast them with other options, identify how the tools have changed students' behavior for the better and for worse, and highlight pedagogical and technological changes we've made to redress the latter. Laptop (with Wi-Fi) required. Linux, macOS, or Windows. Latest version of Chrome.},
booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},
pages = {1393},
numpages = {1},
keywords = {error messages, linting, homework submission, style, open-source, correctness testing},
location = {Portland, OR, USA},
series = {SIGCSE '20}
}

@inproceedings{10.1109/SEmotion.2019.00017,
author = {Ortu, Marco and Marchesi, Michele and Tonelli, Roberto},
title = {Empirical Analysis of Affect of Merged Issues on GitHub},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEmotion.2019.00017},
doi = {10.1109/SEmotion.2019.00017},
abstract = {Pull-request based workflows are popular trends of modern software development platform such as GitHub. A pull-request notifies other developers that new changes are proposed, a code review process follows the pull-request that may be merged in the main branch if other developers accept the changes. Many factors influence the acceptance of pull-requests. Since open source software is based on collaboration, it is essential to discover how the affect expressed by developer discussing pull-request issues, namely how they collaborate, influences the acceptance of the pull-request proposed. In this study we analysed the relations with the affect expressed in pull-request issues' comments and whether an issue is merged in the main branch or not. We focused on pull-request issues and we found that issues with higher level anger, sadness, arousal and valence are less likely to be merged while issues with higher level of valence, joy are more likely to be merged. Positive affect indicates a good collaboration environment, and our finding shows that this healthy collaboration is likely to increase the acceptance of pull-requests.},
booktitle = {Proceedings of the 4th International Workshop on Emotion Awareness in Software Engineering},
pages = {46–48},
numpages = {3},
keywords = {software engineering, human aspect},
location = {Montreal, Quebec, Canada},
series = {SEmotion '19}
}

@inproceedings{10.1145/3017680.3022363,
author = {Kahlon, Amardeep and MacKellar, Bonnie and Kurdia, Anastasia},
title = {GitHub, Tutors, Relatives, and Friends: The Wide Web of Plagiarism (Abstract Only)},
year = {2017},
isbn = {9781450346986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3017680.3022363},
doi = {10.1145/3017680.3022363},
abstract = {Plagiarism is of great concern to faculty in all fields, including computer science as it leads to one certain outcome -- a compromise not just in student learning but also in the entire academic process. Faculty attempt to deal with this epidemic in varied ways such as by writing new course materials each semester, putting a larger or entire grade focus on exams, or even asking individual students to explain their assignments. However, plagiarism remains a source of frustration for both faculty and administrators. This BoF will bring interested faculty together to discuss the various and surprising ways in which students plagiarize, the methods of countering plagiarism, and the currently available tools for detecting plagiarism. Questions we will be discussing include: Do students understand plagiarism in the context of writing software? How can we create an atmosphere that discourages plagiarism, yet fosters collaboration and encourages learning from multiple sources? To what extent can one make an assignment "plagiarism-proof"?},
booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
pages = {726},
numpages = {1},
keywords = {cheating, academic dishonesty, plagiarism, computer science education, programming assignments},
location = {Seattle, Washington, USA},
series = {SIGCSE '17}
}

@inproceedings{10.1145/3361242.3361244,
author = {Wu, Yiwen and Zhang, Yang and Wang, Tao and Wang, Huaimin},
title = {Exploring the Relationship Between Developer Activities and Profile Images on GitHub},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361244},
doi = {10.1145/3361242.3361244},
abstract = {In the GitHub platform, social media profile images are one of many visual components of developers. Besides, developer activities such as reporting issues or following other developers are regarded as important development and self-expression behaviors. However, to the best of our knowledge, no study has yet been conducted to study the relationship between GitHub developer activities and profile images. In this paper, we aim to investigate the relationship between developer activities and profile images to gain some insights into the developers' internal properties. During our experiments, we manually classify profile images into seven categories. Next, we investigate the relationship between developer's demographic information and developer activity. Further, using logistic regression analysis, when controlled for various variables, we statistically identify and quantify the relationships between developer activities and profile image categories. We find that several profile image categories significantly correlate with developer's demographic information and activities. We also provide a rich resource of research ideas for further study. Our examination and analysis provide insights into the developers' internal properties when using different profile images. Moreover, this study is the first step in understanding the relationship between developer activities and profile images on GitHub.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {7},
numpages = {10},
keywords = {Developer activity, GitHub, Profile image, Internal property},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@inproceedings{10.1145/2875913.2875914,
author = {Zhang, Yang and Wang, Huaimin and Yin, Gang and Wang, Tao and Yu, Yue},
title = {Exploring the Use of @-Mention to Assist Software Development in GitHub},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875914},
doi = {10.1145/2875913.2875914},
abstract = {Recently, many researches propose that social media tools can promote the collaboration among developers, which are beneficial to the software development. Nevertheless, there is little empirical evidence to confirm that using @-mention has indeed a beneficial impact on the issues in GitHub. In this paper, we analyze the data from GitHub and give some insights on how @-mention is used in the issues (general-issues and pull-requests). Our statistical results indicate that, @-mention attracts more participants and tends to be used in the difficult issues. @-mention favors the solving process of issues by enlarging the visibility of issues and facilitating the developers' collaboration. In addition to this global study, our study also build a @-network based on the @-mention database we extract. Through the @-network, we can mine the relationships and characteristics of developers in GitHub's issues.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {83–92},
numpages = {10},
keywords = {@-mention, Social media, Issues, GitHub},
location = {Wuhan, China},
series = {Internetware '15}
}

@inproceedings{10.1109/MSR.2019.00022,
author = {Treude, Christoph and Wagner, Markus},
title = {Predicting Good Configurations for GitHub and Stack Overflow Topic Models},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00022},
doi = {10.1109/MSR.2019.00022},
abstract = {Software repositories contain large amounts of textual data, ranging from source code comments and issue descriptions to questions, answers, and comments on Stack Overflow. To make sense of this textual data, topic modelling is frequently used as a text-mining tool for the discovery of hidden semantic structures in text bodies. Latent Dirichlet allocation (LDA) is a commonly used topic model that aims to explain the structure of a corpus by grouping texts. LDA requires multiple parameters to work well, and there are only rough and sometimes conflicting guidelines available on how these parameters should be set. In this paper, we contribute (i) a broad study of parameters to arrive at good local optima for GitHub and Stack Overflow text corpora, (ii) an a-posteriori characterisation of text corpora related to eight programming languages, and (iii) an analysis of corpus feature importance via per-corpus LDA configuration. We find that (1) popular rules of thumb for topic modelling parameter configuration are not applicable to the corpora used in our experiments, (2) corpora sampled from GitHub and Stack Overflow have different characteristics and require different configurations to achieve good model fit, and (3) we can predict good configurations for unseen corpora reliably. These findings support researchers and practitioners in efficiently determining suitable configurations for topic modelling when analysing textual data contained in software repositories.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {84–95},
numpages = {12},
keywords = {topic modelling, corpus features, algorithm portfolio},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3202667.3202694,
author = {Peng, Zhenhui and Yoo, Jeehoon and Xia, Meng and Kim, Sunghun and Ma, Xiaojuan},
title = {Exploring How Software Developers Work with Mention Bot in GitHub},
year = {2018},
isbn = {9781450365086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3202667.3202694},
doi = {10.1145/3202667.3202694},
abstract = {Recently, major software development platforms have started to provide automatic reviewer recommendation (ARR) services for pull requests, to improve the collaborative coding review process. However, the user experience of ARR is under-investigated. In this paper, we use a two-stage mixed-methods approach to study how software developers perceive and work with the Facebook mention bot, one of the most popular ARR bots in GitHub. Specifically, in Stage I, we conduct archival analysis on projects employing mention bot and a user survey to investigate the bot's performance. A year later, in Stage II, we revisit these projects and conduct additional surveys and interviews with three user groups: project owners, contributors and reviewers. Results show that developers appreciate mention bot saving their effort, but are bothered by its unstable setting and unbalanced workload allocation. We conclude with design considerations for improving ARR services.},
booktitle = {Proceedings of the Sixth International Symposium of Chinese CHI},
pages = {152–155},
numpages = {4},
keywords = {user experience, mixed-methods, Automatic reviewer recommendation services, software development platform},
location = {Montreal, QC, Canada},
series = {ChineseCHI '18}
}

@inproceedings{10.1145/2568225.2568315,
author = {Tsay, Jason and Dabbish, Laura and Herbsleb, James},
title = {Influence of Social and Technical Factors for Evaluating Contribution in GitHub},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568315},
doi = {10.1145/2568225.2568315},
abstract = { Open source software is commonly portrayed as a meritocracy, where decisions are based solely on their technical merit. However, literature on open source suggests a complex social structure underlying the meritocracy. Social work environments such as GitHub make the relationships between users and between users and work artifacts transparent. This transparency enables developers to better use information such as technical value and social connections when making work decisions. We present a study on open source software contribution in GitHub that focuses on the task of evaluating pull requests, which are one of the primary methods for contributing code in GitHub. We analyzed the association of various technical and social measures with the likelihood of contribution acceptance. We found that project managers made use of information signaling both good technical contribution practices for a pull request and the strength of the social connection between the submitter and project manager when evaluating pull requests. Pull requests with many comments were much less likely to be accepted, moderated by the submitter's prior interaction in the project. Well-established projects were more conservative in accepting pull requests. These findings provide evidence that developers use both technical and social information when evaluating potential contributions to open source software projects. },
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {356–366},
numpages = {11},
keywords = {social media, social computing, signaling theory, transparency, open source, GitHub, contribution},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/2788993.2789838,
author = {Longo, Justin and Kelley, Tanya M.},
title = {Use of GitHub as a Platform for Open Collaboration on Text Documents},
year = {2015},
isbn = {9781450336666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2788993.2789838},
doi = {10.1145/2788993.2789838},
abstract = {Recently, researchers are paying attention to the use of the software development and code-hosting web service GitHub for other collaborative purposes, including a class of activity referred to as document, text, or prose collaboration. These alternative uses of GitHub as a platform for sharing non-code artifacts represent an important modification in the practice of open collaboration. We survey cases where GitHub has been used to facilitate collaboration on non-code outputs, identify its strengths and weaknesses when used in this mode, and propose conditions for successful collaborations on co-created text documents.},
booktitle = {Proceedings of the 11th International Symposium on Open Collaboration},
articleno = {22},
numpages = {2},
keywords = {documents, co-creation, open collaboration, GitHub},
location = {San Francisco, California},
series = {OpenSym '15}
}

@inproceedings{10.1145/3196398.3196429,
author = {Middleton, Justin and Murphy-Hill, Emerson and Green, Demetrius and Meade, Adam and Mayer, Roger and White, David and McDonald, Steve},
title = {Which Contributions Predict Whether Developers Are Accepted into Github Teams},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196429},
doi = {10.1145/3196398.3196429},
abstract = {Open-source software (OSS) often evolves from volunteer contributions, so OSS development teams must cooperate with their communities to attract new developers. However, in view of the myriad ways that developers interact over platforms for OSS development, observers of these communities may have trouble discerning, and thus learning from, the successful patterns of developer-to-team interactions that lead to eventual team acceptance. In this work, we study project communities on GitHub to discover which forms of software contribution characterize developers who begin as development team outsiders and eventually join the team, in contrast to developers who remain team outsiders. From this, we identify and compare the forms of contribution, such as pull requests and several forms of discussion comments, that influence whether new developers join OSS teams, and we discuss the implications that these behavioral patterns have for the focus of designers and educators.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {403–413},
numpages = {11},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/2666539.2666570,
author = {Zhang, Lingxiao and Zou, Yanzhen and Xie, Bing and Zhu, Zixiao},
title = {Recommending Relevant Projects via User Behaviour: An Exploratory Study on Github},
year = {2014},
isbn = {9781450332248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666539.2666570},
doi = {10.1145/2666539.2666570},
abstract = { Social coding sites (e.g., Github) provide various features like Forking and Sending Pull-requests to support crowd-based software engineering. When using these features, a large amount of user behavior data is recorded. User behavior data can reflect developers preferences and interests in software development activities. Online service providers in many fields have been using user behavior data to discover user preferences and interests to achieve various purposes. In the field of software engineering however, there has been few studies in mining large amount of user behavior data. Our goal is to design an approach based on user behavior data, to recommend relevant open source projects to developers, which can be helpful in activities like searching for the right open source solutions to quickly build prototypes. In this paper, we explore the possibilities of such a method by conducting a set of experiments on selected data sets from Github. We find it a promising direction in mining projects' relevance from user behavior data. Our study also obtain some important issues that is worth considering in this method. },
booktitle = {Proceedings of the 1st International Workshop on Crowd-Based Software Development Methods and Technologies},
pages = {25–30},
numpages = {6},
keywords = {Github, Social coding, Crowd-base software engineering, Recommendation system},
location = {Hong Kong, China},
series = {CrowdSoft 2014}
}

@inproceedings{10.1145/2889160.2891035,
author = {Rastogi, Ayushi},
title = {Do Biases Related to Geographical Location Influence Work-Related Decisions in GitHub?},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2891035},
doi = {10.1145/2889160.2891035},
abstract = {Visible demographic characteristics are seen as elements of bias in offline work environments. In this study, we investigate the influence of the geographical location on the evaluation of pull requests in GitHub -- the most popular online collaborative code development environment. We use a mixed-methods approach and present analyses of 70,000+ pull requests and 2,500+ survey responses. Quantitative analysis of GitHub projects' data suggests that the geographical location significantly explains the pull request acceptance decisions. These observations are in agreement with the perceptions of submitters based on their experiences with bias. Integrators feel that it is easy to work with contributors from the same geographical location and that they encourage contributors from the same geographical location. However, integrators do not feel that contributors from some countries are better at writing pull requests compared to others.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {665–667},
numpages = {3},
keywords = {empirical studies, software process, empirical software engineering},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1109/MSR.2019.00047,
author = {Manes, Saraj Singh and Baysal, Olga},
title = {How Often and What StackOverflow Posts Do Developers Reference in Their GitHub Projects?},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00047},
doi = {10.1109/MSR.2019.00047},
abstract = {Stack Overflow (SO) is a popular Q&amp;A forum for software developers, providing a large amount of copyable code snippets. While GitHub is an independent code collaboration platform, developers often reuse SO code in their GitHub projects. In this paper, we investigate how often GitHub developers re-use code snippets from the SO forum, as well as what concepts they are more likely to reference in their code. To accomplish our goal, we mine SOTorrent dataset that provides connectivity between code snippets on the SO posts with software projects hosted on GitHub. We then study the characteristics of GitHub projects that reference SO posts and discover popular SO discussions that happen in GitHub projects. Our results demonstrate that on average developers make 45 references to SO posts in their projects, with the highest number of references being made within the JavaScript code. We also found that 79% of the SO posts with code snippets that are referenced in GitHub code do change over time (at least ones) raising code maintainability and reliability concerns.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {235–239},
numpages = {5},
keywords = {code snippets, open-source, GitHub, tags, GHTorrent, code evolution, StackOverflow, SOTorrent},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2635868.2635882,
author = {Tsay, Jason and Dabbish, Laura and Herbsleb, James},
title = {Let's Talk about It: Evaluating Contributions through Discussion in GitHub},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635882},
doi = {10.1145/2635868.2635882},
abstract = { Open source software projects often rely on code contributions from a wide variety of developers to extend the capabilities of their software. Project members evaluate these contributions and often engage in extended discussions to decide whether to integrate changes. These discussions have important implications for project management regarding new contributors and evolution of project requirements and direction. We present a study of how developers in open work environments evaluate and discuss pull requests, a primary method of contribution in GitHub, analyzing a sample of extended discussions around pull requests and interviews with GitHub developers. We found that developers raised issues around contributions over both the appropriateness of the problem that the submitter attempted to solve and the correctness of the implemented solution. Both core project members and third-party stakeholders discussed and sometimes implemented alternative solutions to address these issues. Different stakeholders also influenced the outcome of the evaluation by eliciting support from different communities such as dependent projects or even companies. We also found that evaluation outcomes may be more complex than simply acceptance or rejection. In some cases, although a submitter's contribution was rejected, the core team fulfilled the submitter's technical goals by implementing an alternative solution. We found that the level of a submitter's prior interaction on a project changed how politely developers discussed the contribution and the nature of proposed alternative solutions. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {144–154},
numpages = {11},
keywords = {social computing, transparency, evaluation, social media, contribution, discussion, open source, GitHub},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/3383219.3383227,
author = {Di Sipio, Claudio and Rubei, Riccardo and Di Ruscio, Davide and Nguyen, Phuong T.},
title = {A Multinomial Na\"{\i}ve Bayesian (MNB) Network to Automatically Recommend Topics for GitHub Repositories},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383227},
doi = {10.1145/3383219.3383227},
abstract = {GitHub has become a precious service for storing and managing software source code. Over the last year, 10M new developers have joined the GitHub community, contributing to more than 44M repositories. In order to help developers increase the reachability of their repositories, in 2017 GitHub introduced the possibility to classify them by means of topics. However, assigning wrong topics to a given repository can compromise the possibility of helping other developers approach it, and thus preventing them from contributing to its development.In this paper we investigate the application of Multinomial Na\"{\i}ve Bayesian (MNB) networks to automatically classify GitHub repositories. By analyzing the README file(s) of the repository to be classified and the source code implementing it, the conceived approach is able to recommend GitHub topics. To the best of our knowledge, this is the first supervised approach addressing the considered problem. Consequently, since there exists no suitable baseline for the comparison, we validated the approach by considering different metrics, aiming to study various quality aspects.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {71–80},
numpages = {10},
keywords = {GitHub topics, Multinomial Na\"{\i}ve Bayesian network, Recommender systems},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1109/MSR.2019.00037,
author = {van Tonder, Rijnard and Trockman, Asher and Goues, Claire Le},
title = {A Panel Data Set of Cryptocurrency Development Activity on GitHub},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00037},
doi = {10.1109/MSR.2019.00037},
abstract = {Cryptocurrencies are a significant development in recent years, featuring in global news, the financial sector, and academic research. They also hold a significant presence in open source development, comprising some of the most popular repositories on GitHub. Their openly developed software artifacts thus present a unique and exclusive avenue to quantitatively observe human activity, effort, and software growth for cryptocurrencies. Our data set marks the first concentrated effort toward high-fidelity panel data of cryptocurrency development for a wide range of metrics. The data set is foremost a quantitative measure of developer activity for budding open source cryptocurrency development. We collect metrics like daily commits, contributors, lines of code changes, stars, forks, and subscribers. We also include financial data for each cryptocurrency: the daily price and market capitalization. The data set includes data for 236 cryptocurrencies for 380 days (roughly January 2018 to January 2019). We discuss particularly interesting research opportunities for this combination of data, and release new tooling to enable continuing data collection for future research opportunities as development and application of cryptocurrencies mature.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {186–190},
numpages = {5},
keywords = {open source software, software metrics, cryptocurrency, software quality, github},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2961111.2962633,
author = {Au\'{e}, Joop and Haisma, Michiel and T\'{o}masd\'{o}ttir, Krist\'{\i}n Fj\'{o}la and Bacchelli, Alberto},
title = {Social Diversity and Growth Levels of Open Source Software Projects on GitHub},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962633},
doi = {10.1145/2961111.2962633},
abstract = {Background: Projects of all sizes and impact are leveraging the services of the social coding platform GitHub to collaborate. Since users' information and actions are recorded, GitHub has been mined for over 6 years now to investigate aspects of the collaborative open source software (OSS) development paradigm. Aim: In this research, we use this data to investigate the relation between project growth as a proxy for success, and social diversity. Method: We first categorize active OSS projects into a five-star rating using a benchmarking system we based on various project growth metrics; then we study the relation between this rating and the reported social diversities for the team members of those projects. Results: Our findings highlight a statistically significant relation; however, the effect is small. Conclusions: Our findings suggest the need for further research on this topic; moreover, the proposed benchmarking method may be used in future work to determine OSS project success on collaboration platforms such as GitHub.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {41},
numpages = {6},
keywords = {social diversity, GitHub, software project growth},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/2593868.2593875,
author = {Biazzini, Marco and Baudry, Benoit},
title = {"May the Fork Be with You": Novel Metrics to Analyze Collaboration on GitHub},
year = {2014},
isbn = {9781450328548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593868.2593875},
doi = {10.1145/2593868.2593875},
abstract = { Multi-repository software projects are becoming more and more popular, thanks to web-based facilities such as Github. Code and process metrics generally assume a single repository must be analyzed, in order to measure the characteristics of a codebase. Thus they are not apt to measure how much relevant information is hosted in multiple repositories contributing to the same codebase. Nor can they feature the characteristics of such a distributed development process. We present a set of novel metrics, based on an original classification of commits, conceived to capture some interesting aspects of a multi-repository development process. We also describe an efficient way to build a data structure that allows to compute these metrics on a set of Git repositories. Interesting outcomes, obtained by applying our metrics on a large sample of projects hosted on Github, show the usefulness of our contribution. },
booktitle = {Proceedings of the 5th International Workshop on Emerging Trends in Software Metrics},
pages = {37–43},
numpages = {7},
keywords = {Software process metrics, Distributed Version Control, Github, Git},
location = {Hyderabad, India},
series = {WETSoM 2014}
}

@inproceedings{10.1145/3239235.3240504,
author = {Rastogi, Ayushi and Nagappan, Nachiappan and Gousios, Georgios and van der Hoek, Andr\'{e}},
title = {Relationship between Geographical Location and Evaluation of Developer Contributions in Github},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3240504},
doi = {10.1145/3239235.3240504},
abstract = {Background Open source software projects show gender bias suggesting that other demographic characteristics of developers, like geographical location, can negatively influence evaluation of contributions too. Aim This study contributes to this emerging body of knowledge in software development by presenting a quantitative analysis of the relationship between the geographical location of developers and evaluation of their contributions on GitHub. Method We present an analysis of 70,000+ pull requests selected from 17 most actively participating countries to model the relationship between the geographical location of developers and pull request acceptance decision. Results and Conclusion We observed structural differences in pull request acceptance rates across 17 countries. Countries with no apparent similarities such as Switzerland and Japan had one of the highest pull request acceptance rates while countries like China and Germany had one of the lowest pull request acceptance rates. Notably, higher acceptance rates were observed for all but one country when pull requests were evaluated by developers from the same country.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {22},
numpages = {8},
keywords = {geographical location, github, open source, pull requests},
location = {Oulu, Finland},
series = {ESEM '18}
}

@inproceedings{10.1145/3059009.3072984,
author = {Arcelli Fontana, Francesca and Raibulet, Claudia},
title = {Students' Feedback in Using GitHub in a Project Development for a Software Engineering Course},
year = {2017},
isbn = {9781450347044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3059009.3072984},
doi = {10.1145/3059009.3072984},
abstract = {GitHub is a platform used for the development of software projects. It provides a traceable project repository and a social meeting place for communities of practices. This poster presents the students' feedback on using GitHub as a development platform for software projects counting as an exam for a 3rd-year undergraduate software engineering course on software design. Students worked in teams and their feedback is positive overall.},
booktitle = {Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {380},
numpages = {1},
keywords = {students' feedback, github, software engineering course, project development},
location = {Bologna, Italy},
series = {ITiCSE '17}
}

@inproceedings{10.5555/3155562.3155576,
author = {Kavaler, David and Sirovica, Sasha and Hellendoorn, Vincent and Aranovich, Raul and Filkov, Vladimir},
title = {Perceived Language Complexity in GitHub Issue Discussions and Their Effect on Issue Resolution},
year = {2017},
isbn = {9781538626849},
publisher = {IEEE Press},
abstract = { Modern software development is increasingly collaborative. Open Source Software (OSS) are the bellwether; they support dynamic teams, with tools for code sharing, communication, and issue tracking. The success of an OSS project is reliant on team communication. E.g., in issue discussions, individuals rely on rhetoric to argue their position, but also maintain technical relevancy. Rhetoric and technical language are on opposite ends of a language complexity spectrum: the former is stylistically natural; the latter is terse and concise. Issue discussions embody this duality, as developers use rhetoric to describe technical issues. The style mix in any discussion can define group culture and affect performance, e.g., issue resolution times may be longer if discussion is imprecise.  Using GitHub, we studied issue discussions to understand whether project-specific language differences exist, and to what extent users conform to a language norm. We built project-specific and overall GitHub language models to study the effect of perceived language complexity on multiple responses. We find that experienced users conform to project-specific language norms, popular individuals use overall GitHub language rather than project-specific language, and conformance to project-specific language norms reduces issue resolution times. We also provide a tool to calculate project-specific perceived language complexity. },
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {72–83},
numpages = {12},
location = {Urbana-Champaign, IL, USA},
series = {ASE 2017}
}

@inproceedings{10.1145/2468356.2468381,
author = {Lee, Michael J. and Ferwerda, Bruce and Choi, Junghong and Hahn, Jungpil and Moon, Jae Yun and Kim, Jinwoo},
title = {GitHub Developers Use Rockstars to Overcome Overflow of News},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468381},
doi = {10.1145/2468356.2468381},
abstract = {Keeping track of a constantly updating stream of news items on social networking enabled software development sites may be difficult. We analyzed the actions of 544 GitHub.com developers working across 5,657 projects to examine how the network of developers and projects influence where developers choose to contribute. Our analyses revealed the existence of a group of extremely well connected developers, or rockstars. We found that these rockstars': 1) actions have a greater influence on their followers compared to regular developers, 2) type of action affect their followers differently, 3) influence on followers may depend on a project's age, 4) increased activity on a project increases activity by followers, and 5) followers use as guides to projects to work on. We discuss the implications of these findings to the design of software development environments.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {133–138},
numpages = {6},
keywords = {GitHub, open source, social coding, social computing},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/2786805.2786834,
author = {Nagappan, Meiyappan and Robbes, Romain and Kamei, Yasutaka and Tanter, \'{E}ric and McIntosh, Shane and Mockus, Audris and Hassan, Ahmed E.},
title = {An Empirical Study of Goto in C Code from GitHub Repositories},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786834},
doi = {10.1145/2786805.2786834},
abstract = { It is nearly 50 years since Dijkstra argued that goto obscures the flow of control in program execution and urged programmers to abandon the goto statement. While past research has shown that goto is still in use, little is known about whether goto is used in the unrestricted manner that Dijkstra feared, and if it is ‘harmful’ enough to be a part of a post-release bug. We, therefore, conduct a two part empirical study - (1) qualitatively analyze a statistically rep- resentative sample of 384 files from a population of almost 250K C programming language files collected from over 11K GitHub repositories and find that developers use goto in C files for error handling (80.21±5%) and cleaning up resources at the end of a procedure (40.36 ± 5%); and (2) quantitatively analyze the commit history from the release branches of six OSS projects and find that no goto statement was re- moved/modified in the post-release phase of four of the six projects. We conclude that developers limit themselves to using goto appropriately in most cases, and not in an unrestricted manner like Dijkstra feared, thus suggesting that goto does not appear to be harmful in practice. },
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {404–414},
numpages = {11},
keywords = {Empirical SE, Use of goto statements, Dijkstra, Github},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/3287324.3287460,
author = {Hsing, Courtney and Gennarelli, Vanessa},
title = {Using GitHub in the Classroom Predicts Student Learning Outcomes and Classroom Experiences: Findings from a Survey of Students and Teachers},
year = {2019},
isbn = {9781450358903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287324.3287460},
doi = {10.1145/3287324.3287460},
abstract = {GitHub is a widely-used software development platform that supports version control, collaborative development, and project hosting. Currently, an estimated 18,000 educators use GitHub in programming classrooms. Depending on how GitHub is implemented in the classroom, students may rely on GitHub for activities such as, submitting assignments, collaborating on group projects, and receiving feedback. Despite GitHub's growing presence in programming classrooms, to date, few studies have explored how GitHub and the design of its implementation shape students' learning outcomes and classroom experiences. Building on previous research, we investigated how students in classrooms that used GitHub (GitHub classrooms), as opposed to classrooms that did not use GitHub (non-GitHub classrooms), differed across key variables. We surveyed 7530 students and 300 educators from GitHub and non-GitHub classrooms. Overall, we found that using GitHub in the classroom predicted better learning outcomes and classroom experiences. For example, students felt more prepared for the future, and they felt a greater sense of belonging in the classroom and in the field. Importantly, the design of implementation affected learning outcomes. For example, of the students who used GitHub in the classroom and received instructor feedback, those who received (versus did not receive) feedback via GitHub benefited more from the feedback. We discuss best practices for maximizing benefits to student learning when implementing GitHub in the classroom, study limitations, and future research directions. Our research is a step towards understanding how GitHub, a tool with a growing presence in programming classrooms, impacts students' learning experiences.},
booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
pages = {672–678},
numpages = {7},
keywords = {education, learning outcomes, github},
location = {Minneapolis, MN, USA},
series = {SIGCSE '19}
}

@inproceedings{10.1145/3278142.3278143,
author = {Baltes, Sebastian and Knack, Jascha and Anastasiou, Daniel and Tymann, Ralf and Diehl, Stephan},
title = {(No) Influence of Continuous Integration on the Commit Activity in GitHub Projects},
year = {2018},
isbn = {9781450360562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278142.3278143},
doi = {10.1145/3278142.3278143},
abstract = {A core goal of Continuous Integration (CI) is to make small incremental changes to software projects, which are integrated frequently into a mainline repository or branch. This paper presents an empirical study that investigates if developers adjust their commit activity towards the above-mentioned goal after projects start using CI. We analyzed the commit and merge activity in 93 GitHub projects that introduced the hosted CI system Travis CI, but have previously been developed for at least one year before introducing CI. In our analysis, we only found one non-negligible effect, an increased merge ratio, meaning that there were more merging commits in relation to all commits after the projects started using Travis CI. This effect has also been reported in related work. However, we observed the same effect in a random sample of 60 GitHub projects not using CI. Thus, it is unlikely that the effect is caused by the introduction of CI alone. We conclude that: (1) in our sample of projects, the introduction of CI did not lead to major changes in developers' commit activity, and (2) it is important to compare the commit activity to a baseline before attributing an effect to a treatment that may not be the cause for the observed effect.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Software Analytics},
pages = {1–7},
numpages = {7},
keywords = {open source software, mining software repositories, continuous integration, commit activity},
location = {Lake Buena Vista, FL, USA},
series = {SWAN 2018}
}

@inproceedings{10.1145/2786805.2786854,
author = {Casalnuovo, Casey and Vasilescu, Bogdan and Devanbu, Premkumar and Filkov, Vladimir},
title = {Developer Onboarding in GitHub: The Role of Prior Social Links and Language Experience},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786854},
doi = {10.1145/2786805.2786854},
abstract = { The team aspects of software engineering have been a subject of great interest since early work by Fred Brooks and others: how well do people work together in teams? why do people join teams? what happens if teams are distributed? Recently, the emergence of project ecosystems such as GitHub have created an entirely new, higher level of organization. GitHub supports numerous teams; they share a common technical platform (for work activities) and a common social platform (via following, commenting, etc). We explore the GitHub evidence for socialization as a precursor to joining a project, and how the technical factors of past experience and social factors of past connections to team members of a project affect productivity both initially and in the long run. We find developers preferentially join projects in GitHub where they have pre-existing relationships; furthermore, we find that the presence of past social connections combined with prior experience in languages dominant in the project leads to higher productivity both initially and cumulatively. Interestingly, we also find that stronger social connections are associated with slightly less productivity initially, but slightly more productivity in the long run. },
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {817–828},
numpages = {12},
keywords = {social aspects, onboarding, productivity, GitHub},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/3121257.3121261,
author = {Devanbu, Premkumar and Kudigrama, Pallavi and Rubio-Gonz\'{a}lez, Cindy and Vasilescu, Bogdan},
title = {Timezone and Time-of-Day Variance in GitHub Teams: An Empirical Method and Study},
year = {2017},
isbn = {9781450351577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3121257.3121261},
doi = {10.1145/3121257.3121261},
abstract = { Open source projects based in ecosystems like GitHub seamlessly allow distributed software development. Contributors to some GitHub projects may originate from many different timezones; in others they may all reside in just one timezone. How might this timezone dispersion (or concentration) affect the diurnal distribution of work activity in these projects? In commercial projects, there has been a desire to use top-down management and work allocation to exploit timezone dispersion of project teams, to engender a more round-the-clock work cycle. We focus on GitHub, and explore the relationship between timezone dispersion and work activity dispersion. We find that while time-of-day work activity dispersion is indeed associated strongly with timezone dispersion, it is equally (if not more strongly) affected by project team size. },
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Software Analytics},
pages = {19–22},
numpages = {4},
keywords = {Circular Statistics, Timezones, GitHub},
location = {Paderborn, Germany},
series = {SWAN 2017}
}

@inproceedings{10.1145/2666539.2666572,
author = {Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin},
title = {Investigating Social Media in GitHub's Pull-Requests: A Case Study on Ruby on Rails},
year = {2014},
isbn = {9781450332248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666539.2666572},
doi = {10.1145/2666539.2666572},
abstract = { In GitHub, pull-request mechanism is an outstanding social development method by integrating with many social media. Many studies have explored that social media has an important effect on software development. @-mention as a typical social media, is a useful tool in social platform. In this paper, we made a quantitative analysis of @-mention in pull-requests of the project Ruby on Rails. First, we make a convictive statistics of the popularity of pull-request mechanism in GitHub. Then we investigate the current situation of @-mention in the Ruby on Rails. Our empirical analysis results find some insights of @-mention. },
booktitle = {Proceedings of the 1st International Workshop on Crowd-Based Software Development Methods and Technologies},
pages = {37–41},
numpages = {5},
keywords = {GitHub, pull-request, @-mention, Social media},
location = {Hong Kong, China},
series = {CrowdSoft 2014}
}

@inproceedings{10.1145/3368089.3409722,
author = {Brown, Chris and Parnin, Chris},
title = {Understanding the Impact of GitHub Suggested Changes on Recommendations between Developers},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409722},
doi = {10.1145/3368089.3409722},
abstract = {Recommendations between colleagues are effective for encouraging developers to adopt better practices. Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks. However, in-person recommendations between developers in the workplace are declining. One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions. GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests. To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception. Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests. This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1065–1076},
numpages = {12},
keywords = {online programming communities, suggested changes, developer recommendations, Empirical software engineering, GitHub},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.5555/2820518.2820544,
author = {Blincoe, Kelly and Harrison, Francis and Damian, Daniela},
title = {Ecosystems in GitHub and a Method for Ecosystem Identification Using Reference Coupling},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {Software projects are not developed in isolation. Recent research has shifted to studying software ecosystems, communities of projects that depend on each other and are developed together. However, identifying technical dependencies at the ecosystem level can be challenging. In this paper, we propose a new method, known as reference coupling, for detecting technical dependencies between projects. The method establishes dependencies through user-specified cross-references between projects. We use our method to identify ecosystems in GitHub-hosted projects, and we identify several characteristics of the identified ecosystems. We find that most ecosystems are centered around one project and are interconnected with other ecosystems. The predominant type of ecosystems are those that develop tools to support software development. We also found that the project owners' social behaviour aligns well with the technical dependencies within the ecosystem, but project contributors' social behaviour does not align with these dependencies. We conclude with a discussion on future research that is enabled by our reference coupling method.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {202–207},
numpages = {6},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/2635868.2635922,
author = {Ray, Baishakhi and Posnett, Daryl and Filkov, Vladimir and Devanbu, Premkumar},
title = {A Large Scale Study of Programming Languages and Code Quality in Github},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635922},
doi = {10.1145/2635868.2635922},
abstract = { What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study, we gather a very large data set from GitHub (729 projects, 80 Million SLOC, 29,000 authors, 1.5 million commits, in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach, combining multiple regression modeling with visualization and text analytics, to study the effect of language features such as static v.s. dynamic typing, strong v.s. weak typing on software quality. By triangulating findings from different methods, and controlling for confounding effects such as team size, project size, and project history, we report that language design does have a significant, but modest effect on software quality. Most notably, it does appear that strong typing is modestly better than weak typing, and among functional languages, static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size, team size, and commit size. However, we hasten to caution the reader that even these modest effects might quite possibly be due to other, intangible process factors, e.g., the preference of certain personality types for functional, static and strongly typed languages. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {155–165},
numpages = {11},
keywords = {programming language, empirical research, bug fix, code quality, type system, regression analysis, software domain},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2901739.2901751,
author = {Kikas, Riivo and Dumas, Marlon and Pfahl, Dietmar},
title = {Using Dynamic and Contextual Features to Predict Issue Lifetime in GitHub Projects},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2901751},
doi = {10.1145/2901739.2901751},
abstract = {Methods for predicting issue lifetime can help software project managers to prioritize issues and allocate resources accordingly. Previous studies on issue lifetime prediction have focused on models built from static features, meaning features calculated at one snapshot of the issue's lifetime based on data associated to the issue itself. However, during its lifetime, an issue typically receives comments from various stakeholders, which may carry valuable insights into its perceived priority and difficulty and may thus be exploited to update lifetime predictions. Moreover, the lifetime of an issue depends not only on characteristics of the issue itself, but also on the state of the project as a whole. Hence, issue lifetime prediction may benefit from taking into account features capturing the issue's context (contextual features). In this work, we analyze issues from more than 4000 GitHub projects and build models to predict, at different points in an issue's lifetime, whether or not the issue will close within a given calendric period, by combining static, dynamic and contextual features. The results show that dynamic and contextual features complement the predictive power of static ones, particularly for long-term predictions.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {291–302},
numpages = {12},
keywords = {issue tracking, mining software repositories, issue lifetime prediction},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1109/APSEC.2014.58,
author = {Zhang, Yang and Yin, Gang and Yu, Yue and Wang, Huaimin},
title = {A Exploratory Study of @-Mention in GitHub's Pull-Requests},
year = {2014},
isbn = {9781479974269},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2014.58},
doi = {10.1109/APSEC.2014.58},
abstract = {Pull-request mechanism is an outstanding social development method in Git Hub. @-mention is a social media tool that deeply integrated with pull-request mechanism. Recently, many research results show that social media tools can promote the collaborative software development, but few work focuses on the impacts of @-mention. In this paper, we conduct an exploratory study of @-mention in pull-request based software development, including its current situation and benefits. We obtain some interesting findings which indicate that @-mention is beneficial to the processing of pull-request. Our work also proposes some possible research directions and problems of the @-mention. It helps the developers and researchers notice the significance of @-mention in the pull-request based software development.},
booktitle = {Proceedings of the 2014 21st Asia-Pacific Software Engineering Conference - Volume 01},
pages = {343–350},
numpages = {8},
keywords = {pull-request, social media, @-mention},
series = {APSEC '14}
}

@inproceedings{10.1145/2597073.2597113,
author = {Padhye, Rohan and Mani, Senthil and Sinha, Vibha Singhal},
title = {A Study of External Community Contribution to Open-Source Projects on GitHub},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597113},
doi = {10.1145/2597073.2597113},
abstract = { Open-source software projects are primarily driven by community contribution. However, commit access to such projects' software repositories is often strictly controlled. These projects prefer to solicit external participation in the form of patches or pull requests. In this paper, we analyze a set of 89 top-starred GitHub projects and their forks in order to explore the nature and distribution of such community contribution. We first classify commits (and developers) into three categories: core, external and mutant, and study the relative sizes of each of these classes through a ring-based visualization. We observe that projects written in mainstream scripting languages such as JavaScript and Python tend to include more external participation than projects written in upcoming languages such as Scala. We also visualize the geographic spread of these communities via geocoding. Finally, we classify the types of pull requests submitted based on their labels and observe that bug fixes are more likely to be merged into the main projects as compared to feature enhancements. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {332–335},
numpages = {4},
keywords = {Open-source software, pull requests, core committers, community participation, external contribution, mining software repositories},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3379597.3387455,
author = {Golubev, Yaroslav and Eliseeva, Maria and Povarov, Nikita and Bryksin, Timofey},
title = {A Study of Potential Code Borrowing and License Violations in Java Projects on GitHub},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387455},
doi = {10.1145/3379597.3387455},
abstract = {With an ever-increasing amount of open-source software, the popularity of services like GitHub that facilitate code reuse, and common misconceptions about the licensing of open-source software, the problem of license violations in the code is getting more and more prominent. In this study, we compile an extensive corpus of popular Java projects from GitHub, search it for code clones, and perform an original analysis of possible code borrowing and license violations on the level of code fragments. We chose Java as a language because of its popularity in industry, where the plagiarism problem is especially relevant because of possible legal action. We analyze and discuss distribution of 94 different discovered and manually evaluated licenses in files and projects, differences in the licensing of files, distribution of potential code borrowing between licenses, various types of possible license violations, most violated licenses, etc. Studying possible license violations in specific blocks of code, we have discovered that 29.6% of them might be involved in potential code borrowing and 9.4% of them could potentially violate original licenses.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {54–64},
numpages = {11},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1007/978-3-662-45550-0_46,
author = {Yu, Liguo and Mishra, Alok and Mishra, Deepti},
title = {An Empirical Study of the Dynamics of GitHub Repository and Its Impact on Distributed Software Development},
year = {2014},
isbn = {9783662455494},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-45550-0_46},
doi = {10.1007/978-3-662-45550-0_46},
abstract = {GitHub is a distributed code repository and project hosting web site. It is becoming one of the most popular web-based services to host both open-source projects and closed-source projects. In this paper, we review different kinds of version control systems and study the dynamics of GitHub, i.e., the ability and scalability of GitHub to process different requests and provide different services to different GitHub projects and GitHub users. Our study shows that GitHub could handle hundreds of thousands of requests a day for all the projects and thousands of requests for one project. This capability of GitHub makes it suitable for supporting distributed software development.},
booktitle = {Proceedings of the Confederated International Workshops on On the Move to Meaningful Internet Systems: OTM 2014 Workshops - Volume 8842},
pages = {457–466},
numpages = {10},
keywords = {web-based code storage, empirical study, distributed version control system, Git, distributed software development, GitHub}
}

@inproceedings{10.1145/2597073.2597118,
author = {Guzman, Emitza and Az\'{o}car, David and Li, Yang},
title = {Sentiment Analysis of Commit Comments in GitHub: An Empirical Study},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597118},
doi = {10.1145/2597073.2597118},
abstract = { Emotions have a high impact in productivity, task quality, creativity, group rapport and job satisfaction. In this work we use lexical sentiment analysis to study emotions expressed in commit comments of different open source projects and analyze their relationship with different factors such as used programming language, time and day of the week in which the commit was made, team distribution and project approval. Our results show that projects developed in Java tend to have more negative commit comments, and that projects that have more distributed teams tend to have a higher positive polarity in their emotional content. Additionally, we found that commit comments written on Mondays tend to a more negative emotion. While our results need to be confirmed by a more representative sample they are an initial step into the study of emotions and related factors in open source projects. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {352–355},
numpages = {4},
keywords = {Sentiment Analysis, Human Factors in Software Engineering},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3196398.3196436,
author = {Cohen, Eldan and Consens, Mariano P.},
title = {Large-Scale Analysis of the Co-Commit Patterns of the Active Developers in Github's Top Repositories},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196436},
doi = {10.1145/3196398.3196436},
abstract = {GitHub, the largest code hosting site (with 25 million public active repositories and contributions from 6 million active users), provides an unprecedented opportunity to observe the collaboration patterns of software developers. Understanding the patterns behind the social coding phenomena is an active research area where the insights gained can guide the design of better collaboration tools, and can also help to identify and select developer talent. In this paper, we present a large-scale analysis of the co-commit patterns in GitHub. We analyze 10 million commits made by 200 thousand developers to 16 thousand repositories, using 17 of the most popular programming languages over a period of 3 years. Although a large volume of data is included in our study, we pay close attention to the participation criteria for repositories and developers. We select repositories by reputation (based on star ranking), and we introduce the notion of active developer in GitHub (observing that a limited subset of developers is responsible for the vast majority of the commits). Using co-authorship networks, we analyze the co-commit patterns of the active developer network for each programming language. We observe that the active developer networks are less connected and more centralized than the general GitHub developer networks, and that the patterns vary significantly among languages. We compare our results to other collaborative environments (Wikipedia and scientific research networks), and we also describe the evolution of the co-commit patterns over time.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {426–436},
numpages = {11},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1109/MSR.2017.67,
author = {Cito, J\"{u}rgen and Schermann, Gerald and Wittern, John Erik and Leitner, Philipp and Zumberi, Sali and Gall, Harald C.},
title = {An Empirical Analysis of the Docker Container Ecosystem on GitHub},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.67},
doi = {10.1109/MSR.2017.67},
abstract = {Docker allows packaging an application with its dependencies into a standardized, self-contained unit (a so-called container), which can be used for software development and to run the application on any system. Dockerfiles are declarative definitions of an environment that aim to enable reproducible builds of the container. They can often be found in source code repositories and enable the hosted software to come to life in its execution environment. We conduct an exploratory empirical study with the goal of characterizing the Docker ecosystem, prevalent quality issues, and the evolution of Dockerfiles. We base our study on a data set of over 70000 Dockerfiles, and contrast this general population with samplings that contain the Top-100 and Top-1000 most popular Docker-using projects. We find that most quality issues (28.6%) arise from missing version pinning (i.e., specifying a concrete version for dependencies). Further, we were not able to build 34% of Dockerfiles from a representative sample of 560 projects. Integrating quality checks, e.g., to issue version pinning warnings, into the container build process could result into more reproducible builds. The most popular projects change more often than the rest of the Docker population, with 5.81 revisions per year and 5 lines of code changed on average. Most changes deal with dependencies, that are currently stored in a rather unstructured manner. We propose to introduce an abstraction that, for instance, could deal with the intricacies of different package managers and could improve migration to more light-weight images.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {323–333},
numpages = {11},
keywords = {empirical software engineering, GitHub, docker},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/3191697.3214341,
author = {Horschig, Siegfried and Mattis, Toni and Hirschfeld, Robert},
title = {Do Java Programmers Write Better Python? Studying off-Language Code Quality on GitHub},
year = {2018},
isbn = {9781450355131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3191697.3214341},
doi = {10.1145/3191697.3214341},
abstract = {There are style guides and best practices for many programming languages. Their goal is to promote uniformity and readability of code, consequentially reducing the chance of errors.  While programmers who are frequently using the same programming language tend to internalize most of its best practices eventually, little is known about what happens when they casually switch languages and write code in a less familiar language. Insights into the factors that lead to coding convention violations could help to improve tutorials for programmers switching languages, make teachers aware of mistakes they might expect depending on what language students have been using before, or influence the order in which programming languages are taught.  To approach this question, we make use of a large-scale data set representing a major part of the open source development activity happening on GitHub. In this data set, we search for Java and C++ programmers that occasionally program Python and study their Python code quality using a lint tool.  Comparing their defect rates to those from Python programmers reveals significant effects in both directions: We observe that some of Python's best practices have more widespread adoption among Java and C++ programmers than Python experts. At the same time, python-specific coding conventions, especially indentation, scoping, and the use of semicolons, are violated more frequently.  We conclude that programming off-language is not generally associated with better or worse code quality, but individual coding conventions are violated more or less frequently depending on whether they are more universal or language-specific. We intend to motivate a discussion and more research on what causes these effects, how we can mitigate or use them for good, and which related effects can be studied using the presented data set.},
booktitle = {Conference Companion of the 2nd International Conference on Art, Science, and Engineering of Programming},
pages = {127–134},
numpages = {8},
keywords = {lint, github, explorative study, code quality, best practices},
location = {Nice, France},
series = {Programming'18 Companion}
}

@inproceedings{10.5555/2820518.2820536,
author = {Coelho, Roberta and Almeida, Lucas and Gousios, Georgios and van Deursen, Arie},
title = {Unveiling Exception Handling Bug Hazards in Android Based on GitHub and Google Code Issues},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {This paper reports on a study mining the exception stack traces included in 159,048 issues reported on Android projects hosted in GitHub (482 projects) and Google Code (157 projects). The goal of this study is to investigate whether stack trace information can reveal bug hazards related to exception handling code that may lead to a decrease in application robustness. Overall 6,005 exception stack traces were extracted, and subjected to source code and bytecode analysis. The outcomes of this study include the identification of the following bug hazards: (i) unexpected cross-type exception wrappings (for instance, trying to handle an instance of OutOfMemoryError "hidden" in a checked exception) which can make the exception-related code more complex and negatively impact the application robustness; (ii) undocumented runtime exceptions thrown by both the Android platform and third party libraries; and (iii) undocumented checked exceptions thrown by the Android Platform. Such undocumented exceptions make it difficult, and most of the times infeasible for the client code to protect against "unforeseen" situations that may happen while calling third-party code. This study provides further insights on such bug hazards and the robustness threats they impose to Android apps as well as to other systems based on the Java exception model.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {134–145},
numpages = {12},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3366423.3380272,
author = {Maldeniya, Danaja and Budak, Ceren and Robert Jr., Lionel P. and Romero, Daniel M.},
title = {Herding a Deluge of Good Samaritans: How GitHub Projects Respond to Increased Attention},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380272},
doi = {10.1145/3366423.3380272},
abstract = {Collaborative crowdsourcing is a well-established model of work, especially in the case of open source software development. The structure and operation of these virtual and loosely-knit teams differ from traditional organizations. As such, little is known about how their behavior may change in response to an increase in external attention. To understand these dynamics, we analyze millions of actions of thousands of contributors in over 1100 open source software projects that topped the GitHub Trending Projects page and thus experienced a large increase in attention, in comparison to a control group of projects identified through propensity score matching. In carrying out our research, we use the lens of organizational change, which considers the challenges teams face during rapid growth and how they adapt their work routines, organizational structure, and management style. We show that trending results in an explosive growth in the effective team size. However, most newcomers make only shallow and transient contributions. In response, the original team transitions towards administrative roles, responding to requests and reviewing work done by newcomers. Projects evolve towards a more distributed coordination model with newcomers becoming more central, albeit in limited ways. Additionally, teams become more modular with subgroups specializing in different aspects of the project. We discuss broader implications for collaborative crowdsourcing teams that face attention shocks. },
booktitle = {Proceedings of The Web Conference 2020},
pages = {2055–2065},
numpages = {11},
keywords = {attention shocks, crowdsourcing, coordination, PSM, GitHub},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3377812.3382165,
author = {Subramanian, Vikram N.},
title = {An Empirical Study of the First Contributions of Developers to Open Source Projects on GitHub},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3382165},
doi = {10.1145/3377812.3382165},
abstract = {The popularity of Open Source Software (OSS) is at an all-time high and for it to remain so it is vital for new developers to continually join and contribute to the OSS community. In this paper, to better understand the first time contributor, we study the characteristics of the first pull request (PR) made to an OSS project by developers. We mine GitHub for the first OSS PR of 3501 developers to study certain characteristics of PRs like language and size. We find that over 1/3rd of the PRs were in Java while C++ was very unpopular. A large fraction of PRs didn't even involve writing code, and were a mixture of trivial and non-trivial changes.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {116–118},
numpages = {3},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/2901739.2903496,
author = {Barnett, Jacob G. and Gathuru, Charles K. and Soldano, Luke S. and McIntosh, Shane},
title = {The Relationship between Commit Message Detail and Defect Proneness in Java Projects on GitHub},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2903496},
doi = {10.1145/2901739.2903496},
abstract = {Just-In-Time (JIT) defect prediction models aim to predict the commits that will introduce defects in the future. Traditionally, JIT defect prediction models are trained using metrics that are primarily derived from aspects of the code change itself (e.g., the size of the change, the author's prior experience). In addition to the code that is submitted during a commit, authors write commit messages, which describe the commit for archival purposes. It is our position that the level of detail in these commit messages can provide additional explanatory power to JIT defect prediction models. Hence, in this paper, we analyze the relationship between the defect proneness of commits and commit message volume (i.e., the length of the commit message) and commit message content (approximated using spam filtering technology). Through analysis of JIT models that were trained using 342 GitHub repositories, we find that our JIT models outperform random guessing models, achieving AUC and Brier scores that range between 0.63-0.96 and 0.01-0.21, respectively. Furthermore, our metrics that are derived from commit message detail provide a statistically significant boost to the explanatory power to the JIT models in 43%-80% of the studied systems, accounting for up to 72% of the explanatory power. Future JIT studies should consider adding commit message detail metrics.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {496–499},
numpages = {4},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1145/3132498.3134110,
author = {Neto, Casimiro Conde Marco and de O. Barros, M\'{a}rcio},
title = {A Structured Survey on the Usage of the Issue Tracking System Provided by the GitHub Platform},
year = {2017},
isbn = {9781450353250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132498.3134110},
doi = {10.1145/3132498.3134110},
abstract = {Issue tracking systems help software development teams in identifying problems to be solved and new features to be added to a software system. In this paper, we replicate and extend a study carried out in 2013 on the usage of the issue tracking system provided by the GitHub platform. The replication aims at determining whether the results observed four years ago are still valid. The extension seeks to analyze how often issues are terminated by commits to the version control system and understand whether this feature allows developers to relate an issue to the source code modules that were changed to resolve it. We conclude that the results of the previous study remain valid and that issues closed by commits are uncommon (about 4% of our sample) and often linked to technical aspects of the project.},
booktitle = {Proceedings of the 11th Brazilian Symposium on Software Components, Architectures, and Reuse},
articleno = {3},
numpages = {10},
keywords = {issues, GitHub, issue tracking systems, issue management},
location = {Fortaleza, Cear\'{a}, Brazil},
series = {SBCARS '17}
}

@inproceedings{10.1145/3340496.3342759,
author = {Coppola, Riccardo and Ardito, Luca and Torchiano, Marco},
title = {Characterizing the Transition to Kotlin of Android Apps: A Study on F-Droid, Play Store, and GitHub},
year = {2019},
isbn = {9781450368582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340496.3342759},
doi = {10.1145/3340496.3342759},
abstract = {Context: Kotlin is a novel language that represents an alternative to Java, and has been recently adopted as a first-class programming language for Android applications. Kotlin is achieving a significant diffusion among developers, and several studies have highlighted various advantages of the language when compared to Java.  Goal: The objective of this paper is to analyze a set of open-source Android apps, to evaluate their transition to the Kotlin programming language throughout their lifespan and understand whether the adoption of Kotlin has impacts on the success of Android apps.  Methods: We mined all the projects from the F-Droid repository of Android open-source applications, and we found the corresponding projects on the official Google Play Store and on the GitHub platform. We defined a set of eight metrics to quantify the relevance of Kotlin code in the latest update and through all releases of an application. Then, we statistically analyzed the correlation between the presence of Kotlin code in a project and popularity metrics mined from the platforms where the apps were released.  Results: Of a set of 1232 projects that were updated after October 2017, near 20% adopted Kotlin and about 12% had more Kotlin code than Java; most of the projects that adopted Kotlin quickly transitioned from Java to the new language. The projects featuring Kotlin had on average higher popularity metrics; a statistically significant correlation has been found between the presence of Kotlin and the number of stars on the GitHub repository.  Conclusion: The Kotlin language seems able to guarantee a seamless migration from Java for Android developers. With an inspection on a large set of open-source Android apps, we observed that the adoption of the Kotlin language is rapid (when compared to the average lifespan of an Android project) and seems to come at no cost in terms of popularity among the users and other developers.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on App Market Analytics},
pages = {8–14},
numpages = {7},
keywords = {Java, Kotlin, Empirical Software Engineering, App Market Analytics, Mobile Development, Software Maintenance},
location = {Tallinn, Estonia},
series = {WAMA 2019}
}

@inproceedings{10.1145/3306446.3340820,
author = {Gustavsson, Henrik and Brohede, Marcus},
title = {Continuous Assessment in Software Engineering Project Course Using Publicly Available Data from GitHub},
year = {2019},
isbn = {9781450363198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3306446.3340820},
doi = {10.1145/3306446.3340820},
abstract = {This paper describes an approach for assessment in a large software engineering project course. We propose an approach for continuously collecting information from a source code repository and collaboration tool, and using this information for assessing student contributions and also for assessing the course as a whole from the teacher's standpoint. We present how we display metrics for how the students perform in relation to some of the requirements of the course. We argue that continuous summative assessment feedback to the students on how they are performing in the project is a suitable strategy for ensuring active participation from the students for the duration of the project course.},
booktitle = {Proceedings of the 15th International Symposium on Open Collaboration},
articleno = {4},
numpages = {6},
keywords = {issue management, software engineering, project course, education, assessment},
location = {Sk\"{o}vde, Sweden},
series = {OpenSym '19}
}

@inproceedings{10.5555/2664446.2664449,
author = {Gousios, Georgios and Spinellis, Diomidis},
title = {GHTorrent: GitHub's Data from a Firehose},
year = {2012},
isbn = {9781467317610},
publisher = {IEEE Press},
abstract = {A common requirement of many empirical software engineering studies is the acquisition and curation of data from software repositories. During the last few years, GitHub has emerged as a popular project hosting, mirroring and collaboration platform. GitHub provides an extensive rest api, which enables researchers to retrieve both the commits to the projects' repositories and events generated through user actions on project resources. GHTorrent aims to create a scalable off line mirror of GitHub's event streams and persistent data, and offer it to the research community as a service. In this paper, we present the project's design and initial implementation and demonstrate how the provided datasets can be queried and processed.},
booktitle = {Proceedings of the 9th IEEE Working Conference on Mining Software Repositories},
pages = {12–21},
numpages = {10},
keywords = {dataset, events, commits, GitHub, repository},
location = {Zurich, Switzerland},
series = {MSR '12}
}

@inproceedings{10.1145/3382494.3410690,
author = {Di Rocco, Juri and Di Ruscio, Davide and Di Sipio, Claudio and Nguyen, Phuong and Rubei, Riccardo},
title = {TopFilter: An Approach to Recommend Relevant GitHub Topics},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410690},
doi = {10.1145/3382494.3410690},
abstract = {Background: In the context of software development, GitHub has been at the forefront of platforms to store, analyze and maintain a large number of software repositories. Topics have been introduced by GitHub as an effective method to annotate stored repositories. However, labeling GitHub repositories should be carefully conducted to avoid adverse effects on project popularity and reachability. Aims: We present TopFilter, a novel approach to assist open source software developers in selecting suitable topics for GitHub repositories being created. Method: We built a project-topic matrix and applied a syntactic-based similarity function to recommend missing topics by representing repositories and related topics in a graph. The ten-fold cross-validation methodology has been used to assess the performance of TopFilter by considering different metrics, i.e., success rate, precision, recall, and catalog coverage. Result: The results show that TopFilter recommends good topics depending on different factors, i.e., collaborative filtering settings, considered datasets, and pre-processing activities. Moreover, TopFilter can be combined with a state-of-the-art topic recommender system (i.e., MNB network) to improve the overall prediction performance. Conclusion: Our results confirm that collaborative filtering techniques can successfully be used to provide relevant topics for GitHub repositories. Moreover, TopFilter can gain a significant boost in prediction performances by employing the outcomes obtained by the MNB network as its initial set of topics.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {21},
numpages = {11},
keywords = {Recommender systems, GitHub topics recommendation, Collaborative filtering},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.1109/JITRE.2015.7330171,
author = {Portugal, Roxana Lisette Quintanilla and do Prado Leite, Julio Cesar Sampaio and Almentero, Eduardo},
title = {Time-Constrained Requirements Elicitation: Reusing GitHub Content},
year = {2015},
isbn = {9781509001194},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/JITRE.2015.7330171},
doi = {10.1109/JITRE.2015.7330171},
abstract = {Requirements elicitation is the activity of identifying facts that compose the system requirements. One of the steps of this activity is the identification of information sources, which is a time-consuming task. Text documents are typically an important and abundant information source. However, their analysis to gather useful information is also time consuming and hard to automate. Because of its characteristics, the identification of information sources and analysis of text documents are critical in time-constrained projects, which are typically addressed through agile approaches. This paper presents a strategy for time-constrained elicitation, which is based on mining GitHub content. The strategy aims the identification of information sources (similar projects) and the automatic analysis of textual documents (projects content) through text mining techniques. Furthermore, it maintains the traceability between the data mined and its sources, boosting the reuse of existing information. A tool is being created to support the strategy.},
booktitle = {Proceedings of the 2015 IEEE Workshop on Just-In-Time Requirements Engineering (JITRE)},
pages = {5–8},
numpages = {4},
series = {JIT RE 2015 '15}
}

@inproceedings{10.1145/2976767.2976778,
author = {Hebig, Regina and Quang, Truong Ho and Chaudron, Michel R. V. and Robles, Gregorio and Fernandez, Miguel Angel},
title = {The Quest for Open Source Projects That Use UML: Mining GitHub},
year = {2016},
isbn = {9781450343213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976767.2976778},
doi = {10.1145/2976767.2976778},
abstract = {Context: While industrial use of UML was studied intensely, little is known about UML use in Free/Open Source Software (FOSS) projects. Goal: We aim at systematically mining GitHub projects to answer the question when models, if used, are created and updated throughout the whole project's life-span. Method: We present a semi-automated approach to collect UML stored in images, .xmi, and .uml files and scanned ten percent of all GitHub projects (1.24 million). Our focus was on number and role of contributors that created/updated models and the time span during which this happened. Results: We identified and studied 21 316 UML diagrams within 3 295 projects. Conclusion: Creating/updating of UML happens most often during a very short phase at the project start. For 12% of the models duplicates were found, which are in average spread across 1.88 projects. Finally, we contribute a list of GitHub projects that include UML files.},
booktitle = {Proceedings of the ACM/IEEE 19th International Conference on Model Driven Engineering Languages and Systems},
pages = {173–183},
numpages = {11},
keywords = {UML, open source, free software, GitHub, mining software repositories},
location = {Saint-malo, France},
series = {MODELS '16}
}

@inproceedings{10.1145/3183440.3195085,
author = {Ren, Luyao and Zhou, Shurui and K\"{a}stner, Christian},
title = {Forks Insight: Providing an Overview of GitHub Forks},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195085},
doi = {10.1145/3183440.3195085},
abstract = {Fork-based development allows developers to start development from existing software repository by copying the code files. However, when the number of forks grows, contributions are not always visible to others, unless an explicit merge-back attempt is made. To solve this problem, we implemented Forks Insight (www.forks-insight.com) to help developers get an overview of forks on GitHub. The current release version focuses on simple analytics for the high level overview which is lightweight, scalable and practical. It has a user-friendly interactive web interface with features like searching and tagging.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {179–180},
numpages = {2},
keywords = {fork-based development, open-source, GitHub, overview of forks},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1109/ICSME.2014.62,
author = {Vasilescu, Bogdan and Schuylenburg, Stef van and Wulms, Jules and Serebrenik, Alexander and Brand, Mark G. J. van den},
title = {Continuous Integration in a Social-Coding World: Empirical Evidence from GitHub},
year = {2014},
isbn = {9781479961467},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSME.2014.62},
doi = {10.1109/ICSME.2014.62},
abstract = {Continuous integration is a software engineering practice of frequently merging all developer working copies with a shared main branch, e.g., several times a day. With the advent of GitHub, a platform well known for its "social coding" features that aid collaboration and sharing, and currently the largest code host in the open source world, collaborative software development has never been more prominent. In GitHub development one can distinguish between two types of developer contributions to a project: direct ones, coming from a typically small group of developers with write access to the main project repository, and indirect ones, coming from developers who fork the main repository, update their copies locally, and submit pull requests for review and merger. In this paper we explore how GitHub developers use continuous integration as well as whether the contribution type (direct versus indirect) and different project characteristics (e.g., main programming language, or project age) are associated with the success of the automatic builds.},
booktitle = {Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution},
pages = {401–405},
numpages = {5},
keywords = {GitHub, continuous integration, automatic build, collaborative software development},
series = {ICSME '14}
}

@inproceedings{10.1109/MSR.2017.15,
author = {Gharehyazie, Mohammad and Ray, Baishakhi and Filkov, Vladimir},
title = {Some from Here, Some from There: Cross-Project Code Reuse in GitHub},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.15},
doi = {10.1109/MSR.2017.15},
abstract = {Code reuse has well-known benefits on code quality, coding efficiency, and maintenance. Open Source Software (OSS) programmers gladly share their own code and they happily reuse others'. Social programming platforms like GitHub have normalized code foraging via their common platforms, enabling code search and reuse across different projects. Removing project borders may facilitate more efficient code foraging, and consequently faster programming. But looking for code across projects takes longer and, once found, may be more challenging to tailor to one's needs. Learning how much code reuse goes on across projects, and identifying emerging patterns in past cross-project search behavior may help future foraging efforts.To understand cross-project code reuse, here we present an in-depth study of cloning in GitHub. Using Deckard, a clone finding tool, we identified copies of code fragments across projects, and investigate their prevalence and characteristics using statistical and network science approaches, and with multiple case studies. By triangulating findings from different methods, we find that cross-project cloning is prevalent in GitHub, ranging from cloning few lines of code to whole project repositories. Some of the projects serve as popular sources of clones, and others seem to contain more clones than their fair share. Moreover, we find that ecosystem cloning follows an onion model: most clones come from the same project, then from projects in the same application domain, and finally from projects in different domains. Our results show directions for new tools that can facilitate code foraging and sharing within GitHub.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {291–301},
numpages = {11},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/2676723.2678305,
author = {DeCausemaker, Remy and Jacobs, Stephen},
title = {Steal This Courseware: FOSS, Github, Python, and OpenShift (Abstract Only)},
year = {2015},
isbn = {9781450329668},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676723.2678305},
doi = {10.1145/2676723.2678305},
abstract = {This workshop introduces participants to the pedagogy and practice of using Free/Open Source Software development practices into their curriculum, and then guides them through deployment of a turnkey courseware framework to be used for their own courses. The framework supports automatic blog checking, automatically generated student profile pages, Gravatar integration for profile pictures, Travis-CI continuous Integration tests, and repository changes reported via Github webhooks to IRC. Participants will learn how to use Github in the Classroom, the basics of Flask, a python web framework, and how to deploy their courseware to Red Hat's OpenShift Cloud, a free Platform-as-a-Service to host courseware and/or other web sites.},
booktitle = {Proceedings of the 46th ACM Technical Symposium on Computer Science Education},
pages = {708},
numpages = {1},
keywords = {web blocks, python, free content, openshift, open source software, github, free software, flask},
location = {Kansas City, Missouri, USA},
series = {SIGCSE '15}
}

@inproceedings{10.1145/3194932.3194941,
author = {Werder, Karl and Brinkkemper, Sjaak},
title = {MEME: Toward a Method for Emotions Extraction from Github},
year = {2018},
isbn = {9781450357517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194932.3194941},
doi = {10.1145/3194932.3194941},
abstract = {Software engineering researchers are increasingly interested in the role of emotion during software development. While general tools are available to extract emotions from textual data, these perform poorly in the domain of software engineering. Hence, this paper develops MEME - a Method for EMotion Extraction. Using GHtorrent and GitHub as data sources, the paper presents an implementation of the method. The evaluation results suggest a better performance of MEME in contrast to Syuzhet R package emotion analysis.},
booktitle = {Proceedings of the 3rd International Workshop on Emotion Awareness in Software Engineering},
pages = {20–24},
numpages = {5},
location = {Gothenburg, Sweden},
series = {SEmotion '18}
}

@inproceedings{10.1145/3127404.3127431,
author = {Ma, Yezhou and Li, Huiying and Hu, Jiyao and Xie, Rong and Chen, Yang},
title = {Mining the Network of the Programmers: A Data-Driven Analysis of GitHub},
year = {2017},
isbn = {9781450353526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127404.3127431},
doi = {10.1145/3127404.3127431},
abstract = {GitHub is a worldwide popular website for version control and source code management. In addition, since its users can follow each other, it also forms a professional social network of millions of users. In this work, we perform a data-driven study for analyzing the GitHub network. By introducing a distributed crawling framework, we first collect profiles and behavioral data of more than 2 million GitHub users. To the best of our knowledge, this is the largest and latest public dataset of GitHub. Then, we build the social graph of these users and conduct a thorough analysis of the network structure. Moreover, we investigate the user behavior patterns, particularly the patterns of the "commit" activities. Finally, we utilize machine learning methods to discover important users in the network with a high accuracy and a low overhead. Our inspiring findings are helpful for GitHub to provide better services for its users.},
booktitle = {Proceedings of the 12th Chinese Conference on Computer Supported Cooperative Work and Social Computing},
pages = {165–168},
numpages = {4},
keywords = {PageRank, spatial-temporal analysis, machine learning, GitHub, professional social networks},
location = {Chongqing, China},
series = {ChineseCSCW '17}
}

@inproceedings{10.1145/3350768.3350788,
author = {Borges, Hudson and Brito, Rodrigo and Valente, Marco Tulio},
title = {Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350788},
doi = {10.1145/3350768.3350788},
abstract = {Recently, GitHub introduced a new social feature, named reactions, which are "pictorial characters" similar to emoji symbols widely used nowadays in text-based communications. Particularly, GitHub users can use a pre-defined set of such symbols to react to issues and pull requests. However, little is known about the real usage and impact of GitHub reactions. In this paper, we analyze the reactions provided by developers to more than 2.5 million issues and 9.7 million issue comments, in order to answer an extensive list of nine research questions about the usage and adoption of reactions. We show that reactions are being increasingly used by open source developers. Moreover, we also found that issues with reactions usually take more time to be handled and have longer discussions.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {397–406},
numpages = {10},
keywords = {Reactions, Social Coding, GitHub},
location = {Salvador, Brazil},
series = {SBES 2019}
}

@inproceedings{10.5555/2820518.2820556,
author = {Wang, Weiliang and Poo-Caama\~{n}o, Germ\'{a}n and Wilde, Evan and German, Daniel M.},
title = {What is the Gist? Understanding the Use of Public Gists on GitHub},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {GitHub is a popular source code hosting site which serves as a collaborative coding platform. The many features of GitHub have greatly facilitated developers' collaboration, communication, and coordination. Gists are one feature of GitHub, which defines them as "a simple way to share snippets and pastes with others." This three-part study explores how users are using Gists. The first part is a quantitative analysis of Gist metadata and contents. The second part investigates the information contained in a Gist: We sampled 750k users and their Gists (totalling 762k Gists), then manually categorized the contents of 398. The third part of the study investigates what users are saying Gists are for by reading the contents of web pages and twitter feeds. The results indicate that Gists are used by a small portion of GitHub users, and those that use them typically only have a few. We found that Gists are usually small and composed of a single file. However, Gists serve a wide variety of uses, from saving snippets of code, to creating reusable components for web pages.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {314–323},
numpages = {10},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3183428.3183437,
author = {Wang, Zhendong and Wang, Yi and Redmiles, David},
title = {Competence-Confidence Gap: A Threat to Female Developers' Contribution on Github},
year = {2018},
isbn = {9781450356619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183428.3183437},
doi = {10.1145/3183428.3183437},
abstract = {On GitHub, contributing to a new project is crucial for a developer to gain personal growth and maximize impact in the community. It is known that female developers are often hesitant to explore the opportunities to contribute to new projects even when they possess the competence to make valuable contributions. Drawing from the literature of the competence-confidence gap, we develop a fresh explanation for this phenomenon. We validate the theoretical explanation through an empirical study using GitHub's historical data. In this study, we identify all female developers ranking in top 5,000 GitHub users. Using the Granger Causality Test, we find that, for the majority of identified female developers, initiating a pull request to a new repository is "Granger" caused by the quick increase of followers in the preceding couple of weeks. For most male developers, our observations show that their new pull requests have no relationship with the dynamics of follower numbers. The results indicate that the competence-confidence gap is a threat to female developers' contribution on GitHub. The research suggests that helping female developers to overcome the competence-confidence gap is critical for encouraging female's contribution open source development, as well as growing their reputations and impacts in the community.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Society},
pages = {81–90},
numpages = {10},
keywords = {female developers, github, competence-confidence gap, granger causality},
location = {Gothenburg, Sweden},
series = {ICSE-SEIS '18}
}

@inproceedings{10.1145/3217804.3217895,
author = {Celi\'{n}ska, Dorota},
title = {Coding Together in a Social Network: Collaboration among GitHub Users},
year = {2018},
isbn = {9781450363341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3217804.3217895},
doi = {10.1145/3217804.3217895},
abstract = {In this article we investigate developers involved in the creation of Open Source software to identify which characteristics favor innovation in the Open Source community. The results of the analysis show that higher reputation in the community improves the probability of gaining collaborators to a certain degree, but developers are also driven by reciprocity. This is consistent with the concept of gift economy. A significant network effect exists and emerges from standardization, showing that developers using the most popular programming languages in the service are likely to have more collaborators. Providing additional information (valid URL to developer's homepage) improves the chances of finding coworkers. The results can be generalized for the population of mature users of GitHub.},
booktitle = {Proceedings of the 9th International Conference on Social Media and Society},
pages = {31–40},
numpages = {10},
keywords = {reciprocity, collaboration, gift economy, network externality, Open Source, reputation, forking, GitHub, innovations},
location = {Copenhagen, Denmark},
series = {SMSociety '18}
}

@inproceedings{10.1145/2875913.2875924,
author = {Mo, Wenkai and Shen, Beijun and He, Yuming and Zhong, Hao},
title = {GEMiner: Mining Social and Programming Behaviors to Identify Experts in Github},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875924},
doi = {10.1145/2875913.2875924},
abstract = {Hosting over 10 million repositories, GitHub becomes the largest open source community in the world. Besides sharing code, Github is also a social network, in which developers can follow others or keep track of their interested projects. Considering the multi-roles of Github, integrating heterogenous data of each developer to identify experts is a challenging task. In this paper, we propose GEMiner, a novel approach to identify experts for some specific programming languages in Github. Different from previous approaches, GEMiner analyzes the social behaviors and programming behaviors of a developer to determine the expertise of the developer. When modeling social behaviors of developers, to integrate heterogenous social networks in Github, GEMiner implements a Multi-Sources PageRank algorithm. Also, GEMiner analyzes the behaviors of developers when they are programming (e.g., their commit activities and their preferred programming languages) to model programming behaviors of them. Based on our expertise models and our extracted programming languages data, GEMiner can then identify experts for some specific programming languages in Github. We conducted experiments on a real data set, and our results show that GEMiner identifies experts with 60% accuracy higher than the state-of-the-art algorithms.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {93–101},
numpages = {9},
keywords = {Github, Experts Identification, Social Network},
location = {Wuhan, China},
series = {Internetware '15}
}

@inproceedings{10.1145/3273934.3273943,
author = {Ortu, Marco and Hall, Tracy and Marchesi, Michele and Tonelli, Roberto and Bowes, David and Destefanis, Giuseppe},
title = {Mining Communication Patterns in Software Development: A GitHub Analysis},
year = {2018},
isbn = {9781450365932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3273934.3273943},
doi = {10.1145/3273934.3273943},
abstract = {Background: Studies related to human factors in software engineering are providing insightful information on the emotional state of contributors and the impact this has on the code. The open source software development paradigm involves different roles, and previous studies about emotions in software development have not taken into account what different roles might play when people express their feelings. Aim: We present an analysis of issues and commits on five GitHub projects distinguishing contributors between users and developers, and between one-commit and multi-commit developers. Method: We analyzed more than 650K comments from 130K issues of 64K contributors. We calculated emotions (love, joy, anger, sadness) and politeness of the comments related to the issues of the considered projects and introduced the definition of contributor fan-in and fan-out. Results: Results show that users and developers communicate differently as well as multi-commit developers and one-commit developers do. Conclusions: We provide empirical evidence that one-commit developers are more active and more polite in posting comments. Multi-commit developers are less active in posting comments, and while commenting, they are less polite than when commented.},
booktitle = {Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {70–79},
numpages = {10},
keywords = {software engineering, data analytics, human factors},
location = {Oulu, Finland},
series = {PROMISE'18}
}

@inproceedings{10.5555/2820518.2820564,
author = {Yu, Yue and Wang, Huaimin and Filkov, Vladimir and Devanbu, Premkumar and Vasilescu, Bogdan},
title = {Wait for It: Determinants of Pull Request Evaluation Latency on GitHub},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {The pull-based development model, enabled by git and popularised by collaborative coding platforms like BitBucket, Gitorius, and GitHub, is widely used in distributed software teams. While this model lowers the barrier to entry for potential contributors (since anyone can submit pull requests to any repository), it also increases the burden on integrators (i.e., members of a project's core team, responsible for evaluating the proposed changes and integrating them into the main development line), who struggle to keep up with the volume of incoming pull requests. In this paper we report on a quantitative study that tries to resolve which factors affect pull request evaluation latency in GitHub. Using regression modeling on data extracted from a sample of GitHub projects using the Travis-CI continuous integration service, we find that latency is a complex issue, requiring many independent variables to explain adequately.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {367–371},
numpages = {5},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1109/ICSE-C.2017.99,
author = {Baltes, Sebastian and Kiefer, Richard and Diehl, Stephan},
title = {Attribution Required: Stack Overflow Code Snippets in GitHub Projects},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.99},
doi = {10.1109/ICSE-C.2017.99},
abstract = {Stack Overflow (SO) is the largest Q&amp;A website for developers, providing a huge amount of copyable code snippets. Using these snippets raises various maintenance and legal issues. The SO license requires attribution, i.e., referencing the original question or answer, and requires derived work to adopt a compatible license. While there is a heated debate on SO's license model for code snippets and the required attribution, little is known about the extent to which snippets are copied from SO without proper attribution. In this paper, we present the research design and summarized results of an empirical study analyzing attributed and unattributed usages of SO code snippets in GitHub projects. On average, 3.22% of all analyzed repositories and 7.33% of the popular ones contained a reference to SO. Further, we found that developers rather refer to the whole thread on SO than to a specific answer. For Java, at least two thirds of the copied snippets were not attributed.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {161–163},
numpages = {3},
keywords = {survey, empirical study, licensing, GitHub, copy-and-paste programming, code snippets, stack overflow},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1145/3304221.3319784,
author = {Lars\'{e}n, Simon and Glassey, Richard},
title = {RepoBee: Developing Tool Support for Courses Using Git/GitHub},
year = {2019},
isbn = {9781450368957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3304221.3319784},
doi = {10.1145/3304221.3319784},
abstract = {The use of version control systems within computing education is growing in popularity. However, this is challenging because such systems are not particularly well designed to support educational situations, nor are they easy to use with confidence in teaching, as specialist knowledge and experience is required. This experience paper reports the development of the open source tool RepoBee, which assists in the use of Git/GitHub in an educational context. The tool provides a straightforward interface for managing batch tasks such as repository generation and cloning for setting and gathering assignments, opening and closing of issues to communicate with students, as well as facilitating peer reviews. Parts of RepoBee are open to integration with third party tools for additional tasks, such as running unit tests or static analysis on student repositories. We also include the perspectives of both teachers and teaching assistants who have been using the tool as part of a first year course for computer scientists.},
booktitle = {Proceedings of the 2019 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {534–540},
numpages = {7},
keywords = {computing education, course management, version control systems, git/github},
location = {Aberdeen, Scotland Uk},
series = {ITiCSE '19}
}

@inproceedings{10.1109/ICPC.2019.00037,
author = {Chen, Di and Stolee, Kathryn T. and Menzies, Tim},
title = {Replication Can Improve Prior Results: A GitHub Study of Pull Request Acceptance},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICPC.2019.00037},
doi = {10.1109/ICPC.2019.00037},
abstract = {Crowdsourcing and data mining can be used to effectively reduce the effort associated with the partial replication and enhancement of qualitative studies.For example, in a primary study, other researchers explored factors influencing the fate of GitHub pull requests using an extensive qualitative analysis of 20 pull requests. Guided by their findings, we mapped some of their qualitative insights onto quantitative questions. To determine how well their findings generalize, we collected much more data (170 additional pull requests from 142 GitHub projects). Using crowdsourcing, that data was augmented with subjective qualitative human opinions about how pull requests extended the original issue. The crowd's answers were then combined with quantitative features and, using data mining, used to build a predictor for whether code would be merged. That predictor was far more accurate than the one built from the primary study's qualitative factors (F1=90 vs 68%), illustrating the value of a mixed-methods approach and replication to improve prior results.To test the generality of this approach, the next step in future work is to conduct other studies that extend qualitative studies with crowdsourcing and data mining.},
booktitle = {Proceedings of the 27th International Conference on Program Comprehension},
pages = {179–190},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICPC '19}
}

@inproceedings{10.1145/3379597.3387466,
author = {Fang, Hongbo and Klug, Daniel and Lamba, Hemank and Herbsleb, James and Vasilescu, Bogdan},
title = {Need for Tweet: How Open Source Developers Talk About Their GitHub Work on Twitter},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387466},
doi = {10.1145/3379597.3387466},
abstract = {Social media, especially Twitter, has always been a part of the professional lives of software developers, with prior work reporting on a diversity of usage scenarios, including sharing information, staying current, and promoting one's work. However, previous studies of Twitter use by software developers typically lack information about activities of the study subjects (and their outcomes) on other platforms. To enable such future research, in this paper we propose a computational approach to cross-link users across Twitter and GitHub, revealing (at least) 70,427 users active on both. As a preliminary analysis of this dataset, we report on a case study of 786 tweets by open-source developers about GitHub work, combining automatic characterization of tweet authors in terms of their relationship to the GitHub items linked in their tweets with qualitative analysis of the tweet contents. We find that different developer roles tend to have different tweeting behaviors, with repository owners being perhaps the most distinctive group compared to other project contributors and followers. We also note a sizeable group of people who follow others on GitHub and tweet about these people's work, but do not otherwise contribute to those open-source projects. Our results and public dataset open up multiple future research directions.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {322–326},
numpages = {5},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3377811.3380412,
author = {Zhou, Shurui and Vasilescu, Bogdan and K\"{a}stner, Christian},
title = {How Has Forking Changed in the Last 20 Years? A Study of Hard Forks on GitHub},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380412},
doi = {10.1145/3377811.3380412},
abstract = {The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub. Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks. To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories. We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {445–456},
numpages = {12},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/2884781.2884875,
author = {Vasilescu, Bogdan and Blincoe, Kelly and Xuan, Qi and Casalnuovo, Casey and Damian, Daniela and Devanbu, Premkumar and Filkov, Vladimir},
title = {The Sky is Not the Limit: Multitasking across GitHub Projects},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884875},
doi = {10.1145/2884781.2884875},
abstract = {Software development has always inherently required multitasking: developers switch between coding, reviewing, testing, designing, and meeting with colleagues. The advent of software ecosystems like GitHub has enabled something new: the ability to easily switch between projects. Developers also have social incentives to contribute to many projects; prolific contributors gain social recognition and (eventually) economic rewards. Multitasking, however, comes at a cognitive cost: frequent context-switches can lead to distraction, sub-standard work, and even greater stress. In this paper, we gather ecosystem-level data on a group of programmers working on a large collection of projects. We develop models and methods for measuring the rate and breadth of a developers' context-switching behavior, and we study how context-switching affects their productivity. We also survey developers to understand the reasons for and perceptions of multitasking. We find that the most common reason for multitasking is interrelationships and dependencies between projects. Notably, we find that the rate of switching and breadth (number of projects) of a developer's work matter. Developers who work on many projects have higher productivity if they focus on few projects per day. Developers that switch projects too much during the course of a day have lower productivity as they work on more projects overall. Despite these findings, developers perceptions of the benefits of multitasking are varied.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {994–1005},
numpages = {12},
keywords = {multitasking, productivity, GitHub},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2652524.2652564,
author = {Zhu, Jiaxin and Zhou, Minghui and Mockus, Audris},
title = {Patterns of Folder Use and Project Popularity: A Case Study of Github Repositories},
year = {2014},
isbn = {9781450327749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2652524.2652564},
doi = {10.1145/2652524.2652564},
abstract = {Context: Every software development project uses folders to organize software artifacts. Goal: We would like to understand how folders are used and what ramifications different uses may have. Method: In this paper we study the frequency of folders used by 140k Github projects and use regression analysis to model how folder use is related to project popularity, i.e., the extent of forking. Results: We find that the standard folders, such as document, testing, and examples, are not only among the most frequently used, but their presence in a project is associated with increased chances that a project's code will be forked (i.e., used by others) and an increased number of forks. Conclusions: This preliminary study of folder use suggests opportunities to quantify (and improve) file organization practices based on folder use patterns of large collections of repositories.},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {30},
numpages = {4},
keywords = {folder use, project popularity, mining software repository},
location = {Torino, Italy},
series = {ESEM '14}
}

@inproceedings{10.1145/2567948.2578843,
author = {Loyola, Pablo and Ko, In-Young},
title = {Population Dynamics in Open Source Communities: An Ecological Approach Applied to Github},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2578843},
doi = {10.1145/2567948.2578843},
abstract = {Open Source Software (OSS) has gained high amount of popularity during the last few years. It is becoming used by public and private institutions, even companies release portions of their code to obtain feedback from the community of voluntary developers. As OSS is based on the voluntary contributions of developers, the number of participants represents one of the key elements that impact the quality of the software. In order to understand how the the population of contributors evolve over time, we propose a methodology that adapts Lotka-Volterra-based biological models used for describing host-parasite interactions. Experiments based on data from the Github collaborative platform showed that the proposed approach performs effectively in terms of providing an estimation of the population of developers for each project over time.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {993–998},
numpages = {6},
keywords = {open source software development, ecological models, biological mutualism},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/3022198.3026354,
author = {Saxena, Rohit and Pedanekar, Niranjan},
title = {I Know What You Coded Last Summer: Mining Candidate Expertise from GitHub Repositories},
year = {2017},
isbn = {9781450346887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3022198.3026354},
doi = {10.1145/3022198.3026354},
abstract = {Resumes and social recommendations are often high-level indicators of a candidate's technical skillset. In this paper, we present a method to create a more detailed technology skill profile of a candidate based on her code repository contributions. For this purpose, we annotate user contributions to GitHub code repositories with technology tags found in Stack Overflow questions and answers (Q&amp;A) in an unsupervised manner. We also present SkillMap, a visual representation of candidate skill profile, for quick review and comparison with other candidate profiles. We create SkillMaps for 66 Java programmers and present a preliminary qualitative assessment though manual analysis and interviews of technical recruiters.},
booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {299–302},
numpages = {4},
keywords = {programming skills, talent acquisition, github, stack overflow, tagging},
location = {Portland, Oregon, USA},
series = {CSCW '17 Companion}
}

@inproceedings{10.5555/3306127.3331935,
author = {Blythe, James and Ferrara, Emilio and Huang, Di and Lerman, Kristina and Muric, Goran and Sapienza, Anna and Tregubov, Alexey and Pacheco, Diogo and Bollenbacher, John and Flammini, Alessandro and Hui, Pik-Mai and Menczer, Filippo},
title = {The DARPA SocialSim Challenge: Massive Multi-Agent Simulations of the Github Ecosystem},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We model the evolution of GitHub, a large collaborative software-development ecosystem, using massive multi-agent simulations as a part of DARPA's SocialSim program. Our best performing models and our agent-based simulation framework are described here. Six different agent models were tested based on a variety of machine learning and statistical methods. The most successful models are based on sampling from a stationary probability distribution of actions and repositories for each agent.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1835–1837},
numpages = {3},
keywords = {GitHub, massive scale simulations, collaborative platforms},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.1145/3377812.3390911,
author = {Zhou, Shurui and Vasilescu, Bogdan and K\"{a}stner, Christian},
title = {How Has Forking Changed in the Last 20 Years? A Study of Hard Forks on GitHub},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3390911},
doi = {10.1145/3377812.3390911},
abstract = {The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub. Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community. Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks. To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories. We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive non-competitive alternative to the original project.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {268–269},
numpages = {2},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1109/MSR.2017.24,
author = {Beller, Moritz and Gousios, Georgios and Zaidman, Andy},
title = {TravisTorrent: Synthesizing Travis CI and GitHub for Full-Stack Research on Continuous Integration},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.24},
doi = {10.1109/MSR.2017.24},
abstract = {Continuous Integration (CI) has become a best practice of modern software development. Thanks in part to its tight integration with GitHub, Travis CI has emerged as arguably the most widely used CI platform for Open-Source Software (OSS) development. However, despite its prominent role in Software Engineering in practice, the benefits, costs, and implications of doing CI are all but clear from an academic standpoint. Little research has been done, and even less was of quantitative nature. In order to lay the groundwork for data-driven research on CI, we built TravisTorrent, travistorrent.testroots.org, a freely available data set based on Travis CI and GitHub that provides easy access to hundreds of thousands of analyzed builds from more than 1,000 projects. Unique to TravisTorrent is that each of its 2,640,825 Travis builds is synthesized with meta data from Travis CI's API, the results of analyzing its textual build log, a link to the GitHub commit which triggered the build, and dynamically aggregated project data from the time of commit extracted through GHTorrent.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {447–450},
numpages = {4},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/2897659.2897660,
author = {Ying, Haochao and Chen, Liang and Liang, Tingting and Wu, Jian},
title = {EARec: Leveraging Expertise and Authority for Pull-Request Reviewer Recommendation in GitHub},
year = {2016},
isbn = {9781450341585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897659.2897660},
doi = {10.1145/2897659.2897660},
abstract = {Pull-Request (PR) is a primary way of code contribution from developers to improve quality of software projects in GitHub. For a popular GitHub project, tens of PR are submitted daily, while only a small number of developers, i.e core developers, have the grant to judge whether to merge these changes into the main branches or not. Due to the time-consumption of PR review and the diversity of PR aspects, it is becoming a big challenge for core developers to quickly discover the useful PR. Currently, recommending appropriate reviewers (developers) for incoming PR to quickly collect meaningful comments, is treated as an effective and crowdsourced way to help core developers to make decisions and thus accelerate project development. In this paper, we propose a reviewer recommendation approach (EARec) which simultaneously considers developer expertise and authority. Specifically, we first construct a graph of incoming PR and possible reviewers, and then take advantage of text similarity of PR and social relations of reviewers to find the appropriate reviewers. The experimental analysis on MSR Mining Challenge Dataset provides good evaluation for our approach in terms of precision and recall.},
booktitle = {Proceedings of the 3rd International Workshop on CrowdSourcing in Software Engineering},
pages = {29–35},
numpages = {7},
keywords = {random walk with restart, social network, reviewer recommendation, pull-request},
location = {Austin, Texas},
series = {CSI-SE '16}
}

@inproceedings{10.1109/MSR.2019.00036,
author = {Trockman, Asher and van Tonder, Rijnard and Vasilescu, Bogdan},
title = {Striking Gold in Software Repositories? An Econometric Study of Cryptocurrencies on GitHub},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00036},
doi = {10.1109/MSR.2019.00036},
abstract = {Cryptocurrencies have a significant open source development presence on GitHub. This presents a unique opportunity to observe their related developer effort and software growth. Individual cryptocurrency prices are partly driven by attractiveness, and we hypothesize that high-quality, actively-developed software is one of its influences. Thus, we report on a study of a panel data set containing nearly a year of daily observations of development activity, popularity, and market capitalization for over two hundred open source cryptocurrencies. We find that open source project popularity is associated with higher market capitalization, though development activity and quality assurance practices are insignificant variables in our models. Using Granger causality tests, we find no compelling evidence for a dynamic relation between market capitalization and metrics such as daily stars, forks, watchers, commits, contributors, and lines of code changed.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {181–185},
numpages = {5},
keywords = {software metrics, cryptocurrency, github, software quality, open source software},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1109/MSR.2019.00088,
author = {Joshi, Saket Dattatray and Chimalakonda, Sridhar},
title = {RapidRelease: A Dataset of Projects and Issues on Github with Rapid Releases},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00088},
doi = {10.1109/MSR.2019.00088},
abstract = {In the recent years, there has been a surge in the adoption of agile development model and continuous integration (CI) in software development. Recent trends have reduced average release cycle lengths to as low as 1--2 weeks, leading to an extensive number of studies in release engineering. Open-source development (OSD) has also witnessed a rapid increase in release rates, however, no large dataset of open-source projects exists which features high release rates. In this paper, we introduce the RapidRelease dataset, a data showcase of high release frequency open-source projects. The dataset hosts 994 projects from Github, with over 2 million issue reports. To the best of our knowledge, this is the first dataset that can facilitate researchers to empirically study release engineering and agile software development in open-source projects with rapid releases.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {587–591},
numpages = {5},
keywords = {agile development, release engineering, release cycles, Github repositories, open source development},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3379597.3387473,
author = {Gonzalez, Danielle and Zimmermann, Thomas and Nagappan, Nachiappan},
title = {The State of the ML-Universe: 10 Years of Artificial Intelligence &amp; Machine Learning Software Development on GitHub},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387473},
doi = {10.1145/3379597.3387473},
abstract = {In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI &amp; ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI &amp; ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI &amp; ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends.In this paper, we conducted a large-scale empirical study of AI &amp; ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI &amp; ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI &amp; ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI &amp; ML community has unique characteristics that should be accounted for in future research.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {431–442},
numpages = {12},
keywords = {machine learning, Open Source, artificial intelligence, GitHub, mining software repositories, software engineering},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1109/ICPC.2015.32,
author = {Vendome, Christopher and Linares-Vasquez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and German, Daniel and Poshyvanyk, Denys},
title = {License Usage and Changes: A Large-Scale Study of Java Projects on GitHub},
year = {2015},
isbn = {9781467381598},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPC.2015.32},
doi = {10.1109/ICPC.2015.32},
abstract = {Software licenses determine, from a legal point of view, under which conditions software can be integrated, used, and above all, redistributed. Licenses evolve over time to meet the needs of development communities and to cope with emerging legal issues and new development paradigms. Such evolution of licenses is likely to be accompanied by changes in the way how software uses such licenses, resulting in some licenses being adopted while others are abandoned. This paper reports a large empirical study aimed at quantitatively and qualitatively investigating when and why developer change software licenses. Specifically, we first identify licenses' changes in 1,731,828 commits, representing the entire history of 16,221 Java projects hosted on GitHub. Then, to understand the rationale of license changes, we perform a qualitative analysis -- following a grounded theory approach -- of commit notes and issue tracker discussions concerning licensing topics and, whenever possible, try to build trace ability links between discussions and changes. Our results point out a lack of trace ability of when and why licensing changes are made. This can be a major concern, because a change in the license of a system can negatively impact those that reuse it.},
booktitle = {Proceedings of the 2015 IEEE 23rd International Conference on Program Comprehension},
pages = {218–228},
numpages = {11},
keywords = {Software Licenses, Mining Software Repositories, Empirical Studies},
series = {ICPC '15}
}

@inproceedings{10.1145/2889160.2889244,
author = {Rahman, Mohammad Masudur and Roy, Chanchal K. and Collins, Jason A.},
title = {CoRReCT: Code Reviewer Recommendation in GitHub Based on Cross-Project and Technology Experience},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889244},
doi = {10.1145/2889160.2889244},
abstract = {Peer code review locates common coding rule violations and simple logical errors in the early phases of software development, and thus reduces overall cost. However, in GitHub, identifying an appropriate code reviewer for a pull request is a non-trivial task given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation technique that considers not only the relevant cross-project work history (e.g., external library experience) but also the experience of a developer in certain specialized technologies associated with a pull request for determining her expertise as a potential code reviewer. We first motivate our technique using an exploratory study with 10 commercial projects and 10 associated libraries external to those projects. Experiments using 17,115 pull requests from 10 commercial projects and six open source projects show that our technique provides 85%-- 92% recommendation accuracy, about 86% precision and 79%--81% recall in code reviewer recommendation, which are highly promising. Comparison with the state-of-the-art technique also validates the empirical findings and the superiority of our recommendation technique.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {222–231},
numpages = {10},
keywords = {GitHub, cross-project experience, specialized technology experience, code reviewer recommendation, pull request},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.5555/2820282.2820314,
author = {Vendome, Christopher and Linares-V\'{a}squez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and German, Daniel and Poshyvanyk, Denys},
title = {License Usage and Changes: A Large-Scale Study of Java Projects on GitHub},
year = {2015},
publisher = {IEEE Press},
abstract = {Software licenses determine, from a legal point of view, under which conditions software can be integrated, used, and above all, redistributed. Licenses evolve over time to meet the needs of development communities and to cope with emerging legal issues and new development paradigms. Such evolution of licenses is likely to be accompanied by changes in the way how software uses such licenses, resulting in some licenses being adopted while others are abandoned. This paper reports a large empirical study aimed at quantitatively and qualitatively investigating when and why developer change software licenses. Specifically, we first identify licenses' changes in 1,731,828 commits, representing the entire history of 16,221 Java projects hosted on GitHub. Then, to understand the rationale of license changes, we perform a qualitative analysis---following a grounded theory approach---of commit notes and issue tracker discussions concerning licensing topics and, whenever possible, try to build traceability links between discussions and changes. Our results point out a lack of traceability of when and why licensing changes are made. This can be a major concern, because a change in the license of a system can negatively impact those that reuse it.},
booktitle = {Proceedings of the 2015 IEEE 23rd International Conference on Program Comprehension},
pages = {218–228},
numpages = {11},
keywords = {mining software repositories, software licenses, empirical studies},
location = {Florence, Italy},
series = {ICPC '15}
}

@inproceedings{10.1109/MSR.2017.62,
author = {Beller, Moritz and Gousios, Georgios and Zaidman, Andy},
title = {Oops, My Tests Broke the Build: An Explorative Analysis of Travis CI with GitHub},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.62},
doi = {10.1109/MSR.2017.62},
abstract = {Continuous Integration (CI) has become a best practice of modern software development. Yet, at present, we have a shortfall of insight into the testing practices that are common in CI-based software development. In particular, we seek quantifiable evidence on how central testing is to the CI process, how strongly the project language influences testing, whether different integration environments are valuable and if testing on the CI can serve as a surrogate to local testing in the IDE. In an analysis of 2,640,825 Java and Ruby builds on Travis CI, we find that testing is the single most important reason why builds fail. Moreover, the programming language has a strong influence on both the number of executed tests, their run time, and proneness to fail. The use of multiple integration environments leads to 10% more failures being caught at build time. However, testing on Travis CI does not seem an adequate surrogate for running tests locally in the IDE. To further research on Travis CI with GitHub, we introduce TravisTorrent.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {356–367},
numpages = {12},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/3234152.3234160,
author = {Ortu, Marco and Pinna, Andrea and Tonelli, Roberto and Marchesi, Michele and Bowes, David and Destefanis, Giuseppe},
title = {Angry-Builds: An Empirical Study of Affect Metrics and Builds Success on Github Ecosystem},
year = {2018},
isbn = {9781450364225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234152.3234160},
doi = {10.1145/3234152.3234160},
abstract = {Automatic and repeatable builds are an established software engineering practices for achieving continuous integration and continuous delivery processes. The building phase of modern software systems is an important part of the development process such that dedicated roles as "Release Engineer" are more and more required. Software development is a collaborative activity, and when multiple developers work on the same project, they will be changing a shared master development branch at overlapping intervals. This overlap occurs because developers create parallel branches for working and then merge these branches when features are completed. Continuous integration, CI, is a workflow strategy which helps ensure everyone\^{a}\u{A}undefineds changes will integrate with the current version of the project. This activity allows developers to catch bugs and reduce merge conflicts. Improving the building process leads to higher productivity and therefore shorter time to market, but understanding or measuring such a delicate phase is a big challenge. Open Source Communities provide valuable empirical data such as GitHub an Travis CI. These repositories represent a golden mine containing important data which can help researchers understanding the process behind the manufacturing of a software artifact. By analyzing Travis CI logs, we can directly connect a particular build with the development process behind it, not only regarding code changes but also regarding human activities, such as discussions about the implementation of a specific feature or bug resolution. Thanks to this information we can analyze the social activities of the build process enabling us to apply the same approach used for the development process.},
booktitle = {Proceedings of the 19th International Conference on Agile Software Development: Companion},
articleno = {35},
numpages = {2},
location = {Porto, Portugal},
series = {XP '18}
}

@inproceedings{10.1109/ICSE.2017.42,
author = {Ma, Wanwangying and Chen, Lin and Zhang, Xiangyu and Zhou, Yuming and Xu, Baowen},
title = {How Do Developers Fix Cross-Project Correlated Bugs? A Case Study on the GitHub Scientific Python Ecosystem},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2017.42},
doi = {10.1109/ICSE.2017.42},
abstract = {GitHub, a popular social-software-development platform, has fostered a variety of software ecosystems where projects depend on one another and practitioners interact with each other. Projects within an ecosystem often have complex inter-dependencies that impose new challenges in bug reporting and fixing. In this paper, we conduct an empirical study on cross-project correlated bugs, i.e., causally related bugs reported to different projects, focusing on two aspects: 1) how developers track the root causes across projects; and 2) how the downstream developers coordinate to deal with upstream bugs. Through manual inspection of bug reports collected from the scientific Python ecosystem and an online survey with developers, this study reveals the common practices of developers and the various factors in fixing cross-project bugs. These findings provide implications for future software bug analysis in the scope of ecosystem, as well as shed light on the requirements of issue trackers for such bugs.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {381–392},
numpages = {12},
keywords = {coordinate, root causes tracking, GitHub ecosystems, cross-project correlated bugs},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@inproceedings{10.1145/3341161.3342928,
author = {Thomas, Pamela Bilo and Krohn, Rachel and Weninger, Tim},
title = {Dynamics of Team Library Adoptions: An Exploration of GitHub Commit Logs},
year = {2019},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3342928},
doi = {10.1145/3341161.3342928},
abstract = {When a group of people strives to understand new information, struggle ensues as various ideas compete for attention. Steep learning curves are surmounted as teams learn together. To understand how these team dynamics play out in software development, we explore Git logs, which provide a complete change history of software repositories. In these repositories, we observe code additions, which represent successfully implemented ideas, and code deletions, which represent ideas that have failed or been superseded. By examining the patterns between these commit types, we can begin to understand how teams adopt new information. We specifically study what happens after a software library is adopted by a project, i.e., when a library is used for the first time in the project. We find that a variety of factors, including team size, library popularity, and prevalence on Stack Overflow are associated with how quickly teams learn and successfully adopt new software libraries.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {470–473},
numpages = {4},
keywords = {information adoption, innovation, software libraries, GitHub},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1145/2441776.2441792,
author = {Marlow, Jennifer and Dabbish, Laura and Herbsleb, Jim},
title = {Impression Formation in Online Peer Production: Activity Traces and Personal Profiles in Github},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441792},
doi = {10.1145/2441776.2441792},
abstract = {In this paper we describe a qualitative investigation of impression formation in an online distributed software development community with social media functionality. We find that users in this setting seek out additional information about each other to explore the project space, inform future interactions, and understand the potential future value of a new person. They form impressions around other users' expertise based on history of activity across projects, and successful collaborations with key high status projects in the community. These impressions influence their receptivity to strangers' work contributions.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {117–128},
numpages = {12},
keywords = {activity traces, collaborative software development, impression formation, peer production},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/3209626.3209723,
author = {Thangavelu, Senthilkumar and Jyotishi, Amalendu},
title = {Determinants of Open Source Software Project Performance: A Stage-Wise Analysis of GitHub Projects},
year = {2018},
isbn = {9781450357685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209626.3209723},
doi = {10.1145/3209626.3209723},
booktitle = {Proceedings of the 2018 ACM SIGMIS Conference on Computers and People Research},
pages = {41–42},
numpages = {2},
location = {Buffalo-Niagara Falls, NY, USA},
series = {SIGMIS-CPR'18}
}

@inproceedings{10.1109/ICSE.2019.00060,
author = {Kavaler, David and Trockman, Asher and Vasilescu, Bogdan and Filkov, Vladimir},
title = {Tool Choice Matters: JavaScript Quality Assurance Tools and Usage Outcomes in GitHub Projects},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00060},
doi = {10.1109/ICSE.2019.00060},
abstract = {Quality assurance automation is essential in modern software development. In practice, this automation is supported by a multitude of tools that fit different needs and require developers to make decisions about which tool to choose in a given context. Data and analytics of the pros and cons can inform these decisions. Yet, in most cases, there is a dearth of empirical evidence on the effectiveness of existing practices and tool choices.We propose a general methodology to model the time-dependent effect of automation tool choice on four outcomes of interest: prevalence of issues, code churn, number of pull requests, and number of contributors, all with a multitude of controls. On a large data set of npm JavaScript projects, we extract the adoption events for popular tools in three task classes: linters, dependency managers, and coverage reporters. Using mixed methods approaches, we study the reasons for the adoptions and compare the adoption effects within each class, and sequential tool adoptions across classes. We find that some tools within each group are associated with more beneficial outcomes than others, providing an empirical perspective for the benefits of each. We also find that the order in which some tools are implemented is associated with varying outcomes.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {476–487},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1109/SBSC.2008.30,
author = {Provensi, Lucas Luiz and Costa, F\'{a}bio Moreira and Sacramento, Vagner},
title = {Uma Arquitetura de Middleware Para Suporte a Aplica\c{c}\~{o}Es Colaborativas de Tinta Digital},
year = {2008},
isbn = {9780769535005},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SBSC.2008.30},
doi = {10.1109/SBSC.2008.30},
abstract = {A comunica\c{c}\~{a}o \'{e} um dos aspectos fundamentais em sistemas colaborativos, e deve possibilitar uma intera\c{c}\~{a}o efetiva e de qualidade entre os usu\'{a}rios. Solu\c{c}\~{o}es convencionais de comunica\c{c}\~{a}o para aplica\c{c}\~{o}es colaborativas n\~{a}o tratam o dinamismo de alguns ambientes de rede, como o ambiente de computa\c{c}\~{a}o m\'{o}vel. Este artigo apresenta uma infra-estrutura de middleware capaz de se adaptar a varia\c{c}\~{o}es em seu ambiente de execu\c{c}\~{a}o para manter a qualidade da comunica\c{c}\~{a}o em sistemas colaborativos, com interesse espec\'{\i}fico em aplica\c{c}\~{o}es de tinta digital em tablet PCs.},
booktitle = {Proceedings of the 2008 Simp\'{o}sio Brasileiro de Sistemas Colaborativos},
pages = {180–191},
numpages = {12},
keywords = {Middleware Auto-Adaptativo, Tinta Digital, QoS em Aplica\c{c}\~{o}es Colaborativas},
series = {SBSC '08}
}

@inproceedings{10.1109/UIC-ATC.2010.111,
author = {Wang, Ben and Zhou, Xingshe and Yang, Gang and Yang, Yalei},
title = {DS Theory-Based Software Trustworthiness Classification Assessment},
year = {2010},
isbn = {9780769542720},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UIC-ATC.2010.111},
doi = {10.1109/UIC-ATC.2010.111},
abstract = {Software trustworthiness Evaluation has become a research focus nowadays. Referencing the TRUSTIE Software Trust Classification Specification and Trust Evidence Framework Specification, we proposed a software trustworthiness classification assessment method based on DS theory. In this method, the uncertainty and evidences combination which are important during the evaluation but rarely considered by existing studies are taken into account, and DS combination rule and Shannon entropy are applied to address the problems. The simple example shows that this method is effective for ranking trustworthiness of software which is deve},
booktitle = {Proceedings of the 2010 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing},
pages = {434–438},
numpages = {5},
keywords = {DS theory, entropy, software trustworthiness classification, trustie},
series = {UIC-ATC '10}
}

@inproceedings{10.1145/3379597.3387501,
author = {Fan, Jiahao and Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
title = {A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387501},
doi = {10.1145/3379597.3387501},
abstract = {We collected a large C/C++ code vulnerability dataset from open-source Github projects, namely Big-Vul. We crawled the public Common Vulnerabilities and Exposures (CVE) database and CVE-related source code repositories. Specifically, we collected the descriptive information of the vulnerabilities from the CVE database, e.g., CVE IDs, CVE severity scores, and CVE summaries. With the CVE information and its related published Github code repository links, we downloaded all of the code repositories and extracted vulnerability related code changes. In total, Big-Vul contains 3,754 code vulnerabilities spanning 91 different vulnerability types. All these code vulnerabilities are extracted from 348 Github projects. All information is stored in the CSV format. We linked the code changes with the CVE descriptive information. Thus, our Big-Vul can be used for various research topics, e.g., detecting and fixing vulnerabilities, analyzing the vulnerability related code changes. Big-Vul is publicly available on Github.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {508–512},
numpages = {5},
keywords = {Common Vulnerabilities and Exposures, C/C++ Code, Code Changes},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3267183.3267192,
author = {Santos, Adriano and Souza, Maur\'{\i}cio and Oliveira, Johnatan and Figueiredo, Eduardo},
title = {Mining Software Repositories to Identify Library Experts},
year = {2018},
isbn = {9781450365543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267183.3267192},
doi = {10.1145/3267183.3267192},
abstract = {Programming is multi-faceted, inherently involving several different skills. With the advent of collaboration platforms like GitHub, developers have the opportunity to contribute to projects from different organizations and collaborate with various developers from around the world. With GitHub data, new opportunities to identify developers abilities become possible. From GitHub, it is possible to infer several skills from a developer, for instance, the user of libraries. In this paper, we propose a method to identify library experts, based on the knowledge they produce on GitHub. We evaluated our method in an experiment to identify possible experts in three Java libraries. Our method ranked the top 100 developers for each technology. Then we compared the selected profiles from GitHub with profiles of these developers on the social network LinkedIn to see if what they report in LinkedIn matches what they produce in GitHub. We also surveyed students to compare the results of our method to the manual analysis. Our results showed that 89% of selected GitHub developers reported their skills in social networking sites as LinkedIn, according to the ranking made by our method and that the ranking produced by our method is related to the classification made by survey participants.},
booktitle = {Proceedings of the VII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {83–91},
numpages = {9},
keywords = {Software development skills, Mining software repositories, Expert identification},
location = {Sao Carlos, Brazil},
series = {SBCARS '18}
}

@inproceedings{10.5555/2486788.2486804,
author = {Pham, Raphael and Singer, Leif and Liskin, Olga and Figueira Filho, Fernando and Schneider, Kurt},
title = {Creating a Shared Understanding of Testing Culture on a Social Coding Site},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = { Many software development projects struggle with creating and communicating a testing culture that is appropriate for the project's needs. This may degrade software quality by leaving defects undiscovered. Previous research suggests that social coding sites such as GitHub provide a collaborative environment with a high degree of social transparency. This makes developers' actions and interactions more visible and traceable. We conducted interviews with 33 active users of GitHub to investigate how the increased transparency found on GitHub influences developers' testing behaviors. Subsequently, we validated our findings with an online questionnaire that was answered by 569 members of GitHub. We found several strategies that software developers and managers can use to positively influence the testing behavior in their projects. However, project owners on GitHub may not be aware of them. We report on the challenges and risks caused by this and suggest guidelines for promoting a sustainable testing culture in software development projects. },
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {112–121},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.5555/2487085.2487132,
author = {Gousios, Georgios},
title = {The GHTorent Dataset and Tool Suite},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
abstract = { During the last few years, GitHub has emerged as a popular project hosting, mirroring and collaboration platform. GitHub provides an extensive REST API, which enables researchers to retrieve high-quality, interconnected data. The GHTorent project has been collecting data for all public projects available on Github for more than a year. In this paper, we present the dataset details and construction process and outline the challenges and research opportunities emerging from it. },
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {233–236},
numpages = {4},
location = {San Francisco, CA, USA},
series = {MSR '13}
}

@inproceedings{10.1109/ISECS.2008.133,
author = {Han-xia, Liu and Rong-jun, Li},
title = {Responsibility of Net-Bank in Electronic Payment},
year = {2008},
isbn = {9780769532585},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISECS.2008.133},
doi = {10.1109/ISECS.2008.133},
abstract = {This paper investigates five electronic payment tools which are prevalent in the virtual world nowadays. It is demonstrated that the net-banks play an important role in the process of electronic payment, and that they are also facing greater legal risks than ever before because consumer-protection regulations are pervasive in deve-loped countries that govern net-banks' activities and impose more liabilities on them. This paper analyses the responsibilities of net-banks in handling electronic payments under the framework of law in the U.S. and recommends that China enact similar laws defining net-bank's liabilities and responsibilities to ensure the sustainable development of electronic payment.},
booktitle = {Proceedings of the 2008 International Symposium on Electronic Commerce and Security},
pages = {771–775},
numpages = {5},
keywords = {e-commerce, net-bank, payment tools, responsibility},
series = {ISECS '08}
}

@inproceedings{10.5555/2738165.2738196,
author = {Melo, Amanda Meincke},
title = {Acessibilidade e Inclus\~{a}o Digital},
year = {2014},
publisher = {Sociedade Brasileira de Computa\c{c}\~{a}o},
address = {BRA},
abstract = {A promo\c{c}\~{a}o da acessibilidade est\'{a} diretamente relacionada ao exerc\'{\i}cio da cidadania. Efetiv\'{a}-la no desenvolvimento de sistemas computacionais interativos para uso humano -- massivamente presentes em nosso dia a dia -- envolve ter um claro entendimento de seu significado nos dias de hoje, que deve estar alinhado \`{a} defini\c{c}\~{a}o contempor\^{a}nea para defici\^{e}ncia apresentada na Conven\c{c}\~{a}o Internacional sobre os Direitos das Pessoas com Defici\^{e}ncia [2]:[...] a defici\^{e}ncia resulta da intera\c{c}\~{a}o entre pessoas com defici\^{e}ncia e as barreiras devidas \`{a}s atitudes e ao ambiente que impedem a plena e efetiva participa\c{c}\~{a}o dessas pessoas na sociedade em igual de oportunidades com as demais pessoas [...]\'{E} no contexto do Desafio 4 da Sociedade Brasileira de Computa\c{c}\~{a}o (SBC) para o dec\^{e}nio 2006-2016 [1] -- "Acesso Participativo e Universal do Cidad\~{a}o Brasileiro ao Conhecimento" -- e do desafio "Acessibilidade e Inclus\~{a}o Digital", enunciado entre os Grandes Desafios de Pesquisa em Intera\c{c}\~{a}o Humano-Computador do Brasil [5], que este minicurso \'{e} proposto.},
booktitle = {Companion Proceedings of the 13th Brazilian Symposium on Human Factors in Computing Systems},
pages = {73–74},
numpages = {2},
location = {Foz do Igua\c{c}u, Brazil},
series = {IHC '14}
}

@inproceedings{10.1145/2804360.2804366,
author = {Yamashita, Kazuhiro and McIntosh, Shane and Kamei, Yasutaka and Hassan, Ahmed E. and Ubayashi, Naoyasu},
title = {Revisiting the Applicability of the Pareto Principle to Core Development Teams in Open Source Software Projects},
year = {2015},
isbn = {9781450338165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804360.2804366},
doi = {10.1145/2804360.2804366},
abstract = { It is often observed that the majority of the development work of an Open Source Software (OSS) project is contributed by a core team, i.e., a small subset of the pool of active devel- opers. In fact, recent work has found that core development teams follow the Pareto principle — roughly 80% of the code contributions are produced by 20% of the active developers. However, those findings are based on samples of between one and nine studied systems. In this paper, we revisit prior studies about core developers using 2,496 projects hosted on GitHub. We find that even when we vary the heuristic for detecting core developers, and when we control for system size, team size, and project age: (1) the Pareto principle does not seem to apply for 40%-87% of GitHub projects; and (2) more than 88% of GitHub projects have fewer than 16 core developers. Moreover, we find that when we control for the quantity of contributions, bug fixing accounts for a similar proportion of the contributions of both core (18%-20%) and non-core developers (21%-22%). Our findings suggest that the Pareto principle is not compatible with the core teams of many GitHub projects. In fact, several of the studied GitHub projects are susceptible to the “bus factor,” where the impact of a core developer leaving would be quite harmful. },
booktitle = {Proceedings of the 14th International Workshop on Principles of Software Evolution},
pages = {46–55},
numpages = {10},
keywords = {Open source, Pareto principle, Core development team},
location = {Bergamo, Italy},
series = {IWPSE 2015}
}

@inproceedings{10.1145/3183440.3194951,
author = {K\"{a}fer, Verena and Graziotin, Daniel and Bogicevic, Ivan and Wagner, Stefan and Ramadani, Jasmin},
title = {Communication in Open-Source Projects-End of the e-Mail Era?},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194951},
doi = {10.1145/3183440.3194951},
abstract = {Communication is essential in software engineering. Especially in distributed open-source teams, communication needs to be supported by channels including mailing lists, forums, issue trackers, and chat systems. Yet, we do not have a clear understanding of which communication channels stakeholders in open-source projects use. In this study, we fill the knowledge gap by investigating a statistically representative sample of 400 GitHub projects. We discover the used communication channels by regular expressions on project data. We show that (1) half of the GitHub projects use observable communication channels; (2) GitHub Issues, e-mail addresses, and the modern chat system Gitter are the most common channels; (3) mailing lists are only in place five and have a lower market share than all modern chat systems combined.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {242–243},
numpages = {2},
keywords = {mining software repositories, communication, open-source},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1007/978-3-540-87698-4_3,
author = {Rivett, Roger},
title = {Technology, Society and Risk},
year = {2008},
isbn = {9783540876977},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-87698-4_3},
doi = {10.1007/978-3-540-87698-4_3},
abstract = {There remains a healthy debate among those working in the fun-ctional safety field over issues that appear to be fundamental to the discipline. Coming from an industry that is a relative newcomer to this discipline I look to the more established industries to give a lead. Not only are they in debate about key issues, the approaches taken do not always transfer easily to a mass market product, developed within very tight business constraints. Key issues that are debated include:What is meant by risk, what is acceptable risk and who does the accepting?How do we justify that an acceptable risk has been, or will be, achieved?What role does the development process play?What is meant by the concept of a Safety Integrity Level?In this talk I will air some views on these questions based on my experience of deve-loping automotive systems and authoring industry sector guidelines and standards in the hope that this will provoke informed discussion.},
booktitle = {Proceedings of the 27th International Conference on Computer Safety, Reliability, and Security},
pages = {12},
numpages = {1},
location = {Newcastle upon Tyne, UK},
series = {SAFECOMP '08}
}

@inproceedings{10.5555/3155562.3155575,
author = {Zhao, Yangyang and Serebrenik, Alexander and Zhou, Yuming and Filkov, Vladimir and Vasilescu, Bogdan},
title = {The Impact of Continuous Integration on Other Software Development Practices: A Large-Scale Empirical Study},
year = {2017},
isbn = {9781538626849},
publisher = {IEEE Press},
abstract = { Continuous Integration (CI) has become a disruptive innovation in software development: with proper tool support and adoption, positive effects have been demonstrated for pull request throughput and scaling up of project sizes. As any other innovation, adopting CI implies adapting existing practices in order to take full advantage of its potential, and "best practices" to that end have been proposed. Here we study the adaptation and evolution of code writing and submission, issue and pull request closing, and testing practices as Travis CI is adopted by hundreds of established projects on GitHub. To help essentialize the quantitative results, we also survey a sample of GitHub developers about their experiences with adopting Travis CI. Our findings suggest a more nuanced picture of how GitHub teams are adapting to, and benefiting from, continuous integration technology than suggested by prior work. },
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {60–71},
numpages = {12},
location = {Urbana-Champaign, IL, USA},
series = {ASE 2017}
}

@inproceedings{10.1109/SBSC.2010.22,
author = {dos Reis Costa, Jean Marcel and de Souza, Cleidson Ronald Botelho},
title = {Analyzing the Scalability of Awareness Networks in a Distributed Software Development Project},
year = {2010},
isbn = {9780769542393},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SBSC.2010.22},
doi = {10.1109/SBSC.2010.22},
abstract = {Ao longo dos anos muitos trabalhos sobre o conceito de awareness foram publicados. Diversas formas de representar este conceito, bem como defini\c{c}\~{o}es divergentes ou complementares foram apresentadas. De um modo geral, a id\'{e}ia de awareness se refere ao fato de que um ator precisa, ao mesmo tempo, estar ciente do trabalho de seus colegas e informar seus colegas sobre seu pr\'{o}prio trabalho. Esta percep\c{c}\~{a}o sobre o trabalho dos colegas facilita a coordena\c{c}\~{a}o de atividades colaborativas. Apesar das diferentes defini\c{c}\~{o}es, nenhuma delas aborda diretamente o n\'{u}mero de atores sobre os quais um ator precisa estar ciente e, de maneira similar, o n\'{u}mero de atores para os quais este mesmo ator deve informar suas atividades. Baseado em nossos trabalhos anteriores, estes atores formam as chamadas redes de awareness. Esse artigo visa reduzir essa limita\c{c}\~{a}o dos trabalhos anteriores, apresentando dados sobre a escala destas redes de awareness. Estes dados s\~{a}o baseados em um estudo de caso com um projeto distribu\'{\i}do de desenvolvimento de software, o Jazz. Os resultados da an\'{a}lise permitir\~{a}o entender melhor a escalabilidade das redes de awareness ao longo de um projeto e podem nortear futuras pesquisas nessa \'{a}rea.},
booktitle = {Proceedings of the 2010 Brazilian Symposium on Collaborative Systems - Simp\'{o}sio Brasileiro de Sistemas Colaborativos},
pages = {103–110},
numpages = {8},
keywords = {escalabilidade, desenvolvimento distribu\'{\i}do de software},
series = {SBSC '10}
}

@inproceedings{10.1109/ESEM.2017.19,
author = {Fan, Qiang and Yu, Yue and Yin, Gang and Wang, Tao and Wang, Huaimin},
title = {Where is the Road for Issue Reports Classification Based on Text Mining?},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.19},
doi = {10.1109/ESEM.2017.19},
abstract = {Currently, open source projects receive various kinds of issues daily, because of the extreme openness of Issue Tracking System (ITS) in GitHub. ITS is a labor-intensive and time-consuming task of issue categorization for project managers. However, a contributor is only required a short textual abstract to report an issue in GitHub. Thus, most traditional classification approaches based on detailed and structured data (e.g., priority, severity, software version and so on) are difficult to adopt.In this paper, issue classification approaches on a large-scale dataset, including 80 popular projects and over 252,000 issue reports collected from GitHub, were investigated. First, four traditional text-based classification methods and their performances were discussed. Semantic perplexity (i.e., an issues description confuses bug-related sentences with nonbug-related sentences) is a crucial factor that affects the classification performances based on quantitative and qualitative study. Finally, A two-stage classifier framework based on the novel metrics of semantic perplexity of issue reports was designed. Results show that our two-stage classification can significantly improve issue classification performances.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {121–130},
numpages = {10},
keywords = {issue tracking system, machine learning technique, mining software repositories},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@inproceedings{10.1145/2441776.2441794,
author = {Marlow, Jennifer and Dabbish, Laura},
title = {Activity Traces and Signals in Software Developer Recruitment and Hiring},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441794},
doi = {10.1145/2441776.2441794},
abstract = {Social networking tools now allow professionals to post and share their work in online spaces. These professionals build reputation within a community of practice, often with the goal of finding a job. But how are the visible traces of their actions and interactions in online workspaces used in the hiring process? We conducted interviews with members of the GitHub "social coding" community to understand how profiles on the site are used to assess people during recruitment and hiring for software development positions. Both employers and job seekers pointed to specific cues provided on profiles that led them to make inferences (or form impressions) about a candidate's technical skills, motivations, and values. These cues were seen as more reliable indicators of technical abilities and motivation than information provided on a resume, because of the transparency of work actions on GitHub and relative difficulty of manipulating behavior traces. The use of online workspaces like GitHub has implications for the type of information sought by employers as well as the activity traces job hunters might seek to leave.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {145–156},
numpages = {12},
keywords = {open source software development, impression formation, hiring, transparency, impression management},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.5555/3359032.3359039,
author = {Packer, Heather S. and Chapman, Adriane and Carr, Leslie},
title = {GitHub2PROV: Provenance for Supporting Software Project Management},
year = {2019},
publisher = {USENIX Association},
address = {USA},
abstract = {Software project management is a complex task that requires accurate information and experience to inform the decision-making process. In the real world software project managers rarely have access to perfect information. In order to support them, we propose leveraging information from Version Control Systems and their repositories to support decision-making. In this paper, we propose a PROV model GitHub2PROV, which extends Git2PROV with details about GitHub commits and issues from GitHub repositories. We discuss how this model supports project management decisions in agile development, specifically in terms of Control Schedule Reviews and workload.},
booktitle = {Proceedings of the 11th USENIX Conference on Theory and Practice of Provenance},
pages = {5},
numpages = {1},
keywords = {process provenance data, PROV, software project management},
location = {Philadelphia, PA, USA},
series = {TAPP'19}
}

@inproceedings{10.1109/SBCARS.2010.18,
author = {Queiroz, Paulo G. G. and Braga, Rosana T. V.},
title = {Domain Engineering of Software Product Lines with Service-Oriented Architecture},
year = {2010},
isbn = {9780769542591},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SBCARS.2010.18},
doi = {10.1109/SBCARS.2010.18},
abstract = {Software product lines (SPL) have been established as one of the best ways to promote reuse of both requirements and software architecture, even with a high cost when compared to the development of single systems. Service-oriented architecture (SOA) can further facilitate the development of SPL, since several features of the SPL can be implemented by services available on a network. This paper presents SoProL-WS, which is a deve-lopment approach for SPL using SOA. The focus of this article is in the domain engineering phase, where the SPL architecture is developed based on services. From this architecture, one can derive products in the subsequent application engineering phase. The goal of SoProL-WS is to reduce SPL development costs and time, facilitating its maintenance, evolution and derivation of its members. Additionally, this paper presents a case study where SoProl-WS is applied to develop a product line for Web auctions.},
booktitle = {Proceedings of the 2010 Fourth Brazilian Symposium on Software Components, Architectures and Reuse},
pages = {80–89},
numpages = {10},
keywords = {Software product lines, Service-oriented architecture, Domain engineering},
series = {SBCARS '10}
}

@inproceedings{10.1109/ICSE.2019.00046,
author = {Zhang, Tianyi and Yang, Di and Lopes, Crista and Kim, Miryung},
title = {Analyzing and Supporting Adaptation of Online Code Examples},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00046},
doi = {10.1109/ICSE.2019.00046},
abstract = {Developers often resort to online Q&amp;A forums such as Stack Overflow (SO) for filling their programming needs. Although code examples on those forums are good starting points, they are often incomplete and inadequate for developers' local program contexts; adaptation of those examples is necessary to integrate them to production code. As a consequence, the process of adapting online code examples is done over and over again, by multiple developers independently. Our work extensively studies these adaptations and variations, serving as the basis for a tool that helps integrate these online code examples in a target context in an interactive manner.We perform a large-scale empirical study about the nature and extent of adaptations and variations of SO snippets. We construct a comprehensive dataset linking SO posts to GitHub counterparts based on clone detection, time stamp analysis, and explicit URL references. We then qualitatively inspect 400 SO examples and their GitHub counterparts and develop a taxonomy of 24 adaptation types. Using this taxonomy, we build an automated adaptation analysis technique on top of GumTree to classify the entire dataset into these types. We build a Chrome extension called ExampleStack that automatically lifts an adaptation-aware template from each SO example and its GitHub counterparts to identify hot spots where most changes happen. A user study with sixteen programmers shows that seeing the commonalities and variations in similar GitHub counterparts increases their confidence about the given SO example, and helps them grasp a more comprehensive view about how to reuse the example differently and avoid common pitfalls.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {316–327},
numpages = {12},
keywords = {online code examples, code adaptation},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3377811.3380349,
author = {Tan, Shin Hwei and Li, Ziqiang},
title = {Collaborative Bug Finding for Android Apps},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380349},
doi = {10.1145/3377811.3380349},
abstract = {Many automated test generation techniques have been proposed for finding crashes in Android apps. Despite recent advancement in these approaches, a study shows that Android app developers prefer reading test cases written in natural language. Meanwhile, there exist redundancies in bug reports (written in natural language) across different apps that have not been previously reused. We propose collaborative bug finding, a novel approach that uses bugs in other similar apps to discover bugs in the app under test. We design three settings with varying degrees of interactions between programmers: (1) bugs from programmers who develop a different app, (2) bugs from manually searching for bug reports in GitHub repositories, (3) bugs from a bug recommendation system, Bugine. Our studies of the first two settings in a software testing course show that collaborative bug finding helps students who are novice Android app testers to discover 17 new bugs. As students admit that searching for relevant bug reports could be time-consuming, we introduce Bugine, an approach that automatically recommends relevant GitHub issues for a given app. Bugine uses (1) natural language processing to find GitHub issues that mention common UI components shared between the app under test and other apps in our database, and (2) a ranking algorithm to select GitHub issues that are of the best quality. Our results show that Bugine is able to find 34 new bugs. In total, collaborative bug finding helps us find 51 new bugs, in which eight have been confirmed and 11 have been fixed by the developers. These results confirm our intuition that our proposed technique is useful in discovering new bugs for Android apps.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1335–1347},
numpages = {13},
keywords = {test generation, recommendation system, collaborative programming, Android apps},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/2627508.2627515,
author = {Chen, Fangwei and Li, Lei and Jiang, Jing and Zhang, Li},
title = {Predicting the Number of Forks for Open Source Software Project},
year = {2014},
isbn = {9781450329651},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2627508.2627515},
doi = {10.1145/2627508.2627515},
abstract = { GitHub is successful open source software platform which attract many developers. In GitHub, developers are allowed to fork repositories and copy repositories without asking for permission, which make contribution to projects much easier than it has ever been. It is significant to predict the number of forks for open source software projects. The prediction can help GitHub to recommend popular projects, and guide developers to find projects which are likely to succeed and worthy of their contribution.  In this paper, we use stepwise regression and design a model to predict the number of forks for open source software projects. Then we collect datasets of 1,000 repositories through GitHub’s APIs. We use datasets of 700 repositories to compute the weight of attributes and realize the model. Then we use other 300 repositories to verify the prediction accuracy of our model. Advantages of our model include: (1) Some attributes used in our model are new. This is because GitHub is different from traditional open source software platforms and has some new features. These new features are used to build our model. (2) Our model uses project information within t month after its creation, and predicts the number of forks in the month T (t &lt; T). It allows users to set the combination of time parameters and satisfy their own needs. (3) Our model predicts the exact number of forks, rather than the range of the number of forks (4) Experiments show that our model has high prediction accuracy. For example, we use project information with 3 months to prediction the number of forks in month 6 after its creation. The correlation coefficient is as high as 0.992, and the median number of absolute difference between prediction value and actual value is only 1.8. It shows that the predicted number of forks is very close to the actual number of forks. Our model also has high prediction accuracy when we set other time parameters. },
booktitle = {Proceedings of the 2014 3rd International Workshop on Evidential Assessment of Software Technologies},
pages = {40–47},
numpages = {8},
keywords = {Fork, Open Source Software},
location = {Nanjing, China},
series = {EAST 2014}
}

@inproceedings{10.1145/3379597.3387503,
author = {Liu, Pei and Li, Li and Zhao, Yanjie and Sun, Xiaoyu and Grundy, John},
title = {AndroZooOpen: Collecting Large-Scale Open Source Android Apps for the Research Community},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387503},
doi = {10.1145/3379597.3387503},
abstract = {It is critical for research to have an open, well-curated, representative set of apps for analysis. We present a collection of open-source Android apps collected from several sources, including Github. Our dataset, AndroZooOpen, currently contains over 45,000 app artefacts, a representative picture of Github-hosted Android apps. For apps released on Google Play, metadata including categories, ratings and user reviews, are also stored. We share this new dataset as part of our ongoing research to better support and enable new research topics involving Android app artefact analysis, and as a supplement dataset for AndroZoo, a well-known app collection of close-sourced Android apps.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {548–552},
numpages = {5},
keywords = {AndroZooOpen, Open-source, AndroZoo, Android},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.5555/3370272.3370281,
author = {Perrie, Jessica and Xie, Jing and Nayebi, Maleknaz and Fokaefs, Marios and Lyons, Kelly and Stroulia, Eleni},
title = {City on the River: Visualizing Temporal Collaboration},
year = {2019},
publisher = {IBM Corp.},
address = {USA},
abstract = {Collaboration is an important component of most work activities. We are interested in understanding how configurations of people come together to create outputs over time. We propose an interactive visualization tool (City on the River) for visualizing collaborations over time. The City on the River (CotR) visualization shows the contributions and artifacts ("products") of a team on a timeline and the individuals on the team who contributed to each product. CotR enables interactive analyses of each of these components for answering questions such as, which people work together on the most products, which products involve the most people, what kinds of products were produced when and by whom, etc. CotR can be used for analyzing diverse domains such as research collaborations, conference participation, email conversations, and software development. In this paper, we present the results of an experiment to assess CotR for analyzing collaboration and outcomes in GitHub projects. We compared the quality of answers, time to answer, and approaches taken to analyze the project collaborations by two groups of people: one group used the GitHub data displayed in a spreadsheet; the other group used the GitHub data displayed using CotR.},
booktitle = {Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
pages = {82–91},
numpages = {10},
keywords = {visualization, software engineering, collaboration},
location = {Toronto, Ontario, Canada},
series = {CASCON '19}
}

@inproceedings{10.1145/2858036.2858219,
author = {Yu, Haizi and Deka, Biplab and Talton, Jerry O. and Kumar, Ranjitha},
title = {Accounting for Taste: Ranking Curators and Content in Social Networks},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858219},
doi = {10.1145/2858036.2858219},
abstract = {Ranking users in social networks is a well-studied problem, typically solved by algorithms that leverage network structure to identify influential users and recommend people to follow. In the last decade, however, curation --- users sharing and promoting content in a network --- has become a central social activity, as platforms like Facebook, Twitter, Pinterest, and GitHub drive growth and engagement by connecting users through content and content to users. While existing algorithms reward users that are highly active with higher rankings, they fail to account for users' curatorial taste. This paper introduces CuRank, an algorithm for ranking users and content in social networks by explicitly modeling three characteristics of a good curator: discerning taste, high activity, and timeliness. We evaluate CuRank on datasets from two popular social networks --- GitHub and Vine --- and demonstrate its efficacy at ranking content and identifying good curators.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {2383–2389},
numpages = {7},
keywords = {curation, social networks, ranking, content},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1109/SCAM.2014.15,
author = {Rahman, Mohammad Masudur and Roy, Chanchal K.},
title = {On the Use of Context in Recommending Exception Handling Code Examples},
year = {2014},
isbn = {9781479961481},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SCAM.2014.15},
doi = {10.1109/SCAM.2014.15},
abstract = {Studies show that software developers often either misuse exception handling features or use them inefficiently, and such a practice may lead an undergoing software project to a fragile, insecure and non-robust application system. In this paper, we propose a context-aware code recommendation approach that recommends exception handling code examples from a number of popular open source code repositories hosted at GitHub. It collects the code examples exploiting GitHub code search API, and then analyzes, filters and ranks them against the code under development in the IDE by leveraging not only the structural (i.e., graph-based) and lexical features but also the heuristic quality measures of exception handlers in the examples. Experiments with 4,400 code examples and 65 exception handling scenarios as well as comparisons with four existing approaches show that the proposed approach is highly promising.},
booktitle = {Proceedings of the 2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation},
pages = {285–294},
numpages = {10},
keywords = {context-relevance, structural similarity, Exception handler, lexical similarity},
series = {SCAM '14}
}

@inproceedings{10.1145/3377816.3381732,
author = {Raman, Naveen and Cao, Minxuan and Tsvetkov, Yulia and K\"{a}stner, Christian and Vasilescu, Bogdan},
title = {Stress and Burnout in Open Source: Toward Finding, Understanding, and Mitigating Unhealthy Interactions},
year = {2020},
isbn = {9781450371261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377816.3381732},
doi = {10.1145/3377816.3381732},
abstract = {Developers from open-source communities have reported high stress levels from frequent demands for features and bug fixes and from the sometimes aggressive tone of these demands. Toxic conversations may demotivate and burn out developers, creating challenges for sustaining open source. We outline a path toward finding, understanding, and possibly mitigating such unhealthy interactions. We take a first step toward finding them, by developing and demonstrating a measurement instrument (an SVM classifier tailored for software engineering) to detect toxic discussions in GitHub issues. We used our classifier to analyze trends over time and in different GitHub communities, finding that toxicity varies by community and that toxicity decreased between 2012 and 2018.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {57–60},
numpages = {4},
location = {Seoul, South Korea},
series = {ICSE-NIER '20}
}

@inproceedings{10.1145/3183440.3190335,
author = {Trockman, Asher},
title = {Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the <i>Npm</i> Ecosystem},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3190335},
doi = {10.1145/3183440.3190335},
abstract = {Contemporary software development is characterized by increased reuse and speed. Open source software forges such as GitHub host millions of repositories of libraries and tools, which developers reuse liberally [6], creating complex and often fragile networks of interdependencies [1]. Hence, developers must make more decisions at a higher speed, finding which libraries to depend on and which projects to contribute to. This decision making process is supported by the transparency provided by social coding platforms like GitHub [4, 5], where user profile pages display information on a one's contributions, and repository pages provide information on a project's social standing (e.g., through stars and watchers).},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {524–526},
numpages = {3},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3201064.3201067,
author = {Lee, Roy Ka-Wei and Lo, David},
title = {Wisdom in Sum of Parts: Multi-Platform Activity Prediction in Social Collaborative Sites},
year = {2018},
isbn = {9781450355636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3201064.3201067},
doi = {10.1145/3201064.3201067},
abstract = {In this paper, we proposed a novel framework which uses user interests inferred from activities (a.k.a., activity interests) in multiple social collaborative platforms to predict users' platform activities. Included in the framework are two prediction approaches: (i) direct platform activity prediction, which predicts a user's activities in a platform using his or her activity interests from the same platform (e.g., predict if a user answers a given Stack Overflow question using the user's interests inferred from his or her prior answer and favorite activities in Stack Overflow), and (ii) cross-platform activity prediction, which predicts a user's activities in a platform using his or her activity interests from another platform (e.g., predict if a user answers a given Stack Overflow question using the user's interests inferred from his or her fork and watch activities in GitHub). To evaluate our proposed method, we conduct prediction experiments on two widely used social collaborative platforms in the software development community: GitHub and Stack Overflow. Our experiments show that combining both direct and cross platform activity prediction approaches yield the best accuracies for predicting user activities in GitHub (AUC=0.75) and Stack Overflow (AUC=0.89).},
booktitle = {Proceedings of the 10th ACM Conference on Web Science},
pages = {77–86},
numpages = {10},
keywords = {social collaborative platforms, prediction, github, stack overflow},
location = {Amsterdam, Netherlands},
series = {WebSci '18}
}

@inproceedings{10.1109/BotSE.2019.00018,
author = {Wessel, Mairieli and Steinmacher, Igor and Wiese, Igor and Gerosa, Marco A.},
title = {Should I Stale or Should I Close? An Analysis of a Bot That Closes Abandoned Issues and Pull Requests},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/BotSE.2019.00018},
doi = {10.1109/BotSE.2019.00018},
abstract = {On GitHub, projects use bots to automate predefined and repetitive tasks related to issues and pull requests. Our research investigates the adoption of the stale bot, which helps maintainers triaging abandoned issues and pull requests. We analyzed the bots' configuration settings and their modifications over time. These settings define the time for tagging issues and pull request as stale and closing them. We collected data from 765 OSS projects hosted on GitHub. Our results indicate that most of the studied projects made no more than three modifications in the configurations file, issues tagged as bug reports are exempt from being considered stale, while the same occurs with pull requests that need some input to be processed.},
booktitle = {Proceedings of the 1st International Workshop on Bots in Software Engineering},
pages = {38–42},
numpages = {5},
keywords = {open source software, abandoned issues, bots},
location = {Montreal, Quebec, Canada},
series = {BotSE '19}
}

@inproceedings{10.1145/2839509.2851052,
author = {Izbicki, Mike},
title = {Open Sourcing the Classroom (Abstract Only)},
year = {2016},
isbn = {9781450336857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2839509.2851052},
doi = {10.1145/2839509.2851052},
abstract = {This project describes an experimental course on open source software construction. The course has two twists on the standard project-based software construction course. The first twist is simple: all projects are developed and released on GitHub. The second twist is more radical: the course uses an "open source textbook." The textbook is hosted in a git repository that students are required to contribute to throughout the term. Contributions range from minor typo fixes to adding entire chapters. Currently, 88% of the textbook is written by students, including many of the assignments. We use student surveys, participation in social networking sites like GitHub, and web traffic logs to determine that these assignments had a positive effect on students' future contributions to the open source community.},
booktitle = {Proceedings of the 47th ACM Technical Symposium on Computing Science Education},
pages = {723},
numpages = {1},
keywords = {open source, git, education},
location = {Memphis, Tennessee, USA},
series = {SIGCSE '16}
}

@inproceedings{10.1145/3183440.3195073,
author = {Bayati, Shahab},
title = {Understanding Newcomers Success in Open Source Community},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195073},
doi = {10.1145/3183440.3195073},
abstract = {Newcomers and volunteers contributions play an effective role the open source software (OSS) success. This role is confirmed through a rigor set of studies in software engineering discipline. As Open source projects are developed based on social and technical efforts, then it is very important for newcomers to empower their socio-technical skills. This paper focuses on newcomers' success in open source community by analyzing newcomers' reputation on their initial activities in a social coding environment such as GitHub. By applying mining software repositories (MSR) techniques on GitHub data we found the main projects' attributes where successful newcomers contributed to them. These attributes can help other newcomers to select the right project for their initial activities.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {224–225},
numpages = {2},
keywords = {open source, newcomers, social coding, reputation analysis},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.5555/2878379.2878382,
author = {Matteis, Luca and Verborgh, Ruben},
title = {Hosting Queryable and Highly Available Linked Data for Free},
year = {2014},
publisher = {CEUR-WS.org},
address = {Aachen, DEU},
abstract = {SPARQL endpoints suffer from low availability, and require to buy and configure complex servers to host them. With the advent of Linked Data Fragments, and more specifically Triple Pattern Fragments (TPFs), we can now perform complex queries on low-cost servers. Online file repositories and cloud hosting services, such as GitHub, Google Code, Google App Engine or Dropbox can be exploited to host this type of linked data for free. For this purpose we have developed two different proof-of-concept tools that can be used to publish TPFs on GitHub and Google App Engine. A generic TPF client can then be used to perform SPARQL queries on the freely hosted TPF servers.},
booktitle = {Proceedings of the 2014 International Conference on Developers - Volume 1268},
pages = {13–18},
numpages = {6},
keywords = {linked data, hosting, querying, availability},
location = {Riva del Garda, Italy},
series = {ISWC-DEV'14}
}

@inproceedings{10.1145/3034950.3034980,
author = {Aljemabi, Mohammed Abdelrahman and Wang, Zhongjie},
title = {Empirical Study on the Similarity and Difference between VCS-DSN and BTS-DSN},
year = {2017},
isbn = {9781450348348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034950.3034980},
doi = {10.1145/3034950.3034980},
abstract = {Most of the developers are collaborating freely as the team works through the Internet, for developing open source software projects without access restriction, playing different tasks including communications and coordination, making various social collaboration in the open source software projects (e.g., Bug/issue report, discussion, code revisions, etc.). All these activities can be recorded into software repositories like GitHub, and used to generate an implicit developer social network (DSN). In this paper, we conduct our empirical study using 50 open source software projects collected from GitHub and construct VCS-DSN and BTS-DSN to investigate the same collaboration between developers in the real world, and to find similarities and differences between them, in addition to the degree of similarity and diversity.},
booktitle = {Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {30–37},
numpages = {8},
keywords = {Bug tracking system, Mining software repository, Developer social network, Version control system, Software Engineering},
location = {Wuhan, China},
series = {ICMSS '17}
}

@inproceedings{10.5555/2886444.2886499,
author = {Liu, Gary and Siu, Joran and Dawson, Michael and Ho, Ivy and Yan, Yunliang},
title = {Introduction to Debugging and Monitoring Node.Js},
year = {2015},
publisher = {IBM Corp.},
address = {USA},
abstract = {Node.js is a server-side JavaScript platform that has seen explosive growth in recent years. In its 6 years of existence, Node.js has leaped to being the third most-starred repository on GitHub, and is now one of the most popular frameworks for developing cloud, mobile and Internet-of-Things applications.},
booktitle = {Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering},
pages = {291},
numpages = {1},
location = {Markham, Canada},
series = {CASCON '15}
}

@inproceedings{10.5555/2735522.2735554,
author = {Low, Andrew and Siu, Joran and Ho, Ivy and Liu, Gary},
title = {Introduction to Node.Js},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Node.js is a server-side JavaScript platform that has seen explosive growth in recent years. In its 5 years of existence, Node.js has leaped to being the third most-starred repository on GitHub, and is now one of the most popular frameworks for developing cloud, mobile and Internet-of-Things applications.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {283–284},
numpages = {2},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/3183440.3194987,
author = {Nam, Jaechang and Wang, Song and Xi, Yuan and Tan, Lin},
title = {Designing Bug Detection Rules for Fewer False Alarms},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194987},
doi = {10.1145/3183440.3194987},
abstract = {One of the challenging issues of the existing static analysis tools is the high false alarm rate. To address the false alarm issue, we design bug detection rules by learning from a large number of real bugs from open-source projects from GitHub. Specifically, we build a framework that learns and refines bug detection rules for fewer false positives. Based on the framework, we implemented ten patterns, six of which are new ones to existing tools. To evaluate the framework, we implemented a static analysis tool, FeeFin, based on the framework with the ten bug detection rules and applied the tool for 1,800 open-source projects in GitHub. The 57 detected bugs by FeeFin has been confirmed by developers as true positives and 44 bugs out of the detected bugs were actually fixed.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {315–316},
numpages = {2},
keywords = {bug detection rules, bug patterns, static bug finder},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1109/SMC.2019.8914586,
author = {Liu, Renhao and Mubang, Frederick and Hall, Lawrence O. and Horawalavithana, Sameera and Iamnitchi, Adriana and Skvoretz, John},
title = {Predicting Longitudinal User Activity at Fine Time Granularity in Online Collaborative Platforms},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC.2019.8914586},
doi = {10.1109/SMC.2019.8914586},
abstract = {This paper introduces a decomposition approach to address the problem of predicting different user activities at hour granularity over a long period of time. Our approach involves two steps. First, we used a temporal neural network ensemble to predict the number of each type of activity that occurred in a day. Second, we used a set of neural networks to assign the events to a user-repository pair in a particular hour. We focused this work on a subset of the public GitHub dataset that records the activities of over 2 million users on over 400,000 software repositories. Our experiments show we were able to predict hourly user-repo activity with reasonably low error. Our simulations are accurate for 1–3 weeks (168–504 hours) after inception, with accuracy gradually falling off. It was shown that activity on Twitter and Reddit increases the accuracy of activity prediction on GitHub for most events.},
booktitle = {2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)},
pages = {2535–2542},
numpages = {8},
location = {Bari, Italy}
}

@inproceedings{10.1109/MSR.2019.00086,
author = {Biswas, Sumon and Islam, Md Johirul and Huang, Yijia and Rajan, Hridesh},
title = {Boa Meets Python: A Boa Dataset of Data Science Software in Python Language},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00086},
doi = {10.1109/MSR.2019.00086},
abstract = {The popularity of Python programming language has surged in recent years due to its increasing usage in Data Science. The availability of Python repositories in Github presents an opportunity for mining software repository research, e.g., suggesting the best practices in developing Data Science applications, identifying bug-patterns, recommending code enhancements, etc. To enable this research, we have created a new dataset that includes 1,558 mature Github projects that develop Python software for Data Science tasks. By analyzing the metadata and code, we have included the projects in our dataset which use a diverse set of machine learning libraries and managed by a variety of users and organizations. The dataset is made publicly available through Boa infrastructure both as a collection of raw projects as well as in a processed form that could be used for performing large scale analysis using Boa language. We also present two initial applications to demonstrate the potential of the dataset that could be leveraged by the community.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {577–581},
numpages = {5},
keywords = {AST, open source repositories, program analysis, data science, Boa, MSR, machine learning},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2991041.2991044,
author = {Niephaus, Fabio and Henrichs, Dale and Taeumel, Marcel and Pape, Tobias and Felgentreff, Tim and Hirschfeld, Robert},
title = {SmalltalkCI: A Continuous Integration Framework for Smalltalk Projects},
year = {2016},
isbn = {9781450345248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2991041.2991044},
doi = {10.1145/2991041.2991044},
abstract = {Continuous integration (CI) is a programming practice that reduces the risk of project failure by integrating code changes multiple times a day. This has always been important to the Smalltalk community, so custom integration infrastructures are operated that allow CI testing for Smalltalk projects shared in Monticello repositories or traditional changesets.In the last few years, the open hosting platform GitHub has become more and more popular for Smalltalk projects. Unfortunately, there was no convenient way to enable CI testing for those projects.We present smalltalkCI, a continuous integration framework for Smalltalk. It aims to provide a uniform way to load and test Smalltalk projects written in different Smalltalk dialects. smalltalkCI runs on Linux, macOS, and on Windows and can be used locally as well as on a remote server. In addition, it is compatible with Travis CI and AppVeyor, which allows developers to easily set up free CI testing for their GitHub projects without having to run a custom integration infrastructure.},
booktitle = {Proceedings of the 11th Edition of the International Workshop on Smalltalk Technologies},
articleno = {3},
numpages = {9},
keywords = {Coverage Testing, Continuous Integration, Travis CI, Smalltalk, AppVeyor},
location = {Prague, Czech Republic},
series = {IWST'16}
}

@inproceedings{10.1145/3364641.3364650,
author = {Favato, Danilo and Ishitani, Daniel and Oliveira, Johnatan and Figueiredo, Eduardo},
title = {Linus's Law: More Eyes Fewer Flaws in Open Source Projects},
year = {2019},
isbn = {9781450372824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3364641.3364650},
doi = {10.1145/3364641.3364650},
abstract = {Linus's Law states that "given enough eyeballs, all bugs are shallow". In other words, given a large enough number of developers, almost every programming flaw is characterized and fixed quickly. Although there is much debate about this subject, we still lack empirical evidence to support this law. Given that this theme has, and still is, motivating business decisions in software development, we investigate the implications of Linus's Law in two empirical studies on open source projects mined from GitHub. In the first pilot study, we mined seven popular Java projects from GitHub and investigated the correlation between committers and programming flaws in source code files. Results of this pilot study suggest a positive correlation between the number of developers and programming flaws. We cross-validate these results in a second study with almost one hundred Python projects from GitHub. In this second study, we analyzed the correlation between the number of forks - i.e., a proxy for number of developers - and programming flaws identified in projects. In both studies, programming flaws were detected by using static code analysis tools. As a result of the second study, we could not observe a correlation between the number of developers and the number of programming flaws in Python projects. From both studies we conclude that we were unable to find evidence to support the Linus's Law.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Software Quality},
pages = {69–78},
numpages = {10},
keywords = {software quality, Linus's law, python, java},
location = {Fortaleza, Brazil},
series = {SBQS'19}
}

@inproceedings{10.1145/3379597.3387490,
author = {Diamantopoulos, Themistoklis and Papamichail, Michail D. and Karanikiotis, Thomas and Chatzidimitriou, Kyriakos C. and Symeonidis, Andreas L.},
title = {Employing Contribution and Quality Metrics for Quantifying the Software Development Process},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387490},
doi = {10.1145/3379597.3387490},
abstract = {The full integration of online repositories in contemporary software development promotes remote work and collaboration. Apart from the apparent benefits, online repositories offer a deluge of data that can be utilized to monitor and improve the software development process. Towards this direction, we have designed and implemented a platform that analyzes data from GitHub in order to compute a series of metrics that quantify the contributions of project collaborators, both from a development as well as an operations (communication) perspective. We analyze contributions throughout the projects' lifecycle and track the number of coding violations, this way aspiring to identify cases of software development that need closer monitoring and (possibly) further actions to be taken. In this context, we have analyzed the 3000 most popular GitHub Java projects and provide the data to the community.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {558–562},
numpages = {5},
keywords = {DevOps, code violations, mining software repositories, GitHub issues, contribution analysis},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3021460.3021477,
author = {Agrawall, Akash and Chaitanya, Krishna and Agrawal, Arnav Kumar and Choppella, Venkatesh},
title = {Mitigating Browser-Based DDoS Attacks Using CORP},
year = {2017},
isbn = {9781450348560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3021460.3021477},
doi = {10.1145/3021460.3021477},
abstract = {On March 27, 2015, Github witnessed a massive DDoS attack, the largest in Github's history till date. In this incident, browsers and users were used as vectors to launch the attack. In this paper, we analyse such browser-based DDoS attacks and simulate them in a lab environment. Existing browser security policies like Same Origin Policy (SOP), Content Security Policy (CSP) do not mitigate these attacks by design. In this paper we observe that CORP (Cross Origin Request Policy), a browser security policy, can be used to mitigate these attacks. CORP enables a server to control cross-origin interactions initiated by a browser. The browser intercepts the cross-origin requests and blocks unwanted requests by the server. This takes the load off the server to mitigate the attack.},
booktitle = {Proceedings of the 10th Innovations in Software Engineering Conference},
pages = {137–146},
numpages = {10},
keywords = {Javascript, DDoS, Cross-origin requests, MITM (Man in the middle), Browser, Browser-based DDoS},
location = {Jaipur, India},
series = {ISEC '17}
}

@inproceedings{10.1145/3311790.3399616,
author = {Sochat, Vanessa},
title = {AskCI Server: Collaborative Knowledge Base},
year = {2020},
isbn = {9781450366892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311790.3399616},
doi = {10.1145/3311790.3399616},
abstract = { AskCI Server is a collaborative, open source documentation server that uses GitHub for automation and version control of shared knowledge. A programmatic application programming interface, friendly user interface, and organization of concepts into questions makes it versatile as a support or collaborative knowledge base.},
booktitle = {Practice and Experience in Advanced Research Computing},
pages = {514–517},
numpages = {4},
keywords = {knowledge, collaboration, automation, git, version control, articles, documentation, docker},
location = {Portland, OR, USA},
series = {PEARC '20}
}

@inproceedings{10.1109/GLOBECOM38437.2019.9014249,
author = {Liao, Zhifang and Wu, Zexuan and Wu, Jinsong and Zhang, Yan and Liu, Junyi and Long, Jun},
title = {TIRR: A Code Reviewer Recommendation Algorithm with Topic Model and Reviewer Influence},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/GLOBECOM38437.2019.9014249},
doi = {10.1109/GLOBECOM38437.2019.9014249},
abstract = {Code review is an important way to improve software quality and ensure project security. Pull Request (PR), as an important method of collaborative code modification in GitHub open source software community platform, is very important to find a suitable code reviewer to improve code modification efficiency for Pull Request submitted by code modifiers. In order to solve this problem, we have proposed a review recommendation algorithm based on Pull Request topic model and reviewer's influence. This algorithm has not only extracted the topic information of PR through Latent Dirichlet Allocation (LDA) method, but also analyzed the professional knowledge influence of reviewers through influence network. Whatâ€™s more, it has combined the topic information of reviewers to find the appropriate PR reviewers. The experimental results based on GitHub show that the algorithm is more efficient, which can effectively reduce the time of code review and improve the recommendation accuracy.},
booktitle = {2019 IEEE Global Communications Conference (GLOBECOM)},
pages = {1–6},
numpages = {6},
location = {Waikoloa, HI, USA}
}

@inproceedings{10.5555/2486788.2486964,
author = {Pham, Raphael and Singer, Leif and Schneider, Kurt},
title = {Building Test Suites in Social Coding Sites by Leveraging Drive-by Commits},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = { GitHub projects attract contributions from a community of users with varying coding and quality assurance skills. Developers on GitHub feel a need for automated tests and rely on test suites for regression testing and continuous integration. However, project owners report to often struggle with implementing an exhaustive test suite. Convincing contributors to provide automated test cases remains a challenge. The absence of an adequate test suite or using tests of low quality can degrade the quality of the software product. We present an approach for reducing the effort required by project owners for extending their test suites. We aim to utilize the phenomenon of drive-by commits: capable users quickly and easily solve problems in others' projects---even though they are not particularly involved in that project---and move on. By analyzing and directing the drive-by commit phenomenon, we hope to use crowdsourcing to improve projects' quality assurance efforts. Valuable test cases and maintenance tasks would be completed by capable users, giving core developers more resources to work on the more complicated issues. },
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1209–1212},
numpages = {4},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/3412569.3412582,
author = {Gasparini, Mattia and Claris\'{o}, Robert and Brambilla, Marco and Cabot, Jordi},
title = {Participation Inequality and the 90-9-1 Principle in Open Source},
year = {2020},
isbn = {9781450387798},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412569.3412582},
doi = {10.1145/3412569.3412582},
abstract = {Participation inequality is a major challenge in any shared-resource system. This is known as the "volunteer's dilemma": everybody wants to benefit from a resource without contributing, expecting others will do the work. This paper explores whether this problem also arises in open source development. In particular, we analyze the behaviour of GitHub users to assess whether the 90-9-1 principle applies to open source. We study it both from a qualitative (ratio of activity types) and a quantitative (total number of activities) perspective and we show that the principle does not hold if we consider the GitHub platform as a whole. Surprisingly, results are reversed depending on the specific projects we look at. We believe these results are useful to project managers to better understand and optimize the behaviour of the community around their projects and, as a side effect, they show the importance of diversity in sample selection.},
booktitle = {Proceedings of the 16th International Symposium on Open Collaboration},
articleno = {6},
numpages = {7},
keywords = {social network analysis, GitHub, user behavior, open source software},
location = {Virtual conference, Spain},
series = {OpenSym 2020}
}

@inproceedings{10.1109/TechDebt.2019.00024,
author = {Anderson, Paul and Kot, Lucja and Gilmore, Neil and Vitek, David},
title = {SARIF-Enabled Tooling to Encourage Gradual Technical Debt Reduction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/TechDebt.2019.00024},
doi = {10.1109/TechDebt.2019.00024},
abstract = {SARIF is an emerging standard for representing the results of program analysis tools. This tool demo shows how it can enable integration between static analysis tools and version control systems such as GitHub, and by doing so, encourage developers to reduce technical debt in a gradual non-invasive fashion.},
booktitle = {Proceedings of the Second International Conference on Technical Debt},
pages = {71–72},
numpages = {2},
keywords = {technical debt reduction, dynamic analysis, static analysis},
location = {Montreal, Quebec, Canada},
series = {TechDebt '19}
}

@inproceedings{10.1145/3379597.3387512,
author = {Bhattacharjee, Avijit and Nath, Sristy Sumana and Zhou, Shurui and Chakroborti, Debasish and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin},
title = {An Exploratory Study to Find Motives Behind Cross-Platform Forks from Software Heritage Dataset},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387512},
doi = {10.1145/3379597.3387512},
abstract = {The fork-based development mechanism provides the flexibility and the unified processes for software teams to collaborate easily in a distributed setting without too much coordination overhead. Currently, multiple social coding platforms support fork-based development, such as GitHub, GitLab, and Bitbucket. Although these different platforms virtually share the same features, they have different emphasis. As GitHub is the most popular platform and the corresponding data is publicly available, most of the current studies are focusing on GitHub hosted projects. However, we observed anecdote evidences that people are confused about choosing among these platforms, and some projects are migrating from one platform to another, and the reasons behind these activities remain unknown. With the advances of Software Heritage Graph Dataset (SWHGD), we have the opportunity to investigate the forking activities across platforms. In this paper, we conduct an exploratory study on 10 popular open-source projects to identify cross-platform forks and investigate the motivation behind. Preliminary result shows that cross-platform forks do exist. For the 10 subject systems used in this study, we found 81,357 forks in total among which 179 forks are on GitLab. Based on our qualitative analysis, we found that most of the cross-platform forks that we identified are mirrors of the repositories on another platform, but we still find cases that were created due to preference of using certain functionalities (e.g. Continuous Integration (CI)) supported by different platforms. This study lays the foundation of future research directions, such as understanding the differences between platforms and supporting cross-platform collaboration.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {11–15},
numpages = {5},
keywords = {Social coding, OSS, Collaboration, Cross-platform forks},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3340631.3394884,
author = {Lee, Roy Ka-Wei and Hoang, Thong and Oentaryo, Richard J. and Lo, David},
title = {Keen2Act: Activity Recommendation in Online Social Collaborative Platforms},
year = {2020},
isbn = {9781450368612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340631.3394884},
doi = {10.1145/3340631.3394884},
abstract = {Social collaborative platforms such as GitHub and Stack Overflow have been increasingly used to improve work productivity via collaborative efforts. To improve user experiences in these platforms, it is desirable to have a recommender system that can suggest not only items (e.g., a GitHub repository) to a user, but also activities to be performed on the suggested items (e.g., forking a repository). To this end, we propose a new approach dubbed Keen2Act, which decomposes the recommendation problem into two stages: the Keen and Act steps. The Keen step identifies, for a given user, a (sub)set of items in which he/she is likely to be interested. The Act step then recommends to the user which activities to perform on the identified set of items. This decomposition provides a practical approach to tackling complex activity recommendation tasks while producing higher recommendation quality. We evaluate our proposed approach using two real-world datasets and obtain promising results whereby Keen2Act outperforms several baseline models.},
booktitle = {Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {308–312},
numpages = {5},
keywords = {social collaborative platform, GitHub, factorization machine, stack overflow, activity recommendation},
location = {Genoa, Italy},
series = {UMAP '20}
}

@inproceedings{10.1145/2993283.2993285,
author = {North, Kevin J. and Sarma, Anita and Cohen, Myra B.},
title = {Understanding Git History: A Multi-Sense View},
year = {2016},
isbn = {9781450343978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993283.2993285},
doi = {10.1145/2993283.2993285},
abstract = { Version control systems archive data about the development history of a project, which can be used to analyze and understand different facets of a software project. The project history can be used to evaluate the development process of a team, as an aid in bug fixing, or to help new members get on track with development. However, state of the art techniques for analyzing version control data provide only partial views into this information, and lack an easy way to present all the dimensions of the data. In this paper we present GitVS, a hybrid view that incorporates visualization and sonification to represent the multiple dimensions of version control data - development time line, conflicts, etc. In a formative user study comparing the GitHub Network Graph, GitVS, and a version of GitVS without sound, we show GitVS improves over the GitHub Network Graph and that while sound makes it easier to correctly understand version history for some tasks, it is more difficult for others. },
booktitle = {Proceedings of the 8th International Workshop on Social Software Engineering},
pages = {1–7},
numpages = {7},
keywords = {Sonification, Version Control History, Conflicts},
location = {Seattle, WA, USA},
series = {SSE 2016}
}

@inproceedings{10.4108/eai.30-11-2016.2266941,
author = {Iacob, Claudia and Faily, Shamal and Harrison, Rachel},
title = {MARAM: Tool Support for Mobile App Review Management},
year = {2016},
isbn = {9781631901379},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/eai.30-11-2016.2266941},
doi = {10.4108/eai.30-11-2016.2266941},
abstract = {Mobile apps today have millions of user reviews available online. Such reviews cover a large broad of themes and are usually expressed in an informal language. They provide valuable information to developers, such as feature requests, bug reports, and detailed descriptions of one's interaction with the app. Due to the overwhelmingly large number of reviews apps usually get associated with, managing and making sense of reviews is difficult. In this paper, we address this problem by introducing MARAM, a tool designed to provide support for managing and integrating online reviews with other software management tools available, such as GitHub, JIRA and Bugzilla. The tool is designed to a) automatically extract app development relevant information from online reviews, b) support developers' queries on (subsets of) the user generated content available on app stores, namely online reviews, feature requests, and bugs, and c) support the management of online reviews and their integration with other software management tools available, namely GitHub, JIRA or Bugzilla.},
booktitle = {Proceedings of the 8th EAI International Conference on Mobile Computing, Applications and Services},
pages = {42–50},
numpages = {9},
keywords = {mobile applications, online reviews, querying},
location = {Cambridge, Great Britain},
series = {MobiCASE'16}
}

@inproceedings{10.5555/2820518.2820570,
author = {Sinha, Vibha Singhal and Saha, Diptikalyan and Dhoolia, Pankaj and Padhye, Rohan and Mani, Senthil},
title = {Detecting and Mitigating Secret-Key Leaks in Source Code Repositories},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {Several news articles in the past year highlighted incidents in which malicious users stole API keys embedded in files hosted on public source code repositories such as GitHub and BitBucket in order to drive their own work-loads for free. While some service providers such as Amazon have started taking steps to actively discover such developer carelessness by scouting public repositories and suspending leaked API keys, there is little support for tackling the problem from the code sharing platforms themselves.In this paper, we discuss practical solutions to detecting, preventing and fixing API key leaks. We first outline a handful of methods for detecting API keys embedded within source code, and evaluate their effectiveness using a sample set of projects from GitHub. Second, we enumerate the mechanisms which could be used by developers to prevent or fix key leaks in code repositories manually. Finally, we outline a possible solution that combines these techniques to provide tool support for protecting against key leaks in version control systems.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {396–400},
numpages = {5},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.5555/3049877.3049933,
author = {Barboza, John and Mallick, Muntasir and Siu, Joran and Bajwa, Jaideep and Dawson, Michael},
title = {Hands-on: Microservices on NodeJS},
year = {2016},
publisher = {IBM Corp.},
address = {USA},
abstract = {Node.js is a server-side JavaScript platform that has seen explosive growth in recent years. In its 5 years of existence, Node.js has leaped to being the third most-starred repository on GitHub, and is now one of the most popular frameworks for developing cloud, mobile and Internet-of-Things applications.},
booktitle = {Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering},
pages = {342–343},
numpages = {2},
location = {Toronto, Ontario, Canada},
series = {CASCON '16}
}

@inproceedings{10.1145/1985441.1985476,
author = {Heller, Brandon and Marschner, Eli and Rosenfeld, Evan and Heer, Jeffrey},
title = {Visualizing Collaboration and Influence in the Open-Source Software Community},
year = {2011},
isbn = {9781450305747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985441.1985476},
doi = {10.1145/1985441.1985476},
abstract = {We apply visualization techniques to user profiles and repository metadata from the GitHub source code hosting service. Our motivation is to identify patterns within this development community that might otherwise remain obscured. Such patterns include the effect of geographic distance on developer relationships, social connectivity and influence among cities, and variation in projectspecific contribution styles (e.g., centralized vs. distributed). Our analysis examines directed graphs in which nodes represent users' geographic locations and edges represent (a) follower relationships, (b) successive commits, or (c) contributions to the same project. We inspect this data using a set of visualization techniques: geo-scatter maps, small multiple displays, and matrix diagrams. Using these representations, and tools based on them, we develop hypotheses about the larger GitHub community that would be difficult to discern using traditional lists, tables, or descriptive statistics. These methods are not intended to provide conclusive answers; instead, they provide a way for researchers to explore the question space and communicate initial insights.},
booktitle = {Proceedings of the 8th Working Conference on Mining Software Repositories},
pages = {223–226},
numpages = {4},
keywords = {mapping, data exploration, github, visualization, open source, collaboration, geoscatter, social graph},
location = {Waikiki, Honolulu, HI, USA},
series = {MSR '11}
}

@inproceedings{10.1145/3183519.3183542,
author = {Kononenko, Oleksii and Rose, Tresa and Baysal, Olga and Godfrey, Michael and Theisen, Dennis and de Water, Bart},
title = {Studying Pull Request Merges: A Case Study of Shopify's Active Merchant},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183519.3183542},
doi = {10.1145/3183519.3183542},
abstract = {Pull-based development has become a popular choice for developing distributed projects, such as those hosted on GitHub. In this model, contributions are pulled from forked repositories, modified, and then later merged back into the main repository. In this work, we report on two empirical studies that investigate pull request (PR) merges of Active Merchant, a commercial project developed by Shopify Inc. In the first study, we apply data mining techniques on the project's GitHub repository to explore the nature of merges, and we conduct a manual inspection of pull requests; we also investigate what factors contribute to PR merge time and outcome. In the second study, we perform a qualitative analysis of the results of a survey of developers who contributed to Active Merchant. The study addresses the topic of PR review quality and developers' perception of it. The results provide insights into how these developers perform pull request merges, and what factors they find contribute to how they review and merge pull requests.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {124–133},
numpages = {10},
keywords = {survey, industrial case study, review quality, pull request merges},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}

@inproceedings{10.1145/2789853.2806214,
author = {Yan, Bei},
title = {Large Scale, Open Cognitive Collaboration of Distributed Crowds},
year = {2015},
isbn = {9781450337069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2789853.2806214},
doi = {10.1145/2789853.2806214},
abstract = {Drawing on communication, sociology and social psychology theories, my research focuses on large scale, open cognitive collaboration of distributed crowds. I study how individuals interact and collaborate with each other via mediated communication channels, applying social network analysis, conducting online experiments and utilizing big data dumps of online communities, such as Wikipedia, Stack Overflow, Github and Threadless.com.},
booktitle = {Companion to the Proceedings of the 11th International Symposium on Open Collaboration},
articleno = {5},
numpages = {1},
keywords = {social networks, communication, cognitive collaboration},
location = {San Francisco, California},
series = {OpenSym '15}
}

@inproceedings{10.1109/MSR.2019.00038,
author = {Baltes, Sebastian and Treude, Christoph and Diehl, Stephan},
title = {SOTorrent: Studying the Origin, Evolution, and Usage of Stack Overflow Code Snippets},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00038},
doi = {10.1109/MSR.2019.00038},
abstract = {Stack Overflow (SO) is the most popular question-and-answer website for software developers, providing a large amount of copyable code snippets. Like other software artifacts, code on SO evolves over time, for example when bugs are fixed or APIs are updated to the most recent version. To be able to analyze how code and the surrounding text on SO evolves, we built SOTorrent, an open dataset based on the official SO data dump. SOTorrent provides access to the version history of SO content at the level of whole posts and individual text and code blocks. It connects code snippets from SO posts to other platforms by aggregating URLs from surrounding text blocks and comments, and by collecting references from GitHub files to SO posts. Our vision is that researchers will use SOTorrent to investigate and understand the evolution and maintenance of code on SO and its relation to other platforms such as GitHub.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {191–194},
numpages = {4},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2950290.2983929,
author = {Oosterwaal, Sebastiaan and Deursen, Arie van and Coelho, Roberta and Sawant, Anand Ashok and Bacchelli, Alberto},
title = {Visualizing Code and Coverage Changes for Code Review},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2983929},
doi = {10.1145/2950290.2983929},
abstract = { One of the tasks of reviewers is to verify that code modifications are well tested. However, current tools offer little support in understanding precisely how changes to the code relate to changes to the tests. In particular, it is hard to see whether (modified) test code covers the changed code. To mitigate this problem, we developed Operias, a tool that provides a combined visualization of fine-grained source code differences and coverage impact. Operias works both as a stand-alone tool on specific project versions and as a service hooked to GitHub. In the latter case, it provides automated reports for each new pull request, which reviewers can use to assess the code contribution. Operias works for any Java project that works with maven and its standard Cobertura coverage plugin. We present how Operias could be used to identify test-related problems in real-world pull requests. Operias is open source and available on GitHub with a demo video: https://github.com/SERG-Delft/operias },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {1038–1041},
numpages = {4},
keywords = {code review, software evolution, software testing},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/2876034.2876035,
author = {Chen, Guanliang and Davis, Dan and Hauff, Claudia and Houben, Geert-Jan},
title = {Learning Transfer: Does It Take Place in MOOCs? An Investigation into the Uptake of Functional Programming in Practice},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2876035},
doi = {10.1145/2876034.2876035},
abstract = {The rising number of Massive Open Online Courses (MOOCs) enable people to advance their knowledge and competencies in a wide range of fields. Learning though is only the first step, the transfer of the taught concepts into practice is equally important and often neglected in the investigation of MOOCs. In this paper, we consider the specific case of FP101x (a functional programming MOOC on edX) and the extent to which learners alter their programming behaviour after having taken the course. We are able to link about one third of all FP101x learners to GitHub, the most popular social coding platform to date and contribute a first exploratory analysis of learner behaviour beyond the MOOC platform. A detailed longitudinal analysis of GitHub log traces reveals that (i) more than 8% of engaged learners transfer, and that (ii) most existing transfer learning findings from the classroom setting are indeed applicable in the MOOC setting as well.},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {409–418},
numpages = {10},
keywords = {transfer learning, moocs, github, functional programming},
location = {Edinburgh, Scotland, UK},
series = {L@S '16}
}

@inproceedings{10.1145/3196494.3196523,
author = {Afzali, Hammad and Torres-Arias, Santiago and Curtmola, Reza and Cappos, Justin},
title = {Le-Git-Imate: Towards Verifiable Web-Based Git Repositories},
year = {2018},
isbn = {9781450355766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196494.3196523},
doi = {10.1145/3196494.3196523},
abstract = {Web-based Git hosting services such as GitHub and GitLab are popular choices to manage and interact with Git repositories. However, they lack an important security feature - the ability to sign Git commits. Users instruct the server to perform repository operations on their behalf and have to trust that the server will execute their requests faithfully. Such trust may be unwarranted though because a malicious or a compromised server may execute the requested actions in an incorrect manner, leading to a different state of the repository than what the user intended.In this paper, we show a range of high-impact attacks that can be executed stealthily when developers use the web UI of a Git hosting service to perform common actions such as editing files or merging branches. We then propose le-git-imate, a defense against these attacks which provides security guarantees comparable and compatible with Git's standard commit signing mechanism. We implement le-git-imate as a Chrome browser extension. le-git-imate does not require changes on the server side and can thus be used immediately. It also preserves current workflows used in Github/GitLab and does not require the user to leave the browser, and it allows anyone to verify that the server's actions faithfully follow the user's requested actions. Moreover, experimental evaluation using the browser extension shows that le-git-imate has comparable performance with Git's standard commit signature mechanism. With our solution in place, users can take advantage of GitHub/GitLab's web-based features without sacrificing security, thus paving the way towards verifiable web-based Git repositories.},
booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
pages = {469–482},
numpages = {14},
keywords = {verification record, github, commit signature, browser extension},
location = {Incheon, Republic of Korea},
series = {ASIACCS '18}
}

@inproceedings{10.5555/3306127.3331884,
author = {Bhattacharya, Parantapa and Ekanayake, Saliya and Kuhlman, Chris J. and Lebiere, Christian and Morrison, Don and Swarup, Samarth and Wilson, Mandy L. and Orr, Mark G.},
title = {The Matrix: An Agent-Based Modeling Framework for Data Intensive Simulations},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Human decision-making is influenced by social, psychological, neurological, emotional, normative, and learning factors, as well as individual traits like age and education level. Social/cognitive computational models that incorporate these factors are increasingly used to study how humans make decisions. A result is that agent models, within agent-based modeling (ABM), are becoming more heavyweight, i.e., are more computationally demanding, making scalability and at-scale simulations all the more difficult to achieve. To address these challenges, we have developed an ABM simulation framework that addresses data-intensive simulation at-scale. We describe system requirements and design, and demonstrate at-scale simulation by modeling 3 million users (each as an individual agent), 13 million repositories, and 239 million user-repository interactions on GitHub. Simulations predict user interactions with GitHub repositories, which, to our knowledge, are the first simulations of this kind. Our simulations demonstrate a three-order of magnitude increase in the number of cognitive agents simultaneously interacting.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1635–1643},
numpages = {9},
keywords = {agent-based simulation, distributed simulation, simulation framework},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.1145/3377811.3380406,
author = {Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas},
title = {Learning from, Understanding, and Supporting DevOps Artifacts for Docker},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380406},
doi = {10.1145/3377811.3380406},
abstract = {With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code. The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation. We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis. To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts. We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing. To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated. Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection. To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set. These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency. We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set. We also found that industrial Dockerfiles fared no better than those sourced from GitHub.The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {38–49},
numpages = {12},
keywords = {static checking, mining, docker, DevOps},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1109/MSR.2019.00057,
author = {Alqaimi, Anwar and Thongtanunam, Patanamon and Treude, Christoph},
title = {Automatically Generating Documentation for Lambda Expressions in Java},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00057},
doi = {10.1109/MSR.2019.00057},
abstract = {When lambda expressions were introduced to the Java programming language as part of the release of Java 8 in 2014, they were the language's first step into functional programming. Since lambda expressions are still relatively new, not all developers use or understand them. In this paper, we first present the results of an empirical study to determine how frequently developers of GitHub repositories make use of lambda expressions and how they are documented. We find that 11% of Java GitHub repositories use lambda expressions, and that only 6% of the lambda expressions are accompanied by source code comments. We then present a tool called LambdaDoc which can automatically detect lambda expressions in a Java repository and generate natural language documentation for them. Our evaluation of LambdaDoc with 23 professional developers shows that they perceive the generated documentation to be complete, concise, and expressive, while the majority of the documentation produced by our participants without tool support was inadequate. Our contribution builds an important step towards automatically generating documentation for functional programming constructs in an object-oriented language.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {310–320},
numpages = {11},
keywords = {lambda expressions, documentation generation},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3338906.3342495,
author = {Vandenbogaerde, Bram},
title = {A Graph-Based Framework for Analysing the Design of Smart Contracts},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3342495},
doi = {10.1145/3338906.3342495},
abstract = {Used as a platform for executing smart contracts, Blockchain technology has yielded new programming languages. We propose a graph-based framework for computing software design metrics for the Solidity programming language, and use this framework in a preliminary study on 505 smart contracts mined from GitHub. The results show that most of the smart contracts are rather straightforward from an objected-oriented point of view and that new design metrics specific to smart contracts should be developed.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1220–1222},
numpages = {3},
keywords = {Smart Contracts, Metrics, Mining Software Repositories},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1109/TechDebt.2019.00031,
author = {Ericsson, Morgan and Wingkvist, Anna},
title = {TDMentions: A Dataset of Technical Debt Mentions in Online Posts},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/TechDebt.2019.00031},
doi = {10.1109/TechDebt.2019.00031},
abstract = {The term technical debt is easy to understand as a metaphor, but can quickly grow complex in practice. We contribute with a dataset, TDMentions, that enables researchers to study how developers and end users use the term technical debt in online posts and discussions. The dataset consists of posts from news aggregators and Q&amp;A-sites, blog posts, and issues and commits on GitHub.},
booktitle = {Proceedings of the Second International Conference on Technical Debt},
pages = {123–124},
numpages = {2},
keywords = {technical debt, data mining, social networks},
location = {Montreal, Quebec, Canada},
series = {TechDebt '19}
}

@inproceedings{10.1145/3196398.3196464,
author = {Markovtsev, Vadim and Long, Waren},
title = {Public Git Archive: A Big Code Dataset for All},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196464},
doi = {10.1145/3196398.3196464},
abstract = {The number of open source software projects has been growing exponentially. The major online software repository host, GitHub, has accumulated tens of millions of publicly available Git version-controlled repositories. Although the research potential enabled by the available open source code is clearly substantial, no significant large-scale open source code datasets exist. In this paper, we present the Public Git Archive - dataset of 182,014 top-bookmarked Git repositories from GitHub. We describe the novel data retrieval pipeline to reproduce it. We also elaborate on the strategy for performing dataset updates and legal issues. The Public Git Archive occupies 3.0 TB on disk and is an order of magnitude larger than the current source code datasets. The dataset is made available through HTTP and provides the source code of the projects, the related metadata, and development history. The data retrieval pipeline employs an optimized worker queue model and an optimized archive format to efficiently store forked Git repositories, reducing the amount of data to download and persist. Public Git Archive aims to open a myriad of new opportunities for "Big Code" research.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {34–37},
numpages = {4},
keywords = {open dataset, github, source code, development history, git, software repositories},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/3338698.3338892,
author = {Lowe-Power, Jason and Nitta, Christopher},
title = {The Davis In-Order (DINO) CPU: A Teaching-Focused RISC-V CPU Design},
year = {2019},
isbn = {9781450368421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338698.3338892},
doi = {10.1145/3338698.3338892},
abstract = {The DINO CPU is an open source teaching-focused RISC-V CPU design available on GitHub (https://github.com/jlpteaching/dinocpu). We have used the DINO CPU in the computer architecture course at UC Davis for two quarters with two separate instructors. In this paper, we present details of the DINO CPU, the tools included with the DINO CPU, and our experiences using the DINO CPU.},
booktitle = {Proceedings of the Workshop on Computer Architecture Education},
articleno = {2},
numpages = {8},
location = {Phoenix, AZ, USA},
series = {WCAE'19}
}

@inproceedings{10.1109/ICSE.2019.00047,
author = {Horton, Eric and Parnin, Chris},
title = {DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00047},
doi = {10.1109/ICSE.2019.00047},
abstract = {Platforms like Stack Overflow and GitHub's gist system promote the sharing of ideas and programming techniques via the distribution of code snippets designed to illustrate particular tasks. Python, a popular and fast-growing programming language, sees heavy use on both sites, with nearly one million questions asked on Stack Overflow and 400 thousand public gists on GitHub. Unfortunately, around 75% of the Python example code shared through these sites cannot be directly executed. When run in a clean environment, over 50% of public Python gists fail due to an import error for a missing library.We present DockerizeMe, a technique for inferring the dependencies needed to execute a Python code snippet without import error. DockerizeMe starts with offline knowledge acquisition of the resources and dependencies for popular Python packages from the Python Package Index (PyPI). It then builds Docker specifications using a graph-based inference procedure. Our inference procedure resolves import errors in 892 out of nearly 3,000 gists from the Gistable dataset for which Gistable's baseline approach could not find and install all dependencies.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {328–338},
numpages = {11},
keywords = {dependencies, configuration management, python, environment inference, docker},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3183440.3194989,
author = {Liu, Chao and Yang, Dan and Zhang, Xiaohong and Hu, Haibo and Barson, Jed and Ray, Baishakhi},
title = {A Recommender System for Developer Onboarding},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194989},
doi = {10.1145/3183440.3194989},
abstract = {Successfully onboarding open source projects in GitHub is difficult for developers, because it is time-consuming for them to search an expected project by a few query words from numerous repositories, and developers suffer from various social and technical barriers in joined projects. Frequently failed onboarding postpones developers' development schedule, and the evolutionary progress of open source projects. To mitigate developers' costly efforts for onboarding, we propose a ranking model NNLRank (Neural Network for List-wise Ranking) to recommend projects that developers are likely to contribute many commits. Based on 9 measured project features, NNLRank learns a ranking function (represented by a neural network, optimized by a list-wise ranking loss function) to score a list of candidate projects, where top-n scored candidates are recommended to a target developer. We evaluate NNLRank by 2044 succeeded onboarding decisions from GitHub developers, comparing with a related model LP (Link Prediction), and 3 other typical ranking models. Results show that NNLRank can provide developers with effective recommendation, substantially outperforming baselines.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {319–320},
numpages = {2},
keywords = {developer onboarding, learning to rank, recommender system},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/2884781.2884826,
author = {Gousios, Georgios and Storey, Margaret-Anne and Bacchelli, Alberto},
title = {Work Practices and Challenges in Pull-Based Development: The Contributor's Perspective},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884826},
doi = {10.1145/2884781.2884826},
abstract = {The pull-based development model is an emerging way of contributing to distributed software projects that is gaining enormous popularity within the open source software (OSS) world. Previous work has examined this model by focusing on projects and their owners---we complement it by examining the work practices of project contributors and the challenges they face.We conducted a survey with 645 top contributors to active OSS projects using the pull-based model on GitHub, the prevalent social coding site. We also analyzed traces extracted from corresponding GitHub repositories. Our research shows that: contributors have a strong interest in maintaining awareness of project status to get inspiration and avoid duplicating work, but they do not actively propagate information; communication within pull requests is reportedly limited to low-level concerns and contributors often use communication channels external to pull requests; challenges are mostly social in nature, with most reporting poor responsiveness from integrators; and the increased transparency of this setting is a confirmed motivation to contribute. Based on these findings, we present recommendations for practitioners to streamline the contribution process and discuss potential future research directions.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {285–296},
numpages = {12},
keywords = {pull request, pull-based development, open source contribution, distributed software development, GitHub},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2901739.2903507,
author = {Proksch, Sebastian and Amann, Sven and Nadi, Sarah and Mezini, Mira},
title = {A Dataset of Simplified Syntax Trees for C#},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2903507},
doi = {10.1145/2901739.2903507},
abstract = {In this paper, we present a curated collection of 2833 C# solutions taken from Github. We encode the data in a new intermediate representation (IR) that facilitates further analysis by restricting the complexity of the syntax tree and by avoiding implicit information. The dataset is intended as a standardized input for research on recommendation systems for software engineering, but is also useful in many other areas that analyze source code.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {476–479},
numpages = {4},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1109/ICSME.2014.102,
author = {Reiss, Steven P.},
title = {Tool Demo: Browsing Software Repositories},
year = {2014},
isbn = {9781479961467},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSME.2014.102},
doi = {10.1109/ICSME.2014.102},
abstract = {We demonstrate a tool for browsing large software repositories such as GitHub or Source Forge using all the facilities one normally associates with an integrated development environment. The tool integrates code search engines with the Code Bubbles development environment. It lets the user perform and compare multiple searches, investigate and explore the results that are returned, expand searches as necessary, and eventually export appropriate results.},
booktitle = {Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution},
pages = {589–592},
numpages = {4},
keywords = {integrated development environments, Code search, software repositories},
series = {ICSME '14}
}

@inproceedings{10.1145/3287324.3287556,
author = {Cetinkaya-Rundel, Mine},
title = {Computing Infrastructure and Curriculum Design for Introductory Data Science},
year = {2019},
isbn = {9781450358903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287324.3287556},
doi = {10.1145/3287324.3287556},
abstract = {The goal of this workshop is to equip educators with concrete information on content and infrastructure for designing and painlessly running a modern data science course. This is a three-part workshop. Part 1 will outline a curriculum for an introductory data science course and discuss pedagogical decisions that go into the choice of topics and concepts as well as the choice of programming language (R) and syntax (primarily tidyverse), and the emphasis on literate programming for reproducibility (with R Markdown). Part 2 will discuss infrastructure choices around teaching data science with R: RStudio as an integrated development environment, cloud-based access with RStudio Cloud and Server, version control with Git, and collaboration with GitHub. Part 3 will focus on classroom management on GitHub (with ghclass). Workshop attendees will work through several exercises from the course and get first-hand experience with using the tool-chains and techniques described above. While the workshop content will focus on usage of R, many of the pedagogical takeaways will be language agnostic. All workshop content, including teacher facing documentation and student facing course materials, will also be available to participants via datasciencebox.org. Please bring a laptop with you.},
booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
pages = {1236},
numpages = {1},
keywords = {version control, reproducibility, data science, r, pedagogy},
location = {Minneapolis, MN, USA},
series = {SIGCSE '19}
}

@inproceedings{10.1145/3108421.3108437,
author = {Chishiro, Hiroyuki and Tsuchiya, Yosuke and Chubachi, Yoshihide and Abu Bakar, Muhammad Saifullah and De Silva, Liyanage C.},
title = {Global PBL for Environmental IoT},
year = {2017},
isbn = {9781450352482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3108421.3108437},
doi = {10.1145/3108421.3108437},
abstract = {Advanced Institute of Industrial Technology has performed the global Project Based Learning (PBL) for environmental IoT with Universiti Brunei Darussalam (Brunei) and Unitec Institute of Technology (New Zealand) in 2015-2016, in order to address environmental monitoring in Brunei. We evaluate the effectiveness of this global PBL from various metrics including questionnaire and GitHub. Finally, we learn some lessons from this global PBL and suggest the direction of future global PBL.},
booktitle = {Proceedings of the 2017 International Conference on E-Commerce, E-Business and E-Government},
pages = {65–71},
numpages = {7},
keywords = {Global PBL, Environmental IoT},
location = {Turku, Finland},
series = {ICEEG 2017}
}

@inproceedings{10.1145/3357384.3357971,
author = {Gong, Qingyuan and Zhang, Jiayun and Chen, Yang and Li, Qi and Xiao, Yu and Wang, Xin and Hui, Pan},
title = {Detecting Malicious Accounts in Online Developer Communities Using Deep Learning},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357971},
doi = {10.1145/3357384.3357971},
abstract = {Online developer communities like GitHub provide services such as distributed version control and task management, which allow a massive number of developers to collaborate online. However, the openness of the communities makes themselves vulnerable to different types of malicious attacks, since the attackers can easily join and interact with legitimate users. In this work, we formulate the malicious account detection problem in online developer communities, and propose GitSec, a deep learning-based solution to detect malicious accounts. GitSec distinguishes malicious accounts from legitimate ones based on the account profiles as well as dynamic activity characteristics. On one hand, GitSec makes use of users' descriptive features from the profiles. On the other hand, GitSec processes users' dynamic behavioral data by constructing two user activity sequences and applying a parallel neural network design to deal with each of them, respectively. An attention mechanism is used to integrate the information generated by the parallel neural networks. The final judgement is made by a decision maker implemented by a supervised machine learning-based classifier. Based on the real-world data of GitHub users, our extensive evaluations show that GitSec is an accurate detection system, with an F1-score of 0.922 and an AUC value of 0.940.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1251–1260},
numpages = {10},
keywords = {social networks, deep learning, malicious account detection, online developer community},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1109/COMM48946.2020.9142009,
author = {Avram, Andrei-Marius and Morogan, Luciana and Toma, Stefan-Adrian},
title = {OpenNIG - Open Neural Image Generator},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COMM48946.2020.9142009},
doi = {10.1109/COMM48946.2020.9142009},
abstract = {Generative models are statistical models that learn a true underlying data distribution from samples using unsupervised learning, aiming to generate new data points with some variation. In this paper, we introduce OpenNIG (Open Neural Image Generator), an open-source neural networks toolkit for image generation. It offers the possibility to easily train, validate and test state of the art models. The framework also contains a module that enables the user to directly download and process some of the most common databases used in deep learning. OpenNIG is freely available via GitHub.},
booktitle = {2020 13th International Conference on Communications (COMM)},
pages = {177–181},
numpages = {5},
location = {Bucharest, Romania}
}

@inproceedings{10.1145/2597073.2597122,
author = {Gousios, Georgios and Zaidman, Andy},
title = {A Dataset for Pull-Based Development Research},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597122},
doi = {10.1145/2597073.2597122},
abstract = { Pull requests form a new method for collaborating in distributed software development. To study the pull request distributed development model, we constructed a dataset of almost 900 projects and 350,000 pull requests, including some of the largest users of pull requests on Github. In this paper, we describe how the project selection was done, we analyze the selected features and present a machine learning tool set for the R statistics environment. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {368–371},
numpages = {4},
keywords = {empirical software engineering, pull request, distributed software development, pull-based development},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3214745.3214783,
author = {Spielmann, Simon and Helzle, Volker},
title = {Augmented Reality for Virtual Set Extension},
year = {2018},
isbn = {9781450358200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3214745.3214783},
doi = {10.1145/3214745.3214783},
abstract = {We introduce an intuitive workflow where Augmented Reality can be applied on the fly to extend a real set with virtual extensions. The work on intuitive Virtual Production technology at Filmakademie Baden-W\"{u}rttemberg has focused on an open platform tied to existing film creation pipelines. The Virtual Production Editing Tools (VPET) are published and constantly updated on the open source software development platform Github as a result of a former project on Virtual Production funded by the European Union.},
booktitle = {ACM SIGGRAPH 2018 Talks},
articleno = {10},
numpages = {2},
keywords = {augmented reality, virtual production, handheld, collaborative work, filmmaking, production pipeline, on-set editing},
location = {Vancouver, British Columbia, Canada},
series = {SIGGRAPH '18}
}

@inproceedings{10.1145/3338906.3342497,
author = {Golzadeh, Mehdi},
title = {Analysing Socio-Technical Congruence in the Package Dependency Network of Cargo},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3342497},
doi = {10.1145/3338906.3342497},
abstract = {Software package distributions form large dependency networks maintained by large communities of contributors. My PhD research will consist of analysing the evolution of the socio-technical congruence of these package dependency networks, and studying its impact on the health of the ecosystem and its community. I have started a longitudinal empirical study of Cargo's dependency network and the social (commenting) and technical (development) activities in Cargo's package repositories on GitHub, and present some preliminary findings.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1226–1228},
numpages = {3},
keywords = {Software ecosystem, Software repository mining, Package dependency network, Socio-Technical congruence, Software development},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3292006.3300032,
author = {Matyukhina, Alina and Stakhanova, Natalia and Dalla Preda, Mila and Perley, Celine},
title = {Adversarial Authorship Attribution in Open-Source Projects},
year = {2019},
isbn = {9781450360999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292006.3300032},
doi = {10.1145/3292006.3300032},
abstract = {Open-source software is open to anyone by design, whether it is a community of developers, hackers or malicious users. Authors of open-source software typically hide their identity through nicknames and avatars. However, they have no protection against authorship attribution techniques that are able to create software author profiles just by analyzing software characteristics. In this paper we present an author imitation attack that allows to deceive current authorship attribution systems and mimic a coding style of a target developer. Withing this context we explore the potential of the existing attribution techniques to be deceived. Our results show that we are able to imitate the coding style of the developers based on the data collected from the popular source code repository, GitHub. To subvert author imitation attack, we propose a novel author obfuscation approach that allows us to hide the coding style of the author. Unlike existing obfuscation tools, this new obfuscation technique uses transformations that preserve code readability. We assess the effectiveness of our attacks on several datasets produced by actual developers from GitHub, and participants of the GoogleCodeJam competition. Throughout our experiments we show that the author hiding can be achieved by making sensible transformations which significantly reduce the likelihood of identifying the author's style to 0% by current authorship attribution systems.},
booktitle = {Proceedings of the Ninth ACM Conference on Data and Application Security and Privacy},
pages = {291–302},
numpages = {12},
keywords = {open-source software, authorship attribution, attacks, obfuscation, imitation, adversarial},
location = {Richardson, Texas, USA},
series = {CODASPY '19}
}

@inproceedings{10.1145/3121113.3121241,
author = {Doherty, Stanley},
title = {Leveraging Industry Onboarding Materials in the Curriculum},
year = {2017},
isbn = {9781450351607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3121113.3121241},
doi = {10.1145/3121113.3121241},
abstract = {Delivers a resource-sharing project between undergraduate technical writing programs and industry technical documentation groups that provides: 1) Crisp descriptions of the top five content development skills, 2) Industry college-hire and new-employee training materials (conceptuals), 3) Real-world, sample technical content in substantial breadth and depth, 4) Multiple content markup formats (Word, Markdown, XML DITA), 5) Detailed writing exercises based on the sample content and assessment guidelines, and 6) Community-sourced content development, maintenance, and curation (GitHub).},
booktitle = {Proceedings of the 35th ACM International Conference on the Design of Communication},
articleno = {36},
numpages = {5},
keywords = {markdown, onboarding, DITA, experiential learning, new hires, technical communication, GitHub},
location = {Halifax, Nova Scotia, Canada},
series = {SIGDOC '17}
}

@inproceedings{10.1145/2797433.2797476,
author = {Decan, Alexandre and Mens, Tom and Claes, Maelick and Grosjean, Philippe},
title = {On the Development and Distribution of R Packages: An Empirical Analysis of the R Ecosystem},
year = {2015},
isbn = {9781450333931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2797433.2797476},
doi = {10.1145/2797433.2797476},
abstract = {This paper explores the ecosystem of software packages for R, one of the most popular environments for statistical computing today. We empirically study how R packages are developed and distributed on different repositories: CRAN, BioConductor, R-Forge and GitHub. We also explore the role and size of each repository, the inter-repository dependencies, and how these repositories grow over time. With this analysis, we provide a deeper insight into the extent and the evolution of the R package ecosystem.},
booktitle = {Proceedings of the 2015 European Conference on Software Architecture Workshops},
articleno = {41},
numpages = {6},
keywords = {software development, software distribution, package, R, software ecosystem, software repository mining},
location = {Dubrovnik, Cavtat, Croatia},
series = {ECSAW '15}
}

@inproceedings{10.1145/3239235.3240298,
author = {Chakraborty, Partha and Shahriyar, Rifat and Iqbal, Anindya and Bosu, Amiangshu},
title = {Understanding the Software Development Practices of Blockchain Projects: A Survey},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3240298},
doi = {10.1145/3239235.3240298},
abstract = {Background: The application of the blockchain technology has shown promises in various areas, such as smart-contracts, Internet of Things, land registry management, identity management, etc. Although Github currently hosts more than three thousand active blockchain software (BCS) projects, a few software engineering research has been conducted on their software engineering practices. Aims: To bridge this gap, we aim to carry out the first formal survey to explore the software engineering practices including requirement analysis, task assignment, testing, and verification of blockchain software projects. Method: We sent an online survey to 1,604 active BCS developers identified via mining the Github repositories of 145 popular BCS projects. The survey received 156 responses that met our criteria for analysis. Results: We found that code review and unit testing are the two most effective software development practices among BCS developers. The results suggest that the requirements of BCS projects are mostly identified and selected by community discussion and project owners which is different from requirement collection of general OSS projects. The results also reveal that the development tasks in BCS projects are primarily assigned on voluntary basis, which is the usual task assignment practice for OSS projects. Conclusions: Our findings indicate that standard software engineering methods including testing and security best practices need to be adapted with more seriousness to address unique characteristics of blockchain and mitigate potential threats.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {28},
numpages = {10},
keywords = {cryptocurrency, blockchain, bitcoin, survey, ethereum},
location = {Oulu, Finland},
series = {ESEM '18}
}

@inproceedings{10.1145/2950290.2950364,
author = {Zhu, Jiaxin and Zhou, Minghui and Mockus, Audris},
title = {Effectiveness of Code Contribution: From Patch-Based to Pull-Request-Based Tools},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950364},
doi = {10.1145/2950290.2950364},
abstract = { Code contributions in Free/Libre and Open Source Software projects are controlled to maintain high-quality of software. Alternatives to patch-based code contribution tools such as mailing lists and issue trackers have been developed with the pull request systems being the most visible and widely available on GitHub. Is the code contribution process more effective with pull request systems? To answer that, we quantify the effectiveness via the rates contributions are accepted and ignored, via the time until the first response and final resolution and via the numbers of contributions. To control for the latent variables, our study includes a project that migrated from an issue tracker to the GitHub pull request system and a comparison between projects using mailing lists and pull request systems. Our results show pull request systems to be associated with reduced review times and larger numbers of contributions. However, not all the comparisons indicate substantially better accept or ignore rates in pull request systems. These variations may be most simply explained by the differences in contribution practices the projects employ and may be less affected by the type of tool. Our results clarify the importance of understanding the role of tools in effective management of the broad network of potential contributors and may lead to strategies and practices making the code contribution more satisfying and efficient from both contributors' and maintainers' perspectives. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {871–882},
numpages = {12},
keywords = {mailing list, FLOSS, issue tracker, pull request, Code contribution, effectiveness},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/3345629.3345631,
author = {Amit, Idan and Feitelson, Dror G.},
title = {Which Refactoring Reduces Bug Rate?},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345631},
doi = {10.1145/3345629.3345631},
abstract = {We present a methodology to identify refactoring operations that reduce the bug rate in the code. The methodology is based on comparing the bug fixing rate in certain time windows before and after the refactoring. We analyzed 61,331 refactor commits from 1,531 large active GitHub projects. When comparing three-month windows, the bug rate is substantially reduced in 17% of the files of analyzed refactors, compared to 12% of the files in random commits. Within this group, implementing 'todo's provides the most benefits. Certain operations like reuse, upgrade, and using enum and namespaces are also especially beneficial.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {12–15},
numpages = {4},
keywords = {refactoring, Code quality, machine learning},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3014812.3014826,
author = {Sam, Garming and Cameron, Nick and Potanin, Alex},
title = {Automated Refactoring of Rust Programs},
year = {2017},
isbn = {9781450347686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3014812.3014826},
doi = {10.1145/3014812.3014826},
abstract = {Rust is a modern systems programming language developed by Mozilla Research and the Rust community. Rust supports modern constructs such as ownership, lifetimes, traits, and macros, whilst supporting systems programming idioms with low-cost abstractions and memory safety without garbage collection.We describe a new refactoring tool for Rust developers, including discussing the issues and unusual decisions encountered due to the complexities of modern systems languages. We outline lessons learned and hope our paper will help inform design of future programming languages and refactoring tools. The resulting refactoring tool is written in Rust and available from Github under an MIT license [8].},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {14},
numpages = {9},
location = {Geelong, Australia},
series = {ACSW '17}
}

@inproceedings{10.1145/2789168.2789174,
author = {Ding, Aaron Yi and Liu, Yanhe and Tarkoma, Sasu and Flinck, Hannu and Crowcroft, Jon},
title = {Demo: An Open-Source Software Defined Platform for Collaborative and Energy-Aware WiFi Offloading},
year = {2015},
isbn = {9781450336192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2789168.2789174},
doi = {10.1145/2789168.2789174},
abstract = {This demonstration presents a novel software defined platform for achieving collaborative and energy-aware WiFi offloading. The platform consists of an extensible central controller, programmable offloading agents, and offloading extensions on mobile devices. Driven by our extensive measurements of energy consumption on smartphones, we propose an effective energy-aware offloading algorithm and integrate it to our platform. By enabling collaboration between wireless networks and mobile users, our solution can make optimal offloading decisions that improve offloading efficiency for network operators and achieve energy saving for mobile users. To enhance deployability, we have released our platform under open-source licenses on GitHub.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Computing and Networking},
pages = {182–184},
numpages = {3},
keywords = {software-defined networking, mobile data offloading},
location = {Paris, France},
series = {MobiCom '15}
}

@inproceedings{10.1145/2556420.2556833,
author = {Vasilescu, Bogdan},
title = {Software Developers Are Humans, Too!},
year = {2014},
isbn = {9781450325417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556420.2556833},
doi = {10.1145/2556420.2556833},
abstract = {Open-source communities can be seen as knowledge-sharing ecosystems: participants learn from the community and from one another, and share their knowledge through contributions to the source code repositories or by offering support to users. With the emergence and growing popularity of social media sites targeting software developers (e.g., StackOverflow, GitHub), the paths through which knowledge flows within open-source software knowledge-sharing ecosystems are also beginning to change. My dissertation research seeks to raise our understanding of these changes.},
booktitle = {Proceedings of the Companion Publication of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {97–100},
numpages = {4},
keywords = {open-source, human aspects, software developers},
location = {Baltimore, Maryland, USA},
series = {CSCW Companion '14}
}

@inproceedings{10.1145/2645710.2645717,
author = {Loni, Babak and Said, Alan},
title = {WrapRec: An Easy Extension of Recommender System Libraries},
year = {2014},
isbn = {9781450326681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2645710.2645717},
doi = {10.1145/2645710.2645717},
abstract = {WrapRec is an easy-to-use Recommender Systems toolkit, which allows users to easily implement or wrap recommendation algorithms from other frameworks. The main goals of WrapRec are to provide a flexible I/O, evaluation mechanism and code reusability. WrapRec provides a rich data model which makes it easy to implement algorithms for different recommender system problems, such as context-aware and cross-domain recommendation. The toolkit is written in C# and the source code is publicly available on Github under the GPL license.},
booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
pages = {377–378},
numpages = {2},
keywords = {recommender systems, open source library},
location = {Foster City, Silicon Valley, California, USA},
series = {RecSys '14}
}

@inproceedings{10.1145/3197091.3205819,
author = {Glassey, Richard},
title = {Managing Assignment Feedback via Issue Tracking},
year = {2018},
isbn = {9781450357074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3197091.3205819},
doi = {10.1145/3197091.3205819},
abstract = {This poster provides insight into the use of an issue tracker for the management of assignment feedback within an introductory course in computer science (CS). Students have made use of Github for three successive years, and the issue tracker has become one of the key mechanisms for managing formative feedback. This approach has yielded three key benefits: increased student engagement in their own feedback; provided an early experience of an authentic and industry desirable communication skill; and created a means to oversee and learn from feedback discussions for the teaching team.},
booktitle = {Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education},
pages = {382},
numpages = {1},
keywords = {Introductory Programming, Issue Tracker, Formative Feedback},
location = {Larnaca, Cyprus},
series = {ITiCSE 2018}
}

@inproceedings{10.1145/3334480.3382998,
author = {Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan},
title = {Understanding User-Bot Interactions for Small-Scale Automation in Open-Source Development},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382998},
doi = {10.1145/3334480.3382998},
abstract = {Small-scale automation tools, or "bots," have been widely deployed in open-source software development to support manual project maintenance tasks. Though interactions between these bots and human developers can have significant effects on user experience, previous research has instead mostly focused on project outcomes. We reviewed existing small-scale bots in wide use on GitHub. After an in-depth qualitative and quantitative evaluation, we compiled several important design principles for human-bot interaction in this context. Following the requirements, we further propose a workflow to support bot developers.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {HCI design and evaluation methods, software and its engineering, human-centered computing, software creation and management},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3190645.3190710,
author = {Huang, Shengyi (Costa) and Healy, Chris},
title = {StreetTraffic: A Library for Traffic Flow Data Collection and Analysis},
year = {2018},
isbn = {9781450356961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3190645.3190710},
doi = {10.1145/3190645.3190710},
abstract = {This extended abstract introduces StreetTraffic, an open-sourced server library that collects and analyzes traffic flow data. By utilizing REST APIs provided by HERE.com, StreetTraffic allows the users to crawl traffic flow data of interested regions or routes. Then, the users could see the visualized traffic flow history of the crawled data, empowering them to understand the historical traffic pattern of their interested routes, which could be valuable to commuters or someone who wants to optimize a trip. The library is currently hosted at Github (https://github.com/streettraffic/streettraffic), along with its documentation and tutorials.},
booktitle = {Proceedings of the ACMSE 2018 Conference},
articleno = {40},
numpages = {3},
keywords = {traffic data, web crawling, big data, visualization},
location = {Richmond, Kentucky},
series = {ACMSE '18}
}

@inproceedings{10.1145/3126858.3131586,
author = {Duarte, Paulo A.S. and Peixoto, Maria J.P. and Frota, Yuri S.F. and Viana, Windson},
title = {Generating Context Acquisition Code Using Awareness API},
year = {2017},
isbn = {9781450350969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126858.3131586},
doi = {10.1145/3126858.3131586},
abstract = {Development of Context-Aware and Mobile applications have significant challenges, such as the complexity of sensor access code and the heterogeneity of devices. The Google Awareness API is an initiative to mitigate this complexity. This paper presents an analysis of GitHub projects involving Awareness API. However, the results showed that the spread of this API among the developers community is still incipient. We propose to extend a tool to allow high-level modeling of context acquisition and code generation compatible with Awareness API. It reduces the complexity of acquiring contextual information and managing contextual rules.},
booktitle = {Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web},
pages = {181–184},
numpages = {4},
keywords = {android, google awareness, context-awareness, mde, dsl},
location = {Gramado, RS, Brazil},
series = {WebMedia '17}
}

@inproceedings{10.5555/3091125.3091165,
author = {Singh, Dhirendra and Padgham, Lin and Logan, Brian},
title = {Integrating BDI Agents with Agent-Based Simulation Platforms: (JAAMAS Extended Abstract)},
year = {2017},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This paper describes an integration framework that allows development of simulations where the cognitive reasoning and decision making is programmed and executed within an existing BDI (Belief, Desire, Intention) system, and the simulation is played out in an existing ABM (Agent Based Modelling) system. The framework has a generic layer which manages communication and synchronisation, a system layer which integrates specific BDI and ABM systems, and the application layer which contains the program code for a particular application. The code is available on GitHub: https://github.com/agentsoz/bdi-abm-integration},
booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
pages = {249–250},
numpages = {2},
keywords = {social simulation, modelling humans, bdi agents},
location = {S\~{a}o Paulo, Brazil},
series = {AAMAS '17}
}

@inproceedings{10.1145/3384217.3384219,
author = {Shakya, Raunak and Rahman, Akond},
title = {A Preliminary Taxonomy of Techniques Used in Software Fuzzing},
year = {2020},
isbn = {9781450375610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384217.3384219},
doi = {10.1145/3384217.3384219},
abstract = {Software fuzzing is a testing technique, which generates erroneous and random input to a software so that the software of interest can be monitored for exceptions such as crashes [1]. Both in the open source software (OSS) and proprietary domain, fuzzing has been widely used to explore software vulnerabilities. For example, information technology (IT) organizations such as Google1 and Microsoft2 use software fuzzing as part of the software development process. As of Jan 2019, GitHub hosts 2,915 OSS repositories related to fuzzing3.},
booktitle = {Proceedings of the 7th Symposium on Hot Topics in the Science of Security},
articleno = {14},
numpages = {2},
keywords = {scoping review, fuzzing, software security, taxonomy},
location = {Lawrence, Kansas},
series = {HotSoS '20}
}

@inproceedings{10.1145/3274856.3274875,
author = {Steinberg, Boris and Baglij, Anton and Petrenko, Victor and Burkhovetskiy, Victor and Steinberg, Oleg and Metelica, Elena},
title = {An Analyzer for Program Parallelization and Optimization},
year = {2018},
isbn = {9781450365161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274856.3274875},
doi = {10.1145/3274856.3274875},
abstract = {The article describes new facilities for program optimization and parallelization, work-in-progress modifications of previously implemented program transformations and compiler libraries, and future development of Optimizing parallelizing system (OPS) including opening its source code on GitHub. These new facilities, such as dialog-based optimization and parallelization, user-friendly program dependency visualization (which is needed for high-quality analyzers), parallel code generation for accelerators (GPUs, DSPs, FPGAs, or high performance clusters), are made possible by the fact, that OPS uses high-level intermediate representation as opposed to low-level intermediate representation used in popular compilers.},
booktitle = {Proceedings of the 3rd International Conference on Applications in Information Technology},
pages = {90–95},
numpages = {6},
keywords = {data locality, interactive compiler, reconfigurable architectures, tiling, high-level intermediate representation, Parallelizing compiler, program transformations},
location = {Aizu-Wakamatsu, Japan},
series = {ICAIT'2018}
}

@inproceedings{10.1145/3214907.3233760,
author = {Spielmann, Simon and Helzle, Volker and Schuster, Andreas and Trottnow, Jonas and G\"{o}tz, Kai and Rohr, Patricia},
title = {VPET: Virtual Production Editing Tools},
year = {2018},
isbn = {9781450358101},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3214907.3233760},
doi = {10.1145/3214907.3233760},
abstract = {The work on intuitive Virtual Production tools at Filmakademie Baden-W\"{u}rttemberg has focused on an open platform tied to existing film creation pipelines. The Virtual Production Editing Tools (VPET) started in a former project on Virtual Production funded by the European Union and are published and constantly updated on the open source software development platform Github. We introduce an intuitive workflow where Augmented Reality, inside-out tracking and real-time color keying can be applied on the fly to extend a real movie set with editable, virtual extensions in a collaborative setup.},
booktitle = {ACM SIGGRAPH 2018 Emerging Technologies},
articleno = {22},
numpages = {2},
keywords = {filmmaking, color keying, virtual production, production pipeline, collaborative work, augmented reality, on-set editing, handheld},
location = {Vancouver, British Columbia, Canada},
series = {SIGGRAPH '18}
}

@inproceedings{10.1145/3030207.3030226,
author = {Stefan, Petr and Horky, Vojtech and Bulej, Lubomir and Tuma, Petr},
title = {Unit Testing Performance in Java Projects: Are We There Yet?},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3030226},
doi = {10.1145/3030207.3030226},
abstract = {Although methods and tools for unit testing of performance exist for over a decade, anecdotal evidence suggests unit testing of performance is not nearly as common as unit testing of functionality. We examine this situation in a study of GitHub projects written in Java, looking for occurrences of performance evaluation code in common performance testing frameworks. We quantify the use of such frameworks, identifying the most relevant performance testing approaches, and describe how we adjust the design of our SPL performance testing framework to follow these conclusions.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {401–412},
numpages = {12},
keywords = {spl, performance unit testing, open source, jmh, survey},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@inproceedings{10.1145/3368089.3409689,
author = {Huang, Kaifeng and Chen, Bihuan and Shi, Bowen and Wang, Ying and Xu, Congying and Peng, Xin},
title = {Interactive, Effort-Aware Library Version Harmonization},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409689},
doi = {10.1145/3368089.3409689},
abstract = {As a mixed result of intensive dependency on third-party libraries, flexible mechanisms to declare dependencies and increased number of modules in a project, different modules of a project directly depend on multiple versions of the same third-party library. Such library version inconsistencies could increase dependency maintenance cost, or even lead to dependency conflicts when modules are inter-dependent. Although automated build tools (e.g., Maven's enforcer plugin) provide partial support to detect library version inconsistencies, they do not provide any support to harmonize inconsistent library versions.  We first conduct a survey with 131 Java developers from GitHub to retrieve first-hand information about the root causes, detection methods, reasons for fixing or not fixing, fixing strategies, fixing efforts, and tool expectations on library version inconsistencies. Then, based on the insights from our survey, we propose LibHarmo, an interactive, effort-aware library version harmonization technique, to detect library version inconsistencies, interactively suggest a harmonized version with the least harmonization efforts based on library API usage analysis, and refactor build configuration files.  LibHarmo is currently developed for Java Maven projects. Our experimental study on 443 highly-starred Java Maven projects from GitHub shows that i) LibHarmo detected 621 library version inconsistencies in 152 (34.3%) projects with a false positive rate of 16.8%, while Maven's enforcer plugin only detected 219 of them; and ii) LibHarmo saved 87.5% of the harmonization efforts. Further, 31 library version inconsistencies have been confirmed, and 17 of them have been already harmonized by developers.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {518–529},
numpages = {12},
keywords = {Library Version Harmonization, Third-Party Libraries},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1109/ICSE.2019.00099,
author = {Sarker, Farhana and Vasilescu, Bogdan and Blincoe, Kelly and Filkov, Vladimir},
title = {Socio-Technical Work-Rate Increase Associates with Changes in Work Patterns in Online Projects},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00099},
doi = {10.1109/ICSE.2019.00099},
abstract = {Software developers work on a variety of tasks ranging from the technical, e.g., writing code, to the social, e.g., participating in issue resolution discussions. The amount of work developers perform per week (their work-rate) also varies and depends on project needs and developer schedules. Prior work has shown that while moderate levels of increased technical work and multitasking lead to higher productivity, beyond a certain threshold, they can lead to lowered performance.Here, we study how increases in the short-term work-rate along both the technical and social dimensions are associated with changes in developers' work patterns, in particular communication sentiment, technical productivity, and social productivity. We surveyed active and prolific developers on GitHub to understand the causes and impacts of increased work-rates. Guided by the responses, we developed regression models to study how communication and committing patterns change with increased work-rates and fit those models to large-scale data gathered from traces left by thousands of GitHub developers. From our survey and models, we find that most developers do experience work-rate-increase-related changes in behavior. Most notably, our models show that there is a sizable effect when developers comment much more than their average: the negative sentiment in their comments increases, suggesting an increased level of stress. Our models also show that committing patterns do not change with increased commenting, and vice versa, suggesting that technical and social activities tend not to be multitasked.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {936–947},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.5555/3400397.3400677,
author = {Eckman, David J. and Henderson, Shane G. and Pasupathy, Raghu},
title = {Redesigning a Testbed of Simulation-Optimization Problems and Solvers for Experimental Comparisons},
year = {2019},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {We describe major improvements to the testing capabilities of SimOpt, a library of simulation-optimization problems and solvers. Foremost among these improvements is a transition to GitHub that makes SimOpt easier to use and maintain. We also design two new wrapper functions that facilitate empirical comparisons of solvers. The wrapper functions make extensive use of common random numbers (CRN) both within and across solvers for various purposes; e.g., identifying random initial solutions and running simulation replications. We examine some of the intricacies of using CRN to compare simulation-optimization solvers.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3457–3467},
numpages = {11},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.1145/3387904.3389270,
author = {Caulo, Maria and Lin, Bin and Bavota, Gabriele and Scanniello, Giuseppe and Lanza, Michele},
title = {Knowledge Transfer in Modern Code Review},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389270},
doi = {10.1145/3387904.3389270},
abstract = {Knowledge transfer is one of the main goals of modern code review, as shown by several studies that surveyed and interviewed developers. While knowledge transfer is a clear expectation of the code review process, there are no analytical studies using data mined from software repositories to assess the effectiveness of code review in "training" developers and improve their skills over time. We present a mining-based study investigating how and whether the code review process helps developers to improve their contributions to open source projects over time. We analyze 32,062 peer-reviewed pull requests (PRs) made across 4,981 GitHub repositories by 728 developers who created their GitHub account in 2015. We assume that PRs performed in the past by a developer D that have been subject to a code review process have "transferred knowledge" to D. Then, we verify if over time (i.e., when more and more reviewed PRs are made by D), the quality of the contributions made by D to open source projects increases (as assessed by proxies we defined, such as the acceptance of PRs, or the polarity of the sentiment in the review comments left for the submitted PRs). With the above measures, we were unable to capture the positive impact played by the code review process on the quality of developers' contributions. This might be due to several factors, including the choices we made in our experimental design.Additional investigations are needed to confirm or contradict such a negative result.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {230–240},
numpages = {11},
keywords = {code review, mining software repositories, knowledge transfer},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@inproceedings{10.1145/2591062.2591115,
author = {Padhye, Rohan and Mukherjee, Debdoot and Sinha, Vibha Singhal},
title = {API as a Social Glue},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591115},
doi = {10.1145/2591062.2591115},
abstract = { The rapid growth of social platforms such as Facebook, Twitter and LinkedIn underscores the need for people to connect to existing and new contacts for recreational and professional purposes. A parallel of this phenomenon exists in the software development arena as well. Open-source code sharing platforms such as GitHub provide the ability to follow people and projects of interest. However, users are manually required to identify projects or other users whom they might be interested in following. We observe that most software projects use third-party libraries and that developers who contribute to multiple projects often use the same library APIs across projects. Thus, the library APIs seem to be a good fingerprint of their skill set. Hence, we argue that library APIs can form the social glue to connect people and projects having similar interests. We propose APINet, a system that mines API usage profiles from source code version management systems and create a social network of people, projects and libraries. We describe our initial implementation that uses data from 568 open-source projects hosted on GitHub. Our system recommends to a user new projects and people that they may be interested in, suggests communities of people who use related libraries and finds experts for a given topic who are closest in a user's social graph. },
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {516–519},
numpages = {4},
keywords = {Mining software repositories, social networks, usage expertise, recommender systems},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/3380868.3398200,
author = {Chang, Christopher H. and Carpenter, Ilene L. and Jones, Wesley B.},
title = {The ESIF-HPC-2 Benchmark Suite},
year = {2020},
isbn = {9781450375368},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380868.3398200},
doi = {10.1145/3380868.3398200},
abstract = {We describe the development of the ESIF-HPC-2 benchmark suite, a collection of kernel and application benchmark codes for measuring computational and I/O performance from single nodes to full HPC systems that was used for acceptance testing in our recent HPC procurement. The configurations of the benchmarks used for our system is presented. We also describe a set of "dimensions" that can be used to classify benchmarks and assess coverage of a suite systematically. The collection is offered cost-free as a GitHub repository for general usage and further development.},
booktitle = {Proceedings of the Workshop on Benchmarking in the Datacenter},
articleno = {2},
numpages = {8},
keywords = {benchmark, procurement, HPC},
location = {San Diego, California},
series = {BID '20}
}

@inproceedings{10.1145/3196398.3196460,
author = {Geiger, Franz-Xaver and Malavolta, Ivano and Pascarella, Luca and Palomba, Fabio and Di Nucci, Dario and Bacchelli, Alberto},
title = {A Graph-Based Dataset of Commit History of Real-World Android Apps},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196460},
doi = {10.1145/3196398.3196460},
abstract = {Obtaining a good dataset to conduct empirical studies on the engineering of Android apps is an open challenge. To start tackling this challenge, we present AndroidTimeMachine, the first, self-contained, publicly available dataset weaving spread-out data sources about real-world, open-source Android apps. Encoded as a graph-based database, AndroidTimeMachine concerns 8,431 real open-source Android apps and contains: (i) metadata about the apps' GitHub projects, (ii) Git repositories with full commit history and (iii) metadata extracted from the Google Play store, such as app ratings and permissions.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {30–33},
numpages = {4},
keywords = {Android, mining software repositories, dataset},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/3168836.3168839,
author = {Freire, Juliana},
title = {Spatio-Temporal Analytics, Urban Analytics},
year = {2017},
isbn = {9781450373159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168836.3168839},
doi = {10.1145/3168836.3168839},
abstract = {Part 1Lecture 1:Urban Data: Challenges and OpportunitiesData Quality IssuesExploring Urban Data: Usability and InteractivityLecture 2:Finding Interesting FeaturesUsing Data to Discover and Explain DataTransparency and ReproducibilityHands-on 1:Data cleaningHands-on 2:Exploring shadows and trees in NYCCourse Material (lab and data) at https://github.com/julianafreire/ACMSummerSchool2017Course Notes at https://www.dropbox.com/s/4xsq0nubnbfmwaq/big-urban-data-lecture.pdf?dl=0The students will have to install OpenRefine and Jupyter+a few libraries.The instructions are in the lab descriptions in github.},
booktitle = {1st Europe Summer School: Data Science},
articleno = {3},
numpages = {1},
location = {Athens, Greece},
series = {SummerSchool '17}
}

@inproceedings{10.5555/3016387.3016512,
author = {Amir, Ofra and Grosz, Barbara J. and Gajos, Krzysztof Z.},
title = {MIP-Nets: Enabling Information Sharing in Loosely-Coupled Teamwork},
year = {2016},
publisher = {AAAI Press},
abstract = {People collaborate in carrying out such complex activities as treating patients, co-authoring documents and developing software. While technologies such as Dropbox and Github enable groups to work in a distributed manner, coordinating team members' individual activities poses significant challenges. In this paper, we formalize the problem of "information sharing in loosely-coupled extended-duration teamwork". We develop a new representation, Mutual Influence Potential Networks (MIP-Nets), to model collaboration patterns and dependencies among activities, and an algorithm, MIP-DOI, that uses this representation to reason about information sharing.},
booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
pages = {4192–4193},
numpages = {2},
location = {Phoenix, Arizona},
series = {AAAI'16}
}

@inproceedings{10.1109/ASE.2019.00083,
author = {Verhaeghe, Beno\^{\i}t and Fuhrman, Christopher and Guerrouj, Latifa and Anquetil, Nicolas and Ducasse, St\'{e}phane},
title = {Empirical Study of Programming to an Interface},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00083},
doi = {10.1109/ASE.2019.00083},
abstract = {A popular recommendation to programmers in object-oriented software is to "program to an interface, not an implementation" (PTI). Expected benefits include increased simplicity from abstraction, decreased dependency on implementations, and higher flexibility. Yet, interfaces must be immutable, excessive class hierarchies can be a form of complexity, and "speculative generality" is a known code smell. To advance the empirical knowledge of PTI, we conducted an empirical investigation that involves 126 Java projects on GitHub, aiming to measuring the decreased dependency benefits (in terms of cochange).},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {847–850},
numpages = {4},
keywords = {software repositories, Java interfaces, GitHub, coupling, cochange, empirical study},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3361242.3361254,
author = {Wang, Qingye and Xu, Bowen and Xia, Xin and Wang, Ting and Li, Shanping},
title = {Duplicate Pull Request Detection: When Time Matters},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361254},
doi = {10.1145/3361242.3361254},
abstract = {In open source communities (e.g., GitHub), developers frequently submit pull requests to fix bugs or add new features during development process. Since the process of pull request is uncoordinated and distributed, it causes massive duplication. Usually, only the first pull request qualified by reviewers can be merged to the main branch of the repository, and the others are regarded as duplication by maintainers. Since the duplication largely aggravates workloads of project reviewers and maintainers, the evolutionary process of open source repositories is delayed. To identify the duplicate pull requests automatically, Ren et al. proposed a state-of-the-art approach that models a pull request by nine features and determine whether a given request is duplicate with the other existing requests or not. Nevertheless, we notice that their approach overlooked the time factor which is a significant feature for the task. In this study, we investigate the influence of time factor and improve the pull request representation. We assume that two pull requests are more likely duplicate when their created time are close to each other. We verify the assumption based on 26 open source repositories from GitHub with over 100,000 pairs of pull requests. We integrate the time feature to the nine features proposed by Ren et al. and the experimental results show that it can substantially improve the performance of Ren et al.'s work by 14.36% and 11.93% in terms of F1-score@1 and F1-score@5, respectively.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {8},
numpages = {10},
keywords = {GitHub, Time Factor, Duplicate Pull Request},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@inproceedings{10.1145/3377813.3381347,
author = {Chong, Nathan and Cook, Byron and Kallas, Konstantinos and Khazem, Kareem and Monteiro, Felipe R. and Schwartz-Narbonne, Daniel and Tasiran, Serdar and Tautschnig, Michael and Tuttle, Mark R.},
title = {Code-Level Model Checking in the Software Development Workflow},
year = {2020},
isbn = {9781450371230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377813.3381347},
doi = {10.1145/3377813.3381347},
abstract = {This experience report describes a style of applying symbolic model checking developed over the course of four years at Amazon Web Services (AWS). Lessons learned are drawn from proving properties of numerous C-based systems, e.g., custom hypervisors, encryption code, boot loaders, and an IoT operating system. Using our methodology, we find that we can prove the correctness of industrial low-level C-based systems with reasonable effort and predictability. Furthermore, AWS developers are increasingly writing their own formal specifications. All proofs discussed in this paper are publicly available on GitHub.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice},
pages = {11–20},
numpages = {10},
keywords = {model checking, continuous integration, memory safety},
location = {Seoul, South Korea},
series = {ICSE-SEIP '20}
}

@inproceedings{10.1145/3388142.3388146,
author = {Brady, James F.},
title = {Computing System Congestion Management Using Exponential Smoothing Forecasting},
year = {2020},
isbn = {9781450376440},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388142.3388146},
doi = {10.1145/3388142.3388146},
abstract = {An overloaded computer must finish what it starts and not start what will fail or hang. A congestion management algorithm, the author developed, effectively manages traffic overload with its unique formulation of Exponential Smoothing forecasting. This set of equations resolve forecasting startup issues that have limited the model's adoption as a discrete time series predictor. These expressions also satisfy implementation requirements to perform calculations using integer math and be able to reset the forecast seamlessly. A computer program, written in C language, which exercises the methodology, is downloadable from GitHub.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Compute and Data Analysis},
pages = {164–169},
numpages = {6},
keywords = {exponential smoothing, congestion management, overload control},
location = {Silicon Valley, CA, USA},
series = {ICCDA 2020}
}

@inproceedings{10.5555/2820518.2820562,
author = {van der Veen, Erik and Gousios, Georgios and Zaidman, Andy},
title = {Automatically Prioritizing Pull Requests},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {In previous work, we observed that in the pull-based development model integrators face challenges with regard to prioritizing work in the face of multiple concurrent pull requests. We present the design and initial implementation of a prototype pull request prioritisation tool called prioritizer. prioritizer works like a priority inbox for pull requests, recommending the top pull requests the project owner should focus on. A preliminary user study showed that prioritizer provides functionality that GitHub is currently lacking, even though users need more insight into how the priority ranking is established to make prioritizer really useful.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {357–361},
numpages = {5},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3305366.3328067,
author = {Koch, Sebastian and Schneider, Teseo and Williams, Francis and Panozzo, Daniele},
title = {Geometric Computing with Python},
year = {2019},
isbn = {9781450363075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3305366.3328067},
doi = {10.1145/3305366.3328067},
abstract = {This course is a group endeavor by Sebastian Koeh, Teseo Sehneider, Francis Williams, and Daniele Panozzo. Please contact us if you have questions or comments. For troubleshooting, please post an issue on github. We are grateful to the authors of all open souree C++ libraries we are using. In particular, libigl, tetwild, polyfem, pybind11, and Jupyter.The course will mainly use• igl (Section 2)• polyfem (Section 3)• ABC Dataset CAD Processing (Section 4)• TetWild• 3D ViewerWe provide documentation for the first 3 libraries in these course notes and we refer to https://geometryprocessing.github.io/geometric-computing-python/ for a complete and live version.},
booktitle = {ACM SIGGRAPH 2019 Courses},
articleno = {11},
numpages = {45},
location = {Los Angeles, California},
series = {SIGGRAPH '19}
}

@inproceedings{10.1145/3194932.3194934,
author = {Werder, Karl},
title = {The Evolution of Emotional Displays in Open Source Software Development Teams: An Individual Growth Curve Analysis},
year = {2018},
isbn = {9781450357517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194932.3194934},
doi = {10.1145/3194932.3194934},
abstract = {Software developers communicate and interact with each other in order to solve complex problems. Such communication often includes emotional displays that have been shown to influence team processes and performance. Yet, little is known about the evolution of team emotional displays. Hence, we investigate a sample of 1121 Open Source Software (OSS) projects from GitHub, using longitudinal data analysis. The results from growth curve analysis shows that the team emotional display decrease over time. This negative linear trend decelerates mid-term as suggested by a positive quadratic trend of time. Such deceleration diminishes toward the end as a negative cubic trend suggests.},
booktitle = {Proceedings of the 3rd International Workshop on Emotion Awareness in Software Engineering},
pages = {1–6},
numpages = {6},
keywords = {software development, open source software, growth curve analysis, team emotional display},
location = {Gothenburg, Sweden},
series = {SEmotion '18}
}

@inproceedings{10.1145/3377812.3382151,
author = {Martinez, Matias and Etien, Anne and Ducasse, St\'{e}phane and Fuhrman, Christopher},
title = {RTj: A Java Framework for Detecting and Refactoring Rotten Green Test Cases},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3382151},
doi = {10.1145/3377812.3382151},
abstract = {Rotten green tests are passing tests which have at least one assertion that is not executed. They give developers a false sense of trust in the code. In this paper, we present RTj, a framework that analyzes test cases from Java projects with the goal of detecting and refactoring rotten test cases. RTj automatically discovered 418 rotten tests from 26 open-source Java projects hosted on GitHub. Using RTj, developers have an automated recommendation of the tests that need to be modified for improving the quality of the applications under test. A video is available at: https://youtu.be/Uqxf-Wzp3Mg},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {69–72},
numpages = {4},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/2464464.2464498,
author = {Heymann, S\'{e}bastien and Le Grand, B\'{e}n\'{e}dicte},
title = {Towards a Redefinition of Time in Information Networks?},
year = {2013},
isbn = {9781450318891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2464464.2464498},
doi = {10.1145/2464464.2464498},
abstract = {How should we characterize the dynamics of the Web? Whereas network maps have contributed to a redefinition of distances and space in information networks, current studies still use a traditional time unit -the second- to understand the temporality of the Web. This unit leads to the observation of exogenous phenomena like day-night patterns. In order to capture the intrinsic dynamics of the network, we introduce an innovative -yet simple- concept of time which relies on the measure of changes in the network space. We demonstrate its practical interest on the evolution of the Github social network.},
booktitle = {Proceedings of the 5th Annual ACM Web Science Conference},
pages = {158–161},
numpages = {4},
keywords = {dynamics, time, social network, measurement, sliding window, complex networks},
location = {Paris, France},
series = {WebSci '13}
}

@inproceedings{10.1109/ICSE-NIER.2019.00022,
author = {Beller, Moritz and Hejderup, Joseph},
title = {Blockchain-Based Software Engineering},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00022},
doi = {10.1109/ICSE-NIER.2019.00022},
abstract = {Blockchain technology has found a great number of applications, from banking to the Internet of Things (IoT). However, it has not yet been envisioned whether and which problems in Software Engineering (SE) Blockchain technology could solve. In this paper, we coin this field "Blockchain-based Software Engineering" and exemplify how Blockchain technology could solve two core SE problems: Continuous Integration (CI) Services such as Travis CI and Package Managers such as apt-get. We believe that Blockchain technology could help (1) democratize and professionalize Software Engineering infrastructure that currently relies on free work done by few volunteers, (2) improve the quality of artifacts and services, and (3) increase trust in ubiquitously used systems like GitHub or Travis CI.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {53–56},
numpages = {4},
keywords = {blockchain, distributed system},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@inproceedings{10.1145/3126858.3131598,
author = {Lazzari, Hugo Schroter and Tavares da Costa Filho, Roberto Iraja and Roesler, Valter},
title = {QoE Analyser: A Framework to QoE Knowledge Base Generation},
year = {2017},
isbn = {9781450350969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126858.3131598},
doi = {10.1145/3126858.3131598},
abstract = {This paper presents a framework for the creation of a knowledge database on QoE. The QoE Analyzer framework enables the simulation of degradations in video playout and also the application of a survey to evaluate the impact of degradations on the user Quality of Experience. In order to show the versatility of the framework, an instantiation of the framework and its application to a group of 62 users was carried out. The framework was implemented using the JavaScript language and, through it, it was possible to show the impacts of degradation patterns on the user experience. The framework was released under GNU GPLv3 license and is available in github (https://github.com/hugoschroterl/qoe-analyser).},
booktitle = {Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web},
pages = {433–436},
numpages = {4},
keywords = {video subjective analysis., qoe framework, video streaming, video quality, quality of experience},
location = {Gramado, RS, Brazil},
series = {WebMedia '17}
}

@inproceedings{10.1145/3196398.3196430,
author = {Baltes, Sebastian and Dumani, Lorik and Treude, Christoph and Diehl, Stephan},
title = {SOTorrent: Reconstructing and Analyzing the Evolution of Stack Overflow Posts},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196430},
doi = {10.1145/3196398.3196430},
abstract = {Stack Overflow (SO) is the most popular question-and-answer website for software developers, providing a large amount of code snippets and free-form text on a wide variety of topics. Like other software artifacts, questions and answers on SO evolve over time, for example when bugs in code snippets are fixed, code is updated to work with a more recent library version, or text surrounding a code snippet is edited for clarity. To be able to analyze how content on SO evolves, we built SOTorrent, an open dataset based on the official SO data dump. SOTorrent provides access to the version history of SO content at the level of whole posts and individual text or code blocks. It connects SO posts to other platforms by aggregating URLs from text blocks and by collecting references from GitHub files to SO posts. In this paper, we describe how we built SOTorrent, and in particular how we evaluated 134 different string similarity metrics regarding their applicability for reconstructing the version history of text and code blocks. Based on a first analysis using the dataset, we present insights into the evolution of SO posts, e.g., that post edits are usually small, happen soon after the initial creation of the post, and that code is rarely changed without also updating the surrounding text. Further, our analysis revealed a close relationship between post edits and comments. Our vision is that researchers will use SOTorrent to investigate and understand the evolution of SO posts and their relation to other platforms such as GitHub.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {319–330},
numpages = {12},
keywords = {open dataset, software evolution, stack overflow, code snippets},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/3297280.3297501,
author = {Cesarini, Mirko and Mercorio, Fabio and Mezzanzanica, Mario and Moscato, Vincenzo and Picariello, Antonio},
title = {A Tool for Exploring Networks of Computer Scientists as a Graph},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297501},
doi = {10.1145/3297280.3297501},
abstract = {In this paper we present GraphDBLP, a tool to query the DBLP bibliography as a graph. The DBLP source data were enriched with semantic similarity relationships computed using word-embeddings. A user can interact with the system either writing queries on the graph-db visual console or using a shell-interface provided with 4 parametric and pre-defined queries.GraphDBLP would represent a first graph-database instance of the computer scientist network, that can be improved through new relationships and properties on nodes at any time, and this is the main purpose of the tool, we have made freely available on Github.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2240–2242},
numpages = {3},
keywords = {semantic social network, semantic knowledge discovery, graph database, application},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.5555/2859032.2867575,
author = {Nakazawa, Shun and Tanaka, Tetsuo},
title = {Prototype of Kanban Tool and Preliminary Evaluation of Visualizing Method for Task Assignment},
year = {2015},
isbn = {9781467382113},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Kanban is a method used in agile software development. It is a most important tool as it acts as a central communication hub among the members of an agile development team. In this research, the authors develop a prototype of a Kanban tool. The tool displays each developer's tasks across multiple horizontal rows. Therefore, users can assess the task assignment and workloads of team members in one glance. The board also links up with GitHub and has a feature of real time synchronization among clients for distributed development. An experiment showed that the proposed approach was effective.},
booktitle = {Proceedings of the 2015 International Conference on Computer Application Technologies},
pages = {7},
numpages = {1},
keywords = {Agile software development, Real-time synchronization, Task board, GitHub coordination, Kanban},
series = {CCATS '15}
}

@inproceedings{10.1109/CCATS.2015.21,
author = {Nakazawa, Shun and Tanaka, Tetsuo},
title = {Prototype of Kanban Tool and Preliminary Evaluation of Visualizing Method for Task Assignment},
year = {2015},
isbn = {9781467382113},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCATS.2015.21},
doi = {10.1109/CCATS.2015.21},
abstract = {Kanban is a method used in agile software development. It is a most important tool as it acts as a central communication hub among the members of an agile development team. In this research, the authors develop a prototype of a Kanban tool. The tool displays each developer's tasks across multiple horizontal rows. Therefore, users can assess the task assignment and workloads of team members in one glance. The board also links up with GitHub and has a feature of real time synchronization among clients for distributed development. An experiment showed that the proposed approach was effective.},
booktitle = {Proceedings of the 2015 International Conference on Computer Application Technologies},
pages = {48–49},
numpages = {2},
keywords = {Real-time synchronization, Agile software development, Task board, GitHub coordination, Kanban},
series = {CCATS '15}
}

@inproceedings{10.1145/3293882.3330578,
author = {Lou, Yiling and Chen, Junjie and Zhang, Lingming and Hao, Dan and Zhang, Lu},
title = {History-Driven Build Failure Fixing: How Far Are We?},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3330578},
doi = {10.1145/3293882.3330578},
abstract = {Build systems are essential for modern software development and maintenance since they are widely used to transform source code artifacts into executable software. Previous work shows that build systems break frequently during software evolution. Therefore, automated build-fixing techniques are in huge demand. In this paper we target a mainstream build system, Gradle, which has become the most widely used build system for Java projects in the open-source community (e.g., GitHub). HireBuild, state-of-the-art build-fixing tool for Gradle, has been recently proposed to fix Gradle build failures via mining the history of prior fixes. Although HireBuild has been shown to be effective for fixing real-world Gradle build failures, it was evaluated on only a limited set of build failures, and largely depends on the quality/availability of historical fix information. To investigate the efficacy and limitations of the history-driven build fix, we first construct a new and large build failure dataset from Top-1000 GitHub projects. Then, we evaluate HireBuild on the extended dataset both quantitatively and qualitatively. Inspired by the findings of the study, we propose a simplistic new technique that generates potential patches via searching from the present project under test and external resources rather than the historical fix information. According to our experimental results, the simplistic approach based on present information successfully fixes 2X more reproducible build failures than the state-of-art HireBuild based on historical fix information. Furthermore, our results also reveal various findings/guidelines for future advanced build failure fixing.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {43–54},
numpages = {12},
keywords = {Build Failure Fixing, {Automated Program Repair, Build System},
location = {Beijing, China},
series = {ISSTA 2019}
}

@inproceedings{10.1109/MSR.2019.00050,
author = {Ahmad, Mashal and Cinn\'{e}ide, Mel \'{O}},
title = {Impact of Stack Overflow Code Snippets on Software Cohesion: A Preliminary Study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00050},
doi = {10.1109/MSR.2019.00050},
abstract = {Developers frequently copy code snippets from publicly-available resources such as Stack Overflow (SO). While this may lead to a 'quick fix' for a development problem, little is known about how these copied code snippets affect the code quality of the recipient application, or how the quality of the recipient classes subsequently evolves over the time of the project. This has an impact on whether such code copying should be encouraged, and how classes that receive such code snippets should be monitored during evolution. To investigate this issue, we used instances from the SOTorrent database where Java snippets had been copied from Stack Overflow into GitHub projects. In each case, we measured the quality of the recipient class just prior to the addition of the snippet, immediately after the addition of the snippet, and at a later stage in the project. Our goal was to determine if the addition of the snippet caused quality to improve or deteriorate, and what the long-term implications were for the quality of the recipient class. Code quality was measured using the cohesion metrics Low-level Similarity-based Class Cohesion (LSCC) and Class Cohesion (CC). Over a random sample of 378 classes that received code snippets copied from Stack Overflow to GitHub, we found that in almost 70% of the cases where the copied snippet affected cohesion, the effect was to reduce the cohesion of the recipient class. Furthermore, this deterioration in cohesion tends to persist in the subsequent evolution of recipient class. In over 70% of cases the recipient class never fully regained the cohesion it lost in receiving the snippet. These results suggest that when copying code snippets from external repositories, more attention should be paid to integrating the code with the recipient class.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {250–254},
numpages = {5},
keywords = {evolution, metrics, quality, cohesion},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.5555/3104068.3104080,
author = {Watanabe, Keisuke and Ubayashi, Naoyasu and Fukamachi, Takuya and Nakamura, Shunya and Muraoka, Hokuto and Kamei, Yasutaka},
title = {IArch-U: Interface-Centric Integrated Uncertainty-Aware Development Environment},
year = {2017},
isbn = {9781538604267},
publisher = {IEEE Press},
abstract = {Uncertainty can appear in all aspects of software development: uncertainty in requirements analysis, design decisions, implementation and testing. If uncertainty can be dealt with modularly, we can add or delete uncertain concerns to/from models, code and tests whenever these concerns arise or are fixed to certain concerns. To deal with this problem, we developed iArch-U, an IDE (Integrated Development Environment) for managing uncertainty modularly in all phases in software development. In this paper, we introduce an overview of iArch-U. The iArch-U IDE is open source software and can be downloaded from GitHub.},
booktitle = {Proceedings of the 9th International Workshop on Modelling in Software Engineering},
pages = {40–46},
numpages = {7},
keywords = {development environment, modularity, interface, uncertainty},
location = {Buenos Aires, Argentina},
series = {MISE '17}
}

@inproceedings{10.1145/2983402.2983420,
author = {Marques, Oge and Carson, Joseph},
title = {Selfie Search: Image Retrieval and Face Recognition in IOS: [Invited Paper]},
year = {2016},
isbn = {9781450343015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983402.2983420},
doi = {10.1145/2983402.2983420},
abstract = {This paper describes the design and development of an iOS app for selfie search, which combines face detection and recognition capabilities with content-based image retrieval techniques. The app works offline, since all processing takes place entirely on the device. It was implemented in Objective-C and it leverages functionality from Apple's Core Image API for image processing tasks and CouchbaseLite for the database layer. For face recognition, the app employs local binary patterns -- encoded as spatially enhanced histograms, with weight maps that indicate preferred areas within the cropped image containing the face. The source code is available on GitHub.},
booktitle = {Proceedings of the Third International Symposium on Computer Vision and the Internet},
pages = {48–53},
numpages = {6},
keywords = {Face Recognition, Local Binary Descriptors, Content-Based Image Retrieval (CBIR), iOS App Development, Image Retrieval},
location = {Jaipur, India},
series = {VisionNet'16}
}

@inproceedings{10.1145/3377812.3390906,
author = {Li, Ziqiang and Tan, Shin Hwei},
title = {Bugine: A Bug Report Recommendation System for Android Apps},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3390906},
doi = {10.1145/3377812.3390906},
abstract = {Many automated test generation tools were proposed for finding bugs in Android apps. However, a recent study revealed that developers prefer reading automated test generation cased written in natural language. We present Bugine, a new bug recommendation system that automatically selects relevant bug reports from other applications that have similar bugs. Bugine (1) searches for GitHub issues that mentioned common UI components shared between the app under test and the apps in our database, and (2) ranks the quality and relevance of issues. Our results show that Bugine could find 34 new bugs in five evaluated apps.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {278–279},
numpages = {2},
keywords = {bug report, Android apps, recommendation system},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3194932.3194938,
author = {Imtiaz, Nasif and Middleton, Justin and Girouard, Peter and Murphy-Hill, Emerson},
title = {Sentiment and Politeness Analysis Tools on Developer Discussions Are Unreliable, but so Are People},
year = {2018},
isbn = {9781450357517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194932.3194938},
doi = {10.1145/3194932.3194938},
abstract = {Many software engineering researchers use sentiment and politeness analysis tools to study the emotional environment within collaborative software development. However, papers that use these tools rarely establish their reliability. In this paper, we evaluate popular existing tools for sentiment and politeness detection over a dataset of 589 manually rated GitHub comments that represent developer discussions. We also develop a coding scheme on how to quantify politeness for conversational texts found on collaborative platforms. We find that not only do the tools have a low agreement with human ratings on sentiment and politeness, human raters also have a low agreement among themselves.},
booktitle = {Proceedings of the 3rd International Workshop on Emotion Awareness in Software Engineering},
pages = {55–61},
numpages = {7},
keywords = {sentiment, github, affect analysis, politeness, developer discussion},
location = {Gothenburg, Sweden},
series = {SEmotion '18}
}

@inproceedings{10.1145/3379597.3387511,
author = {Ali, Rao Hamza and Parlett-Pelleriti, Chelsea and Linstead, Erik},
title = {Cheating Death: A Statistical Survival Analysis of Publicly Available Python Projects},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387511},
doi = {10.1145/3379597.3387511},
abstract = {We apply survival analysis methods to a dataset of publicly-available software projects in order to examine the attributes that might lead to their inactivity over time. We ran a Kaplan-Meier analysis and fit a Cox Proportional-Hazards model to a subset of Software Heritage Graph Dataset, consisting of 3052 popular Python projects hosted on GitLab/GitHub, Debian, and PyPI, over a period of 165 months. We show that projects with repositories on multiple hosting services, a timeline of publishing major releases, and a good network of developers, remain healthy over time and should be worthy of the effort put in by developers and contributors.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {6–10},
numpages = {5},
keywords = {survival analysis, hazard ratios, software repository health, open source software projects},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3210459.3210479,
author = {Felderer, Michael and Jeschko, Fabian},
title = {A Process for Evidence-Based Engineering of Domain-Specific Languages},
year = {2018},
isbn = {9781450364034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210459.3210479},
doi = {10.1145/3210459.3210479},
abstract = {Domain-specific languages (DSLs) are mainly designed ad-hoc and gut feeling resulting in languages that are often not well suited for their users and engineers. In this paper we develop a process for evidence-based language engineering to design domain-specific languages based on empirical evidence to support decision in language engineering. The developed process comprises an iterative execution of the phases DSL engineering, issue identification, data collection and evidence appraisal. We exemplify the concept by designing a DSL for Gherkin, a language test-driven acceptance testing in Xtext. The required evidence is derived by mining and analyzing all GitHub projects until July 1, 2017 that apply Gherkin.},
booktitle = {Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018},
pages = {169–174},
numpages = {6},
keywords = {empirical research, domain-specific languages, repository mining, evidence-based software engineering, DSL engineering},
location = {Christchurch, New Zealand},
series = {EASE'18}
}

@inproceedings{10.1145/2884781.2884836,
author = {Near, Joseph P. and Jackson, Daniel},
title = {Finding Security Bugs in Web Applications Using a Catalog of Access Control Patterns},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884836},
doi = {10.1145/2884781.2884836},
abstract = {We propose a specification-free technique for finding missing security checks in web applications using a catalog of access control patterns in which each pattern models a common access control use case. Our implementation, Space, checks that every data exposure allowed by an application's code matches an allowed exposure from a security pattern in our catalog. The only user-provided input is a mapping from application types to the types of the catalog; the rest of the process is entirely automatic. In an evaluation on the 50 most watched Ruby on Rails applications on Github, Space reported 33 possible bugs---23 previously unknown security bugs, and 10 false positives.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {947–958},
numpages = {12},
keywords = {bug finding, access control, web application security},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2441955.2441989,
author = {Choi, Joohee and Choi, Junghong and Moon, Jae Yun and Hahn, Jungpil and Kim, Jinwoo},
title = {Herding in Open Source Software Development: An Exploratory Study},
year = {2013},
isbn = {9781450313322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441955.2441989},
doi = {10.1145/2441955.2441989},
abstract = {In spite of the lack of organizational control, a large number of these self-organized groups have successfully developed high quality software in open source software projects. We examined the process through which coordinated action emerges from the collection of individual developers' choices, i.e., how bottom-up coordination occurs and argue that developer herding on a social coding platform may have a positive impact on OSSD outcomes. As an exploratory study, we analyzed the participation patterns in 10 randomly sampled OSSD projects on a social open source code foundry, Github. Based on the findings we generate theoretical propositions regarding developer herding behavior in OSSD.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work Companion},
pages = {129–134},
numpages = {6},
keywords = {open source software development, social computing, collaborative software development, coordination, collaboration},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2591062.2591091,
author = {Vasilescu, Bogdan},
title = {Human Aspects, Gamification, and Social Media in Collaborative Software Engineering},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591091},
doi = {10.1145/2591062.2591091},
abstract = { Software engineering is inherently a collaborative venture. In open-source software (OSS) development, such collaborations almost always span geographies and cultures. Because of the decentralised and self-directed nature of OSS as well as the social diversity inherent to OSS communities, the success of an OSS project depends to a large extent on the social aspects of distributed collaboration and achieving coordination over distance. The goal of this dissertation research is to raise our understanding of how human aspects (e.g., gender or cultural diversity), gamification and social media (e.g., participation in social environments such as Stack Overflow or GitHub) impact distributed collaboration in OSS. },
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {646–649},
numpages = {4},
keywords = {open source, Collaborative software engineering},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/3379597.3387450,
author = {Pietri, Antoine and Rousseau, Guillaume and Zacchiroli, Stefano},
title = {Forking Without Clicking: On How to Identify Software Repository Forks},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387450},
doi = {10.1145/3379597.3387450},
abstract = {The notion of software "fork" has been shifting over time from the (negative) phenomenon of community disagreements that result in the creation of separate development lines and ultimately software products, to the (positive) practice of using distributed version control system (VCS) repositories to collaboratively improve a single product without stepping on each others toes. In both cases the VCS repositories participating in a fork share parts of a common development history.Studies of software forks generally rely on hosting platform metadata, such as GitHub, as the source of truth for what constitutes a fork. These "forge forks" however can only identify as forks repositories that have been created on the platform, e.g., by clicking a "fork" button on the platform user interface. The increased diversity in code hosting platforms (e.g., GitLab) and the habits of significant development communities (e.g., the Linux kernel, which is not primarily hosted on any single platform) call into question the reliability of trusting code hosting platforms to identify forks. Doing so might introduce selection and methodological biases in empirical studies.In this article we explore various definitions of "software forks", trying to capture forking workflows that exist in the real world. We quantify the differences in how many repositories would be identified as forks on GitHub according to the various definitions, confirming that a significant number could be overlooked by only considering forge forks. We study the structure and size of fork networks, observing how they are affected by the proposed definitions and discuss the potential impact on empirical research.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {277–287},
numpages = {11},
keywords = {software evolution, software fork, free software, open source, source code, version control system},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3338906.3338952,
author = {Bavishi, Rohan and Yoshida, Hiroaki and Prasad, Mukul R.},
title = {Phoenix: Automated Data-Driven Synthesis of Repairs for Static Analysis Violations},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338952},
doi = {10.1145/3338906.3338952},
abstract = {Traditional automatic program repair (APR) tools rely on a test-suite as a repair specification. But test suites even when available are not of specification quality, limiting the performance and hence viability of test-suite based repair. On the other hand, static analysis-based bug finding tools are seeing increasing adoption in industry but still face challenges since the reported violations are viewed as not easily actionable. We propose a novel solution that solves both these challenges through a technique for automatically generating high-quality patches for static analysis violations by learning from examples. Our approach uses the static analyzer as an oracle and does not require a test suite. We realize our solution in a system, Phoenix, that implements a fully-automated pipeline that mines and cleans patches for static analysis violations from the wild, learns generalized executable repair strategies as programs in a novel Domain Specific Language (DSL), and then instantiates concrete repairs from them on new unseen violations. Using Phoenix we mine a corpus of 5,389 unique violations and patches from 517 Github projects. In a cross-validation study on this corpus Phoenix successfully produced 4,596 bug-fixes, with a recall of 85% and a precision of 54%. When applied to the latest revisions of a further5 Github projects, Phoenix produced 94 correct patches to previously unknown bugs, 19 of which have already been accepted and merged by the development teams. To the best of our knowledge this constitutes, by far the largest application of any automatic patch generation technology to large-scale real-world systems},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {613–624},
numpages = {12},
keywords = {programming-by-example, program synthesis, static analysis, program repair},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.5220/0005830604640471,
author = {Cruz, Guilherme A. Maldonado da and Huzita, Elisa Hatsue Moriya and Feltrim, Val\'{e}ria D.},
title = {Estimating Trust in Virtual Teams},
year = {2016},
isbn = {9789897581878},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005830604640471},
doi = {10.5220/0005830604640471},
abstract = {The advance in technology has enabled the emergence of virtual teams. In these teams, people are in different places and possibly over different time zones, making use of computer mediated communication. At the same time distribution brings benefits, there are some challenges as the difficulty to develop trust, which is essential for efficiency in these teams. In this scenario, trust information could be used to allocate members in a new team and/or, to monitor them during the project execution. In this paper we present an automatic framework for detecting trust between members of global software development teams using sentiment analysis from comments and profile data available in versioning systems. Besides the framework description, we also present its implementation for the GitHub versioning system.},
booktitle = {Proceedings of the 18th International Conference on Enterprise Information Systems},
pages = {464–471},
numpages = {8},
keywords = {Sentiment Analysis, Global Software Development., Virtual Teams, Versioning System, Trust},
location = {Rome, Italy},
series = {ICEIS 2016}
}

@inproceedings{10.1145/3368089.3417937,
author = {Molavi, Abtin and Downing, Mara and Schneider, Tommy and Bang, Lucas},
title = {MCBAT: A Practical Tool for Model Counting Constraints on Bounded Integer Arrays},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417937},
doi = {10.1145/3368089.3417937},
abstract = {Model counting procedures for data structures are crucial for advancing the field of automated quantitative program analysis. We present a tool for Model Counting for Bounded Array Theory (MCBAT). MCBAT works on quantified integer array constraints in which all arrays have a finite length. We employ reductions from the theory of arrays to uninterpreted functions and linear integer arithmetic (LIA). Once reduced to LIA, we leverage Barvinok's polynomial time integer lattice point enumeration algorithm. Finally, we present a case study demonstrating applicability to automated quantitative program analysis. MCBAT is available for immediate use as a Docker image and the source code is freely available in our Github repository.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1596–1600},
numpages = {5},
keywords = {Software and its engineering~Formal methods, Mathematics of computing~Combinatoric problems},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1109/CHASE.2019.00021,
author = {Pinheiro, Andr\'{e} M. and Rabello, Caio S. and Furtado, Leonardo B. and Pinto, Gustavo and de Souza, Cleidson R. B.},
title = {Expecting the Unexpected: Distilling Bot Development, Challenges, and Motivations},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2019.00021},
doi = {10.1109/CHASE.2019.00021},
abstract = {Software bots are becoming an increasingly popular tool in the software development landscape, which is particularly due to their potential of use in several different contexts. More importantly, software developers interested in transitioning to bot development may have to face challenges intrinsic related to bot software development. However, so far, it is still unclear what is the profile of bot developers, what motivate them, or what challenges do they face when dealing with bot development. To shed an initial light on this direction, we conducted a survey with 43 Github users who have been involved (showing their interest or actively contributing to) in bot software projects.},
booktitle = {Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {51–52},
numpages = {2},
location = {Montreal, Quebec, Canada},
series = {CHASE '19}
}

@inproceedings{10.1145/3183440.3195054,
author = {Lu, Yao and Mao, Xinjun and Wang, Tao and Yin, Gang and Li, Zude and Wang, Huaimin},
title = {Continuous Inspection in the Classroom: Improving Students' Programming Quality with Social Coding Methods},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195054},
doi = {10.1145/3183440.3195054},
abstract = {Rich research has shown that both the teaching and learning of high-quality programming are challenging and deficient in most colleges' education systems. Recently the continuous inspection paradigm has been widely used by developers on social coding sites (e.g., GitHub) as an important method to ensure the internal quality of massive code contributions. In this study we designed a specific continuous inspection process for students' collaborative projects and conducted a controlled experiment with 48 students from the same course during two school years to evaluate how the process affects their programming quality. Our results show that continuous inspection can significantly reduce the density of code quality issues introduced in the code.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {141–142},
numpages = {2},
keywords = {continuous inspection, programming quality SonarQube},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3416921.3416939,
author = {Peksa, Janis},
title = {Autonomous Data-Driven Integration Algorithm},
year = {2020},
isbn = {9781450375382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416921.3416939},
doi = {10.1145/3416921.3416939},
abstract = {In this paper, an autonomous data-driven integration algorithm is the main focus of the Autonomous Open Data Prediction Framework [1]. This paper proposes the autonomous Web Service integration into ERP systems. The paper highlights the Autonomous Open Data Prediction Framework algorithm using flowchart and UML diagrams, also pseudocode of the Kalman filter method, as well as, selection of the appropriate programming language. Described the Autonomous Open Data Prediction Framework API that all programming code is published to the GitHub repository. It is highlighting the lack of forecasting methods offered in ERP systems that have not been able to ensure all the necessary business process opportunities to increase business value.},
booktitle = {Proceedings of the 2020 4th International Conference on Cloud and Big Data Computing},
pages = {63–67},
numpages = {5},
keywords = {integration framework, autonomous algorithm, ERP systems integration, Data-driven integration},
location = {Virtual, United Kingdom},
series = {ICCBDC '20}
}

@inproceedings{10.1145/3196398.3196462,
author = {Joonbakhsh, Alireza and Sami, Ashkan},
title = {Mining and Extraction of Personal Software Process Measures through IDE Interaction Logs},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196462},
doi = {10.1145/3196398.3196462},
abstract = {The Personal Software Process (PSP) is an effective software process improvement method that heavily relies on manual collection of software development data. This paper describes a semi-automated method that reduces the burden of PSP data collection by extracting the required time and size of PSP measurements from IDE interaction logs. The tool mines enriched event data streams so can be easily generalized to other developing environment also. In addition, the proposed method is adaptable to phase definition changes and creates activity visualizations and summarizations that are helpful for software project management. Tools and processed data used for this paper are available on GitHub at: https://github.com/unknowngithubuser1/data.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {78–81},
numpages = {4},
keywords = {personal software process, IDE},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/2970276.2970285,
author = {Greene, Gillian J. and Fischer, Bernd},
title = {CVExplorer: Identifying Candidate Developers by Mining and Exploring Their Open Source Contributions},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970285},
doi = {10.1145/2970276.2970285},
abstract = { Open source code contributions contain a large amount of technical skill information about developers, which can help to identify suitable candidates for a particular development job and therefore impact the success of a development team. We develop CVExplorer as a tool to extract, visualize, and explore relevant technical skills data from GitHub, such as languages and libraries used. It allows non-technical users to filter and identify developers according to technical skills demonstrated across all of their open source contributions, in order to support more accurate candidate identification. We demonstrate the usefulness of CVExplorer by using it to recommend candidates for open positions in two companies. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {804–809},
numpages = {6},
keywords = {Mining software repositories, Developer skills identification, Identifying candidate developers},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.1145/2910674.2935858,
author = {Giannakopoulos, Theodoros and Siantikos, Georgios},
title = {A ROS Framework for Audio-Based Activity Recognition},
year = {2016},
isbn = {9781450343374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910674.2935858},
doi = {10.1145/2910674.2935858},
abstract = {Research on robot perception mostly focuses on visual information analytics. Audio-based perception is mostly based on speech-related information. However, non-verbal information of the audio channel can be equally important in the perception procedure, or at least play a complementary role. This paper presents a framework for audio signal analysis that utilizes the ROS architectural principles. Details on the design and implementation issues of this workflow are described, while classification results are also presented in the context of two use-cases motivated by the task of medical monitoring. The proposed audio analysis framework is provided as an open-source library at github (https://github.com/tyiannak/AUROS).},
booktitle = {Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {41},
numpages = {4},
keywords = {classification, open-source, feature extraction, ROS, audio analysis, audio segmentation},
location = {Corfu, Island, Greece},
series = {PETRA '16}
}

@inproceedings{10.1145/3341105.3374009,
author = {Misra, Vishal and Reddy, Jakku Sai Krupa and Chimalakonda, Sridhar},
title = {Is There a Correlation between Code Comments and Issues? An Exploratory Study},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3374009},
doi = {10.1145/3341105.3374009},
abstract = {Comments in a software code base are one of the key artifacts that help developers in understanding the code with respect to development and maintenance. Comments provide us with the information that is used as a software metric to assess the code quality and which further can be applied to demonstrate its impact on the issues in the code. In this paper, we set out to understand the correlation between code comments and issues in Github. We conduct an empirical study on 625 repositories hosted on GitHub with Python as their primary language. We manually classify comments from a randomly selected sample of python repositories and then train and evaluate classifiers to automatically label comments as Relevant or Auxiliary. We extract the metadata of issues in each repository present in our dataset and perform various experiments to understand the correlation between code comments and issues. From our dataset of python repositories, we then plot a graph between the average time taken to resolve an issue and percentage of relevant comments in a repository to find if there is any relation or a pattern by which the latter affects the former. Our statistical approach of finding out the correlation between code comments and issues gives us the correlation factor by which code comments are related to issues. We conclude from our study that comments are indeed important and play an important role in solving issues of the project. We also found that increasing the percentage of relevant comments along with the source code can help in the reduction of the average number of days before an issue is resolved.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {110–117},
numpages = {8},
keywords = {correlation, machine learning, empirical study, code comments, python repositories, issues},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3183519.3183549,
author = {Agrawal, Amritanshu and Rahman, Akond and Krishna, Rahul and Sobran, Alexander and Menzies, Tim},
title = {We Don't Need Another Hero? The Impact of "Heroes" on Software Development},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183519.3183549},
doi = {10.1145/3183519.3183549},
abstract = {A software project has "Hero Developers" when 80% of contributions are delivered by 20% of the developers. Are such heroes a good idea? Are too many heroes bad for software quality? Is it better to have more/less heroes for different kinds of projects? To answer these questions, we studied 661 open source projects from Public open source software (OSS) Github and 171 projects from an Enterprise Github.We find that hero projects are very common. In fact, as projects grow in size, nearly all projects become hero projects. These findings motivated us to look more closely at the effects of heroes on software development. Analysis shows that the frequency to close issues and bugs are not significantly affected by the presence of heroes or project type (Public or Enterprise). Similarly, the time needed to resolve an issue/bug/enhancement is not affected by heroes or project type. This is a surprising result since, before looking at the data, we expected that increasing heroes on a project will slow down how fast that project reacts to change. However, we do find a statistically significant association between heroes, project types, and enhancement resolution rates. Heroes do not affect enhancement resolution rates in Public projects. However, in Enterprise projects, heroes increase the rate at which projects complete enhancements.In summary, our empirical results call for a revision of a long-held truism in software engineering. Software heroes are far more common and valuable than suggested by the literature, particularly for medium to large Enterprise developments. Organizations should reflect on better ways to find and retain more of these heroes.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {245–253},
numpages = {9},
keywords = {productivity, github, issue, bug, commit, hero, core},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}

@inproceedings{10.1145/3240508.3266431,
author = {Wang, Qi and Lai, Jingxiang and Xu, Kai and Liu, Wenyin and Lei, Liang},
title = {Beauty Product Image Retrieval Based on Multi-Feature Fusion and Feature Aggregation},
year = {2018},
isbn = {9781450356657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240508.3266431},
doi = {10.1145/3240508.3266431},
abstract = {We propose a beauty product image retrieval method based on multi-feature fusion and feature aggregation. The key idea is representing the image with the feature vector obtained by multi-feature fusion and feature aggregation. VGG16 and ResNet50 are chosen to extract image features, and Crow is adopted to perform deep feature aggregation. Benefited from the idea of transfer learning, we fine turn VGG16 on the Perfect-500K data set to improve the performance of image retrieval. The proposed method won the third price in Perfect Corp. Challenge 2018 with the best result 0.270676 mAP. We released our code on GitHub: https://github.com/wangqi12332155/ACMMM-beauty-AI-challenge.},
booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
pages = {2063–2067},
numpages = {5},
keywords = {feature aggregation, multi-feature fusion, image retrieval},
location = {Seoul, Republic of Korea},
series = {MM '18}
}

@inproceedings{10.1145/3127005.3127008,
author = {Coppola, Riccardo and Morisio, Maurizio and Torchiano, Marco},
title = {Scripted GUI Testing of Android Apps: A Study on Diffusion, Evolution and Fragility},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127008},
doi = {10.1145/3127005.3127008},
abstract = {Background. Evidence suggests that mobile applications are not thoroughly tested as their desktop counterparts. In particular GUI testing is generally limited. Like web-based applications, mobile apps suffer from GUI test fragility, i.e. GUI test classes failing due to minor modifications in the GUI, without the application functionalities being altered.Aims. The objective of our study is to examine the diffusion of GUI testing on Android, and the amount of changes required to keep test classes up to date, and in particular the changes due to GUI test fragility. We define metrics to characterize the modifications and evolution of test classes and test methods, and proxies to estimate fragility-induced changes.Method. To perform our experiments, we selected six widely used open-source tools for scripted GUI testing of mobile applications previously described in the literature. We have mined the repositories on GitHub that used those tools, and computed our set of metrics.Results. We found that none of the considered GUI testing frameworks achieved a major diffusion among the open-source Android projects available on GitHub. For projects with GUI tests, we found that test suites have to be modified often, specifically 5%--10% of developers' modified LOCs belong to tests, and that a relevant portion (60% on average) of such modifications are induced by fragility.Conclusions. Fragility of GUI test classes constitute a relevant concern, possibly being an obstacle for developers to adopt automated scripted GUI tests. This first evaluation and measure of fragility of Android scripted GUI testing can constitute a benchmark for developers, and the basis for the definition of a taxonomy of fragility causes, and actionable guidelines to mitigate the issue.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {22–32},
numpages = {11},
keywords = {Software Maintenance, Mobile Development, Automated Software Testing, Software Evolution, GUI Testing},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.5555/2878453.2878568,
author = {Faria, Daniel and Pesquita, Catia and Santos, Emanuel and Cruz, Isabel F. and Couto, Francisco M.},
title = {AgreementMakerLight 2.0: Towards Efficient Large-Scale Ontology Matching},
year = {2014},
publisher = {CEUR-WS.org},
address = {Aachen, DEU},
abstract = {Ontology matching is a critical task to realize the Semantic Web vision, by enabling interoperability between ontologies. However, handling large ontologies efficiently is a challenge, given that ontology matching is a problem of quadratic complexity.AgreementMakerLight (AML) is a scalable automated ontology matching system developed to tackle large ontology matching problems, particularly for the life sciences domain. Its new 2.0 release includes several novel features, including an innovative algorithm for automatic selection of background knowledge sources, and an updated repair algorithm that is both more complete and more efficient.AML is an open source system, and is available through GitHub both for developers (as an Eclipse project) and end-users (as a runnable Jar with a graphical user interface).},
booktitle = {Proceedings of the 2014 International Conference on Posters &amp; Demonstrations Track - Volume 1272},
pages = {457–460},
numpages = {4},
location = {Riva del Garda, Italy},
series = {ISWC-PD'14}
}

@inproceedings{10.1109/NOMS47738.2020.9110350,
author = {Hauser, Frederik and Menth, Michael},
title = {Demo: Execution and Access Control for Restricted Application Containers on Managed Hosts (XRAC)},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/NOMS47738.2020.9110350},
doi = {10.1109/NOMS47738.2020.9110350},
abstract = {Restricted application containers (RACs) encapsulate applications with their dependencies and configuration for execution on a hypervisor host. xRAC [1] is a novel approach for execution control and network access control (NAC). That is, a RAC can be executed only after successful authentication and authorization (AA) and obtain limited access to network resources. A RAC has a unique IPv6 address so that its traffic is identifiable and controllable by network components. For AA, xRAC adopts and extends components and procedures of 802.1X. We publish its source code and a testbed setup guide on GitHub [2]. In this paper, we give a brief overview on the architecture and functionality of xRAC, describe the prototypical implementation, a testbed, and four demo scenarios.},
booktitle = {NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium},
pages = {1–2},
numpages = {2},
location = {Budapest, Hungary}
}

@inproceedings{10.1145/2872518.2891112,
author = {Steiner, Thomas},
title = {Wikipedia Tools for Google Spreadsheets},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2891112},
doi = {10.1145/2872518.2891112},
abstract = {In this paper, we introduce the Wikipedia Tools for Google Spreadsheets. Google Spreadsheets is part of a free, Web-based software office suite offered by Google within its Google Docs service. It allows users to create and edit spreadsheets online, while collaborating with other users in realtime. Wikipedia is a free-access, free-content Internet encyclopedia, whose content and data is available, among other means, through an API. With the Wikipedia Tools for Google Spreadsheets, we have created a toolkit that facilitates working with Wikipedia data from within a spreadsheet context. We make these tools available as open-source on GitHub [https://github.com/tomayac/wikipedia-tools-for-google-spreadsheets], released under the permissive Apache 2.0 license.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {997–1000},
numpages = {4},
keywords = {google spreadsheets, wikidata, google sheets, wikipedia},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@inproceedings{10.1109/ASE.2015.34,
author = {Greene, Gillian J.},
title = {A Generic Framework for Concept-Based Exploration of Semi-Structured Software Engineering Data},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.34},
doi = {10.1109/ASE.2015.34},
abstract = {Software engineering meta-data (SE data), such as revision control data, Github project data or test reports, is typically semi-structured; it comprises a mixture of formatted and free-text fields and is often self-describing. Semi-structured SE data cannot be queried in a SQL-like manner because of its lack of structure. Consequently, there are a variety of customized tools built to analyze specific datasets but these do not generalize. We propose to develop a generic framework for exploration and querying of semi-structured SE data. Our approach investigates the use of a formal concept lattice as a universal data structure and a tag cloud as an intuitive interface to support data exploration.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {894–897},
numpages = {4},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@inproceedings{10.1145/3417990.3420057,
author = {Moin, Armin and R\"{o}ssler, Stephan and Sayih, Marouane and G\"{u}nnemann, Stephan},
title = {From Things' Modeling Language (ThingML) to Things' Machine Learning (ThingML2)},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420057},
doi = {10.1145/3417990.3420057},
abstract = {In this paper, we illustrate how to enhance an existing state-of-the-art modeling language and tool for the Internet of Things (IoT), called ThingML, to support machine learning on the modeling level. To this aim, we extend the Domain-Specific Language (DSL) of ThingML, as well as its code generation framework. Our DSL allows one to define things, which are in charge of carrying out data analytics. Further, our code generators can automatically produce the complete implementation in Java and Python. The generated Python code is responsible for data analytics and employs APIs of machine learning libraries, such as Keras, Tensorflow and Scikit Learn. Our prototype is available as open source software on Github.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {19},
numpages = {2},
keywords = {internet of things, machine learning, domain-specific modeling},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3328778.3372599,
author = {Wagner, Paul J.},
title = {The SQL File Evaluation (SQLFE) Tool: A Flexible and Extendible System for Evaluation of SQL Queries},
year = {2020},
isbn = {9781450367936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328778.3372599},
doi = {10.1145/3328778.3372599},
abstract = {The SQL File Evaluation (SQLFE) tool is a GUI-based, flexible, and extendible software system for evaluating the correctness of files of student SQL queries as compared to specified SQL query answers. SQLFE can be configured per question to weight any of over 30 different tests in judging correctness of a submitted answer for a particular question. These tests include successful DBMS interpretation of the query, same result set (as specified answer), the use count of particular keywords, simple formatting style, and partial credit based on simple structural format. SQLFE currently works for databases constructed under Oracle and MySQL database management systems (DBMSs), and can be extended to more DBMSs. SQLFE is available from GitHub.},
booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},
pages = {1334},
numpages = {1},
keywords = {database systems, evaluation, auto-grading, sql},
location = {Portland, OR, USA},
series = {SIGCSE '20}
}

@inproceedings{10.1145/3340555.3353744,
author = {Aneja, Deepali and McDuff, Daniel and Shah, Shital},
title = {A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities},
year = {2019},
isbn = {9781450368605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340555.3353744},
doi = {10.1145/3340555.3353744},
abstract = {Embodied avatars as virtual agents have many applications and provide benefits over disembodied agents, allowing nonverbal social and interactional cues to be leveraged, in a similar manner to how humans interact with each other. We present an open embodied avatar built upon the Unreal Engine that can be controlled via a simple python programming interface. The avatar has lip syncing (phoneme control), head gesture and facial expression (using either facial action units or cardinal emotion categories) capabilities. We release code and models to illustrate how the avatar can be controlled like a puppet or used to create a simple conversational agent using public application programming interfaces (APIs). GITHUB link: https://github.com/danmcduff/AvatarSim },
booktitle = {2019 International Conference on Multimodal Interaction},
pages = {69–73},
numpages = {5},
keywords = {avatars, conversational systems, embodied agents, multimodality, expression retargeting.},
location = {Suzhou, China},
series = {ICMI '19}
}

@inproceedings{10.1145/3338906.3342486,
author = {Abid, Shamsa},
title = {Recommending Related Functions from API Usage-Based Function Clone Structures},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3342486},
doi = {10.1145/3338906.3342486},
abstract = {Developers need to be able to find reusable code for desired software features in a way that supports opportunistic programming for increased developer productivity. Our objective is to develop a recommendation system that provides a developer with function recommendations having functionality relevant to her development task. We employ a combination of information retrieval, static code analysis and data mining techniques to build the proposed recommendation system called FACER (Feature-driven API usage-based Code Examples Recommender). We performed an experimental evaluation on 122 projects from GitHub from selected categories to determine the accuracy of the retrieved code for related features. FACER recommended functions with a precision of 54% and 75% when evaluated using automated and manual methods respectively.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1193–1195},
numpages = {3},
keywords = {software features, API usage, code recommendation, code clones},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1109/MSR.2019.00076,
author = {Hayashi, Junichi and Higo, Yoshiki and Matsumoto, Shinsuke and Kusumoto, Shinji},
title = {Impacts of Daylight Saving Time on Software Development},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00076},
doi = {10.1109/MSR.2019.00076},
abstract = {Daylight saving time (DST) is observed in many countries and regions. DST is not considered on some software systems at the beginning of their developments, for example, software systems developed in regions where DST is not observed. However, such systems may have to consider DST at the requests of their users. Before now, there has been no study about the impacts of DST on software development. In this paper, we study the impacts of DST on software development by mining the repositories on GitHub. We analyze the date when the code related to DST is changed, and we analyze the regions where the developers applied the changes live. Furthermore, we classify the changes into some patterns.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {502–506},
numpages = {5},
keywords = {code change analysis, daylight saving time, geographical analysis},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2538862.2539011,
author = {Wilson, Greg and Perez, Fernando and Norvig, Peter},
title = {Teaching Computing with the IPython Notebook (Abstract Only)},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2539011},
doi = {10.1145/2538862.2539011},
abstract = {The IPython Notebook is an interactive browser-based environment where you can combine code execution, text, mathematics, plots, and rich media into a single document. Originally designed for use as an electronic lab notebook for computational science, it is increasingly being used in teaching as well, and a rich ecosystem of open source plugins and extensions for teaching is growing around it. The first half of this hands-on workshop will introduce the Notebook and present examples of lessons and instructional materials built around it. In the second half, attendees will explore future directions for the Notebook as a teaching platform. For more information, please view our GitHub repository online at https://github.com/gvwilson/sigcse2014-ipython-workshop.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {740},
numpages = {1},
keywords = {electronic lab notebook, python, pedagogy},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@inproceedings{10.1145/2491055.2491081,
author = {Choi, Junghong and Ferwerda, Bruce and Hahn, Jungpil and Kim, Jinwoo and Moon, Jae Yun},
title = {Impact of Social Features Implemented in Open Collaboration Platforms on Volunteer Self-Organization: Case Study of Open Source Software Development},
year = {2013},
isbn = {9781450318525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491055.2491081},
doi = {10.1145/2491055.2491081},
abstract = {The promise of collective intelligence emerging from voluntary participation, contribution and knowledge sharing brought about by ubiquitous information and communication technologies has recently attracted the attention of academics and practitioners alike. Of many related phenomena, open source software (OSS) development has been touted as one of the leading examples that speak to the potential of collective intelligence. Recently, the advent of novel open collaboration platforms for open source software development, such as Github, has prompted researchers to examine the impact of increased work transparency induced by the introduction of social features on voluntary self-organization and allocation of resources to projects. We present both qualitative and quantitative analyses from which we derive some initial propositions regarding the impact of transparency on voluntary self-organization processes and decision mechanisms.},
booktitle = {Proceedings of the 9th International Symposium on Open Collaboration},
articleno = {25},
numpages = {2},
keywords = {open source software development, information overload, social computing, social coding, github, transparency},
location = {Hong Kong, China},
series = {WikiSym '13}
}

@inproceedings{10.1145/3366424.3382692,
author = {Argyriou, Andreas and Gonz\'{a}lez-Fierro, Miguel and Zhang, Le},
title = {Microsoft Recommenders: Best Practices for Production-Ready Recommendation Systems},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3382692},
doi = {10.1145/3366424.3382692},
abstract = {Recommendation algorithms have been widely applied in various contemporary business areas, however the process of implementing them in production systems is complex and has to address significant challenges. We present Microsoft Recommenders, an open-source Github repository for helping researchers, developers and non-experts in general to prototype, experiment with and bring to production both classic and state-of-the-art recommendation algorithms. A focus of this repository is on best practices in development of recommendation systems. We have also incorporated learnings from our experience with recommendation systems in production, in order to enhance ease of use; speed of implementation and deployment; scalability and performance.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {50–51},
numpages = {2},
keywords = {Algorithms, Libraries, Recommender systems},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1109/MSR.2019.00024,
author = {Raghuraman, Adithya and Ho-Quang, Truong and Chaudron, Michel R. V. and Serebrenik, Alexander and Vasilescu, Bogdan},
title = {Does UML Modeling Associate with Lower Defect Proneness? A Preliminary Empirical Investigation},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00024},
doi = {10.1109/MSR.2019.00024},
abstract = {The benefits of modeling the design to improve the quality and maintainability of software systems have long been advocated and recognized. Yet, the empirical evidence on this remains scarce. In this paper, we fill this gap by reporting on an empirical study of the relationship between UML modeling and software defect proneness in a large sample of open-source GitHub projects. Using statistical modeling, and controlling for confounding variables, we show that projects containing traces of UML models in their repositories experience, on average, a statistically minorly different number of software defects (as mined from their issue trackers) than projects without traces of UML models.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {101–104},
numpages = {4},
keywords = {UML, software design, open-source-software, software quality},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3194124.3194129,
author = {Katsuragawa, Daiki and Ihara, Akinori and Kula, Raula Gaikovina and Matsumoto, Kenichi},
title = {Maintaining Third-Party Libraries through Domain-Specific Category Recommendations},
year = {2018},
isbn = {9781450357302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194124.3194129},
doi = {10.1145/3194124.3194129},
abstract = {Proper maintenance of third-party libraries contributes toward sustaining a healthy project, mitigating the risk it becoming outdated and obsolete. In this paper, we propose domain-specific categories (i.e., grouping of libraries that perform similar functionality) in library recommendations that aids in library maintenance. Our empirical study covers 2,511 GitHub projects and 150 domain-specific categories of Java libraries. Our results show that a system uses up to six different categories in their dependencies. Furthermore, recommending domain-specific categories is practical (i.e., with an accuracy between 66% to 81% for multiple categories) and its suggestion of libraries within that domain is comparable to existing techniques.},
booktitle = {Proceedings of the 1st International Workshop on Software Health},
pages = {2–9},
numpages = {8},
location = {Gothenburg, Sweden},
series = {SoHeal '18}
}

@inproceedings{10.1109/ICSM.2015.7332478,
author = {Hora, Andre and Valente, Marco Tulio},
title = {Apiwave: Keeping Track of API Popularity and Migration},
year = {2015},
isbn = {9781467375320},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSM.2015.7332478},
doi = {10.1109/ICSM.2015.7332478},
abstract = {Every day new frameworks and libraries are created and existing ones evolve. To benefit from such newer or improved APIs, client developers should update their applications. In practice, this process presents some challenges: APIs are commonly backward-incompatible (causing client applications to fail when updating) and multiple APIs are available (making it difficult to decide which one to use). To address these challenges, we propose apiwave, a tool that keeps track of API popularity and migration of major frameworks/libraries. The current version includes data about the evolution of top 650 GitHub Java projects, from which 320K APIs were extracted. We also report an experience using apiwave on real-world scenarios.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
pages = {321–323},
numpages = {3},
series = {ICSME '15}
}

@inproceedings{10.1145/3372787.3390442,
author = {Constantino, Kattiana and Zhou, Shurui and Souza, Mauricio and Figueiredo, Eduardo and K\"{a}stner, Christian},
title = {Understanding Collaborative Software Development: An Interview Study},
year = {2020},
isbn = {9781450370936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372787.3390442},
doi = {10.1145/3372787.3390442},
abstract = {In globally distributed software development, many software developers have to collaborate and deal with issues of collaboration. Although collaboration is challenging, collaborative development produces better software than any developer could produce alone. Unlike previous work which focuses on the proposal and evaluation of models and tools to support collaborative work, this paper presents an interview study aiming to understand (i) the motivations, (ii) how collaboration happens, and (iii) the challenges and barriers of collaborative software development. After interviewing twelve experienced software developers from GitHub, we found different types of collaborative contributions, such as in the management of requests for changes. Our analysis also indicates that the main barriers for collaboration are related to non-technical, rather than technical issues.},
booktitle = {Proceedings of the 15th International Conference on Global Software Engineering},
pages = {55–65},
numpages = {11},
keywords = {fork-based development, open source software projects, collaboration in software development, sustained developer community participation, distributed collaboration},
location = {Seoul, Republic of Korea},
series = {ICGSE '20}
}

@inproceedings{10.1145/3329715.3338880,
author = {Ring, Dan and Barbier, Johanna and Gales, Guillaume and Kent, Ben and Lutz, Sebastian},
title = {Jumping in at the Deep End: How to Experiment with Machine Learning in Post-Production Software},
year = {2019},
isbn = {9781450367998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3329715.3338880},
doi = {10.1145/3329715.3338880},
abstract = {Recent years has seen an explosion in Machine Learning (ML) research. The challenge is now to transfer these new algorithms into the hands of artists and TD's in visual effects and animation studios, so that they can start experimenting with ML within their existing pipelines. This paper presents some of the current challenges to experimentation and deployment of ML frameworks in the post-production industry. It introduces our open-source "ML-Server" client / server system as an answer to enabling rapid prototyping, experimentation and development of ML models in post-production software. Data, code and examples for the system can be found on the GitHub repository page:https://github.com/TheFoundryVisionmongers/nuke-ML-server},
booktitle = {Proceedings of the 2019 Digital Production Symposium},
articleno = {6},
numpages = {5},
keywords = {machine learning, deployment, visual computing, frameworks, image processing, integration, computer vision, deep learning},
location = {Los Angeles, California},
series = {DigiPro '19}
}

@inproceedings{10.1145/2901739.2901748,
author = {Bao, Lingfeng and Lo, David and Xia, Xin and Wang, Xinyu and Tian, Cong},
title = {How Android App Developers Manage Power Consumption? An Empirical Study by Mining Power Management Commits},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2901748},
doi = {10.1145/2901739.2901748},
abstract = {As Android platform becomes more and more popular, a large amount of Android applications have been developed. When developers design and implement Android applications, power consumption management is an important factor to consider since it affects the usability of the applications. Thus, it is important to help developers adopt proper strategies to manage power consumption. Interestingly, today, there is a large number of Android application repositories made publicly available in sites such as GitHub. These repositories can be mined to help crystalize common power management activities that developers do. These in turn can be used to help other developers to perform similar tasks to improve their own Android applications.In this paper, we present an empirical study of power management commits in Android applications. Our study extends that of Moura et al. who perform an empirical study on energy aware commits; however they do not focus on Android applications and only a few of the commits that they study come from Android applications. Android applications are often different from other applications (e.g., those running on a server) due to the issue of limited battery life and the use of specialized APIs. As subjects of our empirical study, we obtain a list of open source Android applications from F-Droid and crawl their commits from Github. We get 468 power management commits after we filter the commits using a set of keywords and by performing manual analysis. These 468 power management commits are from 154 different Android applications and belong to 15 different application categories. Furthermore, we use open card sort to categorize these power management commits and we obtain 6 groups which correspond to different power management activities. Our study also reveals that for different kinds of Android application (e.g., Games, Connectivity, Navigation, Internet, Phone &amp; SMS, Time, etc.), the dominant power management activities differ. For example, the percentage of power management commits belonging to Power Adaptation activity is larger for Navigation applications than those belonging to other categories.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {37–48},
numpages = {12},
keywords = {power consumption, power management, empirical study, mining software repository},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1109/ASE.2019.00158,
author = {Neupane, Krishna Prasad},
title = {An Approach for Investigating Emotion Dynamics in Software Development},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00158},
doi = {10.1109/ASE.2019.00158},
abstract = {Emotion awareness is critical to interpersonal communication, including that in software development. The SE community has studied emotion in software development using isolated emotion states but it has not considered the dynamic nature of emotion. To investigate the emotion dynamics, SE community needs an effective approach. In this paper, we propose such an approach which can automatically collect project teams' communication records, identify the emotions and their intensities in them, model the emotion dynamics into time series, and provide efficient data management. We demonstrate that this approach can provide end-to-end support for various emotion awareness research and practices through automated data collection, modeling, storage, analysis, and presentation using the IPython's project data on GitHub.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1268–1270},
numpages = {3},
keywords = {software development, emotion dynamics, time-series database, emotion intensity, emotion awareness},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3195836.3195848,
author = {Coelho, Jailton and Valente, Marco Tulio and Silva, Luciana L. and Hora, Andr\'{e}},
title = {Why We Engage in FLOSS: Answers from Core Developers},
year = {2018},
isbn = {9781450357258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195836.3195848},
doi = {10.1145/3195836.3195848},
abstract = {The maintenance and evolution of Free/Libre Open Source Software (FLOSS) projects demand the constant attraction of core developers. In this paper, we report the results of a survey with 52 developers, who recently became core contributors of popular GitHub projects. We reveal their motivations to assume a key role in FLOSS projects (e.g., improving the projects because they are also using it), the project characteristics that most helped in their engagement process (e.g., a friendly community), and the barriers faced by the surveyed core developers (e.g., lack of time of the project leaders). We also compare our results with related studies about others kinds of open source contributors (casual, one-time, and newcomers).},
booktitle = {Proceedings of the 11th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {114–121},
numpages = {8},
keywords = {github, open source software, core developers},
location = {Gothenburg, Sweden},
series = {CHASE '18}
}

@inproceedings{10.1145/2804381.2804387,
author = {Novielli, Nicole and Calefato, Fabio and Lanubile, Filippo},
title = {The Challenges of Sentiment Detection in the Social Programmer Ecosystem},
year = {2015},
isbn = {9781450338189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804381.2804387},
doi = {10.1145/2804381.2804387},
abstract = { A recent research trend has emerged to study the role of affect in in the social programmer ecosystem, by applying sentiment analysis to the content available in sites such as GitHub and Stack Overflow. In this paper, we aim at assessing the suitability of a state-of-the-art sentiment analysis tool, already applied in social computing, for detecting affective expressions in Stack Overflow. We also aim at verifying the construct validity of choosing sentiment polarity and strength as an appropriate way to operationalize affective states in empirical studies on Stack Overflow. Finally, we underline the need to overcome the limitations induced by domain-dependent use of lexicon that may produce unreliable results. },
booktitle = {Proceedings of the 7th International Workshop on Social Software Engineering},
pages = {33–40},
numpages = {8},
keywords = {Sentiment Analysis, Stack Overflow, Online Q&amp;A, Social Programmer, Technical Forum, Social Software Engineering},
location = {Bergamo, Italy},
series = {SSE 2015}
}

@inproceedings{10.1145/3368089.3409735,
author = {Wang, Jiawei and Li, Li and Liu, Kui and Cai, Haipeng},
title = {Exploring How Deprecated Python Library APIs Are (Not) Handled},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409735},
doi = {10.1145/3368089.3409735},
abstract = {In this paper, we present the first exploratory study of deprecated Python library APIs to understand the status quo of API deprecation in the realm of Python libraries. Specifically, we aim to comprehend how deprecated library APIs are declared and documented in practice by their maintainers, and how library users react to them. By thoroughly looking into six reputed Python libraries and 1,200 GitHub projects, we experimentally observe that API deprecation is poorly handled by library contributors, which subsequently introduce difficulties for Python developers to resolve the usage of deprecated library APIs. This empirical evidence suggests that our community should take immediate actions to appropriately handle the deprecation of Python library APIs.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {233–244},
numpages = {12},
keywords = {Deprecation, Evolution, Deprecated API, Python library},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.5555/3306127.3332031,
author = {Menashe, Jacob and Stone, Peter},
title = {Escape Room: A Configurable Testbed for Hierarchical Reinforcement Learning},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Recent successes in Reinforcement Learning have encouraged a fast growing network of RL researchers and a number of breakthroughs in RL research. As the RL community and body of work grows, so does the need for widely applicable benchmarks that can fairly and effectively evaluate a variety of RL algorithms. In this paper we present the Escape Room Domain (ERD), a new flexible, scalable, and fully implemented testing domain for Hierarchical RL that bridges the "moderate complexity" gap left behind by existing alternatives. ERD is open-source and freely available through GitHub, and conforms to widely-used public testing interfaces for simple integration and testing with a variety of public RL agent implementations.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2123–2125},
numpages = {3},
keywords = {platforms, reinforcement learning, simulation techniques, tools},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.5555/3432601.3432616,
author = {Podolskiy, Vladimir and Patrou, Maria and Patros, Panos and Gerndt, Michael and Kent, Kenneth B.},
title = {The Weakest Link: Revealing and Modeling the Architectural Patterns of Microservice Applications},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud microservice applications comprise interconnected services packed into containers. Such applications generate complex communication patterns among their microservices. Studying such patterns can support assuring various quality attributes, such as autoscaling for satisfying performance, availability and scalability, or targeted penetration testing for satisfying security and correctness. We study the structure of containerized microservice applications via providing the methodology and the results of a structural graph-based analysis of 103 Docker Compose deployment files from open-sourced Github repositories. Our findings indicate the dominance of a power-law distribution of microservice interconnections. Further analysis highlights the suitability of the Barab\'{a}si-Albert model for generating large random graphs that model the architecture of real microservice applications. The exhibited structures and their usage for engineering microservice applications are discussed.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {113–122},
numpages = {10},
keywords = {software vulnerability, cloud-native application, microservice, application topology},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@inproceedings{10.1145/2597073.2597132,
author = {Williams, James R. and Di Ruscio, Davide and Matragkas, Nicholas and Di Rocco, Juri and Kolovos, Dimitris S.},
title = {Models of OSS Project Meta-Information: A Dataset of Three Forges},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597132},
doi = {10.1145/2597073.2597132},
abstract = { The process of selecting open-source software (OSS) for adoption is not straightforward as it involves exploring various sources of information to determine the quality, maturity, activity, and user support of each project. In the context of the OSSMETER project, we have developed a forge-agnostic metamodel that captures the meta-information common to all OSS projects. We specialise this metamodel for popular OSS forges in order to capture forge-specific meta-information. In this paper we present a dataset conforming to these metamodels for over 500,000 OSS projects hosted on three popular OSS forges: Eclipse, SourceForge, and GitHub. The dataset enables different kinds of automatic analysis and supports objective comparisons of cross-forge OSS alternatives with respect to a user's needs and quality requirements. },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {408–411},
numpages = {4},
keywords = {Data mining},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/3183440.3183491,
author = {Li, Yi and Zhu, Chenguang and Rubin, Julia and Chechik, Marsha},
title = {CSlicerCloud: A Web-Based Semantic History Slicing Framework},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183491},
doi = {10.1145/3183440.3183491},
abstract = {Traditional commit-based sequential organization of software version histories is insufficient for many development tasks which require high-level, semantic understanding of program functionality, such as porting features or cutting new releases. Semantic history slicing is a technique which uses well-organized unit tests as identifiers for corresponding software functionalities and extracts a set of commits that correspond to a specific high-level functionality. In this paper, we present CSlicerCloud, a Web-based semantic history slicing service tailored for Java projects hosted on GitHub. It is accessible through Web browsers and powered in the backend by a collection of history slicing techniques underneath. We evaluated CSlicerCloud on a dataset containing developer-annotated change histories collected from 10 open source software projects. A video demonstration which showcases the main features of CSlicerCloud can be found at https://youtu.be/7kcswA0bQzo.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {57–60},
numpages = {4},
keywords = {version histories, program semantics, software evolution},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3338906.3338922,
author = {Widder, David Gray and Hilton, Michael and K\"{a}stner, Christian and Vasilescu, Bogdan},
title = {A Conceptual Replication of Continuous Integration Pain Points in the Context of Travis CI},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338922},
doi = {10.1145/3338906.3338922},
abstract = {Continuous integration (CI) is an established software quality assurance practice, and the focus of much prior research with a diverse range of methods and populations. In this paper, we first conduct a literature review of 37 papers on CI pain points. We then conduct a conceptual replication study on results from these papers using a triangulation design consisting of a survey with 132 responses, 12 interviews, and two logistic regressions predicting Travis CI abandonment and switching on a dataset of 6,239 GitHub projects. We report and discuss which past results we were able to replicate, those for which we found conflicting evidence, those for which we did not find evidence, and the implications of these findings.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {647–658},
numpages = {12},
keywords = {open source software, Continuous integration, replication},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1109/ASE.2019.00082,
author = {K\"{o}hler, Mirko and Salvaneschi, Guido},
title = {Automated Refactoring to Reactive Programming},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00082},
doi = {10.1109/ASE.2019.00082},
abstract = {Reactive programming languages and libraries, such as ReactiveX, have been shown to significantly improve software design and have seen important industrial adoption over the last years. Asynchronous applications - which are notoriously error-prone to implement and to maintain - greatly benefit from reactive programming because they can be defined in a declarative style, which improves code clarity and extensibility.In this paper, we tackle the problem of refactoring existing software that has been designed with traditional abstractions for asynchronous programming. We propose 2Rx, a refactoring approach to automatically convert asynchronous code to reactive programming. Our evaluation on top-starred GitHub projects shows that 2Rx is effective with common asynchronous constructs and it can provide a refactoring for 91.7% of their occurrences.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {835–846},
numpages = {12},
keywords = {refactoring, reactive programming, asynchronous programming, Java},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1109/MSR.2019.00032,
author = {Kolovos, Dimitris and Neubauer, Patrick and Barmpis, Konstantinos and Matragkas, Nicholas and Paige, Richard},
title = {Crossflow: A Framework for Distributed Mining of Software Repositories},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00032},
doi = {10.1109/MSR.2019.00032},
abstract = {Large-scale software repository mining typically requires substantial storage and computational resources, and often involves a large number of calls to (rate-limited) APIs such as those of GitHub and StackOverflow. This creates a growing need for distributed execution of repository mining programs to which remote collaborators can contribute computational and storage resources, as well as API quotas (ideally without sharing API access tokens or credentials). In this paper we introduce CROSSFLOW, a novel framework for building distributed repository mining programs. We demonstrate how CROSSFLOW can delegate mining jobs to remote workers and cache their results, and how workers can implement advanced behaviour such as load balancing and rejecting jobs they cannot perform (e.g. due to lack of space, credentials for a specific API).},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {155–159},
numpages = {5},
keywords = {open source software, distributed processing, modeling, data integration, public domain software, software engineering, scalability, computer aided software engineering, data flow computing, data collection, data analysis, pipeline processing, client-server systems},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3211933.3211934,
author = {Kr\'{o}l, Micha\l{} and Re\~{n}\'{e}, Sergi and Ascigil, Onur and Psaras, Ioannis},
title = {ChainSoft: Collaborative Software Development Using Smart Contracts},
year = {2018},
isbn = {9781450358385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3211933.3211934},
doi = {10.1145/3211933.3211934},
abstract = {In recent years, more and more companies require dedicated software to increase the efficiency of their business. However, with rapidly changing technologies it is often inefficient to maintain a dedicated team of developers. On the other hand, outsourcing software development requires considerable effort and trust between involved parties to ensure the quality of the code and adequate payment.We present ChainSoft - a platform for outsourcing software development and automatic payments between parties that distrust each other, by means of blockchain technology. ChainSoft allows any developer to create software and submit software, includes automatic code verification and enforce users' proper behavior. We implement our system using Ethereum Smart Contracts and Github/Travis CI and present first evaluation proving its security and low usage cost.},
booktitle = {Proceedings of the 1st Workshop on Cryptocurrencies and Blockchains for Distributed Systems},
pages = {1–6},
numpages = {6},
keywords = {blockchain, github, smart contracts, software development},
location = {Munich, Germany},
series = {CryBlock'18}
}

@inproceedings{10.1145/3194793.3194796,
author = {Treude, Christoph and Aniche, Maur\'{\i}cio},
title = {Where Does Google Find API Documentation?},
year = {2018},
isbn = {9781450357548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194793.3194796},
doi = {10.1145/3194793.3194796},
abstract = {The documentation of popular APIs is spread across many formats, from vendor-curated reference documentation to Stack Overflow threads. For developers, it is often not obvious from where a particular piece of information can be retrieved. To understand this documentation landscape, we systematically conducted Google searches for the elements of ten popular APIs. We found that their documentation is widely dispersed among many sources, that GitHub and Stack Overflow play a prominent role among the search results, and that most sources are quick to document new API functionalities. These findings inform API vendors about where developers find documentation about their products, they inform developers about places to look for documentation, and they enable researchers to further study the software documentation landscape.},
booktitle = {Proceedings of the 2nd International Workshop on API Usage and Evolution},
pages = {19–22},
numpages = {4},
location = {Gothenburg, Sweden},
series = {WAPI '18}
}

@inproceedings{10.5555/2487085.2487153,
author = {Vasilescu, Bogdan and Serebrenik, Alexander and Mens, Tom},
title = {A Historical Dataset of Software Engineering Conferences},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
abstract = { The Mining Software Repositories community typically focuses on data from software configuration management tools, mailing lists, and bug tracking repositories to uncover interesting and actionable information about the evolution of software systems. However, the techniques employed and the challenges faced when mining are not restricted to these types of repositories. In this paper, we present an atypical dataset of software engineering conferences, containing historical data about the accepted papers and the composition of programme committees for eleven well-established conferences. The dataset (published on Github at https://github.com/tue-mdse/conferenceMetrics) can be used, e.g., by conference steering committees or programme committee chairs to assess their selection process and compare against other conferences in the field, or by prospective authors to decide in which conferences to publish. },
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {373–376},
numpages = {4},
location = {San Francisco, CA, USA},
series = {MSR '13}
}

@inproceedings{10.5555/2457524.2457690,
author = {Loyola, Pablo and Ko, In-Young},
title = {Biological Mutualistic Models Applied to Study Open Source Software Development},
year = {2012},
isbn = {9780769548807},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {The evolution of the Web has allowed the generation of several platforms for collaborative work. One of the main contributors to these advances is the Open Source initiative, in which projects are boosted to a new level of interaction and cooperation that improves their software quality and reliability. In order to understand how the group of contributors interacts with the software under development, we propose a novel methodology that adapts Lotka-Volterra-based biological models used for host-parasite interaction. In that sense, we used the concept mutualism from social parasites. Preliminary results based on experiments on the Github collaborative platform showed that Open Source phenomena can be modeled as a mutualistic system, in terms of the evolution of the population of developers and repositories.},
booktitle = {Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology - Volume 01},
pages = {248–253},
numpages = {6},
keywords = {web-based collaborative work, population models, open source software development},
series = {WI-IAT '12}
}

@inproceedings{10.1145/3183440.3183486,
author = {Golagha, Mojdeh and Raisuddin, Abu Mohammed and Mittag, Lennart and Hellhake, Dominik and Pretschner, Alexander},
title = {Aletheia: A Failure Diagnosis Toolchain},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183486},
doi = {10.1145/3183440.3183486},
abstract = {Testing and debugging are time-consuming, tedious and costly. As many automated test generation tools are being applied in practice nowadays, there is a growing need for automated failure diagnosis. We introduce Aletheia, a failure diagnosis toolchain, which aims to help developers and testers reduce failure analysis time. The key ideas include: data generation to provide the relevant data for further analysis, failure clustering to group failing tests based on the hypothesized faults, and fault localization to pinpoint suspicious elements of the code. We evaluated Aletheia in a large-scale industrial case study as well as two open-source projects. Aletheia is released as an open-source tool on Github, and a demo video can be found at: https://youtu.be/BP9D68D02ZI},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {13–16},
numpages = {4},
keywords = {fault localization, hit spectra, failure clustering, parallel debugging},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3183440.3183481,
author = {Cito, J\"{u}rgen and Leitner, Philipp and Bosshard, Christian and Knecht, Markus and Mazlami, Genc and Gall, Harald C.},
title = {PerformanceHat: Augmenting Source Code with Runtime Performance Traces in the IDE},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183481},
doi = {10.1145/3183440.3183481},
abstract = {Performance problems observed in production environments that have their origin in program code are immensely hard to localize and prevent. Data that can help solve such problems is usually found in external dashboards and is thus not integrated into the software development process. We propose an approach that augments source code with runtime traces to tightly integrate runtime performance traces into developer workflows. Our goal is to create operational awareness of performance problems in developers' code and contextualize this information to tasks they are currently working on. We implemented this approach as an Eclipse IDE plugin for Java applications that is available as an open source project on GitHub. A video of PerformanceHat in action is online: https://youtu.be/fTBBiylRhag},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {41–44},
numpages = {4},
keywords = {program analysis, development workflow, software performance engineering},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1109/ICSM.2015.7332503,
author = {Badashian, Ali Sajedi and Hindle, Abram and Stroulia, Eleni},
title = {Crowdsourced Bug Triaging},
year = {2015},
isbn = {9781467375320},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSM.2015.7332503},
doi = {10.1109/ICSM.2015.7332503},
abstract = {Bug triaging and assignment is a time-consuming task in big projects. Most research in this area examines the developers' prior development and bug-fixing activities in order to recognize their areas of expertise and assign to them relevant bug fixes. We propose a novel method that exploits a new source of evidence for the developers' expertise, namely their contributions to Q&amp;A platforms such as Stack Overflow. We evaluated this method in the context of the 20 largest GitHub projects, considering 7144 bug reports. Our results demonstrate that our method exhibits superior accuracy to other state-of-the-art methods, and that future bug-assignment algorithms should consider exploring other sources of expertise, beyond the project's version-control system and bug tracker.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
pages = {506–510},
numpages = {5},
series = {ICSME '15}
}

@inproceedings{10.1145/3379597.3387498,
author = {Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas},
title = {A Dataset of Dockerfiles},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387498},
doi = {10.1145/3379597.3387498},
abstract = {Dockerfiles are one of the most prevalent kinds of DevOps artifacts used in industry. Despite their prevalence, there is a lack of sophisticated semantics-aware static analysis of Dockerfiles. In this paper, we introduce a dataset of approximately 178,000 unique Dockerfiles collected from GitHub. To enhance the usability of this data, we describe five representations we have devised for working with, mining from, and analyzing these Dockerfiles. Each Dockerfile representation builds upon the previous ones, and the final representation, created by three levels of nested parsing and abstraction, makes tasks such as mining and static checking tractable. The Dockerfiles, in each of the five representations, along with metadata and the tools used to shepard the data from one representation to the next are all available at: https://doi.org/10.5281/zenodo.3628771.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {528–532},
numpages = {5},
keywords = {Datasets, DevOps, Bash, Mining, Docker},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3092703.3098238,
author = {Santolucito, Mark},
title = {Version Space Learning for Verification on Temporal Differentials},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092703.3098238},
doi = {10.1145/3092703.3098238},
abstract = { Configuration files provide users with the ability to quickly alter the behavior of their software system. Ensuring that a configuration file does not induce errors in the software is a complex verification issue. The types of errors can be easy to measure, such as an initialization failure of system boot, or more insidious such as performance degrading over time under heavy network loads. In order to warn a user of potential configuration errors ahead of time, we propose using version space learning specifications for configuration languages. We frame an existing tool, ConfigC, in terms of version space learning. We extend that algorithm to leverage the temporal structuring available in training sets scraped from versioning control systems. We plan to evaluate our system on a case study using TravisCI configuration files collected from Github. },
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {428–431},
numpages = {4},
keywords = {Configuration Files, Machine Learning, Verification},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.5555/3320516.3320674,
author = {Yao, Shuochao and Hao, Yifan and Liu, Dongxin and Liu, Shengzhong and Shao, Huajie and Wu, Jiahao and Bamba, Mouna and Abdelzaher, Tarek and Flamino, James and Szymanski, Boleslaw},
title = {A Predictive Self-Configuring Simulator for Online Media},
year = {2018},
isbn = {978153866570},
publisher = {IEEE Press},
abstract = {This paper describes the design, implementation, and early experiences with a novel agent-based simulator of online media streams, developed under DARPA's SocialSim Program to extract and predict trends in information dissemination on online media. A hallmark of the simulator is its self-configuring property. Instead of requiring initial set-up, the input to the simulator constitutes data traces collected from the medium to be simulated. The simulator automatically learns from the data such elements as the number of agents involved, the number of objects involved, and the rate of introduction of new agents and objects. It also develops behavior models of simulated agents and objects, and their dependencies. These models are then used to run simulations allowing for future extrapolations and "what if" analyses. Results are presented on using this system to simulate GitHub transactions. They show good performance in terms of both simulation accuracy and overhead.},
booktitle = {Proceedings of the 2018 Winter Simulation Conference},
pages = {1262–1273},
numpages = {12},
location = {Gothenburg, Sweden},
series = {WSC '18}
}

@inproceedings{10.5555/2819321.2819325,
author = {Hata, Hideaki and Todo, Taiki and Onoue, Saya and Matsumoto, Kenichi},
title = {Characteristics of Sustainable OSS Projects: A Theoretical and Empirical Study},
year = {2015},
publisher = {IEEE Press},
abstract = {How can we attract developers? What can we do to incentivize developers to write code? We started the study by introducing the population pyramid visualization to software development communities, called software population pyramids, and found a typical pattern in shapes. This pattern comes from the differences in attracting coding contributors and discussion contributors. To understand the causes of the differences, we then build game-theoretical models of the contribution situation. Based on these results, we again analyzed the projects empirically to support the outcome of the models, and found empirical evidence. The answers to the initial questions are clear. To incentivize developers to code, the projects should prepare documents, or the projects or third parties should hire developers, and these are what sustainable projects in GitHub did in reality. In addition, making innovations to reduce the writing costs can also have an impact in attracting coding contributors.},
booktitle = {Proceedings of the Eighth International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {15–21},
numpages = {7},
location = {Florence, Italy},
series = {CHASE '15}
}

@inproceedings{10.1145/2801040.2801066,
author = {Trouv\'{e}, Antoine and Murakami, Kazuaki J.},
title = {Interactive Visualization of Quantitative Data with G2D3},
year = {2015},
isbn = {9781450334822},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2801040.2801066},
doi = {10.1145/2801040.2801066},
abstract = {This article introduces G2D3, an implementation of the grammar of graphics in JavaScript, along with two practical use cases that illustrate its practicability. It makes it possible to generate interactive visualization of quantitative data in HTML/SVG. Compared to traditional static data visualization systems such as those featured in Excel and R, G2D3 makes it possible to greatly enhance the amount of conveyed information by means of animation and interaction. Compared to other JavaScript plotting libraries such as Rapha\"{e}l and D3, G2D3 leverages the expressiveness and the flexibility of the grammar of graphics to concisely generate complex visualization with many plotting dimensions, including time. It makes it possible to create a wide range of graphics with a few lines of code. G2D3 is open source and hosted in GitHub: join us!},
booktitle = {Proceedings of the 8th International Symposium on Visual Information Communication and Interaction},
pages = {154–155},
numpages = {2},
location = {Tokyo, AA, Japan},
series = {VINCI '15}
}

@inproceedings{10.1145/3238147.3238159,
author = {Shen, Yuju and Jiang, Yanyan and Xu, Chang and Yu, Ping and Ma, Xiaoxing and Lu, Jian},
title = {ReScue: Crafting Regular Expression DoS Attacks},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238159},
doi = {10.1145/3238147.3238159},
abstract = {Regular expression (regex) with modern extensions is one of the most popular string processing tools. However, poorly-designed regexes can yield exponentially many matching steps, and lead to regex Denial-of-Service (ReDoS) attacks under well-conceived string inputs. This paper presents Rescue, a three-phase gray-box analytical technique, to automatically generate ReDoS strings to highlight vulnerabilities of given regexes. Rescue systematically seeds (by a genetic search), incubates (by another genetic search), and finally pumps (by a regex-dedicated algorithm) for generating strings with maximized search time. We implemenmted the Rescue tool and evaluated it against 29,088 practical regexes in real-world projects. The evaluation results show that Rescue found 49% more attack strings compared with the best existing technique, and applying Rescue to popular GitHub projects discovered ten previously unknown ReDoS vulnerabilities.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {225–235},
numpages = {11},
keywords = {egular expression, genetic algorithm, ReDoS, denial of service},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.1145/2487788.2487832,
author = {Venkataramani, Rahul and Gupta, Atul and Asadullah, Allahbaksh and Muddu, Basavaraju and Bhat, Vasudev},
title = {Discovery of Technical Expertise from Open Source Code Repositories},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2487832},
doi = {10.1145/2487788.2487832},
abstract = {Online Question and Answer websites for developers have emerged as the main forums for interaction during the software development process. The veracity of an answer in such websites is typically verified by the number of 'upvotes' that the answer garners from peer programmers using the same forum. Although this mechanism has proved to be extremely successful in rating the usefulness of the answers, it does not lend itself very elegantly to model the expertise of a user in a particular domain. In this paper, we propose a model to rank the expertise of the developers in a target domain by mining their activity in different opensource projects. To demonstrate the validity of the model, we built a recommendation system for StackOverflow which uses the data mined from GitHub.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {97–98},
numpages = {2},
keywords = {source code repository, stackoverflow, knowledge discovery, technical expertise, recommendations, github},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@inproceedings{10.1145/3092703.3098221,
author = {Walsh, Thomas A. and Kapfhammer, Gregory M. and McMinn, Phil},
title = {ReDeCheck: An Automatic Layout Failure Checking Tool for Responsively Designed Web Pages},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092703.3098221},
doi = {10.1145/3092703.3098221},
abstract = { Since people frequently access websites with a wide variety of devices (e.g., mobile phones, laptops, and desktops), developers need frameworks and tools for creating layouts that are useful at many viewport widths. While responsive web design (RWD) principles and frameworks facilitate the development of such sites, there is a lack of tools supporting the detection of failures in their layout. Since the quality assurance process for responsively designed websites is often manual, time-consuming, and error-prone, this paper presents ReDeCheck, an automated layout checking tool that alerts developers to both potential unintended regressions in responsive layout and common types of layout failure. In addition to summarizing ReDeCheck’s benefits, this paper explores two different usage scenarios for this tool that is publicly available on GitHub. },
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {360–363},
numpages = {4},
keywords = {Responsive web design, layout failures, presentation failures},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.1109/ICSE-C.2017.114,
author = {Hassan, Foyzul and Wang, Xiaoyin},
title = {Mining Readme Files to Support Automatic Building of Java Projects in Software Repositories: Poster},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.114},
doi = {10.1109/ICSE-C.2017.114},
abstract = {Automatic building of software projects provides a desirable foundation to support a large variety of software engineering research tasks based on open software repositories. In this paper, we propose the first technique to automatically extract software build commands from software readme files and Wiki pages, and combine the extracted commands for software building. Specifically, we leverage the Named Entity Recognition (NER) technique for build-command extraction, and prioritize the extracted build commands to identify which one should be used in software build. Our experiment on top Java projects from GitHub reveals that, the proposed technique can correctly identify more than 90% of build commands, and can successfully build 84% of the projects that can be built successfully through manual inspection of software support documents.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {277–279},
numpages = {3},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1145/2993412.3003384,
author = {Constantinou, Eleni and Mens, Tom},
title = {Social and Technical Evolution of Software Ecosystems: A Case Study of Rails},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3003384},
doi = {10.1145/2993412.3003384},
abstract = {Software ecosystems evolve through an active community of developers who contribute to projects within the ecosystem. However, development teams change over time, suggesting a potential impact on the evolution of the technical parts of the ecosystem. The impact of such modifications has been studied by previous works, but only temporary changes have been investigated, while the long-term effect of permanent changes has yet to be explored. In this paper, we investigate the evolution of the ecosystem of Ruby on Rails in GitHub in terms of such temporary and permanent changes of the development team. We use three viewpoints of the Rails ecosystem evolution to discuss our preliminary findings: (1) the base project; (2) the forks; and (3) the entire ecosystem containing both base project and forks.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {23},
numpages = {4},
keywords = {technical evolution, social evolution, software ecosystems},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@inproceedings{10.1145/3379597.3387483,
author = {Wu, Yiwen and Zhang, Yang and Wang, Tao and Wang, Huaimin},
title = {An Empirical Study of Build Failures in the Docker Context},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387483},
doi = {10.1145/3379597.3387483},
abstract = {Docker containers have become the de-facto industry standard. Docker builds often break, and a large amount of efforts are put into troubleshooting broken builds. Prior studies have evaluated the rate at which builds in large organizations fail. However, little is known about the frequency and fix effort of failures that occur in Docker builds of open-source projects. This paper provides a first attempt to present a preliminary study on 857,086 Docker builds from 3,828 open-source projects hosted on GitHub. Using the Docker build data, we measure the frequency of broken builds and report their fix time. Furthermore, we explore the evolution of Docker build failures across time. Our findings help to characterize and understand Docker build failures and motivate the need for collecting more empirical evidence.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {76–80},
numpages = {5},
keywords = {Docker, Build failure, Open-source},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3383583.3398548,
author = {Yang, Le and Zhang, Zhongda and Chen, Enci},
title = {Customization and Localization of DSpace-CRIS in China},
year = {2020},
isbn = {9781450375856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383583.3398548},
doi = {10.1145/3383583.3398548},
abstract = {Traditional institutional repository (IR) has been broadly used and improved in practice for decades. Current Research Information System (CRIS) is one of the extended systems that broadens the traditional IR systems' functionality by expanding the data and visualization modules. Beyond the basic functions of an IR, CRIS extends to distribute multimedia scholarly publications, manage research data, provide evaluation on research performance, visualize research network, enable research profiling, support project-based activities, integrate citation metrics, etc. This paper introduces the first DSpace-CRIS system that was implemented in mainland China at Wenzhou-Kean University (WKU) and explains the localized efforts of technologies and customized development of modules. The development team has also released the installation of developed modules as open sources on GitHub. The paper outlines the future development plan for the institution.},
booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020},
pages = {545–546},
numpages = {2},
keywords = {DSpace-CRIS, visualization tools, readership map, current research information system, institutional repository},
location = {Virtual Event, China},
series = {JCDL '20}
}

@inproceedings{10.1145/3337722.3341843,
author = {Pirker, Johanna and Punz, Andreas and Kopf, Johannes},
title = {Social Interactions in Game Jams: A Jammer Recommender Tool},
year = {2019},
isbn = {9781450372176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337722.3341843},
doi = {10.1145/3337722.3341843},
abstract = {In game jams, the jammer constellations and teams are essential elements for successful and engaging game jams and game jam outcomes. In this paper, we discuss and analyze group forming behavior in jam environments but also look at jammers who want to prefer to jam by themselves. In jam environments, especially the group forming task at the beginning of every game jam is essential for the success of the event and the outcomes. However, it is also one of the most challenging tasks. For this paper, we analyzed the data of the Global Game Jams between 2015-2018 with a focus on the formed groups as well as the linked Github profiles. Based on first results, we build an early prototype for recommending groups for the Global Game Jam automatically.},
booktitle = {Proceedings of the 14th International Conference on the Foundations of Digital Games},
articleno = {71},
numpages = {4},
keywords = {game jam, social network analysis, game development, github},
location = {San Luis Obispo, California, USA},
series = {FDG '19}
}

@inproceedings{10.1109/ICSM.2013.50,
author = {Venkataramani, Rahul and Asadullah, Allahbaksh and Bhat, Vasudev and Muddu, Basavaraju},
title = {Latent Co-Development Analysis Based Semantic Search for Large Code Repositories},
year = {2013},
isbn = {9780769549811},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSM.2013.50},
doi = {10.1109/ICSM.2013.50},
abstract = {Distributed and collaborative software development has increased the popularity of source code repositories like GitHub. With the number of projects in such code repositories exceeding millions, it is important to identify the domains to which the projects belong. A domain is a concept or a hierarchy of concepts used to categorize a project. We have proposed a model to cluster projects in a code repository by mining the latent co-development network. These identified clusters are mapped to domains with the help of a taxonomy which we constructed using the metadata from an online Question and Answer (Q&amp;A) website. To demonstrate the validity of the model, we built a prototype for semantic search on source code repositories. In this paper, we outline the proposed model and present the early results.},
booktitle = {Proceedings of the 2013 IEEE International Conference on Software Maintenance},
pages = {372–375},
numpages = {4},
keywords = {source code repositories, Human aspects of software evolution, Software repository analysis and mining, semantic search},
series = {ICSM '13}
}

@inproceedings{10.1145/3379597.3387510,
author = {Pietri, Antoine and Spinellis, Diomidis and Zacchiroli, Stefano},
title = {The Software Heritage Graph Dataset: Large-Scale Analysis of Public Software Development History},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387510},
doi = {10.1145/3379597.3387510},
abstract = {Software Heritage is the largest existing public archive of software source code and accompanying development history. It spans more than five billion unique source code files and one billion unique commits, coming from more than 80 million software projects. These software artifacts were retrieved from major collaborative development platforms (e.g., GitHub, GitLab) and package repositories (e.g., PyPI, Debian, NPM), and stored in a uniform representation linking together source code files, directories, commits, and full snapshots of version control systems (VCS) repositories as observed by Software Heritage during periodic crawls. This dataset is unique in terms of accessibility and scale, and allows to explore a number of research questions on the long tail of public software development, instead of solely focusing on "most starred" repositories as it often happens.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {1–5},
numpages = {5},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3366424.3382184,
author = {Hernandez, Anthony and Ng, Kin and Iamnitchi, Adriana},
title = {Using Deep Learning for Temporal Forecasting of User Activity on Social Media: Challenges and Limitations},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3382184},
doi = {10.1145/3366424.3382184},
abstract = {The recent advances in neural network-based machine learning algorithms promise a revolution in prediction-based tasks in a variety of domains. Of these, forecasting user activity in social media is particularly relevant for problems such as modeling and predicting information diffusion and designing intervention techniques to mitigate disinformation campaigns. Social media seems an ideal context for applying neural network techniques, as they provide large datasets and challenging prediction objectives. Yet, our experiments find a number of limitations in the power of deep neural networks and traditional machine learning approaches in predicting user activity on social media platforms. These limitations are related to dataset characteristics due to temporal aspects of user behavior. This work describes the challenges we encountered while attempting to forecast user activity on two popular social interaction sites: Twitter and GitHub.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {331–336},
numpages = {6},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3328020.3353917,
author = {Hardin, Ashley R.},
title = {Building Bridges to Customer Needs in Open Source Documentation},
year = {2019},
isbn = {9781450367905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328020.3353917},
doi = {10.1145/3328020.3353917},
abstract = {The Red Hat OpenShift documentation repository is situated in a unique open source environment in which anybody with a GitHub account can contribute directly to the documentation set. One of the primary contributors to the documentation repository are developers, which presents a challenge. The technical writers on the Red Hat OpenShift documentation team who collaboratively write, edit, and merge these contributions are faced with the challenge of maintaining user-centered rather than engineering- centered documentation. Furthermore, the technical writers lack direct interaction with external customers. Considering these challenges, this industry insight report discusses several methods that can be employed to maintain a customer-centric focus and improve the documentation set: focus on user stories, network with internal customers and stakeholders who work closest with external customers, and seek opportunities to work on customer cases.},
booktitle = {Proceedings of the 37th ACM International Conference on the Design of Communication},
articleno = {35},
numpages = {3},
keywords = {user stories, open source documentation, agile software development, collaborative writing},
location = {Portland, Oregon},
series = {SIGDOC '19}
}

@inproceedings{10.1109/ALLERTON.2019.8919901,
author = {Song, Bowen and Trachtenberg, Ari},
title = {Scalable String Reconciliation by Recursive Content-Dependent Shingling},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ALLERTON.2019.8919901},
doi = {10.1109/ALLERTON.2019.8919901},
abstract = {We consider the problem of reconciling similar, but remote, strings with minimum communication complexity. This “string reconciliation” problem is a fundamental building block for a variety of networking applications, including those that maintain large-scale distributed networks and perform remote file synchronization. We present the novel Recursive Content-Dependent Shingling (RCDS) protocol that is computationally practical for large strings and scales linearly with the edit distance between the remote strings. We provide comparisons to the performance of rsync, one of the most popular file synchronization tools in active use. Our experiments show that, with minimal engineering, RCDS outperforms the heavily optimized rsync in reconciling release revisions for about 51% of the 5000 top starred git repositories on GitHub. The improvement is particularly evident for repositories that see frequent, but small, updates.},
booktitle = {2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
pages = {623–630},
numpages = {8},
location = {Monticello, IL, USA}
}

@inproceedings{10.1145/3241403.3241422,
author = {Ahmar, Yosser El and Pallec, Xavier Le and G\'{e}rard, S\'{e}bastien},
title = {The Visual Variables in UML: How Are They Used by Women?},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241422},
doi = {10.1145/3241403.3241422},
abstract = {This paper presents results of an empirical research study of the Unified Modeling Language (UML) actual state of practice. It reports on a quantitative analysis of &gt; 3500 UML diagrams related to open source projects in GitHub. The aim of the study is to shed light on the use of the visual variables (i.e., color, size, brightness, texture/grain, shape and orientation) in UML, with a particular focus on the practices of women in such usages. The theoretical perspective of the study is to explore the usefulness of the visual variables in UML. These latter are highly significant in reducing the cognitive load of human beings, when effectively employed. We conclude by discussions of the obtained results and commenting on the role of women in the projects involving visual variations in their diagrams.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {17},
numpages = {5},
keywords = {women in software engineering, UML, color, visual variables, secondary notation},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3183440.3183488,
author = {Wang, Kaiyuan and Sullivan, Allison and Khurshid, Sarfraz},
title = {MuAlloy: A Mutation Testing Framework for Alloy},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183488},
doi = {10.1145/3183440.3183488},
abstract = {Creating models of software systems and analyzing the models helps develop more reliable systems. A well-known software modeling tool-set is embodied by the declarative language Alloy and its automatic SAT-based analyzer. Recent work introduced a novel approach to testing Alloy models to validate their correctness in the spirit of traditional software testing: A Unit defined the foundations of testing (unit tests, test execution, and model coverage) for Alloy, and MuAlloy defined mutation testing (mutation operators, mutant generation, and equivalent mutant checking) for Alloy. This tool paper describes our Java implementation of MuAlloy, which is a command-line tool that we released as an open-source project on GitHub. Our experimental results show that MuAlloy is efficient and practical. The demo video for MuAlloy can be found at https://youtu.be/3lvnQKiLcLE.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {29–32},
numpages = {4},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1007/978-3-319-49004-5_20,
author = {Halilaj, Lavdim and Petersen, Niklas and Grangel-Gonz\'{a}lez, Irl\'{a}n and Lange, Christoph and Auer, S\"{o}ren and Coskun, G\"{o}khan and Lohmann, Steffen},
title = {VoCol: An Integrated Environment to Support Version-Controlled Vocabulary Development},
year = {2016},
isbn = {9783319490038},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-49004-5_20},
doi = {10.1007/978-3-319-49004-5_20},
abstract = {Vocabularies are increasingly being developed on platforms for hosting version-controlled repositories, such as GitHub. However, these platforms lack important features that have proven useful in vocabulary development. We present VoCol, an integrated environment that supports the development of vocabularies using Version Control Systems. VoCol is based on a fundamental model of vocabulary development, consisting of the three core activities modeling, population, and testing. We implemented VoCol using a loose coupling of validation, querying, analytics, visualization, and documentation generation components on top of a standard Git repository. All components, including the version-controlled repository, can be configured and replaced with little effort to cater for various use cases. We demonstrate the applicability of VoCol with a real-world example and report on a user study that confirms its usability and usefulness.},
booktitle = {20th International Conference on Knowledge Engineering and Knowledge Management - Volume 10024},
pages = {303–319},
numpages = {17},
keywords = {Version control system, Webhook, GitHub, IDE, Ontology engineering, Vocabulary development, Integrated development environment, Git},
location = {Bologna, Italy},
series = {EKAW 2016}
}

@inproceedings{10.5555/2820518.2820588,
author = {Spinellis, Diomidis},
title = {A Repository with 44 Years of Unix Evolution},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {The evolution of the Unix operating system is made available as a version-control repository, covering the period from its inception in 1972 as a five thousand line kernel, to 2015 as a widely-used 26 million line system. The repository contains 659 thousand commits and 2306 merges. The repository employs the commonly used Git system for its storage, and is hosted on the popular GitHub archive. It has been created by synthesizing with custom software 24 snapshots of systems developed at Bell Labs, Berkeley University, and the 386BSD team, two legacy repositories, and the modern repository of the open source FreeBSD system. In total, 850 individual contributors are identified, the early ones through primary research. The data set can be used for empirical research in software engineering, information systems, and software archaeology.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {462–465},
numpages = {4},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3387905.3388597,
author = {Rahkema, Kristiina and Pfahl, Dietmar},
title = {Empirical Study on Code Smells in IOS Applications},
year = {2020},
isbn = {9781450379595},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387905.3388597},
doi = {10.1145/3387905.3388597},
abstract = {Code smells are recurring patterns in code that have been identified as bad practices. They have been analysed extensively in Java desktop applications. For mobile applications most of the research has been done for Android with very little research done for iOS. Although Android has the largest market share, iOS is a very popular platform. Our goal is to understand the distribution of code smells in iOS applications. For this analysis we used a collaborative list of open source iOS applications from GitHub. We combined code smells defined by Fowler and object oriented code smells studied on Android. We developed a tool that can detect these code smells in Swift applications. We discovered that iOS applications are most often affected by Lazy Class, Long Method and Message Chain code smells. Most often occurring code smells are Internal Duplication, Lazy Class and Long Method.},
booktitle = {Proceedings of the IEEE/ACM 7th International Conference on Mobile Software Engineering and Systems},
pages = {61–65},
numpages = {5},
keywords = {iOS, mobile applications, code smells, empirical study},
location = {Seoul, Republic of Korea},
series = {MOBILESoft '20}
}

@inproceedings{10.1145/3213846.3213866,
author = {Zhang, Yuhao and Chen, Yifan and Cheung, Shing-Chi and Xiong, Yingfei and Zhang, Lu},
title = {An Empirical Study on TensorFlow Program Bugs},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213866},
doi = {10.1145/3213846.3213866},
abstract = {Deep learning applications become increasingly popular in important domains such as self-driving systems and facial identity systems. Defective deep learning applications may lead to catastrophic consequences. Although recent research efforts were made on testing and debugging deep learning applications, the characteristics of deep learning defects have never been studied. To fill this gap, we studied deep learning applications built on top of TensorFlow and collected program bugs related to TensorFlow from StackOverflow QA pages and Github projects. We extracted information from QA pages, commit messages, pull request messages, and issue discussions to examine the root causes and symptoms of these bugs. We also studied the strategies deployed by TensorFlow users for bug detection and localization. These findings help researchers and TensorFlow users to gain a better understanding of coding defects in TensorFlow programs and point out a new direction for future research.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {129–140},
numpages = {12},
keywords = {Deep Learning, Empirical Study, TensorFlow Program Bug},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@inproceedings{10.1145/3106237.3106246,
author = {Coelho, Jailton and Valente, Marco Tulio},
title = {Why Modern Open Source Projects Fail},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106246},
doi = {10.1145/3106237.3106246},
abstract = { Open source is experiencing a renaissance period, due to the appearance of modern platforms and workflows for developing and maintaining public code. As a result, developers are creating open source software at speeds never seen before. Consequently, these projects are also facing unprecedented mortality rates. To better understand the reasons for the failure of modern open source projects, this paper describes the results of a survey with the maintainers of 104 popular GitHub systems that have been deprecated. We provide a set of nine reasons for the failure of these open source projects. We also show that some maintenance practices---specifically the adoption of contributing guidelines and continuous integration---have an important association with a project failure or success. Finally, we discuss and reveal the principal strategies developers have tried to overcome the failure of the studied projects. },
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {186–196},
numpages = {11},
keywords = {Open Source Software, Project failure, GitHub},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/3377811.3380358,
author = {Wu, Mingyuan and Ouyang, Yicheng and Zhou, Husheng and Zhang, Lingming and Liu, Cong and Zhang, Yuqun},
title = {Simulee: Detecting CUDA Synchronization Bugs via Memory-Access Modeling},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380358},
doi = {10.1145/3377811.3380358},
abstract = {While CUDA has become a mainstream parallel computing platform and programming model for general-purpose GPU computing, how to effectively and efficiently detect CUDA synchronization bugs remains a challenging open problem. In this paper, we propose the first lightweight CUDA synchronization bug detection framework, namely Simulee, to model CUDA program execution by interpreting the corresponding LLVM bytecode and collecting the memory-access information for automatically detecting general CUDA synchronization bugs. To evaluate the effectiveness and efficiency of Simulee, we construct a benchmark with 7 popular CUDA-related projects from GitHub, upon which we conduct an extensive set of experiments. The experimental results suggest that Simulee can detect 21 out of the 24 manually identified bugs in our preliminary study and also 24 previously unknown bugs among all projects, 10 of which have already been confirmed by the developers. Furthermore, Simulee significantly outperforms state-of-the-art approaches for CUDA synchronization bug detection.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {937–948},
numpages = {12},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3397537.3397559,
author = {Ehmueller, Jan and Riese, Alexander and Tjabben, Hendrik and Niephaus, Fabio and Hirschfeld, Robert},
title = {Polyglot Code Finder},
year = {2020},
isbn = {9781450375078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397537.3397559},
doi = {10.1145/3397537.3397559},
abstract = {With the increasing complexity of software, it becomes even more important to build on the work of others. At the same time, websites, such as Stack Overflow or GitHub, are used by millions of developers to host their code, which could potentially be reused.  The process of finding the right code, however, is often time-consuming. In addition, the right solution may be written in a programming language that does not fit the developer's requirements. Current approaches to automate code search allow users to search for code based on keywords and transformation rules, but they are limited to one programming language.  Our approach enables developers to find code for reuse written in different languages, which is especially useful when building polyglot applications. In addition to conventional search filters, users can filter code by providing example input and expected output. Based on our approach, we have implemented a tool prototype in GraalSqueak. We evaluate both approach and prototype with an experience report.},
booktitle = {Conference Companion of the 4th International Conference on Art, Science, and Engineering of Programming},
pages = {106–112},
numpages = {7},
keywords = {programming experience, GraalVM, polyglot, code search, code reuse},
location = {Porto, Portugal},
series = {20}
}

@inproceedings{10.1145/3295453.3295457,
author = {Murillo, Andr\'{e}s Felipe and C\'{o}mbita, Luis Francisco and Gonzalez, Andrea Calder\'{o}n and Rueda, Sandra and Cardenas, Alvaro A. and Quijano, Nicanor},
title = {A Virtual Environment for Industrial Control Systems: A Nonlinear Use-Case in Attack Detection, Identification, and Response},
year = {2018},
isbn = {9781450362207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3295453.3295457},
doi = {10.1145/3295453.3295457},
abstract = {The integration of modern information technologies with industrial control systems has created an enormous interest in the security of industrial control, however, given the cost, variety, and industry practices, it is hard for researchers to test and deploy security solutions in real-world systems. Industrial control testbeds can be used as tools to test security solutions before they are deployed, and in this paper we extend our previous work to develop open-source virtual industrial control testbeds where computing and networking components are emulated and virtualized, and the physical system is simulated through differential equations. In particular, we implement a nonlinear control system emulating a three-water tank with the associated sensors, PLCs, and actuators that communicate through an emulated network. In addition, we design unknown input observers (UIO) to not only detect that an attack is occurring, but also to identify the source of the malicious false data injections and mitigate its impact. Our system is available through Github to the academic community.},
booktitle = {Proceedings of the 4th Annual Industrial Control System Security Workshop},
pages = {25–32},
numpages = {8},
keywords = {Network Function Virtualization, Industrial Control Systems, Virtual Environment Testbeds, Network Security},
location = {San Juan, PR, USA},
series = {ICSS '18}
}

@inproceedings{10.1145/3194932.3194935,
author = {Ding, Jin and Sun, Hailong and Wang, Xu and Liu, Xudong},
title = {Entity-Level Sentiment Analysis of Issue Comments},
year = {2018},
isbn = {9781450357517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194932.3194935},
doi = {10.1145/3194932.3194935},
abstract = {Emotions and sentiment of software developers can largely influence the software productivity and quality. However, existing work on emotion mining and sentiment analysis is still in the early stage in software engineering in terms of accuracy, the size of datasets used and the specificity of the analysis. In this work, we are concerned with conducting entity-level sentiment analysis. We first build a manually labeled dataset containing 3,000 issue comments selected from 231,732 issue comments collected from 10 open source projects in GitHub. Then we design and develop SentiSW, an entity-level sentiment analysis tool consisting of sentiment classification and entity recognition, which can classify issue comments into <sentiment, entity=""> tuples. We evaluate the sentiment classification using ten-fold cross validation, and it achieves 68.71% mean precision, 63.98% mean recall and 77.19% accuracy, which is significantly higher than existing tools. We evaluate the entity recognition by manually annotation and it achieves a 75.15% accuracy.},
booktitle = {Proceedings of the 3rd International Workshop on Emotion Awareness in Software Engineering},
pages = {7–13},
numpages = {7},
keywords = {entity recognition, entity-level sentiment analysis, open source software project, sentiment classification},
location = {Gothenburg, Sweden},
series = {SEmotion '18}
}

@inproceedings{10.1145/3123266.3129391,
author = {Dong, Hao and Supratak, Akara and Mai, Luo and Liu, Fangde and Oehmichen, Axel and Yu, Simiao and Guo, Yike},
title = {TensorLayer: A Versatile Library for Efficient Deep Learning Development},
year = {2017},
isbn = {9781450349062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123266.3129391},
doi = {10.1145/3123266.3129391},
abstract = {Recently we have observed emerging uses of deep learning techniques in multimedia systems. Developing a practical deep learning system is arduous and complex. It involves labor-intensive tasks for constructing sophisticated neural networks, coordinating multiple network models, and managing a large amount of training-related data. To facilitate such a development process, we propose TensorLayer which is a Python-based versatile deep learning library. TensorLayer provides high-level modules that abstract sophisticated operations towards neuron layers, network models, training data and dependent training jobs. In spite of offering simplicity, it has transparent module interfaces that allows developers to flexibly embed low-level controls within a backend engine, with the aim of supporting fine-grain tuning towards training. Real-world cluster experiment results show that TensorLayeris able to achieve competitive performance and scalability in critical deep learning tasks. TensorLayer was released in September 2016 on GitHub. Since after, it soon become one of the most popular open-sourced deep learning library used by researchers and practitioners.},
booktitle = {Proceedings of the 25th ACM International Conference on Multimedia},
pages = {1201–1204},
numpages = {4},
keywords = {natural language processing, parallel computation, data management, deep learning, computer vision, reinforcement learning},
location = {Mountain View, California, USA},
series = {MM '17}
}

@inproceedings{10.1145/3238147.3240485,
author = {Sung, Chungha and Paulsen, Brandon and Wang, Chao},
title = {CANAL: A Cache Timing Analysis Framework via LLVM Transformation},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240485},
doi = {10.1145/3238147.3240485},
abstract = {A unified modeling framework for non-functional properties of a program is essential for research in software analysis and verification, since it reduces burdens on individual researchers to implement new approaches and compare existing approaches. We present CANAL, a framework that models the cache behaviors of a program by transforming its intermediate representation in the LLVM compiler. CANAL inserts auxiliary variables and instructions over these variables, to allow standard verification tools to handle a new class of cache related properties, e.g., for computing the worst-case execution time and detecting side-channel leaks. We demonstrate the effectiveness of using three verification tools: KLEE, SMACK and Crab-llvm. We confirm the accuracy of our cache model by comparing with CPU cycle-accurate simulation results of GEM5. CANAL is available on GitHub(https://github.com/canalcache/canal) and YouTube(https://youtu.be/JDou3F1j2nY).},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {904–907},
numpages = {4},
keywords = {cache, abstract interpretation, symbolic execution, execution time, verification, bounded model checking, side channel},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.5555/3277355.3277362,
author = {Oakes, Edward and Yang, Leon and Zhou, Dennis and Houck, Kevin and Harter, Tyler and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},
title = {SOCK: Rapid Task Provisioning with Serverless-Optimized Containers},
year = {2018},
isbn = {9781931971447},
publisher = {USENIX Association},
address = {USA},
abstract = {Serverless computing promises to provide applications with cost savings and extreme elasticity. Unfortunately, slow application and container initialization can hurt common-case latency on serverless platforms. In this work, we analyze Linux container primitives, identifying scalability bottlenecks related to storage and network isolation. We also analyze Python applications from GitHub and show that importing many popular libraries adds about 100 ms to startup. Based on these findings, we implement SOCK, a container system optimized for serverless workloads. Careful avoidance of kernel scalability bottlenecks gives SOCK an 18\texttimes{} speedup over Docker. A generalized-Zygote provisioning strategy yields an additional 3\texttimes{} speedup. A more sophisticated three-tier caching strategy based on Zygotes provides a 45\texttimes{} speedup over SOCK without Zygotes. Relative to AWS Lambda and OpenWhisk, OpenLambda with SOCK reduces platform overheads by 2.8\texttimes{} and 5.3\texttimes{} respectively in an image processing case study.},
booktitle = {Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference},
pages = {57–69},
numpages = {13},
location = {Boston, MA, USA},
series = {USENIX ATC '18}
}

@inproceedings{10.5555/3155562.3155698,
author = {Li, Yi},
title = {Managing Software Evolution through Semantic History Slicing},
year = {2017},
isbn = {9781538626849},
publisher = {IEEE Press},
abstract = { Software change histories are results of incremental updates made by developers. As a side-effect of the software development process, version history is a surprisingly useful source of information for understanding, maintaining and reusing software. However, traditional commit-based sequential organization of version histories lacks semantic structure and thus are insufficient for many development tasks that require high-level, semantic understanding of program functionality, such as locating feature implementations and porting hot fixes. In this work, we propose to use well-organized unit tests as identifiers for corresponding software functionalities. We then present a family of automated techniques which analyze the semantics of historical changes and assist developers in many everyday practical settings. For validation, we evaluate our approaches on a benchmark of developer-annotated version history instances obtained from real-world open source software projects on GitHub. },
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {1014–1017},
numpages = {4},
keywords = {software changes, software reuse, program analysis, version histories},
location = {Urbana-Champaign, IL, USA},
series = {ASE 2017}
}

@inproceedings{10.1109/ICSM.2015.7332512,
author = {Goeminne, Mathieu and Mens, Tom},
title = {Towards a Survival Analysis of Database Framework Usage in Java Projects},
year = {2015},
isbn = {9781467375320},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSM.2015.7332512},
doi = {10.1109/ICSM.2015.7332512},
abstract = {Many software projects rely on a relational database in order to realize part of their functionality. Various database frameworks and object-relational mappings have been developed and used to facilitate data manipulation. Little is known about whether and how such frameworks co-occur, how they complement or compete with each other, and how this changes over time. We empirically studied these aspects for 5 Java database frameworks, based on a corpus of 3,707 GitHub Java projects. In particular, we analysed whether certain database frameworks co-occur frequently, and whether some database frameworks get replaced over time by others. Using the statistical technique of survival analysis, we explored the survival of the database frameworks in the considered projects. This provides useful evidence to software developers about which frameworks can be used successfully in combination and which combinations should be avoided.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
pages = {551–555},
numpages = {5},
series = {ICSME '15}
}

@inproceedings{10.1109/RELENG.2015.11,
author = {Bass, Len and Holz, Ralph and Rimba, Paul and Tran, An Binh and Zhu, Liming},
title = {Securing a Deployment Pipeline},
year = {2015},
isbn = {9781467370707},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/RELENG.2015.11},
doi = {10.1109/RELENG.2015.11},
abstract = {At the RELENG 2014 Q&amp;A, the question was asked, "What is your greatest concern?" and the response was "someone subverting our deployment pipeline". That is the motivation for this paper. We explore what it means to subvert a pipeline and provide several different scenarios of subversion. We then focus on the issue of securing a pipeline. As a result, we provide an engineering process that is based on having trustworthy components mediate access to sensitive portions of the pipeline from other components, which can remain untrustworthy. Applying our process to a pipeline involving Chef, Jenkins, Docker, Github, and AWS, we find that some aspects of our process result in easy to make changes to the pipeline, whereas others are more difficult. Consequently, we have developed a design that hardens the pipeline, although it does not yet completely secure it.},
booktitle = {Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering},
pages = {4–7},
numpages = {4},
keywords = {supply chain, continuous deployment, DevOps},
series = {RELENG '15}
}

@inproceedings{10.5555/2487085.2487131,
author = {Wagstrom, Patrick and Jergensen, Corey and Sarma, Anita},
title = {A Network of Rails: A Graph Dataset of Ruby on Rails and Associated Projects},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
abstract = { Software projects, whether open source, proprietary, or a combination thereof, rarely exist in isolation. Rather, most projects build on a network of people and ideas from dozens, hundreds, or even thousands of other projects. Using the GitHub APIs it is possible to extract these relationships for millions of users and projects. In this paper we present a dataset of a large network of open source projects centered around Ruby on Rails. This dataset provides insight into the relationships between Ruby on Rails and an ecosystem involving 1116 projects. To facilitate understanding of this data in the context of relationships between projects, users, and their activities, it is provided as a graph database suitable for assessing network properties of the community and individuals within those communities and can be found at https://github.com/pridkett/gitminer-data-rails. },
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {229–232},
numpages = {4},
location = {San Francisco, CA, USA},
series = {MSR '13}
}

@inproceedings{10.1109/CHASE.2019.00011,
author = {Cheng, Jinghui and Guo, Jin L. C.},
title = {Activity-Based Analysis of Open Source Software Contributors: Roles and Dynamics},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2019.00011},
doi = {10.1109/CHASE.2019.00011},
abstract = {Contributors to open source software (OSS) communities assume diverse roles to take different responsibilities. One major limitation of the current OSS tools and platforms is that they provide a uniform user interface regardless of the activities performed by the various types of contributors. This paper serves as a non-trivial first step towards resolving this challenge by demonstrating a methodology and establishing knowledge to understand how the contributors' roles and their dynamics, reflected in the activities contributors perform, are exhibited in OSS communities. Based on an analysis of user action data from 29 GitHub projects, we extracted six activities that distinguished four Active roles and five Supporting roles of OSS contributors, as well as patterns in role changes. Through the lens of the Activity Theory, these findings provided rich design guidelines for OSS tools to support diverse contributor roles.},
booktitle = {Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {11–18},
numpages = {8},
keywords = {contributor roles, activity-based analysis, open source community, open source software},
location = {Montreal, Quebec, Canada},
series = {CHASE '19}
}

@inproceedings{10.5555/3327546.3327670,
author = {Hashimoto, Tatsunori B. and Guu, Kelvin and Oren, Yonatan and Liang, Percy},
title = {A Retrieve-and-Edit Framework for Predicting Structured Outputs},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {For the task of generating complex outputs such as source code, editing existing outputs can be easier than generating complex outputs from scratch. With this motivation, we propose an approach that first retrieves a training example based on the input (e.g., natural language description) and then edits it to the desired output (e.g., code). Our contribution is a computationally efficient method for learning a retrieval model that embeds the input in a task-dependent way without relying on a hand-crafted metric or incurring the expense of jointly training the retriever with the editor. Our retrieve-and-edit framework can be applied on top of any base model. We show that on a new autocomplete task for GitHub Python code and the Hearthstone cards benchmark, retrieve-and-edit significantly boosts the performance of a vanilla sequence-to-sequence model on both tasks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {10073–10083},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.1145/3238147.3240732,
author = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and Di Penta, Massimiliano and White, Martin and Poshyvanyk, Denys},
title = {An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via Neural Machine Translation},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240732},
doi = {10.1145/3238147.3240732},
abstract = {Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. We mine millions of bug-fixes from the change histories of GitHub repositories to extract meaningful examples of such bug-fixes. Then, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. Our model is able to fix hundreds of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9% of the cases.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {832–837},
numpages = {6},
keywords = {neural machine translation, bug-fixes},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.5555/3304222.3304412,
author = {Zheng, Renjie and Chen, Junkun and Qiu, Xipeng},
title = {Same Representation, Different Attentions: Shareable Sentence Representation Learning from Multiple Tasks},
year = {2018},
isbn = {9780999241127},
publisher = {AAAI Press},
abstract = {Distributed representation plays an important role in deep learning based natural language processing. However, the representation of a sentence often varies in different tasks, which is usually learned from scratch and suffers from the limited amounts of training data. In this paper, we claim that a good sentence representation should be invariant and can benefit the various subsequent tasks. To achieve this purpose, we propose a new scheme of information sharing for multi-task learning. More specifically, all tasks share the same sentence representation and each task can select the task-specific information from the shared sentence representation with attention mechanisms. The query vector of each task's attention could be either static parameters or generated dynamically. We conduct extensive experiments on 16 different text classification tasks, which demonstrate the benefits of our architecture. Source codes of this paper are available on Github.},
booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
pages = {4616–4622},
numpages = {7},
location = {Stockholm, Sweden},
series = {IJCAI'18}
}

@inproceedings{10.1145/3426426.3428487,
author = {Ashouri, Mohammadreza},
title = {Kaizen: A Scalable Concolic Fuzzing Tool for Scala},
year = {2020},
isbn = {9781450381772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426426.3428487},
doi = {10.1145/3426426.3428487},
abstract = {Scala is an open-source programming language created by Martin Odersky in 2001 and released under the BSD or Berkeley Software Distribution license. The language consolidates object-oriented and functional programming in one high-level and robust language. Scala also maintains static types that help to reduce tricky errors during the execution time. In this paper, we introduce ”Kaizen” as a practical security analysis tool that works based on concolic fuzzing for evaluating real-world Scala applications. To evaluated our approach, we analyzed 1,000 popular Scala projects existing on GitHub. As a result, Kaizen could report and exploit 101 security issues; some of those have not been reported before. Furthermore, our performance analysis outcome on the ScalaBench test suite demonstrates a 49% runtime overhead that proves Kaizen’s usefulness for security testing in the Scala ecosystem.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Symposium on Scala},
pages = {25–32},
numpages = {8},
keywords = {Vulnerability Analysis, Scala, Security, Fuzzing, Concolic Testing},
location = {Virtual, USA},
series = {SCALA 2020}
}

@inproceedings{10.1109/ASE.2019.00109,
author = {Escobar-Velasquez, Camilo and Osorio-Ria\~{n}o, Michael and Linares-V\'{a}squez, Mario},
title = {MutAPK: Source-Codeless Mutant Generation for Android Apps},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00109},
doi = {10.1109/ASE.2019.00109},
abstract = {The amount of Android application is having a tremendous increasing trend, exerting pressure over practitioners and researchers around application quality, frequent releases, and quick fixing of bugs. This pressure leads practitioners to make usage of automated approaches based on using source-code as input. Nevertheless, third-party services are not able to use these approaches due to privacy factors. In this paper we present MutAPK, an open source mutation testing tool that enables the usage of Android Application Packages (APKs) as input for this task. MutAPK generates mutants without the need of having access to source code, because the mutations are done in an intermediate representation of the code (i.e., SMALI) that does not require compilation. MutAPK is publicly available at GitHub: https://bit.ly/2KYvgP9 VIDEO: https://bit.ly/2WOjiyy},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1090–1093},
numpages = {4},
keywords = {closed-source apps, mutation testing, Android},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3170427.3188467,
author = {Cheng, Jinghui and Guo, Jin L.C.},
title = {How Do the Open Source Communities Address Usability and UX Issues? An Exploratory Study},
year = {2018},
isbn = {9781450356213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170427.3188467},
doi = {10.1145/3170427.3188467},
abstract = {Usability and user experience (UX) issues are often not well emphasized and addressed in open source software (OSS) development. There is an imperative need for supporting OSS communities to collaboratively identify, understand, and fix UX design issues in a distributed environment. In this paper, we provide an initial step towards this effort and report on an exploratory study that investigated how the OSS communities currently reported, discussed, negotiated, and eventually addressed usability and UX issues. We conducted in-depth qualitative analysis of selected issue tracking threads from three OSS projects hosted on GitHub. Our findings indicated that discussions about usability and UX issues in OSS communities were largely influenced by the personal opinions and experiences of the participants. Moreover, the characteristics of the community may have greatly affected the focus of such discussion.},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {open source community, user experience, open source software development, usability, issue tracking},
location = {Montreal QC, Canada},
series = {CHI EA '18}
}

@inproceedings{10.1145/3377811.3380395,
author = {Humbatova, Nargiz and Jahangirova, Gunel and Bavota, Gabriele and Riccio, Vincenzo and Stocco, Andrea and Tonella, Paolo},
title = {Taxonomy of Real Faults in Deep Learning Systems},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380395},
doi = {10.1145/3377811.3380395},
abstract = {The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance. In this paper we introduce a large taxonomy of faults in deep learning (DL) systems. We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our taxonomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1110–1121},
numpages = {12},
keywords = {deep learning, software testing, taxonomy, real faults},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3077286.3077320,
author = {Darwish, Ali and Nakhmani, Arie},
title = {Internal Covariate Shift Reduction in Encoder-Decoder Convolutional Neural Networks},
year = {2017},
isbn = {9781450350242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077286.3077320},
doi = {10.1145/3077286.3077320},
abstract = {Internal covariant shift in deep neural networks affects the learning and convergence speed in ConvNets. Batch normalization was recently proposed to reduce the distribution of each layer's input to accelerate the training process. It also reduces overfitting and eliminates the need for using dropout in the fully connected layers, or RELU activation. Batch normalization, in its essence, seeks stable distribution of activation values throughout training, and normalizes the inputs of nonlinear data. In order to determine the usefulness of batch normalization in neural networks that don't use fully connected layers we evaluated the performance of an encoder-decoder ConvNet with and without using batch normalization. We found that batch normalization increased the learning performance by 18% but also increased the training time in each epoch (iteration) by 26%. The code for this work and the datasets are provided in a github repository.},
booktitle = {Proceedings of the SouthEast Conference},
pages = {179–182},
numpages = {4},
location = {Kennesaw, GA, USA},
series = {ACM SE '17}
}

@inproceedings{10.1145/3411502.3418429,
author = {Li, Kaiyuan and Woo, Maverick and Jia, Limin},
title = {On the Generation of Disassembly Ground Truth and the Evaluation of Disassemblers},
year = {2020},
isbn = {9781450380898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411502.3418429},
doi = {10.1145/3411502.3418429},
abstract = {When a software transformation or software security task needs to analyze a given program binary, the first step is often disassembly. Since many modern disassemblers have become highly accurate on many binaries, we believe reliable disassembler benchmarking requires standardizing the set of binaries used and the disassembly ground truth about these binaries. This paper presents (i) a first version of our work-in-progress disassembly benchmark suite, which comprises $879$ binaries from diverse projects compiled with multiple compilers and optimization settings, and (ii) a novel disassembly ground truth generator leveraging the notion of "listing files'', which has broad support by clang, gcc, icc, and msvc. In additional, it presents our evaluation of four prominent open-source disassemblers using this benchmark suite and a custom evaluation system. Our entire system and all generated data are maintained openly on GitHub to encourage community adoption.},
booktitle = {Proceedings of the 2020 ACM Workshop on Forming an Ecosystem Around Software Transformation},
pages = {9–14},
numpages = {6},
keywords = {ground-truth generation, disassembly, benchmark suite},
location = {Virtual Event, USA},
series = {FEAST'20}
}

@inproceedings{10.1145/3368089.3418541,
author = {Wang, Zhendong},
title = {Assisting the Elite-Driven Open Source Development through Activity Data},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3418541},
doi = {10.1145/3368089.3418541},
abstract = {Elite developers, who own the administrative privileges for a project, maintain a diverse profile of contributing activities, and drive the development of open source software (OSS). To advance our understanding and further support the OSS community, I present a fresh approach to investigate developers’ public activities from the fine-grained event data provided by GitHub. Further, I develop this approach into an analysis framework for collecting, modeling, and analyzing elite developers’ online contributing activities. Employing this framework, I have conducted empirical studies on various OSS projects and ecosystems to characterize elite developers’ full-spectrum activities and their dynamics, and also unveil relationships between their effort allocation and projects’ technical outcomes. Finally, I propose to design and implement a toolset based on this framework and my results to date, which supports individual developers’ decision-making and assists their routine workflows with automation.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1670–1673},
numpages = {4},
keywords = {open source software, project outcomes, Elite developers},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1007/978-3-030-31901-4_2,
author = {Kao, Po-Yu and Zhang, Angela and Goebel, Michael and Chen, Jefferson W. and Manjunath, B. S.},
title = {Predicting Fluid Intelligence of Children Using T1-Weighted MR Images and a StackNet},
isbn = {978-3-030-31900-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31901-4_2},
doi = {10.1007/978-3-030-31901-4_2},
abstract = {In this work, we utilize T1-weighted MR images and StackNet to predict fluid intelligence in adolescents. Our framework includes feature extraction, feature normalization, feature denoising, feature selection, training a StackNet, and predicting fluid intelligence. The extracted feature is the distribution of different brain tissues in different brain parcellation regions. The proposed StackNet consists of three layers and 11 models. Each layer uses the predictions from all previous layers including the input layer. The proposed StackNet is tested on a public benchmark Adolescent Brain Cognitive Development Neurocognitive Prediction Challenge 2019 and achieves a mean squared error of 82.42 on the combined training and validation set with 10-fold cross-validation. The proposed StackNet achieves a mean squared error of 94.25 on the testing data. The source code is available on GitHub ().},
booktitle = {Adolescent Brain Cognitive Development Neurocognitive Prediction},
pages = {9–16},
numpages = {8},
keywords = {StackNet, Fluid intelligence (Gf), Machine learning, T1-weighted MRI}
}

@inproceedings{10.1145/3211346.3211353,
author = {Sachdev, Saksham and Li, Hongyu and Luan, Sifei and Kim, Seohyun and Sen, Koushik and Chandra, Satish},
title = {Retrieval on Source Code: A Neural Code Search},
year = {2018},
isbn = {9781450358347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3211346.3211353},
doi = {10.1145/3211346.3211353},
abstract = {Searching over large code corpora can be a powerful productivity tool for both beginner and experienced developers because it helps them quickly find examples of code related to their intent. Code search becomes even more attractive if developers could express their intent in natural language, similar to the interaction that Stack Overflow supports. In this paper, we investigate the use of natural language processing and information retrieval techniques to carry out natural language search directly over source code, i.e. without having a curated Q&amp;A forum such as Stack Overflow at hand. Our experiments using a benchmark suite derived from Stack Overflow and GitHub repositories show promising results. We find that while a basic word–embedding based search procedure works acceptably, better results can be obtained by adding a layer of supervision, as well as by a customized ranking strategy.},
booktitle = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
pages = {31–41},
numpages = {11},
keywords = {TF-IDF, word-embedding, code search},
location = {Philadelphia, PA, USA},
series = {MAPL 2018}
}

@inproceedings{10.1145/2876034.2893422,
author = {Martin, Taylor and Brasiel, Sarah and Jeong, Soojeong and Close, Kevin and Lawanto, Kevin and Janisciewcz, Phil},
title = {Macro Data for Micro Learning: Developing the FUN! Tool for Automated Assessment of Learning},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2893422},
doi = {10.1145/2876034.2893422},
abstract = {Digital learning environments are becoming more common for students to engage in during and outside of school. With the immense amount of data now available from these environments, researchers need tools to process, manage, and analyze the data. Current methods used by many education researchers are inefficient; however, without data science experience tools used in other professions are not accessible. In this paper, we share about a tool we created called the Functional Understanding Navigator! (FUN! Tool). We have used this tool for different research projects which has allowed us the opportunity to (1) organize our workflow process from start to finish, (2) record log data of all of our analyses, and (3) provide a platform to share our analyses with others through GitHub. This paper extends and improves existing work in educational data mining and learning analytics.},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {233–236},
numpages = {4},
keywords = {digital learning environments, educational data mining, micro learning, assessment},
location = {Edinburgh, Scotland, UK},
series = {L@S '16}
}

@inproceedings{10.5555/2820690.2820696,
author = {Bass, Len and Holz, Ralph and Rimba, Paul and Tran, An Binh and Zhu, Liming},
title = {Securing a Deployment Pipeline},
year = {2015},
publisher = {IEEE Press},
abstract = {At the RELENG 2014 Q&amp;A, the question was asked, "What is your greatest concern?" and the response was "someone subverting our deployment pipeline". That is the motivation for this paper. We explore what it means to subvert a pipeline and provide several different scenarios of subversion. We then focus on the issue of securing a pipeline. As a result, we provide an engineering process that is based on having trusted components mediate access to sensitive portions of the pipeline from other components, which can remain untrusted. Applying our process to a pipeline we constructed involving Chef, Jenkins, Docker, Github, and AWS, we find that some aspects of our process result in easy to make changes to the pipeline, whereas others are more difficult. Consequently, we have developed a design that hardens the pipeline, although it does not yet completely secure it.},
booktitle = {Proceedings of the Third International Workshop on Release Engineering},
pages = {4–7},
numpages = {4},
keywords = {DevOps, continuous deployment, supply chain},
location = {Florence, Italy},
series = {RELENG '15}
}

